{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "toc": "true"
   },
   "source": [
    "# Table of Contents\n",
    " <p><div class=\"lev1 toc-item\"><a href=\"#Classificação-de-Textos\" data-toc-modified-id=\"Classificação-de-Textos-1\"><span class=\"toc-item-num\">1&nbsp;&nbsp;</span>Classificação de Textos</a></div><div class=\"lev2 toc-item\"><a href=\"#Preâmbulo\" data-toc-modified-id=\"Preâmbulo-11\"><span class=\"toc-item-num\">1.1&nbsp;&nbsp;</span>Preâmbulo</a></div><div class=\"lev2 toc-item\"><a href=\"#O-Dataset\" data-toc-modified-id=\"O-Dataset-12\"><span class=\"toc-item-num\">1.2&nbsp;&nbsp;</span>O Dataset</a></div><div class=\"lev3 toc-item\"><a href=\"#Lendo-do-disco\" data-toc-modified-id=\"Lendo-do-disco-121\"><span class=\"toc-item-num\">1.2.1&nbsp;&nbsp;</span>Lendo do disco</a></div><div class=\"lev2 toc-item\"><a href=\"#A-Rede-Neural\" data-toc-modified-id=\"A-Rede-Neural-13\"><span class=\"toc-item-num\">1.3&nbsp;&nbsp;</span>A Rede Neural</a></div><div class=\"lev3 toc-item\"><a href=\"#Preparando-a-matriz-de-embeddings\" data-toc-modified-id=\"Preparando-a-matriz-de-embeddings-131\"><span class=\"toc-item-num\">1.3.1&nbsp;&nbsp;</span>Preparando a matriz de embeddings</a></div><div class=\"lev3 toc-item\"><a href=\"#Construindo-a-rede\" data-toc-modified-id=\"Construindo-a-rede-132\"><span class=\"toc-item-num\">1.3.2&nbsp;&nbsp;</span>Construindo a rede</a></div><div class=\"lev2 toc-item\"><a href=\"#Treinando\" data-toc-modified-id=\"Treinando-14\"><span class=\"toc-item-num\">1.4&nbsp;&nbsp;</span>Treinando</a></div><div class=\"lev2 toc-item\"><a href=\"#Avaliando\" data-toc-modified-id=\"Avaliando-15\"><span class=\"toc-item-num\">1.5&nbsp;&nbsp;</span>Avaliando</a></div>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Classificação de Textos"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Preâmbulo"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2017-10-27T11:21:05.165606Z",
     "start_time": "2017-10-27T11:21:05.154197Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "GPU available: True\n"
     ]
    }
   ],
   "source": [
    "%matplotlib inline\n",
    "import matplotlib.pyplot as plt\n",
    "import os,sys\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import numpy.random as nr\n",
    "\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "from torch.optim.lr_scheduler import MultiStepLR, StepLR\n",
    "from torch.utils.data import DataLoader, TensorDataset\n",
    "from torch.autograd import Variable\n",
    "\n",
    "from torchvision import datasets, transforms, models\n",
    "\n",
    "import lib.pytorch_trainer as ptt\n",
    "\n",
    "use_gpu = torch.cuda.is_available()\n",
    "print('GPU available:', use_gpu)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## O Dataset"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Lendo do disco"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2017-10-27T11:21:05.227138Z",
     "start_time": "2017-10-27T11:21:05.167125Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Vocabulary: 20000 words\n",
      "Training dataset: (20553, 50) (20553,)\n",
      "Validation dataset: (5139, 50) (5139,)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "(dtype('int64'), dtype('int64'))"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dd = np.load('/data/datasets/livros/livros_sequences_50.npz')\n",
    "Xtra, ytra = dd['Xtra'], dd['ytra']\n",
    "Xval, yval = dd['Xval'], dd['yval']\n",
    "i2w = dd['i2w']\n",
    "\n",
    "num_words = len(i2w)\n",
    "seq_size = Xtra.shape[1]\n",
    "n_labels = max(ytra) + 1\n",
    "embedding_dim = 300\n",
    "\n",
    "Xtra, ytra = Xtra.astype(np.int), ytra.astype(np.int)\n",
    "Xval, yval = Xval.astype(np.int), yval.astype(np.int)\n",
    "\n",
    "print('Vocabulary: {} words'.format(len(i2w)))\n",
    "print('Training dataset:', Xtra.shape, ytra.shape)\n",
    "print('Validation dataset:', Xval.shape, yval.shape)\n",
    "\n",
    "Xtra.dtype, ytra.dtype\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## A Rede Neural"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Preparando a matriz de embeddings\n",
    "\n",
    "Neste notebook o embedding é treinado a partir de pesos aleatórios.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2017-10-27T11:21:05.623320Z",
     "start_time": "2017-10-27T11:21:05.228816Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(torch.Size([5, 50, 300]), torch.Size([5, 50]))"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "xx = Variable(torch.from_numpy(Xtra[:5].astype(int)))\n",
    "\n",
    "emb = nn.Embedding(num_words, embedding_dim)\n",
    "a = emb(xx)\n",
    "a.data.shape, xx.data.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Construindo a rede"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2017-10-27T11:21:05.661962Z",
     "start_time": "2017-10-27T11:21:05.625152Z"
    },
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "\n",
    "class MyNet(nn.Module):\n",
    "    \n",
    "    def __init__(self, seq_len=seq_size, voc_size=num_words, embed_dim=embedding_dim, \n",
    "                 n_conv_filters=128, conv_kernel_size=5):\n",
    "        super().__init__()\n",
    "        \n",
    "        k = conv_kernel_size - 1\n",
    "        n = (((seq_len - k) // 2 - k) // 2 - k) // 2\n",
    "        self.flat_size = n * n_conv_filters\n",
    "        \n",
    "        self.emb = nn.Embedding(voc_size, embed_dim)\n",
    "        nn.init.xavier_uniform(self.emb.weight)\n",
    "\n",
    "        self.conv1 = nn.Conv1d(embed_dim, n_conv_filters, conv_kernel_size)\n",
    "        self.conv2 = nn.Conv1d(n_conv_filters, n_conv_filters, conv_kernel_size)\n",
    "        self.conv3 = nn.Conv1d(n_conv_filters, n_conv_filters, conv_kernel_size)\n",
    "        \n",
    "        self.fc1 = nn.Linear(self.flat_size, 128)\n",
    "        self.fc2 = nn.Linear(128, 3)\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = self.emb(x)\n",
    "        \n",
    "        x = x.transpose(1, 2)\n",
    "        \n",
    "        x = F.relu(self.conv1(x))\n",
    "        x = F.max_pool1d(x, 2)\n",
    "        x = F.dropout(x, 0.5)\n",
    "    \n",
    "        x = F.relu(self.conv2(x))\n",
    "        x = F.max_pool1d(x, 2)\n",
    "\n",
    "        x = F.relu(self.conv3(x))\n",
    "        x = F.max_pool1d(x, 2)\n",
    "        x = F.dropout(x, 0.5)\n",
    "        \n",
    "        x = x.view(-1, self.flat_size)\n",
    "        \n",
    "        x = F.relu(self.fc1(x))\n",
    "        x = F.dropout(x, 0.5)\n",
    "        \n",
    "        x = self.fc2(x)\n",
    "        \n",
    "        return x\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Treinando"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2017-10-27T11:21:06.110973Z",
     "start_time": "2017-10-27T11:21:05.663481Z"
    },
    "collapsed": true,
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "trainIt = True\n",
    "resetIt = True\n",
    "\n",
    "# Callbacks\n",
    "# ---------\n",
    "accuracy_cb = ptt.AccuracyMetric()\n",
    "chkpt_cb = ptt.ModelCheckpoint('../../models/livros_classif_50_1', reset=resetIt, verbose=1)\n",
    "print_cb = ptt.PrintCallback()\n",
    "plot_cb = ptt.PlotCallback()\n",
    "\n",
    "# Model, optimizer and learning rate scheduler\n",
    "# --------------------------------------------\n",
    "model = MyNet()\n",
    "optimizer = torch.optim.Adam(model.parameters(), lr=5e-4)\n",
    "scheduler = StepLR(optimizer, step_size=5, gamma=0.75)\n",
    "\n",
    "# Network trainer\n",
    "# ---------------\n",
    "training_parameters = {\n",
    "    'model':         model, \n",
    "    'criterion':     nn.CrossEntropyLoss(),\n",
    "    'optimizer':     optimizer, \n",
    "    'lr_scheduler':  scheduler, \n",
    "    'callbacks':     [accuracy_cb, print_cb],\n",
    "}\n",
    "trainer = ptt.DeepNetTrainer(**training_parameters)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2017-10-27T11:22:33.097404Z",
     "start_time": "2017-10-27T11:21:06.112625Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Start training for 10 epochs\n",
      "  1:  17.9s   T: 0.36057 0.82966   V: 0.14837 0.94882 best\n",
      "  2:  17.9s   T: 0.06131 0.98010   V: 0.15311 0.94746 \n",
      "  3:  17.9s   T: 0.02229 0.99275   V: 0.18231 0.95077 \n",
      "  4:  18.0s   T: 0.01449 0.99557   V: 0.20554 0.94785 \n",
      "Stop training at epoch: 4/10\n"
     ]
    }
   ],
   "source": [
    "if trainIt:\n",
    "    Xtrain = torch.from_numpy(Xtra)\n",
    "    ytrain = torch.from_numpy(ytra)\n",
    "    Xvalid = torch.from_numpy(Xval)\n",
    "    yvalid = torch.from_numpy(yval)\n",
    "    \n",
    "    trainer.fit(10, Xtrain, ytrain, valid_data=(Xvalid, yvalid))\n",
    "else:\n",
    "    print('\\nTraining disabled.\\nThis model was trained for {} epochs.'.format(trainer.last_epoch))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Avaliando"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2017-10-27T11:22:38.177446Z",
     "start_time": "2017-10-27T11:22:33.099083Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "evaluate: 2055/2055 ok\n",
      "Model training set accuracy after training: 0.99504\n",
      "\n",
      "evaluate: 513/513 ok\n",
      "Model validation set accuracy after training: 0.93676\n"
     ]
    }
   ],
   "source": [
    "rmetrics = trainer.evaluate(Xtrain, ytrain, metrics=[accuracy_cb])\n",
    "print('Model training set accuracy after training: {:.5f}'.format(rmetrics['acc']))\n",
    "print()\n",
    "rmetrics = trainer.evaluate(Xvalid, yvalid, metrics=[accuracy_cb])\n",
    "print('Model validation set accuracy after training: {:.5f}'.format(rmetrics['acc']))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2017-10-25T17:37:28.741974Z",
     "start_time": "2017-10-25T17:37:28.737638Z"
    },
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.1"
  },
  "latex_envs": {
   "LaTeX_envs_menu_present": true,
   "autocomplete": true,
   "bibliofile": "biblio.bib",
   "cite_by": "apalike",
   "current_citInitial": 1,
   "eqLabelWithNumbers": true,
   "eqNumInitial": 1,
   "hotkeys": {
    "equation": "Ctrl-E",
    "itemize": "Ctrl-I"
   },
   "labels_anchors": false,
   "latex_user_defs": false,
   "report_style_numbering": false,
   "user_envs_cfg": false
  },
  "toc": {
   "colors": {
    "hover_highlight": "#DAA520",
    "navigate_num": "#000000",
    "navigate_text": "#333333",
    "running_highlight": "#FF0000",
    "selected_highlight": "#FFD700",
    "sidebar_border": "#EEEEEE",
    "wrapper_background": "#FFFFFF"
   },
   "moveMenuLeft": true,
   "nav_menu": {
    "height": "264px",
    "width": "252px"
   },
   "navigate_menu": true,
   "number_sections": true,
   "sideBar": true,
   "threshold": 4,
   "toc_cell": true,
   "toc_section_display": "block",
   "toc_window_display": false,
   "widenNotebook": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
