{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Seleção dos hyperparâmetros "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2017-10-25T14:42:06.358993",
     "start_time": "2017-10-25T14:42:06.342896"
    }
   },
   "source": [
    "Hyperparâmetros são os parâmetros que não são aprendidos no processo de treinamento da rede neural. São parâmetros tanto do modelo, como número e tipo de camadas, \n",
    "número de neurônios ou canais em cada camada, como parâmetros do processo de otimização, tais como tipo do otimizador, taxa de aprendizado (learning rate), tamanho\n",
    "do mini-batch, entre outros.\n",
    "\n",
    "Uma opção é disparar um processo automático de busca no espaço de hyperparâmetros para buscar o melhor índice de validação cruzada. \n",
    "\n",
    "Normalmente a busca neste espaço de hyperparâmetros consiste de:\n",
    "- o modelo da rede;\n",
    "- o espaço de hyperparâmetros;\n",
    "- o método de busca e amostragem neste espaço;\n",
    "- o esquema de validação cruzada; e\n",
    "- uma função alvo (*score function*)\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2017-10-25T14:47:19.785475",
     "start_time": "2017-10-25T14:47:19.781571"
    }
   },
   "source": [
    "<img src='../figures/model_selection.png', width=600></img>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Validação cruzada"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2017-10-25T14:43:06.568757",
     "start_time": "2017-10-25T14:43:06.564456"
    }
   },
   "source": [
    "<img src='../figures/cross_validation.png', width=600></img>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Objetivos desse experimento"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Neste experimento apresentamos implementações simplificadas de dois métodos populares de busca de hiperparâmetros, a busca em grade e a busca randomizada.\n",
    "\n",
    "Este experimento utiliza:\n",
    "- **modelo da rede:** fixa - Fully connected, já usada anteriormente\n",
    "\n",
    "- **espaço de hiperparâmetros:** variando learning rate e weight decay\n",
    "\n",
    "- **métodos de busca:** \n",
    "\n",
    "  - RandomizedSearch, onde o número de iterações é especificado\n",
    "  - GridSearch, onde o número de iterações é dado pelas combinações de valores dos parâmetros\n",
    "\n",
    "- **validação cruzada:** n. de folds especificado\n",
    "\n",
    "- **função alvo:** mse loss"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Importação dos pacotes tradicionais"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-02-20T23:07:01.608733Z",
     "start_time": "2018-02-20T23:07:00.385288Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "GPU available: True\n"
     ]
    }
   ],
   "source": [
    "%matplotlib inline\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "import os, sys\n",
    "import time\n",
    "import numpy as np\n",
    "import itertools\n",
    "\n",
    "import scipy.stats as st\n",
    "import numpy.random as nr\n",
    "\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "from torch.utils.data import DataLoader, TensorDataset\n",
    "\n",
    "import torchvision as tv\n",
    "import lib.pytorch_trainer as ptt\n",
    "\n",
    "use_gpu = torch.cuda.is_available()\n",
    "print('GPU available:', use_gpu)\n",
    "\n",
    "np.set_printoptions(precision=3)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Carregamento dos dados - Boston Housing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-02-20T23:07:01.627968Z",
     "start_time": "2018-02-20T23:07:01.611787Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Número de amostras no dataset (treino): 506\n"
     ]
    }
   ],
   "source": [
    "datain = np.load('../data/boston_housing_normalize.npz')\n",
    "\n",
    "x, y = datain['Xtra'], datain['ytra']\n",
    "\n",
    "n_samples, n_attributes = x.shape\n",
    "\n",
    "x_train = torch.FloatTensor(x)\n",
    "y_train = torch.FloatTensor(y)\n",
    "\n",
    "train_ds = TensorDataset(x_train, y_train)\n",
    "print('Número de amostras no dataset (treino):', len(train_ds))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Sampler"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-02-20T23:07:01.675816Z",
     "start_time": "2018-02-20T23:07:01.630788Z"
    },
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from torch.utils.data.sampler import Sampler\n",
    "\n",
    "class MySampler(Sampler):\n",
    "    \"\"\" Esta é uma classe auxiliar que auxilia no processo de obtenção de amostras\n",
    "    de um dataset. Trabalha com os índices de um subconjunto dessas amostras para\n",
    "    a implementação da valiação cruzada. Um objeto dessa classe é passado ao construtor \n",
    "    do dataloader.\n",
    "    \"\"\"\n",
    "    def __init__(self, indexes):\n",
    "        self.indexes = indexes\n",
    "\n",
    "    def __iter__(self):\n",
    "        return iter(self.indexes[torch.randperm(len(self.indexes)).long()])\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.indexes)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Definição da rede neural"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-02-20T23:07:01.730043Z",
     "start_time": "2018-02-20T23:07:01.678477Z"
    },
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "class Model(nn.Module):\n",
    "    def __init__(self, n_attributes=n_attributes):\n",
    "        super(Model, self).__init__()\n",
    "        self.layer1 = nn.Linear(n_attributes, 64)\n",
    "        self.ativ1  = nn.SELU()\n",
    "        self.layer2 = nn.Linear(64, 64)\n",
    "        self.ativ2  = nn.SELU()\n",
    "        self.layer3 = nn.Linear(64, 64)\n",
    "        self.ativ3  = nn.SELU()\n",
    "        self.layer4 = nn.Linear(64, 1)\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = self.layer1(x)\n",
    "        x = self.ativ1(x)\n",
    "        x = nn.functional.dropout(x)\n",
    "        x = self.layer2(x)\n",
    "        x = self.ativ2(x)\n",
    "        x = nn.functional.dropout(x)\n",
    "        x = self.layer3(x)\n",
    "        x = self.ativ3(x)\n",
    "        x = nn.functional.dropout(x)\n",
    "        x = self.layer4(x)\n",
    "        return x\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Implementação das classes de busca"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Funcionalidade básica"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-02-20T23:07:02.168103Z",
     "start_time": "2018-02-20T23:07:01.733018Z"
    }
   },
   "outputs": [],
   "source": [
    "class MyBaseSearch(object):\n",
    "    \"\"\" Classe base para a busca aleatória e em grade\n",
    "    \"\"\"\n",
    "    def __init__(self, params, num_splits):\n",
    "        if params['model_class'] is None:\n",
    "            raise Exception('')\n",
    "        self.parameters = params\n",
    "        self.n_splits = num_splits\n",
    "        \n",
    "    def do_cross_validation(self, p, dataset, verbose):\n",
    "        \"\"\" Implementa a valiação cruzada. Retorna os scores de valiação para \n",
    "        cada treinamento realizado.\n",
    "        \"\"\"\n",
    "        split_scores = []\n",
    "        for train_dloader, valid_dloader in self.gen_data_loaders(dataset, \n",
    "                                                                  self.n_splits, \n",
    "                                                                  p['batch_size']):\n",
    "            tt = time.time()\n",
    "            trainer = self.make_trainer(p, verbose=verbose)\n",
    "            trainer.fit_loader(p['num_epochs'], train_dloader, valid_dloader)\n",
    "            trainer.load_state(self.state_fn)\n",
    "            score = trainer.metrics['valid']['losses'][-1]\n",
    "            # metrics = trainer.evaluate_loader(valid_dloader, verbose=0)\n",
    "            # score = metrics['losses']\n",
    "            split_scores.append(score)\n",
    "            print('{: 3.5f}'.format(score), end=' ')\n",
    "        return split_scores\n",
    "            \n",
    "    @staticmethod\n",
    "    def gen_data_loaders(dataset, n_splits, batch_size):\n",
    "        \"\"\" Gerador que divide o dataset e retorna os dataloaders para cada \n",
    "        split de validação.\n",
    "        \"\"\"\n",
    "        n_total = len(dataset)\n",
    "        split_size = n_total // n_splits\n",
    "        indices = torch.arange(n_total)\n",
    "        split = torch.LongTensor([n_splits - 1 for _ in indices])\n",
    "        split[:n_splits * split_size] = torch.arange(n_splits * split_size).long() / split_size\n",
    "        for i in range(n_splits):\n",
    "            vii = indices[split == i].long()\n",
    "            tii = indices[split != i].long()\n",
    "            train_dloader = DataLoader(dataset, batch_size=batch_size, sampler=MySampler(tii))\n",
    "            valid_dloader = DataLoader(dataset, batch_size=batch_size, sampler=MySampler(vii))\n",
    "            yield train_dloader, valid_dloader\n",
    "    \n",
    "    def make_trainer(self, p, verbose):\n",
    "        \"\"\" Constroi um treinador com os parâmetros especificados no dicionário 'p'.\n",
    "        \"\"\"\n",
    "        callbacks = [ptt.ModelCheckpoint(self.state_fn, reset=True, verbose=0)]\n",
    "        if verbose > 0:\n",
    "            callbacks += [ptt.PrintCallback()]\n",
    "        self.model = p['model_class']()\n",
    "        loss_fn = self.make_criterion(p)\n",
    "        optimizer = self.make_optimizer(p)\n",
    "        trainer = ptt.DeepNetTrainer(model=self.model, criterion=loss_fn, \n",
    "                                     optimizer=optimizer, callbacks=callbacks)\n",
    "        return trainer\n",
    "        \n",
    "    def make_optimizer(self, p):\n",
    "        \"\"\" Constroi um otimizador com base nos parâmetros 'p'.\n",
    "        \"\"\"\n",
    "        if p['optim_class'] == 'Adam':\n",
    "            optimz = optim.Adam(self.model.parameters(), lr=p['optim_lr'], \n",
    "                                weight_decay=p['optim_weight_decay'])\n",
    "        elif p['optim_class'] == 'SGD':\n",
    "            optimz = optim.SGD(self.model.parameters(), lr=p['optim_lr'], \n",
    "                               momentum=p['optim_momentum'], \n",
    "                               weight_decay=p['optim_weight_decay'], nesterov=True)\n",
    "        elif p['optim_class'] == 'RMSprop':\n",
    "            optimz = optim.RMSprop(self.model.parameters(), lr=p['optim_lr'], alpha=p['optim_alpha'],\n",
    "                                   weight_decay=p['optim_weight_decay'])\n",
    "        else:\n",
    "            raise Exception(\"A ser implementado...\")\n",
    "        return optimz\n",
    "    \n",
    "    def make_criterion(self, p):\n",
    "        \"\"\" Constroi uma função de custo com base nos parâmetros 'p'.\n",
    "        \"\"\"\n",
    "        if p['loss_class'] == 'CrossEntropyLoss':\n",
    "            loss_fn = nn.CrossEntropyLoss()\n",
    "        elif p['loss_class'] == 'MSELoss':\n",
    "            loss_fn = nn.MSELoss()\n",
    "        else:\n",
    "            raise Exception(\"A ser implementado...\")\n",
    "        return loss_fn\n",
    "    \n",
    "    def show_results(self):\n",
    "        self.mean_scores = torch.FloatTensor(self.scores).mean(1)\n",
    "        self.best_loss, self.best_index = [x[0] for x in self.mean_scores.min(0)]\n",
    "        self.best_trainer = self.make_trainer(self.parameter_sets[self.best_index], verbose=0)\n",
    "        print('\\nBest parameter set from iteraction {} with loss = {:.5f}:'.format(self.best_index, self.best_loss))\n",
    "        for p, v in self.parameter_sets[self.best_index].items():\n",
    "            print('    {:20s}: {}'.format(p, v))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Randomized Search"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-02-20T23:07:02.262312Z",
     "start_time": "2018-02-20T23:07:02.170759Z"
    },
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# param_distributions = {\n",
    "#     'model_class':        None,\n",
    "#     'loss_class':         ['MSELoss'],\n",
    "#     'optim_class':        ['RMSprop'],\n",
    "#     'optim_lr':           st.uniform(0.0005, 0.0015),     # range: 0.0005-0.002\n",
    "#     'optim_weight_decay': st.uniform(0.001, 0.009),       # 0.001-0.01\n",
    "#     'optim_alpha':        st.uniform(0.7, 0.29),          # 0.7-0.99\n",
    "#     'batch_size':         [30],\n",
    "#     'num_epochs':         [100],\n",
    "# }\n",
    "\n",
    "class MyRandomizedSearch(MyBaseSearch):\n",
    "    \"\"\" Classe que implementa a busca randômica.\n",
    "    \"\"\"\n",
    "    def __init__(self, params, num_splits=3, num_iter=10):\n",
    "        super().__init__(params, num_splits)\n",
    "        self.n_iteractions = num_iter\n",
    "        self.state_fn = '/data/models/model_selection_random'\n",
    "        \n",
    "    def fit(self, dataset, verbose=False):\n",
    "        \"\"\" Para cada iteração, amostra o espaço de parâmetros e executa uma\n",
    "        validação cruzada.\n",
    "        \"\"\"\n",
    "        self.parameter_sets = []\n",
    "        self.scores = []\n",
    "        for it in range(self.n_iteractions):\n",
    "            print('Iteraction {:2d}:'.format(it), end=' ')\n",
    "            t0 = time.time()\n",
    "            p = self.sample_parameter_space()\n",
    "            self.parameter_sets.append(p)\n",
    "            \n",
    "            split_scores = self.do_cross_validation(p, dataset, verbose)\n",
    "            self.scores.append(split_scores)\n",
    "            print('[{:.1f} s]'.format(time.time() - t0))\n",
    "        self.show_results()\n",
    "            \n",
    "    def sample_parameter_space(self):\n",
    "        \"\"\" Amostra cada parâmetro em 'self.parameters'. A especificação do \n",
    "        espaço é feita através de valores discretos em uma lista (que serão\n",
    "        sorteados) ou de uma distribuição contínua (objeto do scipy.stats \n",
    "        com um método 'rvs') que será amostrada.\n",
    "        \"\"\"\n",
    "        pars = dict()\n",
    "        for p, v in self.parameters.items():\n",
    "            if type(v) == list:\n",
    "                pars[p] = v[0] if len(v) == 1 else v[nr.randint(0, len(v))]\n",
    "            elif getattr(v, 'rvs', None) is not None:\n",
    "                pars[p] = v.rvs()\n",
    "            else:\n",
    "                raise Exception('Unknown par dist type')\n",
    "        return pars\n",
    "    \n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Grid Search"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-02-20T23:07:02.308877Z",
     "start_time": "2018-02-20T23:07:02.265239Z"
    },
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# param_distributions = {\n",
    "#     'model_class':        None,\n",
    "#     'loss_class':         ['MSELoss'],\n",
    "#     'optim_class':        ['RMSprop'],\n",
    "#     'optim_lr':           [0.0005, 0.001, 0.002],\n",
    "#     'optim_weight_decay': [0.001, 0.005, 0.01],\n",
    "#     'optim_alpha':        [0.7, 0.99],\n",
    "#     'batch_size':         [30],\n",
    "#     'num_epochs':         [100],\n",
    "# }\n",
    "\n",
    "class MyGridSearch(MyBaseSearch):\n",
    "    def __init__(self, params, num_splits=3):\n",
    "        super().__init__(params, num_splits)\n",
    "        self.state_fn = '/data/models/model_selection_grid'\n",
    "\n",
    "    def fit(self, dataset, verbose=False):\n",
    "        \"\"\" Avalia o desempenho para cada combinação de parâmetros. Usa 'itertools.product' \n",
    "        para obter o produto cartesiano entre as listas especificadas em 'self.parameters'.\n",
    "        Nota: 'itertools.product(A, B)' retorna o mesmo que '((x, y) for x in A for y in B)'.\n",
    "        \"\"\"\n",
    "        self.parameter_sets = []\n",
    "        self.scores = []\n",
    "        keys = self.parameters.keys()\n",
    "        for it, x in enumerate(itertools.product(*params.values())):\n",
    "            print('Iteraction {:2d}:'.format(it), end=' ')\n",
    "            t0 = time.time()\n",
    "            p = dict(zip(keys, x))\n",
    "            self.parameter_sets.append(p)\n",
    "            \n",
    "            split_scores = self.do_cross_validation(p, dataset, verbose)\n",
    "            self.scores.append(split_scores)\n",
    "            print('[{:.1f} s]'.format(time.time() - t0))        \n",
    "        self.show_results()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Random Searching"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-02-20T23:49:31.129476Z",
     "start_time": "2018-02-20T23:07:02.311355Z"
    },
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iteraction  0:  6.24696  18.56860  12.26453  47.52807  14.15301 [87.4 s]\n",
      "Iteraction  1:  5.31770  13.95588  14.40160  50.43629  13.08523 [83.2 s]\n",
      "Iteraction  2:  6.26278  20.23700  8.05917  52.62885  16.25098 [83.3 s]\n",
      "Iteraction  3:  6.33826  20.27767  11.93542  43.58981  13.51593 [83.3 s]\n",
      "Iteraction  4:  6.92073  19.04859  13.12680  44.50853  10.55239 [83.7 s]\n",
      "Iteraction  5:  6.03344  17.91357  12.44797  48.98238  13.31631 [83.4 s]\n",
      "Iteraction  6:  5.99609  13.97222  9.14008  48.35522  14.29169 [83.5 s]\n",
      "Iteraction  7:  6.06414  17.97815  13.82636  47.17277  11.67926 [83.7 s]\n",
      "Iteraction  8:  6.28640  19.82875  15.16874  45.19716  11.80703 [83.6 s]\n",
      "Iteraction  9:  6.15534  18.31290  11.44172  47.54664  10.79677 [83.6 s]\n",
      "Iteraction 10:  6.08410  12.36792  12.00369  51.14266  15.24391 [83.5 s]\n",
      "Iteraction 11:  6.68842  21.08453  13.86811  46.90276  12.33577 [83.4 s]\n",
      "Iteraction 12:  6.00180  12.18465  12.87174  48.67128  13.61852 [83.5 s]\n",
      "Iteraction 13:  6.82717  22.31982  11.34131  44.86667  11.12137 [83.8 s]\n",
      "Iteraction 14:  5.95586  14.28785  12.47790  44.11463  14.57011 [83.6 s]\n",
      "Iteraction 15:  6.17989  16.28274  13.90176  45.29924  13.55529 [83.5 s]\n",
      "Iteraction 16:  6.48803  17.81080  9.47965  49.19313  11.35951 [83.5 s]\n",
      "Iteraction 17:  6.29802  19.62738  9.28403  46.94448  10.83108 [83.6 s]\n",
      "Iteraction 18:  6.19063  21.54084  11.89365  46.45440  15.10245 [83.6 s]\n",
      "Iteraction 19:  5.45630  20.04508  8.30984  48.46872  15.03830 [83.5 s]\n",
      "Iteraction 20:  5.80601  19.05894  9.60357  44.14110  14.85592 [83.7 s]\n",
      "Iteraction 21:  5.96537  18.73548  17.78484  48.83487  11.30910 [83.7 s]\n",
      "Iteraction 22:  6.01276  17.58671  12.33144  46.26381  12.70287 [88.4 s]\n",
      "Iteraction 23:  7.03703  14.27746  17.85997  46.21418  12.34664 [88.9 s]\n",
      "Iteraction 24:  5.89715  15.36124  12.28330  43.65323  10.58442 [93.1 s]\n",
      "Iteraction 25:  5.80263  15.36657  13.44411  44.13149  13.90900 [87.5 s]\n",
      "Iteraction 26:  6.35467  19.47530  10.78889  45.03075  11.75427 [89.0 s]\n",
      "Iteraction 27:  5.32641  16.82863  9.65961  46.79668  11.89929 [89.3 s]\n",
      "Iteraction 28:  7.27315  18.05409  14.40370  48.72729  9.63959 [87.4 s]\n",
      "Iteraction 29:  5.92648  15.91096  12.31900  48.13802  16.95985 [83.7 s]\n",
      "\n",
      "Best parameter set from iteraction 24 with loss = 17.55587:\n",
      "    model_class         : <class '__main__.Model'>\n",
      "    loss_class          : MSELoss\n",
      "    optim_class         : RMSprop\n",
      "    optim_lr            : 0.0023395012290367253\n",
      "    optim_weight_decay  : 0.00886738770763571\n",
      "    optim_alpha         : 0.8952854475107642\n",
      "    batch_size          : 30\n",
      "    num_epochs          : 200\n"
     ]
    }
   ],
   "source": [
    "params = {\n",
    "    'model_class':        [Model],\n",
    "    'loss_class':         ['MSELoss'],\n",
    "    'optim_class':        ['RMSprop'],\n",
    "    'optim_lr':           st.uniform(0.001, 0.002),       # range: 0.001-0.003\n",
    "    'optim_weight_decay': st.uniform(0.0005, 0.0095),     # 0.0005-0.01\n",
    "    'optim_alpha':        st.uniform(0.7, 0.29),          # 0.7-0.99\n",
    "    'batch_size':         [30],\n",
    "    'num_epochs':         [200],\n",
    "}\n",
    "rs = MyRandomizedSearch(params, num_splits=5, num_iter=30)\n",
    "rs.fit(train_ds)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-02-20T23:50:18.141436Z",
     "start_time": "2018-02-20T23:49:31.131717Z"
    },
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\r",
      "evaluate: 0/16\r",
      "evaluate: 1/16\r",
      "evaluate: 2/16\r",
      "evaluate: 3/16\r",
      "evaluate: 4/16\r",
      "evaluate: 5/16\r",
      "evaluate: 6/16\r",
      "evaluate: 7/16\r",
      "evaluate: 8/16\r",
      "evaluate: 9/16\r",
      "evaluate: 10/16\r",
      "evaluate: 11/16\r",
      "evaluate: 12/16\r",
      "evaluate: 13/16\r",
      "evaluate: 14/16\r",
      "evaluate: 15/16\r",
      "evaluate: 16/16 ok\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "{'losses': 2.2148042936098906}"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "batch_size = rs.parameter_sets[rs.best_index]['batch_size']\n",
    "dloader = DataLoader(train_ds, batch_size=batch_size)\n",
    "rs.best_trainer.fit_loader(500, dloader)\n",
    "rs.best_trainer.load_state(rs.state_fn)\n",
    "rs.best_trainer.evaluate_loader(dloader)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Grid Searching"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-02-21T00:15:09.735268Z",
     "start_time": "2018-02-20T23:50:18.143884Z"
    },
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iteraction  0:  7.02916  19.48315  11.58768  46.30515  9.29859 [83.1 s]\n",
      "Iteraction  1:  6.12518  20.44003  16.14215  43.68536  11.29524 [82.7 s]\n",
      "Iteraction  2:  5.25284  21.52369  13.99203  55.15636  10.41153 [83.2 s]\n",
      "Iteraction  3:  6.24196  16.30851  13.32567  48.13969  11.65188 [83.0 s]\n",
      "Iteraction  4:  6.84649  21.08872  13.82133  42.17008  12.57196 [83.3 s]\n",
      "Iteraction  5:  6.46902  12.75646  12.88601  46.52734  12.02584 [83.2 s]\n",
      "Iteraction  6:  5.95193  13.46878  8.72200  52.48876  13.62923 [82.9 s]\n",
      "Iteraction  7:  6.11243  16.46185  6.78928  48.38416  11.99127 [82.6 s]\n",
      "Iteraction  8:  6.34976  18.85601  13.35772  44.94875  10.21562 [82.9 s]\n",
      "Iteraction  9:  5.37473  14.62576  7.92592  41.57780  11.76086 [82.9 s]\n",
      "Iteraction 10:  5.66566  15.62877  12.19935  50.26344  14.14203 [82.9 s]\n",
      "Iteraction 11:  6.76237  14.19914  16.05852  48.85175  13.95611 [82.8 s]\n",
      "Iteraction 12:  6.28464  18.23318  12.96982  48.88411  13.96927 [82.8 s]\n",
      "Iteraction 13:  5.73671  14.33412  10.85710  51.05961  13.62985 [82.7 s]\n",
      "Iteraction 14:  5.79620  19.92443  11.93965  51.17093  11.75684 [82.8 s]\n",
      "Iteraction 15:  5.35817  14.68732  12.27333  45.01741  17.09319 [82.6 s]\n",
      "Iteraction 16:  6.24991  16.82623  9.29111  50.34975  13.31311 [82.7 s]\n",
      "Iteraction 17:  6.41902  16.11129  9.54360  46.75455  15.22853 [82.6 s]\n",
      "\n",
      "Best parameter set from iteraction 9 with loss = 16.25301:\n",
      "    model_class         : <class '__main__.Model'>\n",
      "    loss_class          : MSELoss\n",
      "    optim_class         : RMSprop\n",
      "    optim_lr            : 0.002\n",
      "    optim_weight_decay  : 0.005\n",
      "    optim_alpha         : 0.99\n",
      "    batch_size          : 30\n",
      "    num_epochs          : 200\n"
     ]
    }
   ],
   "source": [
    "params = {\n",
    "    'model_class':        [Model],\n",
    "    'loss_class':         ['MSELoss'],\n",
    "    'optim_class':        ['RMSprop'],\n",
    "    'optim_lr':           [0.001, 0.002, 0.003],\n",
    "    'optim_weight_decay': [0.0005, 0.005, 0.01],\n",
    "    'optim_alpha':        [0.7, 0.99],\n",
    "    'batch_size':         [30],\n",
    "    'num_epochs':         [200],\n",
    "}\n",
    "gs = MyGridSearch(params, num_splits=5)\n",
    "gs.fit(train_ds)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-02-21T00:15:56.190991Z",
     "start_time": "2018-02-21T00:15:09.737624Z"
    },
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\r",
      "evaluate: 0/16\r",
      "evaluate: 1/16\r",
      "evaluate: 2/16\r",
      "evaluate: 3/16\r",
      "evaluate: 4/16\r",
      "evaluate: 5/16\r",
      "evaluate: 6/16\r",
      "evaluate: 7/16\r",
      "evaluate: 8/16\r",
      "evaluate: 9/16\r",
      "evaluate: 10/16\r",
      "evaluate: 11/16\r",
      "evaluate: 12/16\r",
      "evaluate: 13/16\r",
      "evaluate: 14/16\r",
      "evaluate: 15/16\r",
      "evaluate: 16/16 ok\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "{'losses': 2.6628452054125518}"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "batch_size = gs.parameter_sets[gs.best_index]['batch_size']\n",
    "dloader = DataLoader(train_ds, batch_size=batch_size)\n",
    "gs.best_trainer.fit_loader(500, dloader)\n",
    "gs.best_trainer.load_state(gs.state_fn)\n",
    "gs.best_trainer.evaluate_loader(dloader)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "# Exercícios"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "1. Adicione um parâmetro adicional na escolha do otimizador: 'SGV' e o 'Adam'.\n",
    "2. Adicione agora um parâmetro na rede, por exemplo trocar a função de ativação de 'ReLU' para 'Sigmoid'.\n",
    "3. Adicione um parâmetro a sua escolha."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.3"
  },
  "toc": {
   "nav_menu": {},
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": false,
   "toc_cell": false,
   "toc_position": {},
   "toc_section_display": "block",
   "toc_window_display": false
  },
  "varInspector": {
   "cols": {
    "lenName": 16,
    "lenType": 16,
    "lenVar": 40
   },
   "kernels_config": {
    "python": {
     "delete_cmd_postfix": "",
     "delete_cmd_prefix": "del ",
     "library": "var_list.py",
     "varRefreshCmd": "print(var_dic_list())"
    },
    "r": {
     "delete_cmd_postfix": ") ",
     "delete_cmd_prefix": "rm(",
     "library": "var_list.r",
     "varRefreshCmd": "cat(var_dic_list()) "
    }
   },
   "types_to_exclude": [
    "module",
    "function",
    "builtin_function_or_method",
    "instance",
    "_Feature"
   ],
   "window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
