{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "toc": "true"
   },
   "source": [
    "# Table of Contents\n",
    " <p><div class=\"lev1 toc-item\"><a href=\"#Classificação-de-Textos\" data-toc-modified-id=\"Classificação-de-Textos-1\"><span class=\"toc-item-num\">1&nbsp;&nbsp;</span>Classificação de Textos</a></div><div class=\"lev2 toc-item\"><a href=\"#Preâmbulo\" data-toc-modified-id=\"Preâmbulo-11\"><span class=\"toc-item-num\">1.1&nbsp;&nbsp;</span>Preâmbulo</a></div><div class=\"lev2 toc-item\"><a href=\"#O-Dataset\" data-toc-modified-id=\"O-Dataset-12\"><span class=\"toc-item-num\">1.2&nbsp;&nbsp;</span>O Dataset</a></div><div class=\"lev3 toc-item\"><a href=\"#Lendo-do-disco\" data-toc-modified-id=\"Lendo-do-disco-121\"><span class=\"toc-item-num\">1.2.1&nbsp;&nbsp;</span>Lendo do disco</a></div><div class=\"lev2 toc-item\"><a href=\"#A-Rede-Neural\" data-toc-modified-id=\"A-Rede-Neural-13\"><span class=\"toc-item-num\">1.3&nbsp;&nbsp;</span>A Rede Neural</a></div><div class=\"lev3 toc-item\"><a href=\"#Carregando-os-vetores-word2vec-para-português\" data-toc-modified-id=\"Carregando-os-vetores-word2vec-para-português-131\"><span class=\"toc-item-num\">1.3.1&nbsp;&nbsp;</span>Carregando os vetores word2vec para português</a></div><div class=\"lev3 toc-item\"><a href=\"#Preparando-a-matriz-de-embeddings\" data-toc-modified-id=\"Preparando-a-matriz-de-embeddings-132\"><span class=\"toc-item-num\">1.3.2&nbsp;&nbsp;</span>Preparando a matriz de embeddings</a></div><div class=\"lev3 toc-item\"><a href=\"#Construindo-a-rede\" data-toc-modified-id=\"Construindo-a-rede-133\"><span class=\"toc-item-num\">1.3.3&nbsp;&nbsp;</span>Construindo a rede</a></div><div class=\"lev2 toc-item\"><a href=\"#Treinando\" data-toc-modified-id=\"Treinando-14\"><span class=\"toc-item-num\">1.4&nbsp;&nbsp;</span>Treinando</a></div><div class=\"lev2 toc-item\"><a href=\"#Avaliando\" data-toc-modified-id=\"Avaliando-15\"><span class=\"toc-item-num\">1.5&nbsp;&nbsp;</span>Avaliando</a></div>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Classificação de Textos"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Preâmbulo"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2017-10-25T18:28:42.719474Z",
     "start_time": "2017-10-25T18:28:41.915874Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "GPU available: True\n"
     ]
    }
   ],
   "source": [
    "%matplotlib inline\n",
    "import matplotlib.pyplot as plt\n",
    "import os,sys\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import numpy.random as nr\n",
    "\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "from torch.optim.lr_scheduler import MultiStepLR, StepLR\n",
    "from torch.utils.data import DataLoader, TensorDataset\n",
    "from torch.autograd import Variable\n",
    "\n",
    "from torchvision import datasets, transforms, models\n",
    "\n",
    "import lib.pytorch_trainer as ptt\n",
    "\n",
    "use_gpu = torch.cuda.is_available()\n",
    "print('GPU available:', use_gpu)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## O Dataset"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Lendo do disco"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2017-10-25T18:28:42.785401Z",
     "start_time": "2017-10-25T18:28:42.721264Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Vocabulary: 20000 words\n",
      "Training dataset: (20553, 50) (20553,)\n",
      "Validation dataset: (5139, 50) (5139,)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "(dtype('int64'), dtype('int64'))"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dd = np.load('/data/datasets/livros/livros_sequences_50.npz')\n",
    "Xtra, ytra = dd['Xtra'], dd['ytra']\n",
    "Xval, yval = dd['Xval'], dd['yval']\n",
    "i2w = dd['i2w']\n",
    "\n",
    "num_words = len(i2w)\n",
    "seq_size = Xtra.shape[1]\n",
    "n_labels = max(ytra) + 1\n",
    "embedding_dim = 300\n",
    "\n",
    "Xtra, ytra = Xtra.astype(np.int), ytra.astype(np.int)\n",
    "Xval, yval = Xval.astype(np.int), yval.astype(np.int)\n",
    "\n",
    "print('Vocabulary: {} words'.format(len(i2w)))\n",
    "print('Training dataset:', Xtra.shape, ytra.shape)\n",
    "print('Validation dataset:', Xval.shape, yval.shape)\n",
    "\n",
    "Xtra.dtype, ytra.dtype\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## A Rede Neural"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Carregando os vetores word2vec para português"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2017-10-25T18:28:43.305623Z",
     "start_time": "2017-10-25T18:28:42.787044Z"
    },
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "w2v_model_fn = '/data/datasets/word2vec_pt_br.npz'\n",
    "\n",
    "if not os.path.isfile(w2v_model_fn):\n",
    "    wvec_words = '../../datasets/word2vec_portuguese.tsv'\n",
    "\n",
    "    words = []\n",
    "    vectors = []\n",
    "    word_index = {}\n",
    "    for line in open(wvec_pt):\n",
    "        line = line.rstrip()\n",
    "        if line[0] != ' ':\n",
    "            i, w, vec0 = line.split(maxsplit=2)\n",
    "            assert int(i) == len(words)\n",
    "            assert vec0[0] == '[', vec0\n",
    "            words.append(w)\n",
    "            vv = [float(x) for x in vec0[1:].split()]\n",
    "        elif line[-1] == ']':\n",
    "            vv += [float(x) for x in line[:-1].split()]\n",
    "            vectors.append(vv)\n",
    "        else:\n",
    "            vv += [float(x) for x in line.split()]\n",
    "            \n",
    "    words = np.array(words)\n",
    "    vectors = np.array(vects)\n",
    "    np.savez_compressed(w2v_model_fn, words=words, vectors=vectors)\n",
    "\n",
    "else:\n",
    "    dd = np.load(w2v_model_fn)\n",
    "    words = dd['words']\n",
    "    vectors = dd['vectors']\n",
    "\n",
    "embeddings_index = {}\n",
    "for i, w in enumerate(words):\n",
    "    embeddings_index[w] = vectors[i]\n",
    "    \n",
    "embedding_dim = vectors.shape[1]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Preparando a matriz de embeddings\n",
    "\n",
    "Neste notebook o embedding é treinado a partir de pesos aleatórios.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2017-10-25T18:28:43.404344Z",
     "start_time": "2017-10-25T18:28:43.307153Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Embedding Matrix: (20000, 300).\n",
      "Words not found:  6546\n",
      "\n",
      "W2V embedding mean: 0.00524, variance: 0.54893, sum: 31429.54515\n"
     ]
    }
   ],
   "source": [
    "nr.seed(20170601)\n",
    "\n",
    "# prepare embedding matrix\n",
    "num_words = len(i2w)\n",
    "embedding_matrix = np.zeros((num_words, embedding_dim))\n",
    "\n",
    "notfound = []\n",
    "for i in range(1, num_words):\n",
    "    word = i2w[i]\n",
    "    embedding_vector = embeddings_index.get(word)\n",
    "    if embedding_vector is not None:\n",
    "        embedding_matrix[i] = embedding_vector\n",
    "    else:\n",
    "        notfound.append(word)\n",
    "\n",
    "print('Embedding Matrix: {}.\\nWords not found:  {}'.format(embedding_matrix.shape, len(notfound)))\n",
    "print('\\nW2V embedding mean: {:.5f}, variance: {:.5f}, sum: {:.5f}'\n",
    "      .format(embedding_matrix.mean(), embedding_matrix.var(), embedding_matrix.sum()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2017-10-25T18:28:43.895948Z",
     "start_time": "2017-10-25T18:28:43.406041Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Embedding (default init) mean: 0.00002, variance: 1.00010, sum: 92.72173\n",
      "Embedding (xavier init)  mean: -0.00000, variance: 0.00010, sum: -12.06245\n"
     ]
    }
   ],
   "source": [
    "emb = nn.Embedding(num_words, embedding_dim)\n",
    "print('Embedding (default init) mean: {:.5f}, variance: {:.5f}, sum: {:.5f}'\n",
    "      .format(emb.weight.data.mean(), emb.weight.data.var(), emb.weight.data.sum()))\n",
    "nn.init.xavier_uniform(emb.weight)\n",
    "print('Embedding (xavier init)  mean: {:.5f}, variance: {:.5f}, sum: {:.5f}'\n",
    "      .format(emb.weight.data.mean(), emb.weight.data.var(), emb.weight.data.sum()))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Construindo a rede"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2017-10-25T18:28:43.937215Z",
     "start_time": "2017-10-25T18:28:43.897604Z"
    },
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "\n",
    "class MyNet(nn.Module):\n",
    "    \n",
    "    def __init__(self, seq_len=seq_size, embedding_matrix=embedding_matrix, \n",
    "                 n_conv_filters=128, conv_kernel_size=5):\n",
    "        super().__init__()\n",
    "        \n",
    "        voc_size, embed_dim = embedding_matrix.shape\n",
    "        \n",
    "        k = conv_kernel_size - 1\n",
    "        n = (((seq_len - k) // 2 - k) // 2 - k) // 2\n",
    "        self.flat_size = n * n_conv_filters\n",
    "                \n",
    "        self.emb = nn.Embedding(voc_size, embed_dim)\n",
    "        \n",
    "        dd = self.emb.state_dict()\n",
    "        dd['weight'] = torch.from_numpy(embedding_matrix / 10000.0)\n",
    "        self.emb.load_state_dict(dd)\n",
    "\n",
    "        self.conv1 = nn.Conv1d(embed_dim, n_conv_filters, conv_kernel_size)\n",
    "        self.conv2 = nn.Conv1d(n_conv_filters, n_conv_filters, conv_kernel_size)\n",
    "        self.conv3 = nn.Conv1d(n_conv_filters, n_conv_filters, conv_kernel_size)\n",
    "        \n",
    "        self.fc1 = nn.Linear(self.flat_size, 128)\n",
    "        self.fc2 = nn.Linear(128, 3)\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = self.emb(x)\n",
    "        x = x.transpose(1, 2)\n",
    "        \n",
    "        x = F.relu(self.conv1(x))\n",
    "        x = F.max_pool1d(x, 2)\n",
    "        x = F.dropout(x, 0.5)\n",
    "    \n",
    "        x = F.relu(self.conv2(x))\n",
    "        x = F.max_pool1d(x, 2)\n",
    "\n",
    "        x = F.relu(self.conv3(x))\n",
    "        x = F.max_pool1d(x, 2)\n",
    "        x = F.dropout(x, 0.5)\n",
    "        \n",
    "        x = x.view(-1, self.flat_size)\n",
    "        \n",
    "        x = F.relu(self.fc1(x))\n",
    "        x = F.dropout(x, 0.5)\n",
    "        \n",
    "        x = self.fc2(x)\n",
    "        \n",
    "        return x\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Treinando"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2017-10-25T18:28:46.433641Z",
     "start_time": "2017-10-25T18:28:43.938794Z"
    },
    "collapsed": true,
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "trainIt = True\n",
    "resetIt = False\n",
    "\n",
    "# Callbacks\n",
    "# ---------\n",
    "accuracy_cb = ptt.AccuracyMetric()\n",
    "chkpt_cb = ptt.ModelCheckpoint('../../models/livros_classif_50_1', reset=resetIt, verbose=1)\n",
    "print_cb = ptt.PrintCallback()\n",
    "plot_cb = ptt.PlotCallback()\n",
    "\n",
    "# Model, optimizer and learning rate scheduler\n",
    "# --------------------------------------------\n",
    "model = MyNet()\n",
    "optimizer = torch.optim.Adam(model.parameters(), lr=1e-4)\n",
    "scheduler = StepLR(optimizer, step_size=5, gamma=0.75)\n",
    "\n",
    "# Network trainer\n",
    "# ---------------\n",
    "training_parameters = {\n",
    "    'model':         model, \n",
    "    'criterion':     nn.CrossEntropyLoss(),\n",
    "    'optimizer':     optimizer, \n",
    "    'lr_scheduler':  scheduler, \n",
    "    'callbacks':     [accuracy_cb, print_cb],\n",
    "}\n",
    "trainer = ptt.DeepNetTrainer(**training_parameters)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2017-10-25T18:31:48.203182Z",
     "start_time": "2017-10-25T18:28:46.435259Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Start training for 10 epochs\n",
      "  1:  18.7s   T: 0.51409 0.76072   V: 0.19539 0.92878 best\n",
      "  2:  18.1s   T: 0.08552 0.96954   V: 0.15972 0.94435 best\n",
      "  3:  18.1s   T: 0.01638 0.99484   V: 0.20268 0.94162 \n",
      "  4:  18.1s   T: 0.00338 0.99912   V: 0.24776 0.94415 \n",
      "  5:  18.1s   T: 0.00203 0.99932   V: 0.30243 0.94318 \n",
      "  6:  18.1s   T: 0.00104 0.99961   V: 0.29067 0.94435 \n",
      "  7:  18.1s   T: 0.00076 0.99976   V: 0.35808 0.93987 \n",
      "  8:  18.1s   T: 0.00033 0.99981   V: 0.32042 0.94415 \n",
      "  9:  18.1s   T: 0.00001 1.00000   V: 0.31239 0.94785 \n",
      " 10:  18.1s   T: 0.00000 1.00000   V: 0.31742 0.94766 \n",
      "Stop training at epoch: 10/10\n"
     ]
    }
   ],
   "source": [
    "if trainIt:\n",
    "    Xtrain = torch.from_numpy(Xtra)\n",
    "    ytrain = torch.from_numpy(ytra)\n",
    "    Xvalid = torch.from_numpy(Xval)\n",
    "    yvalid = torch.from_numpy(yval)\n",
    "    \n",
    "    trainer.fit(10, Xtrain, ytrain, valid_data=(Xvalid, yvalid))\n",
    "else:\n",
    "    print('\\nTraining disabled.\\nThis model was trained for {} epochs.'.format(trainer.last_epoch))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Avaliando"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2017-10-25T18:31:53.399548Z",
     "start_time": "2017-10-25T18:31:48.205007Z"
    },
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "evaluate: 2055/2055 ok\n",
      "Model training set accuracy after training: 1.00000\n",
      "\n",
      "evaluate: 513/513 ok\n",
      "Model validation set accuracy after training: 0.94766\n"
     ]
    }
   ],
   "source": [
    "rmetrics = trainer.evaluate(Xtrain, ytrain, metrics=[accuracy_cb])\n",
    "print('Model training set accuracy after training: {:.5f}'.format(rmetrics['acc']))\n",
    "print()\n",
    "rmetrics = trainer.evaluate(Xvalid, yvalid, metrics=[accuracy_cb])\n",
    "print('Model validation set accuracy after training: {:.5f}'.format(rmetrics['acc']))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2017-10-25T18:20:14.355028Z",
     "start_time": "2017-10-25T18:20:14.350623Z"
    },
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.1"
  },
  "latex_envs": {
   "LaTeX_envs_menu_present": true,
   "autocomplete": true,
   "bibliofile": "biblio.bib",
   "cite_by": "apalike",
   "current_citInitial": 1,
   "eqLabelWithNumbers": true,
   "eqNumInitial": 1,
   "hotkeys": {
    "equation": "Ctrl-E",
    "itemize": "Ctrl-I"
   },
   "labels_anchors": false,
   "latex_user_defs": false,
   "report_style_numbering": false,
   "user_envs_cfg": false
  },
  "toc": {
   "colors": {
    "hover_highlight": "#DAA520",
    "navigate_num": "#000000",
    "navigate_text": "#333333",
    "running_highlight": "#FF0000",
    "selected_highlight": "#FFD700",
    "sidebar_border": "#EEEEEE",
    "wrapper_background": "#FFFFFF"
   },
   "moveMenuLeft": true,
   "nav_menu": {
    "height": "264px",
    "width": "252px"
   },
   "navigate_menu": true,
   "number_sections": true,
   "sideBar": true,
   "threshold": 4,
   "toc_cell": true,
   "toc_section_display": "block",
   "toc_window_display": false,
   "widenNotebook": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
