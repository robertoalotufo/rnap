{"nbformat":4,"nbformat_minor":0,"metadata":{"kernelspec":{"display_name":"Python 3","language":"python","name":"python3"},"language_info":{"codemirror_mode":{"name":"ipython","version":3},"file_extension":".py","mimetype":"text/x-python","name":"python","nbconvert_exporter":"python","pygments_lexer":"ipython3","version":"3.6.3"},"latex_envs":{"LaTeX_envs_menu_present":true,"autocomplete":true,"bibliofile":"biblio.bib","cite_by":"apalike","current_citInitial":1,"eqLabelWithNumbers":true,"eqNumInitial":1,"hotkeys":{"equation":"Ctrl-E","itemize":"Ctrl-I"},"labels_anchors":false,"latex_user_defs":false,"report_style_numbering":false,"user_envs_cfg":false},"toc":{"colors":{"hover_highlight":"#DAA520","running_highlight":"#FF0000","selected_highlight":"#FFD700"},"moveMenuLeft":true,"nav_menu":{"height":"12px","width":"252px"},"navigate_menu":true,"number_sections":true,"sideBar":true,"skip_h1_title":false,"threshold":4,"toc_cell":false,"toc_position":{},"toc_section_display":"block","toc_window_display":false},"varInspector":{"cols":{"lenName":16,"lenType":16,"lenVar":40},"kernels_config":{"python":{"delete_cmd_postfix":"","delete_cmd_prefix":"del ","library":"var_list.py","varRefreshCmd":"print(var_dic_list())"},"r":{"delete_cmd_postfix":") ","delete_cmd_prefix":"rm(","library":"var_list.r","varRefreshCmd":"cat(var_dic_list()) "}},"types_to_exclude":["module","function","builtin_function_or_method","instance","_Feature"],"window_display":false},"colab":{"name":"embedding-basics-pytorch.ipynb","provenance":[],"collapsed_sections":[]}},"cells":[{"cell_type":"markdown","metadata":{"id":"kMjtDxIqf_DN","colab_type":"text"},"source":["# Embedding - Atributos Latentes - Entradas categóricas"]},{"cell_type":"markdown","metadata":{"id":"dtaOxkUff_DP","colab_type":"text"},"source":["Este notebook apresenta o conceito de embedding e como usá-lo no PyTorch, através dos seguintes exemplos numéricos:\n","- Rede com entrada categórica (one-hot) e camada densa linear\n","- Embedding como forma eficiente de tratar entrada categórica"]},{"cell_type":"markdown","metadata":{"id":"5wtCuxRLf_DP","colab_type":"text"},"source":["## Importação"]},{"cell_type":"code","metadata":{"ExecuteTime":{"end_time":"2018-09-10T10:48:19.173050","start_time":"2018-09-10T10:48:18.938674"},"id":"gYkGO3rHf_DQ","colab_type":"code","colab":{}},"source":["from collections import OrderedDict\n","import numpy as np\n","import torch\n","from torch import nn"],"execution_count":0,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"cJyfXhkjf_DU","colab_type":"text"},"source":["## Entrada categórica"]},{"cell_type":"markdown","metadata":{"id":"XKdtFbaMf_DV","colab_type":"text"},"source":["Uma variável categórica pode ter um valor dentro de um conjunto limitado que represente uma categoria nominal.\n","Alguns exemplos de variáveis categóricas:\n","- Grupo sanguíneo: A, B, AB or O.\n","- Cidade onde uma pessoa reside\n","- Cor de um produto: vermelho, verde, azul\n","- Uma palavra, dentro de um vocabulário limitado\n","- Dias da semana"]},{"cell_type":"markdown","metadata":{"id":"sW3BjU2qf_DV","colab_type":"text"},"source":["# Rede neural com entrada categórica"]},{"cell_type":"markdown","metadata":{"id":"NC0OBsx6f_DW","colab_type":"text"},"source":["Quando a rede neural possui entradas categóricas, temos a necessidade de colocá-lo na forma \n","categórica utilizando a codificação *one-hot*. \n","Iremos fazer um exemplo de rede neural com apenas uma camada densa e entrada com \n","dados categóricos com os seguintes parâmetros:\n","- entrada categórica pertencente a um conjunto de 20 classes (n_classes)\n","- entrada é constituída de 10 amostras categóricos (n_amostras)\n","- cada amostra é um número (id) entre 0 e 19: [19, 10, 0, 1, 7, 5, 0, 1, 15, 2]\n","- camada densa linear com 5 neurônios (n_neuronios)"]},{"cell_type":"code","metadata":{"ExecuteTime":{"end_time":"2018-09-10T10:48:19.178715","start_time":"2018-09-10T10:48:19.175011"},"id":"XxH_8VuLf_DX","colab_type":"code","colab":{}},"source":["n_classes = 20\n","n_neuronios = 5\n","n_amostras = 10"],"execution_count":0,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"yokkCP04f_Da","colab_type":"text"},"source":["## Diagrama da rede neural com entradas categóricas de uma camada e sem bias"]},{"cell_type":"markdown","metadata":{"id":"IrfD6_OYf_Db","colab_type":"text"},"source":["<img src='https://raw.githubusercontent.com/robertoalotufo/files/master/figures/Embedding_neural.png' width = \"400\"></img>"]},{"cell_type":"markdown","metadata":{"id":"oCotY82cf_Dc","colab_type":"text"},"source":["### Criação da codificação categórica (one-hot) da sequência de entrada"]},{"cell_type":"code","metadata":{"ExecuteTime":{"end_time":"2018-09-10T10:48:19.193654","start_time":"2018-09-10T10:48:19.180824"},"id":"3ObtfGAjf_Dc","colab_type":"code","colab":{"base_uri":"https://localhost:8080/","height":34},"outputId":"b5be2d7d-168c-4012-fb9c-288eb4d3a1b5","executionInfo":{"status":"ok","timestamp":1586547754191,"user_tz":180,"elapsed":957,"user":{"displayName":"Roberto Lotufo","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GgvhWGp9VHQ1-KYYl4kf7NPZUoCK4e9jt7V92r06A=s64","userId":"00857172468435692304"}}},"source":["x = torch.tensor([19, 10, 0, 1, 7, 5, 0, 1, 15, 2])\n","x, x.shape"],"execution_count":18,"outputs":[{"output_type":"execute_result","data":{"text/plain":["(tensor([19, 10,  0,  1,  7,  5,  0,  1, 15,  2]), torch.Size([10]))"]},"metadata":{"tags":[]},"execution_count":18}]},{"cell_type":"markdown","metadata":{"id":"AsL2Rf5vf_Dh","colab_type":"text"},"source":["Codificação one-hot"]},{"cell_type":"code","metadata":{"id":"AIcx-wfVhi6_","colab_type":"code","colab":{"base_uri":"https://localhost:8080/","height":187},"outputId":"6e6e7501-9977-4210-9d8b-2b48e6299b2a","executionInfo":{"status":"ok","timestamp":1586547771505,"user_tz":180,"elapsed":901,"user":{"displayName":"Roberto Lotufo","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GgvhWGp9VHQ1-KYYl4kf7NPZUoCK4e9jt7V92r06A=s64","userId":"00857172468435692304"}}},"source":["x_oh = torch.nn.functional.one_hot(x, n_classes)\n","print(x_oh)"],"execution_count":19,"outputs":[{"output_type":"stream","text":["tensor([[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1],\n","        [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0],\n","        [1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0],\n","        [0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0],\n","        [0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0],\n","        [0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0],\n","        [1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0],\n","        [0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0],\n","        [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0],\n","        [0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]])\n"],"name":"stdout"}]},{"cell_type":"markdown","metadata":{"id":"4u3WvjFvf_Dm","colab_type":"text"},"source":["## Criação do modelo da rede densa com 5 camadas"]},{"cell_type":"code","metadata":{"ExecuteTime":{"end_time":"2018-09-10T10:48:19.218509","start_time":"2018-09-10T10:48:19.212012"},"id":"rEMVnMT2f_Dn","colab_type":"code","colab":{"base_uri":"https://localhost:8080/","height":34},"outputId":"b13210c6-5aca-4779-cbf6-9b25b012a242","executionInfo":{"status":"ok","timestamp":1586547780154,"user_tz":180,"elapsed":878,"user":{"displayName":"Roberto Lotufo","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GgvhWGp9VHQ1-KYYl4kf7NPZUoCK4e9jt7V92r06A=s64","userId":"00857172468435692304"}}},"source":["linear = nn.Linear(n_classes,n_neuronios,bias=False)\n","linear"],"execution_count":20,"outputs":[{"output_type":"execute_result","data":{"text/plain":["Linear(in_features=20, out_features=5, bias=False)"]},"metadata":{"tags":[]},"execution_count":20}]},{"cell_type":"markdown","metadata":{"id":"rQbxPtBbf_Dr","colab_type":"text"},"source":["### Criação dos pesos da rede"]},{"cell_type":"markdown","metadata":{"id":"K5xg0bukf_Dr","colab_type":"text"},"source":["Como ilustração, iremos inicializar a rede com pesos de modo que possamos identificar quando cada conjunto de pesos\n","for utilizado para cada símbolo categórico:\n","- quando a categoria for $i$, os neurônios de saída devem receber os valores $[i,2i,3i,4i,5i]$.\n","\n","Os pesos da rede possuem 20 linhas (uma para cada classes de entrada) por 5 colunas (atributos de cada categoria):"]},{"cell_type":"code","metadata":{"ExecuteTime":{"end_time":"2018-09-10T10:48:19.230338","start_time":"2018-09-10T10:48:19.220274"},"id":"H0lcNo4Xf_Ds","colab_type":"code","colab":{"base_uri":"https://localhost:8080/","height":204},"outputId":"eae41ca8-ea78-4fb4-ae47-abeea2a03de5","executionInfo":{"status":"ok","timestamp":1586547788512,"user_tz":180,"elapsed":1035,"user":{"displayName":"Roberto Lotufo","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GgvhWGp9VHQ1-KYYl4kf7NPZUoCK4e9jt7V92r06A=s64","userId":"00857172468435692304"}}},"source":["W = np.arange(1,n_neuronios+1).reshape(-1,1).dot(np.arange(n_classes).reshape(1,-1))\n","\n","my_weights = OrderedDict([\n","    ('weight',  torch.FloatTensor(W.astype(np.float)))])\n","\n","linear.load_state_dict(my_weights) # inicializa pesos da camada linear\n","linear.state_dict()"],"execution_count":21,"outputs":[{"output_type":"execute_result","data":{"text/plain":["OrderedDict([('weight',\n","              tensor([[ 0.,  1.,  2.,  3.,  4.,  5.,  6.,  7.,  8.,  9., 10., 11., 12., 13.,\n","                       14., 15., 16., 17., 18., 19.],\n","                      [ 0.,  2.,  4.,  6.,  8., 10., 12., 14., 16., 18., 20., 22., 24., 26.,\n","                       28., 30., 32., 34., 36., 38.],\n","                      [ 0.,  3.,  6.,  9., 12., 15., 18., 21., 24., 27., 30., 33., 36., 39.,\n","                       42., 45., 48., 51., 54., 57.],\n","                      [ 0.,  4.,  8., 12., 16., 20., 24., 28., 32., 36., 40., 44., 48., 52.,\n","                       56., 60., 64., 68., 72., 76.],\n","                      [ 0.,  5., 10., 15., 20., 25., 30., 35., 40., 45., 50., 55., 60., 65.,\n","                       70., 75., 80., 85., 90., 95.]]))])"]},"metadata":{"tags":[]},"execution_count":21}]},{"cell_type":"markdown","metadata":{"id":"fa508Dyqf_Dy","colab_type":"text"},"source":["## Predição com as 10 amostras: [19, 10, 0, 1, 7, 5, 0, 1, 15, 2]"]},{"cell_type":"markdown","metadata":{"id":"eWcQpGB2f_Dz","colab_type":"text"},"source":["<img src = 'https://raw.githubusercontent.com/robertoalotufo/files/master/figures/Embedding_categorical_predict.png' width=\"800\"></img>"]},{"cell_type":"markdown","metadata":{"id":"bE-Yhjzqf_Dz","colab_type":"text"},"source":["Observe que a predição da rede com a sequência categórica acima é feita com a substituição\n","da categoria com os 5 atributos de cada classe.\n","\n","Observe que data_oh estava em long e foi preciso ser convertido para float para entrar na rede neural."]},{"cell_type":"code","metadata":{"ExecuteTime":{"end_time":"2018-09-10T10:48:19.296052","start_time":"2018-09-10T10:48:19.240730"},"id":"OaU3fj0if_D0","colab_type":"code","colab":{"base_uri":"https://localhost:8080/","height":187},"outputId":"3b15063a-251c-44c2-ef87-b56ea6a6ccb2","executionInfo":{"status":"ok","timestamp":1586547821262,"user_tz":180,"elapsed":897,"user":{"displayName":"Roberto Lotufo","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GgvhWGp9VHQ1-KYYl4kf7NPZUoCK4e9jt7V92r06A=s64","userId":"00857172468435692304"}}},"source":["y_pred = linear(x_oh.type(torch.float))\n","y_pred"],"execution_count":23,"outputs":[{"output_type":"execute_result","data":{"text/plain":["tensor([[19., 38., 57., 76., 95.],\n","        [10., 20., 30., 40., 50.],\n","        [ 0.,  0.,  0.,  0.,  0.],\n","        [ 1.,  2.,  3.,  4.,  5.],\n","        [ 7., 14., 21., 28., 35.],\n","        [ 5., 10., 15., 20., 25.],\n","        [ 0.,  0.,  0.,  0.,  0.],\n","        [ 1.,  2.,  3.,  4.,  5.],\n","        [15., 30., 45., 60., 75.],\n","        [ 2.,  4.,  6.,  8., 10.]], grad_fn=<MmBackward>)"]},"metadata":{"tags":[]},"execution_count":23}]},{"cell_type":"markdown","metadata":{"id":"Zk7OqvdJf_D4","colab_type":"text"},"source":["# Embedding como implementação eficiente de entradas categóricas"]},{"cell_type":"markdown","metadata":{"id":"DK_1SXx9f_D5","colab_type":"text"},"source":["Nesta implementação de rede neural com entrada categórica, existem dois fatores que dificultam a sua\n","implementação eficiente:\n","- necessidade de se fazer a codificação para categórico antes de colocá-lo na rede\n","- se o número de classes for muito alto, a implementação pode se tornar muito ineficiente. É comum\n","  termos centenas de milhares de classes, como é o caso de palavras dentro de um vocabulário.\n","  \n","A camada `Embedding` resolve estes dois problemas de forma eficiente:\n","- faz a codificação categórica automaticamente e já retorna a aplicação dos pesos nos valores categóricos\n","\n","Assim, a camada `Embedding` é sempre uma camada de entrada e nela é preciso especificar o número de\n","classes e o número de atributos de cada classe:\n","\n","O diagrama a seguir mostra a aplicação do Embedding."]},{"cell_type":"markdown","metadata":{"id":"66swAUsef_D5","colab_type":"text"},"source":["<img src = 'https://raw.githubusercontent.com/robertoalotufo/files/master/figures/Embedding_1.png' width=\"700pt\"></img>"]},{"cell_type":"markdown","metadata":{"id":"8cf0xQkRf_D6","colab_type":"text"},"source":["## Criação da mesma rede, porém agora mais eficiente, com o uso do Embedding"]},{"cell_type":"code","metadata":{"ExecuteTime":{"end_time":"2018-09-10T10:48:19.302901","start_time":"2018-09-10T10:48:19.297703"},"id":"UV2-vyyZf_D6","colab_type":"code","colab":{"base_uri":"https://localhost:8080/","height":34},"outputId":"7d012d67-250f-4c80-9386-3f16ac3120fa","executionInfo":{"status":"ok","timestamp":1586547834776,"user_tz":180,"elapsed":850,"user":{"displayName":"Roberto Lotufo","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GgvhWGp9VHQ1-KYYl4kf7NPZUoCK4e9jt7V92r06A=s64","userId":"00857172468435692304"}}},"source":["emb = nn.Embedding(n_classes, n_neuronios)\n","emb"],"execution_count":24,"outputs":[{"output_type":"execute_result","data":{"text/plain":["Embedding(20, 5)"]},"metadata":{"tags":[]},"execution_count":24}]},{"cell_type":"code","metadata":{"ExecuteTime":{"end_time":"2018-09-10T10:48:19.312290","start_time":"2018-09-10T10:48:19.304445"},"id":"Q-U-QgL2f_D9","colab_type":"code","colab":{"base_uri":"https://localhost:8080/","height":357},"outputId":"642e6140-893c-4ebf-c3ad-9165bad364f6","executionInfo":{"status":"ok","timestamp":1586547843261,"user_tz":180,"elapsed":1024,"user":{"displayName":"Roberto Lotufo","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GgvhWGp9VHQ1-KYYl4kf7NPZUoCK4e9jt7V92r06A=s64","userId":"00857172468435692304"}}},"source":["my_weights = OrderedDict([\n","    ('weight',  torch.FloatTensor(W.T.astype(np.float)))])\n","emb.load_state_dict(my_weights) # inicializa pesos da camada linear\n","emb.state_dict()"],"execution_count":25,"outputs":[{"output_type":"execute_result","data":{"text/plain":["OrderedDict([('weight', tensor([[ 0.,  0.,  0.,  0.,  0.],\n","                      [ 1.,  2.,  3.,  4.,  5.],\n","                      [ 2.,  4.,  6.,  8., 10.],\n","                      [ 3.,  6.,  9., 12., 15.],\n","                      [ 4.,  8., 12., 16., 20.],\n","                      [ 5., 10., 15., 20., 25.],\n","                      [ 6., 12., 18., 24., 30.],\n","                      [ 7., 14., 21., 28., 35.],\n","                      [ 8., 16., 24., 32., 40.],\n","                      [ 9., 18., 27., 36., 45.],\n","                      [10., 20., 30., 40., 50.],\n","                      [11., 22., 33., 44., 55.],\n","                      [12., 24., 36., 48., 60.],\n","                      [13., 26., 39., 52., 65.],\n","                      [14., 28., 42., 56., 70.],\n","                      [15., 30., 45., 60., 75.],\n","                      [16., 32., 48., 64., 80.],\n","                      [17., 34., 51., 68., 85.],\n","                      [18., 36., 54., 72., 90.],\n","                      [19., 38., 57., 76., 95.]]))])"]},"metadata":{"tags":[]},"execution_count":25}]},{"cell_type":"markdown","metadata":{"id":"2H42xISyf_EA","colab_type":"text"},"source":["## Predição com mesma sequência: [19, 10, 0, 1, 7, 5, 0, 1, 15, 2]"]},{"cell_type":"markdown","metadata":{"id":"3Rb_cwtAf_EB","colab_type":"text"},"source":["Confirmamos aqui que a camada Embedding é equivalente à rede densa da entrada categórica feita anteriormente.\n","\n","Observe que não foi necessário criar a codificação one_hot."]},{"cell_type":"code","metadata":{"ExecuteTime":{"end_time":"2018-09-10T10:48:19.385925","start_time":"2018-09-10T10:48:19.313998"},"id":"zF8DCcy_f_EB","colab_type":"code","colab":{"base_uri":"https://localhost:8080/","height":187},"outputId":"ac137a15-5a00-430b-b254-adbb27a74c9c","executionInfo":{"status":"ok","timestamp":1586547954076,"user_tz":180,"elapsed":1006,"user":{"displayName":"Roberto Lotufo","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GgvhWGp9VHQ1-KYYl4kf7NPZUoCK4e9jt7V92r06A=s64","userId":"00857172468435692304"}}},"source":["y = emb(x)  # predição da rede\n","y"],"execution_count":27,"outputs":[{"output_type":"execute_result","data":{"text/plain":["tensor([[19., 38., 57., 76., 95.],\n","        [10., 20., 30., 40., 50.],\n","        [ 0.,  0.,  0.,  0.,  0.],\n","        [ 1.,  2.,  3.,  4.,  5.],\n","        [ 7., 14., 21., 28., 35.],\n","        [ 5., 10., 15., 20., 25.],\n","        [ 0.,  0.,  0.,  0.,  0.],\n","        [ 1.,  2.,  3.,  4.,  5.],\n","        [15., 30., 45., 60., 75.],\n","        [ 2.,  4.,  6.,  8., 10.]], grad_fn=<EmbeddingBackward>)"]},"metadata":{"tags":[]},"execution_count":27}]},{"cell_type":"markdown","metadata":{"id":"YPECr-XOrxRm","colab_type":"text"},"source":["## Tratando o embeddings no batch"]},{"cell_type":"markdown","metadata":{"id":"ZRyYgDOitS8K","colab_type":"text"},"source":["No exemplo a seguir, temos dois exemplos num minibatch, cada exemplo com 4 atributos. O shape da entrada x é (2,4)\n","\n","Observe que na saída da camada de embedding é acrescentada uma nova dimensão. O shape da saíde é (2, 4, 5). Cada atributo categórico foi substituído por um vetor com 5 elementos. "]},{"cell_type":"code","metadata":{"id":"k7LgKP5Zr3Ci","colab_type":"code","colab":{"base_uri":"https://localhost:8080/","height":187},"outputId":"35732f78-bb5e-4fcb-e4b0-d194350b70e1","executionInfo":{"status":"ok","timestamp":1586549186871,"user_tz":180,"elapsed":850,"user":{"displayName":"Roberto Lotufo","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GgvhWGp9VHQ1-KYYl4kf7NPZUoCK4e9jt7V92r06A=s64","userId":"00857172468435692304"}}},"source":["x = torch.LongTensor([[1,6,3,2],\n","                      [3,5,9,4]])\n","y = emb(x)\n","print(y.shape)\n","print(y)"],"execution_count":31,"outputs":[{"output_type":"stream","text":["torch.Size([2, 4, 5])\n","tensor([[[ 1.,  2.,  3.,  4.,  5.],\n","         [ 6., 12., 18., 24., 30.],\n","         [ 3.,  6.,  9., 12., 15.],\n","         [ 2.,  4.,  6.,  8., 10.]],\n","\n","        [[ 3.,  6.,  9., 12., 15.],\n","         [ 5., 10., 15., 20., 25.],\n","         [ 9., 18., 27., 36., 45.],\n","         [ 4.,  8., 12., 16., 20.]]], grad_fn=<EmbeddingBackward>)\n"],"name":"stdout"}]},{"cell_type":"markdown","metadata":{"id":"pqHcUIRpt6CD","colab_type":"text"},"source":["Se for necessário fazer uma concatenação dos embeddings categóricos, basta fazer um reshape combinando as duas últimas dimensões:"]},{"cell_type":"code","metadata":{"id":"mddfxs_atJrO","colab_type":"code","colab":{"base_uri":"https://localhost:8080/","height":85},"outputId":"a8d39b90-b7a2-44c5-dc8e-300db7319301","executionInfo":{"status":"ok","timestamp":1586549285981,"user_tz":180,"elapsed":1233,"user":{"displayName":"Roberto Lotufo","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GgvhWGp9VHQ1-KYYl4kf7NPZUoCK4e9jt7V92r06A=s64","userId":"00857172468435692304"}}},"source":["print(y.reshape(2,-1))"],"execution_count":32,"outputs":[{"output_type":"stream","text":["tensor([[ 1.,  2.,  3.,  4.,  5.,  6., 12., 18., 24., 30.,  3.,  6.,  9., 12.,\n","         15.,  2.,  4.,  6.,  8., 10.],\n","        [ 3.,  6.,  9., 12., 15.,  5., 10., 15., 20., 25.,  9., 18., 27., 36.,\n","         45.,  4.,  8., 12., 16., 20.]], grad_fn=<ViewBackward>)\n"],"name":"stdout"}]},{"cell_type":"markdown","metadata":{"id":"ab2Z8VOCf_EE","colab_type":"text"},"source":["## Embedding como atributos latentes de um objeto categórico"]},{"cell_type":"markdown","metadata":{"id":"_bEkmSQUf_EF","colab_type":"text"},"source":["Podemos interpretar o embedding como uma codificação de atributos latentes de um objeto\n","categórico. Por exemplo, se estamos codificando filmes, as 5 categorias visto no exemplo\n","acima poderiam representar a quantidade de suspense, romantismo, aventura, infantil e terror\n","que um filme possui. Se fosse processar palavras, os atributos poderiam representar o seu\n","significado (*word embedding*).\n","\n","O embedding pode ser fixo (não deve ser treinado), quando sabemos exatamente os atributos\n","das classes ou treináveis, quando queremos que a rede utilize estes atributos como parâmetros\n","a serem minimizados."]},{"cell_type":"markdown","metadata":{"id":"-_YWfjFpf_EF","colab_type":"text"},"source":["# Aprendizados com este notebook"]}]}