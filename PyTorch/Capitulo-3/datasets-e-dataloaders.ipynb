{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Datasets e DataLoaders no Pytorch"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Demonstração do funcionamento dos Datasets e Dataoaders no Pytorch"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Datasets"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "No Pytorch, datasets são objetos utilizados para armazenar, indexar e e retornar elementos de um conjunto de dados.\n",
    "\n",
    "Usualmente eles devem ter funções para retornar o elemento de um índice e deve ser possível saber o tamanho do dataset."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Criando um Dataset com torch.utils.data.TensorDataset"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Se os dados e as classes forem disponibilizados em arrays do numpy ou tensores do próprio PyTorch é possível criar um dataset utilizando [torch.utils.data.TensorDataset](http://pytorch.org/docs/master/data.html#torch.utils.data.TensorDataset):"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "dimensões de x_data: (20, 3)\n",
      "dimensões de target: (20,)\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import torch\n",
    "from torch.utils.data import TensorDataset\n",
    "\n",
    "# suposta entrada  \n",
    "x_data = np.random.rand(20, 3)                 # 20 vetores de 3 elementos criados aleatoriamente\n",
    "target = np.random.randint(0, 3, size=20)    # 20 classes 0, 1, ou 2 criadas aleatoriamente\n",
    "\n",
    "print('dimensões de x_data:', x_data.shape)\n",
    "print('dimensões de target:', target.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {},
   "outputs": [],
   "source": [
    "# passo 1: transformar em tensores torch\n",
    "x_data = torch.from_numpy(x_data)\n",
    "target = torch.from_numpy(target)\n",
    "\n",
    "# passo 2: usar TensorDataset para criar o dataset com os tensores\n",
    "dataset = TensorDataset(x_data, target)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Cada elemento do dataset retornará o dado e a classe do índice pedido em uma tupla"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "dado: \n",
      " 0.9509\n",
      " 0.4563\n",
      " 0.6243\n",
      "[torch.DoubleTensor of size 3]\n",
      "\n",
      "classe: 1\n"
     ]
    }
   ],
   "source": [
    "i = 10\n",
    "x, y = dataset[i]\n",
    "\n",
    "print('dado:', x)\n",
    "print('classe:', y)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Criando um Dataset com torch.utils.data.Dataset"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Estrutura básica do Dataset"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Vamos criar um dataset de exemplo utilizando como classe base [torch.utils.data.Dataset](http://pytorch.org/docs/master/data.html#torch.utils.data.Dataset).\n",
    "\n",
    "Para criar uma subclasse de `Dataset` é preciso definir as funções `__len__`, para retornar o tamanho do dataset, e `__getitem__`, para retornar um elemento de um índice dado.\n",
    "\n",
    "A função `__len__` é chamada quando usamos o método `len(dataset)` do Python e `__getitem__` é chamada quando fazemos a indexação `dataset[i]`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "from torch.utils.data import Dataset\n",
    "\n",
    "class MyDataset(Dataset):\n",
    "    def __len__(self):\n",
    "        pass\n",
    "    \n",
    "    def __getitem__(self):\n",
    "        pass"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Acima temos a estrutura básica de uma classe do Dataset, mas precisamos de dados, por isso vamos criar dados aleatórios para testar o seu funcionamento."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [],
   "source": [
    "### from torch.utils.data import Dataset\n",
    "\n",
    "class MyDataset(Dataset):\n",
    "    def __init__(self):\n",
    "        super(MyDataset, self).__init__()\n",
    "       \n",
    "        # gera 20 vetores de 3 elementos\n",
    "        self.data = torch.rand(20, 3)\n",
    "    \n",
    "    def __len__(self):\n",
    "        pass\n",
    "    \n",
    "    def __getitem__(self):\n",
    "        pass"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "No código acima utilizamos o método [torch.rand](http://pytorch.org/docs/master/torch.html#torch.rand) para gerar 20 vetores de 3 elementos (ou uma matrix 20x3) no construtor da classe, que serão nossos dados. \n",
    "\n",
    "Podemos, então, definir  `__len__` e `__getitem__`:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "from torch.utils.data import Dataset\n",
    "\n",
    "class MyDataset(Dataset):\n",
    "    def __init__(self):\n",
    "        super(MyDataset, self).__init__()\n",
    "        \n",
    "        # gera 20 vetores de 3 elementos\n",
    "        self.data = torch.rand(20, 3)\n",
    "    \n",
    "    def __len__(self):\n",
    "        # retorna o tamanho da primeira dimensão\n",
    "        return self.data.size(0)\n",
    "    \n",
    "    def __getitem__(self, i):\n",
    "        # retornar a i-ésima matriz 3x3 de data\n",
    "        return self.data[i, :]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Nossa classe está pronta, podemos criar um objeto dela."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Criando um objeto da nossa classe\n",
    "dataset = MyDataset()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Nosso método `__len__` deve retornar o tamanho da primeira dimensão dos dados (20), que é o tamanho de vetores de 3 elementos no dataset.\n",
    "\n",
    "Podemos verificar se o método está correto chamando o `len()` do Python:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "20\n"
     ]
    }
   ],
   "source": [
    "print(len(dataset))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Nosso método `__getitem__()` deve retornar o elemento na i-ésima posição no dataset, no nosso caso `data[i]`:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      " 0.0516\n",
      " 0.4421\n",
      " 0.8458\n",
      "[torch.FloatTensor of size 3]\n",
      "\n",
      "\n",
      " 0.0516\n",
      " 0.4421\n",
      " 0.8458\n",
      "[torch.FloatTensor of size 3]\n",
      "\n"
     ]
    }
   ],
   "source": [
    "i = 1\n",
    "print(dataset[i])\n",
    "# é equivalente à:\n",
    "print(dataset.data[i])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Incluindo a classe dos dados"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Um dataset também deve contém a classe a qual o dado pertence, a seguir incluiremos classes ao exemplo anterior."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [],
   "source": [
    "from torch.utils.data import Dataset\n",
    "\n",
    "class MyDataset(Dataset):\n",
    "    def __init__(self):\n",
    "        super(MyDataset, self).__init__()\n",
    "        \n",
    "        # gera 20 vetores de 3 elementos\n",
    "        self.data = torch.rand(20, 3)\n",
    "        # gera as 20 elementos contendo classes 0, 1 ou 2\n",
    "        self.classes = (torch.rand(20)*3).type(torch.LongTensor)\n",
    "    \n",
    "    def __len__(self):\n",
    "        # retorna o tamanho da primeira dimensão\n",
    "        return self.data.size(0)\n",
    "    \n",
    "    def __getitem__(self, i):\n",
    "        # retornar a i-ésima matriz 3x3 de data\n",
    "        return (self.data[i, :], self.classes[i])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Agora nosso método `__getitem__` retorna uma tupla (dado, classe)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "dado: \n",
      " 0.9795\n",
      " 0.7468\n",
      " 0.1999\n",
      "[torch.FloatTensor of size 3]\n",
      "\n",
      "classe: 0\n"
     ]
    }
   ],
   "source": [
    "dataset = MyDataset()\n",
    "\n",
    "data, label = dataset[1]\n",
    "\n",
    "print('dado:', data)\n",
    "print('classe:', label)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Conclusão"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "O caso apresentado neste tópico é muito simples, apresentando os conceitos básicos da estrutura que o Pytorch utiliza para representar datasets. A classe torch.utils.data.Dataset é usada para casos complexos em que é preciso, por exemplo, carregar o dataset de arquivos e quando o gerenciamento dos dados não é tão trivial."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## DataLoaders"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Um DataLoader ([torch.utils.data.DataLoader](http://pytorch.org/docs/master/data.html#torch.utils.data.DataLoader)) combina um Dataset e um Sampler (divide os dados em batches). Ele torna possível iterar sobre os dados utilizando vários processos (multi-process iterator) tornando o treinameto mais simples e rápido."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Criando um DataLoader"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Inicialmente vamos definir um dataset para ser a fonte de dados do nosso DataLoader."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "dimensões de x_data: (20, 3, 3)\n",
      "dimensões de target: (20,)\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import torch\n",
    "from torch.utils.data import TensorDataset\n",
    "\n",
    "# dados aleatorios  \n",
    "x_data = np.random.rand(20, 3, 3)            # 20 matrizes de 3x3 criadas aleatoriamente\n",
    "target = np.random.randint(0, 3, size=20)    # 20 classes 0, 1, ou 2 criadas aleatoriamente\n",
    "\n",
    "print('dimensões de x_data:', x_data.shape)\n",
    "print('dimensões de target:', target.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tamanho do dataset:  20\n"
     ]
    }
   ],
   "source": [
    "# transforma em tensores torch\n",
    "x_data = torch.from_numpy(x_data)\n",
    "target = torch.from_numpy(target)\n",
    "\n",
    "# usar TensorDataset para criar o dataset com os tensores\n",
    "dataset = TensorDataset(x_data, target)\n",
    "\n",
    "print('tamanho do dataset: ', len(dataset))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Agora podemos criar o DataLoader com o dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 171,
   "metadata": {},
   "outputs": [],
   "source": [
    "from torch.utils.data import DataLoader\n",
    "\n",
    "data_loader = DataLoader(dataset, \n",
    "                         batch_size=5,           # tamanho do batch de dados\n",
    "                         shuffle=False,          # se for True, embaralha os dados no inicio de cada iteração\n",
    "                         num_workers=2)          # número de processos criados para pegar os dados"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Iterando sobre o DataLoader"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Podemos iterar sobre o DataLoader utilizando um `for`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 149,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "batch  0\n",
      "batch  1\n",
      "batch  2\n",
      "batch  3\n",
      "tamanho do DataLoader 4\n"
     ]
    }
   ],
   "source": [
    "batch_n = 0\n",
    "\n",
    "for data in data_loader:\n",
    "    print('batch ', batch_n)\n",
    "    batch_n += 1\n",
    "    \n",
    "print('tamanho do DataLoader', len(data_loader))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "O tamanho do DataLoader é 4, pois temos batches de tamanho 5 e 20 dados no dataloader.\n",
    "\n",
    "Agora podemos utilizar os dados do DataLoader:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 150,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "dimensão do batch de dados 0:   torch.Size([5, 3, 3])\n",
      "dimensão do batch de classes 0: torch.Size([5])\n",
      "\n",
      "dimensão do batch de dados 1:   torch.Size([5, 3, 3])\n",
      "dimensão do batch de classes 1: torch.Size([5])\n",
      "\n",
      "dimensão do batch de dados 2:   torch.Size([5, 3, 3])\n",
      "dimensão do batch de classes 2: torch.Size([5])\n",
      "\n",
      "dimensão do batch de dados 3:   torch.Size([5, 3, 3])\n",
      "dimensão do batch de classes 3: torch.Size([5])\n",
      "\n"
     ]
    }
   ],
   "source": [
    "batch_n = 0\n",
    "\n",
    "for data in data_loader:\n",
    "    # separa a tupla em dados e classes\n",
    "    data_batch, targets_batch = data\n",
    "    \n",
    "    print('dimensão do batch de dados {}:   {}'.format(batch_n, data_batch.size()))\n",
    "    print('dimensão do batch de classes {}: {}\\n'.format(batch_n, targets_batch.size()))\n",
    "    batch_n += 1\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "É possível ver que os batches tem mesmo 5 dados (5 matrizes 3x3 e 5 classes)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Exercício"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Defina seu próprio DataLoader na segunda célula abaixo. Faça com que cada batch tenha 10 matrizes 3x3. Utilize o dataset já criado anteriormente.\n",
    "\n",
    "Em seguida complete o loop que itera sobre o seu DataLoader para que seja possível plotar as matrizes de cada batch. Utilize a função plot_batch para plotar as matrizes de um batch inteiro."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 176,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Código usado no exercício para plotar as imagens, NÃO É NECESSÁRIO ALTERAR\n",
    "import matplotlib.pyplot as plt\n",
    "import math \n",
    "\n",
    "def plot_batch(batch, batch_n):\n",
    "    fig = plt.figure(figsize=(5,2))\n",
    "    for j, mat in enumerate(batch):\n",
    "        plt.subplot(1, batch.size(0), j+1)\n",
    "        plt.imshow(mat.numpy(), cmap='gray')\n",
    "        plt.axis('off')\n",
    "    plt.suptitle('batch {} - {} elementos'.format(batch_n, batch.size(0)))\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 177,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "# -- Defina aqui seu DataLoader com batches de 10 elementos cada ---\n",
    "data_loader = None\n",
    "    \n",
    "# -- Defina aqui o loop sobre todo o DataLoader dando plot em cada batch com os dados\n",
    "for data in []:\n",
    "    # separe o dado das classes\n",
    "    \n",
    "    plot_batch([], batch_n)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- A ordem dos elementos se altera entre execuções da célula acima?\n",
    "- Tente colocar o parametro `shuffle` do DataLoader como `True` e obeseve o resultado do exercício, rodando várias vezes."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
