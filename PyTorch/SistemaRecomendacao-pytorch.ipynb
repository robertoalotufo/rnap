{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Sistema de Recomendação"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Este notebook apresenta algumas implementações de sistema de recomendação utilizando\n",
    "o dataset Movielens.\n",
    "Este notebook contém:\n",
    "- Modelo de Sistema de Recomendação utilizando atributos latentes e produto interno\n",
    "- Modelo utilizando atributos latentes concatenados e uma rede neural\n",
    "- Calcula a predição para todos os filmes e usuários que não fizeram suas avaliações\n",
    "- Visualiza a matriz de avaliações por usuários x filmes com todas as predições\n",
    "- Análise do significado dos embeddings"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Obs: Este notebook foi inspirado em exemplo divulgado pelo curso online disponível em [fast.ai](http://fast.ai)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Importação da bibliotecas"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2017-09-30T23:28:18.414616Z",
     "start_time": "2017-09-30T23:28:16.922827Z"
    },
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "%matplotlib inline\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import os, sys\n",
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2017-09-30T23:28:18.648894Z",
     "start_time": "2017-09-30T23:28:18.416885Z"
    },
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import torch\n",
    "from torch import nn\n",
    "from torch.autograd import Variable"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2017-09-30T23:28:18.662806Z",
     "start_time": "2017-09-30T23:28:18.651316Z"
    },
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "np.set_printoptions(formatter={'float': '{: 0.1f}'.format})\n",
    "\n",
    "# from course libs\n",
    "sys.path.append('./lib')\n",
    "from pytorch_utils import DeepNetTrainer"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Movielens dataset"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- [Movielens - Readme](http://files.grouplens.org/datasets/movielens/ml-latest-small-README.html)\n",
    "- Movielens - Small data set - 100.000 avaliações:[ml-latest-small.zip](http://files.grouplens.org/datasets/movielens/ml-latest-small.zip)\n",
    "\n",
    "F. Maxwell Harper and Joseph A. Konstan. 2015. The MovieLens Datasets: History and Context. ACM Transactions on Interactive Intelligent Systems (TiiS) 5, 4, Article 19 (December 2015).\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Leitura dos Dados - Movielens dataset"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Caso a célula a seguir falhar, é necessário executar o notebook:\n",
    "- [Movielens Dataset](MovieLens_dataset.ipynb) que é responsável por ler o dataset original e\n",
    "prepará-lo para este notebook\n",
    "\n",
    "Este dataset consiste de:\n",
    "- 100.004 avaliações de filmes (amostras), feitas por\n",
    "- 671 usuários, sobre\n",
    "- 9066 filmes\n",
    "\n",
    "As amostras estão no array `ratings` organizados da seguinte forma:\n",
    "- cada linha é uma amostra\n",
    "- coluna 0 é o iD do usuário\n",
    "- coluna 1 é o iD do filme\n",
    "- coluna 2 é a avaliação do usuários entre 0.0 e 5.0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2017-09-30T23:28:18.735906Z",
     "start_time": "2017-09-30T23:28:18.665383Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "n_samples: 100004\n",
      "ratings:\n",
      " [[ 0.0  30.0  2.5]\n",
      " [ 0.0  833.0  3.0]\n",
      " [ 0.0  859.0  3.0]\n",
      " [ 0.0  906.0  2.0]\n",
      " [ 0.0  931.0  4.0]]\n"
     ]
    }
   ],
   "source": [
    "data = np.load('../data/movielens_norm.npz')\n",
    "ratings = data['ratings']\n",
    "movie_names = data['movie_names']\n",
    "n_samples = ratings.shape[0]\n",
    "print('n_samples:',n_samples)\n",
    "print('ratings:\\n', ratings[:5])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2017-09-30T23:28:18.744512Z",
     "start_time": "2017-09-30T23:28:18.738049Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Dangerous Minds (1995)\n",
      "Dumbo (1941)\n",
      "Sleepers (1996)\n",
      "Escape from New York (1981)\n",
      "Cinema Paradiso (Nuovo cinema Paradiso) (1989)\n"
     ]
    }
   ],
   "source": [
    "for i in (ratings[:5,1]).astype(np.int):\n",
    "    print(movie_names[i])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2017-09-30T23:28:18.757779Z",
     "start_time": "2017-09-30T23:28:18.747142Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "n_users: 671\n",
      "n_movies: 9066\n"
     ]
    }
   ],
   "source": [
    "h_userId = np.bincount(ratings[:,0].astype(np.int))\n",
    "n_users = h_userId.size\n",
    "h_movieId = np.bincount(ratings[:,1].astype(np.int))\n",
    "n_movies = h_movieId.size\n",
    "print('n_users:',n_users)\n",
    "print('n_movies:',n_movies)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Divisão dos dados em treinamento e validação"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2017-09-30T23:28:18.766427Z",
     "start_time": "2017-09-30T23:28:18.760234Z"
    },
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "np.random.seed = 42"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Faz a divisão com 80% das amostras para treinamento e 20% para validação:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2017-09-30T23:28:18.791730Z",
     "start_time": "2017-09-30T23:28:18.769229Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train: 80005  amostras:\n",
      " [[ 0.0  30.0  2.5]\n",
      " [ 0.0  833.0  3.0]\n",
      " [ 0.0  859.0  3.0]\n",
      " [ 0.0  906.0  2.0]\n",
      " [ 0.0  1017.0  2.0]]\n",
      "valid: 19999  amostras:\n",
      " [[ 0.0  931.0  4.0]\n",
      " [ 0.0  1140.0  1.0]\n",
      " [ 0.0  1665.0  4.0]\n",
      " [ 1.0  37.0  5.0]\n",
      " [ 1.0  45.0  4.0]]\n"
     ]
    }
   ],
   "source": [
    "msk = np.random.rand(n_samples) < 0.8\n",
    "train = ratings[msk]\n",
    "valid = ratings[~msk]\n",
    "print('train:',train.shape[0],' amostras:\\n',train[:5])\n",
    "print('valid:',valid.shape[0],' amostras:\\n',valid[:5])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "`userId` e `movieId` precisam ser inteiros pois são entradas do *Embedding*:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2017-09-30T23:28:18.848597Z",
     "start_time": "2017-09-30T23:28:18.794329Z"
    }
   },
   "outputs": [],
   "source": [
    "train_userId =  torch.LongTensor(train[:,0].astype(np.int))\n",
    "train_movieId = torch.LongTensor(train[:,1].astype(np.int))\n",
    "train_ratings = torch.FloatTensor(train[:,2:3]) # importante que fique bidimensional\n",
    "valid_userId =  torch.LongTensor(valid[:,0].astype(np.int))\n",
    "valid_movieId = torch.LongTensor(valid[:,1].astype(np.int))\n",
    "valid_ratings = torch.FloatTensor(valid[:,2:3]) # importante que fique bidimensional"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Definição da classe MLDataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2017-09-30T23:28:18.876075Z",
     "start_time": "2017-09-30T23:28:18.851336Z"
    }
   },
   "outputs": [],
   "source": [
    "from torch.utils.data import Dataset\n",
    "class MLDataset(Dataset):\n",
    "    \n",
    "    def __init__(self, data_user, data_movie, target):\n",
    "        assert data_user.size(0) == target.size(0) and \\\n",
    "               data_movie.size(0) == target.size(0)\n",
    "        \n",
    "        self.data = torch.transpose(torch.stack( (data_user, data_movie) ),0,1)\n",
    "        self.target = target\n",
    "    \n",
    "    def __len__(self):\n",
    "        return self.target.size(0)\n",
    "    \n",
    "    def __getitem__(self, i):\n",
    "        return (self.data[i], self.target[i])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Criação dos objetos datasets e dataloaders"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2017-09-30T23:28:18.901479Z",
     "start_time": "2017-09-30T23:28:18.880619Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'train': 80005, 'val': 19999}\n"
     ]
    }
   ],
   "source": [
    "datasets = {\n",
    "    'train': MLDataset(train_userId, train_movieId, train_ratings),\n",
    "    'val'  : MLDataset(valid_userId, valid_movieId, valid_ratings)\n",
    "    }\n",
    "\n",
    "dataloaders = {\n",
    "    'train': torch.utils.data.DataLoader(datasets['train'], batch_size=64, shuffle=True, num_workers=4),\n",
    "    'val'  : torch.utils.data.DataLoader(datasets['val'], batch_size=64, shuffle=True, num_workers=4)\n",
    "    }\n",
    "\n",
    "dataset_sizes = {\n",
    "    'train': len(datasets['train']),\n",
    "    'val'  : len(datasets['val'])\n",
    "    }\n",
    "\n",
    "print(dataset_sizes)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Testando os datasets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2017-09-30T23:47:28.052413Z",
     "start_time": "2017-09-30T23:47:28.044755Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "   0  906\n",
      "[torch.LongTensor of size 1x2]\n",
      "\n",
      "\n",
      " 2\n",
      "[torch.FloatTensor of size 1x1]\n",
      "\n"
     ]
    }
   ],
   "source": [
    "x, y = datasets['train'][3:4]\n",
    "print(x)\n",
    "print(y)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Testando os dataloaders"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2017-09-30T23:47:39.109086Z",
     "start_time": "2017-09-30T23:47:39.045967Z"
    },
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "20032\n",
      "0 64 64\n",
      "1 64 64\n",
      "2 64 64\n"
     ]
    }
   ],
   "source": [
    "batch_size = 64\n",
    "print( len(dataloaders['val']) * batch_size ) # verificando mini-batches\n",
    "for k,data in enumerate(dataloaders['val']):\n",
    "    print(k, len(data[0]), len(data[1]))\n",
    "    if k > 1: break"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "## Primeira solução - usando produto interno: Dot"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<img src='../figures/Recomendacao_dot.png', width=600ptx></img>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "O primeiro modelo é o produto interno entre os atributos latentes dos usuários e dos filmes.\n",
    "Este produto interno é implementado pela operação `dot` do Keras. Como o modelo agora não é\n",
    "sequencial, há necessidade de utilizarmos o modelo API:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2017-09-30T23:28:19.025196Z",
     "start_time": "2017-09-30T23:28:19.008260Z"
    },
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "class DotNet(nn.Module):\n",
    "    def __init__(self, n_users, n_movies, n_attributes):\n",
    "        \"\"\"\n",
    "        No construtor, criamos as duas embeddings, uma para os usuários e \n",
    "        outra para os filmes.\n",
    "        \"\"\"\n",
    "        super(DotNet, self).__init__()\n",
    "        self.user_emb  = nn.Embedding(n_users, n_attributes)\n",
    "        self.movie_emb = nn.Embedding(n_movies, n_attributes)\n",
    "\n",
    "    def forward(self, x):\n",
    "        \"\"\"\n",
    "        x: (user_id, movie_id)\n",
    "        \"\"\"\n",
    "        user_id  = x[:,0]\n",
    "        movie_id = x[:,1]\n",
    "        user_attr  = self.user_emb(user_id)\n",
    "        movie_attr = self.movie_emb(movie_id)\n",
    "        y_pred = (user_attr * movie_attr).sum(1)\n",
    "        return y_pred\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Instanciando a rede"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2017-09-30T23:28:19.093368Z",
     "start_time": "2017-09-30T23:28:19.027499Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "DotNet (\n",
       "  (user_emb): Embedding(671, 50)\n",
       "  (movie_emb): Embedding(9066, 50)\n",
       ")"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "n_factors = 50\n",
    "model_dot = DotNet(n_users, n_movies, n_factors)\n",
    "model_dot"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Testando o predict e o loss da rede com poucos dados e sem treinar"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2017-09-30T23:28:19.118112Z",
     "start_time": "2017-09-30T23:28:19.096446Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "   0   30\n",
      "   0  833\n",
      "   0  859\n",
      "[torch.LongTensor of size 3x2]\n",
      "\n",
      "Variable containing:\n",
      "-8.9329\n",
      "-3.2705\n",
      "-5.3418\n",
      "[torch.FloatTensor of size 3]\n",
      "\n",
      "Variable containing:\n",
      " 79.8723\n",
      "[torch.FloatTensor of size 1]\n",
      "\n"
     ]
    }
   ],
   "source": [
    "criterion = nn.MSELoss(size_average=True)\n",
    "data_um = torch.transpose(torch.stack( (train_userId[0:3],train_movieId[0:3]) ),1,0)\n",
    "print(data_um)\n",
    "y_pred = model_dot(Variable(data_um))\n",
    "print(y_pred)\n",
    "loss = criterion(y_pred, Variable(train_ratings[0:3]))\n",
    "print(loss)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Testando o predict e loss com dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2017-09-30T23:28:19.138215Z",
     "start_time": "2017-09-30T23:28:19.123634Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "   0  906\n",
      "[torch.LongTensor of size 1x2]\n",
      "\n",
      "\n",
      " 2\n",
      "[torch.FloatTensor of size 1x1]\n",
      "\n",
      "Variable containing:\n",
      "-2.7927\n",
      "[torch.FloatTensor of size 1]\n",
      "\n",
      "Variable containing:\n",
      " 22.9697\n",
      "[torch.FloatTensor of size 1]\n",
      "\n"
     ]
    }
   ],
   "source": [
    "x,y = datasets['train'][3:4]\n",
    "print(x)\n",
    "print(y)\n",
    "y_pred = model_dot(Variable(x))\n",
    "print(y_pred)\n",
    "loss = criterion(y_pred, Variable(y))\n",
    "print(loss)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Testando o predict e o dataset"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Treinando a rede"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Verificando se um pequeno conjunto de dados consegue treinar a rede"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2017-10-01T00:42:57.566677Z",
     "start_time": "2017-10-01T00:42:57.366454Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0 26.89550018310547\n",
      "1 26.700855255126953\n",
      "2 26.50751304626465\n",
      "3 26.315481185913086\n",
      "4 26.124956130981445\n",
      "5 25.935815811157227\n",
      "6 25.748126983642578\n",
      "7 25.5617733001709\n",
      "8 25.376920700073242\n",
      "9 25.193567276000977\n"
     ]
    }
   ],
   "source": [
    "batch_size = 6400\n",
    "criterion = nn.MSELoss()\n",
    "#optimizer = torch.optim.SGD(model_dot.parameters(), lr=1e-1)\n",
    "optimizer = torch.optim.Adam(model_dot.parameters())\n",
    "for t in range(10):\n",
    "    # Forward pass: Compute predicted y by passing x to the model\n",
    "    data_um = torch.transpose(torch.stack( (train_userId[0:batch_size],\n",
    "                                            train_movieId[0:batch_size]) ),0,1)\n",
    "\n",
    "    y_pred = model_dot((Variable(data_um)))\n",
    "\n",
    "    # Compute and print loss\n",
    "    loss = criterion(y_pred, Variable(train_ratings[:batch_size]))\n",
    "    print(t, loss.data[0])\n",
    "\n",
    "    # Zero gradients, perform a backward pass, and update the weights.\n",
    "    optimizer.zero_grad()\n",
    "    loss.backward()\n",
    "    optimizer.step()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2017-10-01T00:43:06.934850Z",
     "start_time": "2017-10-01T00:43:05.563614Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "14.412419885018407"
      ]
     },
     "execution_count": 58,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "a = torch.pow(y_pred.data - train_ratings[:batch_size],2).mean()\n",
    "a = torch.pow(y_pred.data ,2).mean()\n",
    "a"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2017-10-01T00:43:10.113516Z",
     "start_time": "2017-10-01T00:43:10.100036Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model loaded from ../../models/Recomendacao_dot.model\n"
     ]
    }
   ],
   "source": [
    "trainer = DeepNetTrainer(file_basename='../../models/Recomendacao_dot', \n",
    "                         model=model_dot, \n",
    "                         criterion=criterion, \n",
    "                         optimizer=optimizer, \n",
    "                         #lr_scheduler=exp_lr_scheduler,\n",
    "                         #metrics=metrics,\n",
    "                         reset=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "start_time": "2017-10-01T03:43:11.313Z"
    },
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Starting training for 200 epochs\n",
      "\n",
      " 37:   0.0s   T: 32.59958   V: 39.09452 best\n",
      " 38:  11.4s   T: 30.80627   V: 35.53824 best\n",
      " 39:  17.7s   T: 25.27228   V: 32.82726 best\n",
      " 40:  17.2s   T: 20.94904   V: 30.59887 best\n",
      " 41:  17.3s   T: 17.50834   V: 28.64466 best\n",
      " 42:  17.5s   T: 14.56231   V: 26.79902 best\n",
      " 43:  18.7s   T: 11.96924   V: 24.84748 best\n",
      " 44:  18.6s   T: 9.57837   V: 22.77557 best\n",
      " 45:  18.9s   T: 7.39973   V: 20.58994 best\n",
      " 46:  18.7s   T: 5.54455   V: 18.55400 best\n",
      " 47:  18.8s   T: 4.09127   V: 16.76489 best\n",
      " 48:  18.9s   T: 3.03149   V: 15.29595 best\n",
      " 49:  18.7s   T: 2.27597   V: 14.11400 best\n",
      " 50:  19.0s   T: 1.74406   V: 13.16956 best\n",
      " 51:  18.9s   T: 1.36700   V: 12.38711 best\n",
      " 52:  18.8s   T: 1.09069   V: 11.72898 best\n",
      " 53:  19.1s   T: 0.89112   V: 11.20232 best\n",
      " 54:  19.0s   T: 0.74250   V: 10.75294 best\n",
      " 55:  19.0s   T: 0.63340   V: 10.39412 best\n",
      " 56:  19.2s   T: 0.54887   V: 10.05649 best\n",
      " 57:  19.6s   T: 0.48588   V: 9.81799 best\n",
      " 58:  19.0s   T: 0.43647   V: 9.59381 best\n",
      " 59:  19.0s   T: 0.39752   V: 9.40377 best\n",
      " 60:  19.1s   T: 0.36730   V: 9.24774 best\n",
      " 61:  19.6s   T: 0.34162   V: 9.13475 best\n"
     ]
    }
   ],
   "source": [
    "trainer.fit(n_epochs=200, \n",
    "            train_data = dataloaders['train'], \n",
    "            valid_data = dataloaders['val'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Avaliando a rede"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2017-09-30T23:28:27.531874Z",
     "start_time": "2017-10-01T02:28:16.756Z"
    }
   },
   "outputs": [],
   "source": [
    "model = test_network(model_name, [valid_userId, valid_movieId], valid_ratings)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Os bons modelos [best benchmarks](http://www.librec.net/example.html) são próximos de 0.9, há necessidade de melhorias."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Predição de usuário e filme"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Para calcular qualquer predição de qualquer usuário e qualquer filme, usa-se o `predict` do modelo treinado:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2017-09-30T23:28:27.532231Z",
     "start_time": "2017-10-01T02:28:16.763Z"
    }
   },
   "outputs": [],
   "source": [
    "model.predict([np.array([3]), np.array([6])])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##  Usado Rede Neural"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<img src='../figures/Recomendacao_NN.png', width=600ptx></img>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Uma solução usando rede neural é concatenar a saída dos embeddings e em seguida colocar uma camada densa\n",
    "antes da última camada de um neurônio. No exemplo a seguir foi utilizado uma camada de 70 neurônios."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2017-09-30T23:28:27.532531Z",
     "start_time": "2017-10-01T02:28:16.769Z"
    },
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "user_in = Input(shape=(1,),dtype='int64', name='user_in')\n",
    "u = Embedding(n_users, n_factors, input_length=1, \n",
    "              embeddings_regularizer=l2(1e-4))(user_in)\n",
    "\n",
    "movie_in = Input(shape=(1,),dtype='int64', name='movie_in')\n",
    "m = Embedding(n_movies, n_factors, input_length=1, \n",
    "              embeddings_regularizer=l2(1e-4))(movie_in)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2017-09-30T23:28:27.532820Z",
     "start_time": "2017-10-01T02:28:16.775Z"
    }
   },
   "outputs": [],
   "source": [
    "x = keras.layers.concatenate([u, m])\n",
    "x = Flatten()(x)\n",
    "x = Dropout(0.3)(x)\n",
    "x = Dense(70, activation='relu')(x)\n",
    "x = Dropout(0.75)(x)\n",
    "x = Dense(1)(x)\n",
    "model_nn = Model([user_in, movie_in], x)\n",
    "print(model_nn.summary())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Treinando a rede"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2017-09-30T23:28:27.533104Z",
     "start_time": "2017-10-01T02:28:16.781Z"
    }
   },
   "outputs": [],
   "source": [
    "model_name = '../../models/Recomendacao_nn'\n",
    "fit_params = {\n",
    "    'model_name': model_name,\n",
    "    'loss':       'mse',\n",
    "    'opt':        Adam(), \n",
    "    'batch_size': 64, \n",
    "    'nepochs':    10,\n",
    "    'patience':   5,\n",
    "    'ploss':      3.,\n",
    "    'reset':      False,\n",
    "}\n",
    "\n",
    "train_network(model_nn, \n",
    "              [train_userId, train_movieId], train_ratings, \n",
    "              [valid_userId, valid_movieId], valid_ratings, **fit_params);"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Avaliando a rede"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2017-09-30T23:28:27.533382Z",
     "start_time": "2017-10-01T02:28:16.786Z"
    }
   },
   "outputs": [],
   "source": [
    "model_nn = test_network(model_name, [valid_userId, valid_movieId], valid_ratings)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2017-09-30T23:28:27.533648Z",
     "start_time": "2017-10-01T02:28:16.791Z"
    }
   },
   "outputs": [],
   "source": [
    "model_nn.predict([np.array([3]), np.array([6])])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Com esta rede, a perda já é bem melhor, comparável com os melhores sistemas de recomendação."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Matriz de recomendações, por usuário e por filme"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "O sistema de recomendação pode ser visualizado por uma matriz onde as linhas sejam os\n",
    "IDs dos usuários e as colunas sejam os IDs dos títulos dos filmes. Colocamos como -1\n",
    "os elementos em que não existem avaliações. Esta matriz é bastante esparsa, pois existem\n",
    "normalmente poucas avaliações feitas."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2017-09-30T23:28:27.533925Z",
     "start_time": "2017-10-01T02:28:16.798Z"
    }
   },
   "outputs": [],
   "source": [
    "grid_ratings = -1. * np.ones((n_users,n_movies))\n",
    "uId = (ratings[:,0]).astype(np.int)\n",
    "mId = (ratings[:,1]).astype(np.int)\n",
    "grid_ratings[uId,mId] = ratings[:,2] # Criação da matriz\n",
    "print(grid_ratings.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Visualização da matriz de recomendações, original"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2017-09-30T23:28:27.534397Z",
     "start_time": "2017-10-01T02:28:16.804Z"
    }
   },
   "outputs": [],
   "source": [
    "show_ratings = np.zeros((n_users,n_movies,3))\n",
    "show_ratings[:,:,0] = np.where(grid_ratings == -1., 5, grid_ratings)\n",
    "show_ratings[:,:,1] = np.where(grid_ratings == -1., 0., grid_ratings)\n",
    "show_ratings[:,:,2] = np.where(grid_ratings == -1., 0., grid_ratings)\n",
    "\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "plt.figure(figsize=(7,7))\n",
    "plt.title('usuários (linhas) x filmes (colunas)')\n",
    "plt.imshow(show_ratings[:150,:150,:])\n",
    "plt.xlabel('filmes')\n",
    "plt.ylabel('usuários')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Predições para todos os usuários e filmes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2017-09-30T23:28:27.534718Z",
     "start_time": "2017-10-01T02:28:16.811Z"
    }
   },
   "outputs": [],
   "source": [
    "n2p_user,n2p_movie = np.nonzero(grid_ratings==-1)\n",
    "recommend = model_nn.predict([n2p_user, n2p_movie])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Montagem da matriz de recomendação \"cheia\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2017-09-30T23:28:27.535015Z",
     "start_time": "2017-10-01T02:28:16.816Z"
    }
   },
   "outputs": [],
   "source": [
    "gg = grid_ratings.copy()\n",
    "gg[n2p_user,n2p_movie] = recommend[:,0]\n",
    "\n",
    "plt.figure(figsize=(8,8))\n",
    "plt.title('usuários (linhas) x filmes (colunas)')\n",
    "plt.xlabel('usuarios')\n",
    "plt.ylabel('filmes')\n",
    "plt.imshow(gg[:150,:150],cmap='gray')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Visualização de uma parte da matriz"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2017-09-30T23:28:27.535433Z",
     "start_time": "2017-10-01T02:28:16.822Z"
    }
   },
   "outputs": [],
   "source": [
    "plt.figure(figsize=(8,8))\n",
    "plt.imshow(show_ratings[:150,:150,:])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Visualização da parte de usuários mais ativos e filmes mais populares"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2017-09-30T23:28:27.535935Z",
     "start_time": "2017-10-01T02:28:16.827Z"
    }
   },
   "outputs": [],
   "source": [
    "io_popular_movies = np.argsort(h_movieId)[::-1]\n",
    "io_top_users = np.argsort(h_userId)[::-1].astype(np.int)\n",
    "gg_ord = gg[np.ix_(io_top_users,io_popular_movies)]\n",
    "plt.figure(figsize=(7,7))\n",
    "plt.title('usuários (linhas) x filmes (colunas)')\n",
    "plt.imshow(gg_ord[:150,:150],cmap='gray')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Visualização dos usuários menos ativos e filmes menos avaliados"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2017-09-30T23:28:27.536396Z",
     "start_time": "2017-10-01T02:28:16.833Z"
    }
   },
   "outputs": [],
   "source": [
    "plt.figure(figsize=(7,7))\n",
    "plt.title('usuários (linhas) x filmes (colunas)')\n",
    "plt.imshow(gg_ord[-150:,-150:],cmap='gray')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Analise dos embeddings dos filmes"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "A análise a seguir será feita apenas com os 2000 filmes mais populares:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2017-09-30T23:28:27.536733Z",
     "start_time": "2017-10-01T02:28:16.838Z"
    }
   },
   "outputs": [],
   "source": [
    "topMovies = io_popular_movies[:2000]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Extração dos atributos latentes (embeddings) dos 2000 fimes mais populares"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Para obter os atributos latentes dos 2000 filmes mais populares, primeiro criamos uma\n",
    "nova rede, denominada `get_movie_emb`, a partir da rede `Model`, com a entrada apenas o ID dos filmes e\n",
    "a saída `m`, após o embedding. Aplicamos a predição desta rede nos `topMovies`:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2017-09-30T23:28:27.537016Z",
     "start_time": "2017-10-01T02:28:16.844Z"
    }
   },
   "outputs": [],
   "source": [
    "get_movie_emb = Model(movie_in, m)\n",
    "m_emb = get_movie_emb.predict([topMovies])\n",
    "movie_emb = np.squeeze(m_emb) # elimina dimensões 1\n",
    "print(m_emb.shape)\n",
    "movie_emb.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Como o embedding de cada filme tem dimensão 50, é muito difícil conseguir analisá-lo desta forma.\n",
    "Uma forma muito usual é reduzir esta dimensionalidade utilizando uma técnica denominada PCA -\n",
    "Principal Component Analysis: [PCA](https://plot.ly/ipython-notebooks/principal-component-analysis/).\n",
    "Iremos reduzir a dimensão dos embeddings de 50 para 3. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2017-09-30T23:28:27.537308Z",
     "start_time": "2017-10-01T02:28:16.850Z"
    },
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from sklearn.decomposition import PCA\n",
    "pca = PCA(n_components=3)\n",
    "movie_pca = pca.fit(movie_emb.T).components_"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Filmes com alto valor na primeira dimensão do PCA"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2017-09-30T23:28:27.537587Z",
     "start_time": "2017-10-01T02:28:16.856Z"
    }
   },
   "outputs": [],
   "source": [
    "fac0 = movie_pca[0]\n",
    "isort = np.argsort(fac0)[::-1]\n",
    "\n",
    "for ii in isort[:15]:\n",
    "    print(fac0[ii],movie_names[ii])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Filmes com baixo valor na primeira dimensão do PCA"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2017-09-30T23:28:27.537853Z",
     "start_time": "2017-10-01T02:28:16.861Z"
    }
   },
   "outputs": [],
   "source": [
    "for ii in isort[-15:]:\n",
    "    print(fac0[ii],movie_names[ii])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Análise da segunda dimensão do PCA"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2017-09-30T23:28:27.538124Z",
     "start_time": "2017-10-01T02:28:16.867Z"
    },
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "fac1 = movie_pca[1]\n",
    "isort = np.argsort(fac1)[::-1]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Mais bem avaliados na segunda dimensão"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2017-09-30T23:28:27.538397Z",
     "start_time": "2017-10-01T02:28:16.872Z"
    }
   },
   "outputs": [],
   "source": [
    "for ii in isort[:15]:\n",
    "    print(fac1[ii],movie_names[ii])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Piores avaliados na segunda dimensão"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2017-09-30T23:28:27.538663Z",
     "start_time": "2017-10-01T02:28:16.878Z"
    }
   },
   "outputs": [],
   "source": [
    "for ii in isort[-15:]:\n",
    "    print(fac1[ii],movie_names[ii])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Análise da terceira dimensão do PCA"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2017-09-30T23:28:27.538941Z",
     "start_time": "2017-10-01T02:28:16.886Z"
    },
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "fac2 = movie_pca[2]\n",
    "isort = np.argsort(fac2)[::-1]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2017-06-11T07:23:06.447188",
     "start_time": "2017-06-11T07:23:06.443940"
    }
   },
   "source": [
    "#### Mais bem avaliados na terceira dimensão do PCA"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2017-09-30T23:28:27.539220Z",
     "start_time": "2017-10-01T02:28:16.894Z"
    }
   },
   "outputs": [],
   "source": [
    "for ii in isort[:15]:\n",
    "    print(fac2[ii],movie_names[ii])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Piores avaliados na terceira dimensão do PCA"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2017-09-30T23:28:27.539611Z",
     "start_time": "2017-10-01T02:28:16.901Z"
    }
   },
   "outputs": [],
   "source": [
    "for ii in isort[-15:]:\n",
    "    print(fac2[ii],movie_names[ii])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Visualizando duas dimensões do PCA"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2017-09-30T23:28:27.539970Z",
     "start_time": "2017-10-01T02:28:16.909Z"
    }
   },
   "outputs": [],
   "source": [
    "start=50; end=100\n",
    "X = fac0[start:end]\n",
    "Y = fac2[start:end]\n",
    "plt.figure(figsize=(15,15))\n",
    "plt.scatter(X, Y)\n",
    "for i, x, y in zip(topMovies[start:end], X, Y):\n",
    "    plt.text(x,y,movie_names[i], color=np.random.rand(3)*0.7, fontsize=14)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Exercícios"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "1. Inclua um novo usuário, sem nenhuma avaliação. Treine a rede e verifique\n",
    "   se após a rede treinada, se haverá alguma avaliação.\n",
    "2. Com o novo usuário, faça uma única avaliação e verifique quais os 10 filmes\n",
    "   mais recomendados para ele."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "## Aprendizados com este notebook"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.0"
  },
  "toc": {
   "nav_menu": {
    "height": "119px",
    "width": "252px"
   },
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": false,
   "toc_cell": false,
   "toc_position": {},
   "toc_section_display": "block",
   "toc_window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
