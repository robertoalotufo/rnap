{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Redes totalmente convolucionais"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Este notebook aborda os seguintes aspectos relacionados às redes totalmente convolucionais:\n",
    "\n",
    "- como transformar uma camada densa em convolucional, aproveitando seus pesos;\n",
    "- como criar, a partir de uma rede pré-treinada para classificar imagens, uma rede totalmente convolucional;\n",
    "- demonstrar que uma rede totalmente convolucional, quando aplicada em imagens maiores que aquelas usadas em seu treinamento, implementa uma varredura implícita com ganhos de eficiência.\n",
    "- apresentar um método para aumentar a resolução (*shift-and-stitch*)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Motivação"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Rede 2 camadas convolucionais e 2 camadas densas"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<img src='../figures/Rede_LeNet_like.png', width=800pt></img>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Rede equivalente com 4 camadas convolucionais "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<img src='../figures/Rede_LeNet_like_fully_convolutional.png', width=800pt></img>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Importando os módulos"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "%matplotlib inline\n",
    "\n",
    "import numpy as np\n",
    "import sys,os\n",
    "import matplotlib.pyplot as plt\n",
    "from IPython import display\n",
    "from collections import OrderedDict\n",
    "\n",
    "# from torch\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "from torch.autograd import Variable\n",
    "from torch.optim import lr_scheduler\n",
    "\n",
    "# from torchvision\n",
    "import torchvision\n",
    "import torchvision.transforms as transforms\n",
    "from torchvision.datasets import MNIST\n",
    "\n",
    "# from course libs\n",
    "sys.path.append('./lib')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2017-05-28T20:00:13.497594",
     "start_time": "2017-05-28T20:00:08.009441"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Usando GPU: False\n"
     ]
    }
   ],
   "source": [
    "# verifica se a GPU esta disponivel\n",
    "use_gpu = torch.cuda.is_available()\n",
    "print(\"Usando GPU:\", use_gpu)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Carregando MNIST dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2017-05-28T20:00:14.824860",
     "start_time": "2017-05-28T20:00:13.546991"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Amostras para treinamento: 60000\n",
      "Amostras para validação: 10000\n",
      "<class 'torch.ByteTensor'>\n",
      "torch.Size([60000, 28, 28])\n",
      "0 255\n",
      "['__class__', '__delattr__', '__dict__', '__dir__', '__doc__', '__eq__', '__format__', '__ge__', '__getattribute__', '__getitem__', '__gt__', '__hash__', '__init__', '__init_subclass__', '__le__', '__len__', '__lt__', '__module__', '__ne__', '__new__', '__reduce__', '__reduce_ex__', '__repr__', '__setattr__', '__sizeof__', '__str__', '__subclasshook__', '__weakref__', '_check_exists', 'download', 'processed_folder', 'raw_folder', 'root', 'target_transform', 'test_file', 'train', 'train_data', 'train_labels', 'training_file', 'transform', 'urls']\n",
      "<torchvision.transforms.ToTensor object at 0x7f618568f5f8>\n",
      "[<class 'torch.FloatTensor'>, <class 'torch.LongTensor'>]\n"
     ]
    }
   ],
   "source": [
    "dataset_dir = '/data/datasets/MNIST/'\n",
    "\n",
    "# Transformara os dados em tensores no intervalo [0.0, 1.0] (Os dados serão normalizados)\n",
    "data_transform = transforms.ToTensor()\n",
    "# data_transform = None\n",
    "\n",
    "# carrega o conjunto de treinamento e de teste\n",
    "datasets = {\n",
    "    'train': MNIST(dataset_dir, train=True, transform=data_transform, download=False),\n",
    "    'val': MNIST(dataset_dir, train=False, transform=data_transform, download=False),\n",
    "}\n",
    "\n",
    "print('Amostras para treinamento:', len(datasets['train']))\n",
    "print('Amostras para validação:', len(datasets['val']))\n",
    "print(type(datasets['train'].train_data))\n",
    "print(datasets['train'].train_data.size())\n",
    "print(datasets['train'].train_data.min(), datasets['train'].train_data.max())\n",
    "print(dir(datasets['train']))\n",
    "print(datasets['train'].transform)\n",
    "dl = torch.utils.data.DataLoader(dataset=datasets['train'], batch_size=1)\n",
    "a = next(iter(dl))\n",
    "print(list(map(type, a)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Pequena amostra apenas para testar o código"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2017-05-28T20:00:17.173586",
     "start_time": "2017-05-28T20:00:17.165912"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Amostras para treinamento: 1000\n",
      "Amostras para validação: 500\n"
     ]
    }
   ],
   "source": [
    "if True:\n",
    "    n_samples_train = 1000\n",
    "    n_samples_test  = 500\n",
    "\n",
    "    datasets['train'].train_data = datasets['train'].train_data[:n_samples_train]\n",
    "    datasets['train'].train_labels = datasets['train'].train_labels[:n_samples_train]\n",
    "    datasets['val'].test_data = datasets['val'].test_data[:n_samples_test]\n",
    "    datasets['val'].test_labels = datasets['val'].test_labels[:n_samples_test]\n",
    "    \n",
    "    print('Amostras para treinamento:', len(datasets['train']))\n",
    "    print('Amostras para validação:', len(datasets['val']))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Definição do modelo com camadas densas (igual ao notebook anterior)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "class MyModel(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(MyModel, self).__init__()\n",
    "        \n",
    "        # Camadas convolucionais\n",
    "        self.conv_layer = nn.Sequential(OrderedDict([\n",
    "            # lembrar de usar zero padding para manter o tamanho da imagem\n",
    "            ('conv1', nn.Conv2d(in_channels=1, out_channels=20, kernel_size=5, padding=2)),   \n",
    "            ('relu1', nn.ReLU()),\n",
    "            ('max_pool1', nn.MaxPool2d(2)),\n",
    "\n",
    "            ('conv2', nn.Conv2d(in_channels=20, out_channels=50, kernel_size=5, padding=2)),\n",
    "            ('relu2', nn.ReLU()),\n",
    "            ('max_pool2', nn.MaxPool2d(2)),\n",
    "            \n",
    "            ('drop', nn.Dropout(p=0.5))\n",
    "        ]))\n",
    "        \n",
    "        # Camadas densas\n",
    "        self.dense_layer = nn.Sequential(OrderedDict([\n",
    "            ('dense1', nn.Linear(in_features=2450, out_features=50)),\n",
    "            ('relu1', nn.ReLU()),\n",
    "            ('dense2', nn.Linear(in_features=50, out_features=10)),\n",
    "        ]))\n",
    "        \n",
    "    def forward(self, x):\n",
    "        x = self.conv_layer(x)\n",
    "        x = x.view(-1, 2450)  # Transforma a matriz em vetor\n",
    "        x = self.dense_layer(x)\n",
    "        \n",
    "        return x"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Carregando nosso modelo pré-treinado anteriormente"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Iremos converter a rede já treinada no exemplo anterior. Caso a próxima célula deste notebook\n",
    "der erro, é muito provável que o modelo da rede não foi salvo. Deve-se portanto executar o notebook:\n",
    "\n",
    "- [keras-lenet-mnist.ipynb](keras-lenet-mnist.ipynb)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2017-05-28T20:00:20.621276",
     "start_time": "2017-05-28T20:00:19.162809"
    }
   },
   "outputs": [],
   "source": [
    "model_name = '/data/models/lenet-mnist.model'\n",
    "saved_weights = torch.load(model_name)\n",
    "\n",
    "model_dense = MyModel()\n",
    "model_dense.load_state_dict(saved_weights)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'torch.ByteTensor'>\n",
      "torch.Size([10000, 28, 28])\n"
     ]
    },
    {
     "ename": "ValueError",
     "evalue": "Expected 4D tensor as input, got 3D tensor instead.",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-36-436752690a07>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtype\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdatasets\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'val'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtest_data\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdatasets\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'val'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtest_data\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msize\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 6\u001b[0;31m \u001b[0mmodel_dense\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdatasets\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'val'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtest_data\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m/usr/local/lib/python3.6/site-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, *input, **kwargs)\u001b[0m\n\u001b[1;32m    222\u001b[0m         \u001b[0;32mfor\u001b[0m \u001b[0mhook\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_forward_pre_hooks\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mvalues\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    223\u001b[0m             \u001b[0mhook\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minput\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 224\u001b[0;31m         \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mforward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    225\u001b[0m         \u001b[0;32mfor\u001b[0m \u001b[0mhook\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_forward_hooks\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mvalues\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    226\u001b[0m             \u001b[0mhook_result\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mhook\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mresult\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m<ipython-input-5-3d3828f43460>\u001b[0m in \u001b[0;36mforward\u001b[0;34m(self, x)\u001b[0m\n\u001b[1;32m     25\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     26\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mforward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mx\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 27\u001b[0;31m         \u001b[0mx\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mconv_layer\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     28\u001b[0m         \u001b[0mx\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mx\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mview\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m-\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m2450\u001b[0m\u001b[0;34m)\u001b[0m  \u001b[0;31m# Transforma a matriz em vetor\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     29\u001b[0m         \u001b[0mx\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdense_layer\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.6/site-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, *input, **kwargs)\u001b[0m\n\u001b[1;32m    222\u001b[0m         \u001b[0;32mfor\u001b[0m \u001b[0mhook\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_forward_pre_hooks\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mvalues\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    223\u001b[0m             \u001b[0mhook\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minput\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 224\u001b[0;31m         \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mforward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    225\u001b[0m         \u001b[0;32mfor\u001b[0m \u001b[0mhook\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_forward_hooks\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mvalues\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    226\u001b[0m             \u001b[0mhook_result\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mhook\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mresult\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.6/site-packages/torch/nn/modules/container.py\u001b[0m in \u001b[0;36mforward\u001b[0;34m(self, input)\u001b[0m\n\u001b[1;32m     65\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mforward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minput\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     66\u001b[0m         \u001b[0;32mfor\u001b[0m \u001b[0mmodule\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_modules\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mvalues\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 67\u001b[0;31m             \u001b[0minput\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmodule\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     68\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0minput\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     69\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.6/site-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, *input, **kwargs)\u001b[0m\n\u001b[1;32m    222\u001b[0m         \u001b[0;32mfor\u001b[0m \u001b[0mhook\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_forward_pre_hooks\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mvalues\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    223\u001b[0m             \u001b[0mhook\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minput\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 224\u001b[0;31m         \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mforward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    225\u001b[0m         \u001b[0;32mfor\u001b[0m \u001b[0mhook\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_forward_hooks\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mvalues\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    226\u001b[0m             \u001b[0mhook_result\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mhook\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mresult\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.6/site-packages/torch/nn/modules/conv.py\u001b[0m in \u001b[0;36mforward\u001b[0;34m(self, input)\u001b[0m\n\u001b[1;32m    252\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mforward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minput\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    253\u001b[0m         return F.conv2d(input, self.weight, self.bias, self.stride,\n\u001b[0;32m--> 254\u001b[0;31m                         self.padding, self.dilation, self.groups)\n\u001b[0m\u001b[1;32m    255\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    256\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.6/site-packages/torch/nn/functional.py\u001b[0m in \u001b[0;36mconv2d\u001b[0;34m(input, weight, bias, stride, padding, dilation, groups)\u001b[0m\n\u001b[1;32m     46\u001b[0m     \"\"\"\n\u001b[1;32m     47\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0minput\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32mNone\u001b[0m \u001b[0;32mand\u001b[0m \u001b[0minput\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdim\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m!=\u001b[0m \u001b[0;36m4\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 48\u001b[0;31m         \u001b[0;32mraise\u001b[0m \u001b[0mValueError\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"Expected 4D tensor as input, got {}D tensor instead.\"\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mformat\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdim\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     49\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     50\u001b[0m     f = ConvNd(_pair(stride), _pair(padding), _pair(dilation), False,\n",
      "\u001b[0;31mValueError\u001b[0m: Expected 4D tensor as input, got 3D tensor instead."
     ]
    }
   ],
   "source": [
    "# model_dense = model_dense.cpu()\n",
    "# criterion = nn.CrossEntropyLoss()\n",
    "# preds_dense, _ = test_network(model_dense, datasets['val'], criterion, use_gpu=False)\n",
    "print(type(datasets['val'].test_data))\n",
    "print(datasets['val'].test_data.size())\n",
    "model_dense(datasets['val'].test_data)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Modelo totalmente convolucional equivalente"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "O modelo seguinte é todo ele convolucional.\n",
    "\n",
    "A primeira camada densa do modelo tem como entrada um tensor de dimensão 2450, resultante do redimensionamento (via *Flatten*) da saída do *Dropout*, 50x7x7. Esta camada gera uma saída com dimensão 50. Seus pesos têm portanto dimensão 2450x50.\n",
    "\n",
    "Uma camada convolucional que substitua estas camadas *Flatten* e *Dense* terá como entrada um tensor 50x7x7. Para gerar uma saída 50x1x1, a convolução deve criar 50 mapas com um kernel 7x7 e com borda do tipo 'valid'.\n",
    "\n",
    "Para substituir a última camada densa, usamos uma convolução com 10 mapas e kernel 1x1.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class MyModelFullyConv(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(MyModelFullyConv, self).__init__()\n",
    "        \n",
    "        # Camadas convolucionais\n",
    "        self.conv_layer = nn.Sequential(OrderedDict([\n",
    "            # lembrar de usar zero padding para manter o tamanho da imagem\n",
    "            ('conv1', nn.Conv2d(in_channels=1, out_channels=20, kernel_size=5, padding=2)),   \n",
    "            ('relu1', nn.ReLU()),\n",
    "            ('max_pool1', nn.MaxPool2d(2)),\n",
    "\n",
    "            ('conv2', nn.Conv2d(in_channels=20, out_channels=50, kernel_size=5, padding=2)),\n",
    "            ('relu2', nn.ReLU()),\n",
    "            ('max_pool2', nn.MaxPool2d(2)),\n",
    "            \n",
    "            ('conv3', nn.Conv2d(in_channels=50, out_channels=50, kernel_size=7)),\n",
    "            ('relu3', nn.ReLU()),\n",
    "            \n",
    "            ('conv4', nn.Conv2d(in_channels=50, out_channels=10, kernel_size=1)),\n",
    "        ]))\n",
    "        \n",
    "    def forward(self, x):\n",
    "        x = self.conv_layer(x)        \n",
    "        x = x.view(-1, 10)\n",
    "        return x"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Observando a saida de cada camada"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_conv = MyModelFullyConv()\n",
    "\n",
    "x = Variable(torch.zeros(1, 1, 28, 28))\n",
    "\n",
    "print('{:10}: {}'.format('input', str(x.size())))\n",
    "\n",
    "for name, layer in model_conv.conv_layer.named_children():\n",
    "    x = layer(x)\n",
    "    print('{:10}: {}'.format(name, str(x.size())))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### comparando o tamanho dos pesos das duas redes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def print_weights_size(weight_dict):\n",
    "    for name, weight in weight_dict.items():\n",
    "        print('{:25} -> {}'.format(name, weight.size()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print('--Pesos no modelo com densa--')\n",
    "print_weights_size(model_dense.state_dict())\n",
    "print('\\n--Pesos no modelo full convolucional--')\n",
    "print_weights_size(model_conv.state_dict())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Ajustando os pesos do modelo todo convolucional"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "w_dense = model_dense.state_dict()\n",
    "w_conv = model_conv.state_dict()\n",
    "\n",
    "# Só precisamos ajustar as dimensões dos pesos das camadas:\n",
    "# - dense1.weight para o tamanho de conv3.weight\n",
    "# - dense2.weight para o tamanho de conv4.weight\n",
    "# As outras camadas serão somente copiadas\n",
    "\n",
    "# weigths\n",
    "w_conv['conv_layer.conv1.weight'] = w_dense['conv_layer.conv1.weight']\n",
    "w_conv['conv_layer.conv2.weight'] = w_dense['conv_layer.conv2.weight']\n",
    "w_conv['conv_layer.conv3.weight'] = w_dense['dense_layer.dense1.weight'].view(50, 50, 7, 7)\n",
    "w_conv['conv_layer.conv4.weight'] = w_dense['dense_layer.dense2.weight'].view(10, 50, 1, 1)\n",
    "\n",
    "# bias\n",
    "w_conv['conv_layer.conv1.bias'] = w_dense['conv_layer.conv1.bias']\n",
    "w_conv['conv_layer.conv2.bias'] = w_dense['conv_layer.conv2.bias']\n",
    "w_conv['conv_layer.conv3.bias'] = w_dense['dense_layer.dense1.bias']\n",
    "w_conv['conv_layer.conv4.bias'] = w_dense['dense_layer.dense2.bias']\n",
    "\n",
    "model_conv.load_state_dict(w_conv)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Verificando se o desempenho é o mesmo"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Uma vez que colocamos na rede B os pesos da rede A, precisamos verificar se o desempenho da rede B (totalmente convolucional)\n",
    "possui o mesmo desempenho da rede A.\n",
    "Fazermos isso medindo a acurácia das duas redes no conjunto de testes."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_conv.cpu()\n",
    "criterion = nn.CrossEntropyLoss()\n",
    "preds_conv, _ = test_network(model_conv, datasets['val'], criterion, use_gpu=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2017-05-29T00:06:51.666141",
     "start_time": "2017-05-29T00:06:48.508665"
    }
   },
   "outputs": [],
   "source": [
    "# Mostra os 10 primeiros elementos preditos\n",
    "labels = datasets['val'].test_labels.numpy()\n",
    "\n",
    "print('{:6}: {}'.format('labels', labels[:10]))\n",
    "print('{:6}: {}'.format('dense', preds_dense[:10]))\n",
    "print('{:6}: {}'.format('conv', preds_conv[:10]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2017-05-29T00:06:55.312956",
     "start_time": "2017-05-29T00:06:55.306978"
    }
   },
   "outputs": [],
   "source": [
    "print('Acurácia rede totalmente convolucional: {:.5}%'.format(100.0 *(preds_conv == labels).sum() / labels.shape[0]))\n",
    "print('Acurácia rede clássica:                 {:.5}%'.format(100.0 * (preds_dense == labels).sum() / labels.shape[0]))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Aplicando o classificador numa imagem maior que 28x28"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "labels = datasets['val'].test_labels.numpy()\n",
    "x_test = datasets['val'].test_data.numpy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2017-05-28T20:00:13.544801",
     "start_time": "2017-05-28T20:00:13.499769"
    }
   },
   "outputs": [],
   "source": [
    "# Função para criar uma imagem de teste, maior que 28x28 colocando várias amostras\n",
    "def make_image(X_test, y_test, M=200, H=28, W=28):\n",
    "    char_index = np.random.choice(X_test.shape[0], 10, replace=False)\n",
    "    char_img = [img.reshape(H,W) for img in (X_test)[char_index]]\n",
    "    char_lab = [y for y in y_test[char_index]]\n",
    "\n",
    "    image = np.zeros((M, M), np.uint8)\n",
    "    coords = [(20, 20), (50, 150), (100, 100), (151, 151), (120,30)] # posição das imagens na imagem maior\n",
    "    xlabel = []\n",
    "    for k, (i, j) in enumerate(coords):\n",
    "        image[i:i+H, j:j+W] = char_img[k]\n",
    "        xlabel.append(char_lab[k])\n",
    "    return image, coords, xlabel"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2017-05-29T00:06:57.287055",
     "start_time": "2017-05-29T00:06:57.279313"
    }
   },
   "outputs": [],
   "source": [
    "M = 200\n",
    "image, coords, xlabel = make_image(x_test, labels, M) # Construindo uma imagem para testes M x M com 4 dígitos\n",
    "plt.imshow(image, cmap='gray');"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Aplicando classificador na imagem 200 x 200"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(image.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# transforma imagem de input em Tensor e em seguida a coloca em uma variável\n",
    "in_image = image.reshape(1, 1, M, M)\n",
    "in_image = torch.from_numpy(in_image).type(torch.FloatTensor)\n",
    "in_image = Variable(in_image)\n",
    "print('{:30}{}'.format('tamanho na entrada:', in_image.size()))\n",
    "\n",
    "# passa a imagem pela rede e faz o padding de 3 para a imagem ficar com tamanho (50, 50)\n",
    "output = model_conv.conv_layer(in_image)\n",
    "print('{:30}{}'.format('tamanho na saída:', output.size()))\n",
    "output = nn.functional.pad(output, (3,3,3,3))\n",
    "print('{:30}{}'.format('tamanho após o padding:', output.size()))\n",
    "\n",
    "# pega o maior valor entre as 10 classes\n",
    "max_pred, max_class = torch.max(output, 1)\n",
    "hot_map = max_pred.data.view(50, 50)\n",
    "print('{:30}{}'.format('tamanho do hot map:', hot_map.size()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.imshow(hot_map.numpy(), plt.cm.hot)\n",
    "plt.colorbar()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Imagem de probabilidade máxima de cada pixel referente a uma janela 28x28 (mapa de calor)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2017-05-29T00:07:00.997642",
     "start_time": "2017-05-29T00:07:00.205282"
    }
   },
   "outputs": [],
   "source": [
    "fig = plt.figure(figsize=(15,6)) \n",
    "\n",
    "fig.add_subplot(1,2,1)\n",
    "plt.imshow(image, cmap='gray')\n",
    "\n",
    "\n",
    "print(hot_map.max())\n",
    "hot_map = hot_map.numpy()\n",
    "#hot_map = hot_map * hot_map>3500\n",
    "\n",
    "import scipy.misc\n",
    "hot_map = scipy.misc.imresize(hot_map, (200, 200))\n",
    "\n",
    "fig.add_subplot(1,2,2)\n",
    "plt.imshow(hot_map, cmap=plt.cm.hot);\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Atenção:** Observe que as duas imagens acima possuem resolução (*shape*) diferentes. A resolução da imagem de entrada, mostrada à esquerda, é de (200,200) e a resolução da imagem de saída (à direita) é de (50,50)."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Aumentando a resolução para obter a mesma resolução da imagem de entrada"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Observe que a cada janela de 4x4 pixels da imagem de entrada, existe um resultado na imagem de saída.\n",
    "\n",
    "O objetivo agora é conseguir fazer com que a imagem resultante tenha o mesmo shape da imagem de entrada."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Janela deslizante"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Agora que temos uma rede toda convolucional, vejamos o que acontece se a imagem de entrada é maior que as imagens utilizadas para treinamento (28x28).\n",
    "\n",
    "A figura abaixo, ilustra o processo mostrando as dimensões dos *features* através de uma linha da imagem de entrada com dimensões 36x36. Acompanhemos cada passo:\n",
    "\n",
    "- imagem de entrada (representada na figura em uma dimensão apenas): 1x36x36;\n",
    "- convolução 20 filtros 5x5, borda *'same'*: 20x36x36\n",
    "- maxpool 2x2, stride 2x2: 20x18x18\n",
    "- convolução 50 filtros 5x5, borda *'same'*: 50x18x18\n",
    "- maxpool 2x2, stride 2x2: 50x9x9\n",
    "- convolução 50 filtros 7x7, borda *'valid'*: 50x3x3\n",
    "- convolução 10 filtros 1x1: 10x3x3\n",
    "\n",
    "<table align='left'>\n",
    "<!-- <tr><td> <img src=\"../figures/fully_conv_4.png\" alt=\"Drawing\" style=\"width: 200px;\"/> </td> <td/></tr> -->\n",
    "<tr><td colspan=2> <img src=\"../figures/fully_conv_3.png\" alt=\"Drawing\" style=\"width: 600px;\"/> </td></tr>\n",
    "</table>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Demonstrando a técnica de *shift* e *stitch*"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import time\n",
    "# Para demonstrar a técnica shift e stitch\n",
    "def show_scan(M, H=28, W=28):\n",
    "    from IPython import display\n",
    "    def printt(arr):\n",
    "        for line in output.tolist():\n",
    "            print(' '.join([' abcdefghijklmnop'[x] for x in line]))\n",
    "\n",
    "    M = 36\n",
    "    image = np.zeros((1, 1, M, M))\n",
    "\n",
    "    lab = 1\n",
    "    output = np.zeros((M-H+1, M-W+1), np.uint8)\n",
    "    for i in range(4):\n",
    "        for j in range(4):\n",
    "            oo = output[i::4, j::4]\n",
    "            output[i::4, j::4] = lab * np.ones_like(oo)\n",
    "            print('origin: ({}, {}), shape: {}, label: {}'.format(i, j, oo.shape, ' abcdefghijklmnop'[lab]))\n",
    "            print()\n",
    "            printt(output)\n",
    "            lab += 1\n",
    "            time.sleep(2)\n",
    "            display.clear_output(wait=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2017-05-29T00:07:40.701922",
     "start_time": "2017-05-29T00:07:08.586291"
    }
   },
   "outputs": [],
   "source": [
    "show_scan(M) # Demonstração da varredura e preenchimento (shift, stitch)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Rodando o classificador 16 vezes, preenchendo na forma shift-stitch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2017-05-29T00:08:56.280972",
     "start_time": "2017-05-29T00:08:50.612974"
    }
   },
   "outputs": [],
   "source": [
    "fig = plot.figure(figsize=(15,6)) \n",
    "\n",
    "fig.add_subplot(1,2,1)\n",
    "plot.imshow(255 - image, cmap=plot.cm.gray)\n",
    "plot.grid(True)\n",
    "\n",
    "# Aplicando a técnica shift e stitch na imagem\n",
    "# A rede convolucional é aplicada na imagem, 16 vezes para\n",
    "# preencher os dados\n",
    "output = np.zeros((10, M-H+1, M-W+1), np.float32)\n",
    "for i in range(4):\n",
    "    for j in range(4):\n",
    "        output[:, i::4, j::4] = oo = model_B.predict(in_image[:, :, i:, j:])[0] # Execução da rede\n",
    "        print(i, j, oo.shape)\n",
    "\n",
    "output = softmax(output, axis=0)\n",
    "pmax = output.max(0)\n",
    "y_hat = output.argmax(0)\n",
    "pmax = np.where(pmax < 0.3, 0, pmax)\n",
    "print(pmax.min(), pmax.max())\n",
    "print(pmax.shape)\n",
    "\n",
    "pmax_img = np.zeros((M,M), pmax.dtype)\n",
    "pmax_img[(H+1)//2-1:-H//2, (W+1)//2-1:-W//2] = pmax\n",
    "\n",
    "y_hat_img = np.zeros((M,M), y_hat.dtype)\n",
    "y_hat_img[(H+1)//2-1:-H//2, (W+1)//2-1:-W//2] = y_hat\n",
    "\n",
    "fig.add_subplot(1,2,2)\n",
    "plot.imshow(255 * (1.0 - pmax_img), cmap=plot.cm.hot)\n",
    "# plot.imsave('heatmap.png', 255 * pmax)\n",
    "plot.grid(True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Mostrando as probabilidades dos picos do mapa de calor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2017-05-29T00:09:26.485503",
     "start_time": "2017-05-29T00:09:26.428531"
    },
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "for k, (i, j) in zip(xlabel, coords):\n",
    "    for m in (-1, 0, 1):\n",
    "        for n in (-1, 0, 1):\n",
    "            print('p = {:.5f}, char: \\'{}\\' [correct: \\'{}\\']'.format(pmax_img[i+m+13, j+n+13], \n",
    "                                                                      y_hat_img[i+m+13, j+n+13], k), end=' ')\n",
    "            if m == n == 0:\n",
    "                print('**')\n",
    "            else:\n",
    "                print()\n",
    "    print()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Observações\n",
    "\n",
    "- A rede base utilizada não foi treinada para a não-ocorrência de um dos dez caracteres, nem de recortes parciais dos caracteres originais.\n",
    "- Um exercício interessante seria treinar o modelo com os caracteres sobrepostos a imagens de fundo, além de recortes do fundo sem caracter (11 classes).\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "## Aprendizados com este notebook\n"
   ]
  }
 ],
 "metadata": {
  "anaconda-cloud": {},
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.2"
  },
  "toc": {
   "nav_menu": {
    "height": "210px",
    "width": "252px"
   },
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": false,
   "toc_cell": false,
   "toc_position": {},
   "toc_section_display": "block",
   "toc_window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
