{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Regressão Softmax com dados do MNIST\n",
    "\n",
    "O objetivo deste notebook é ilustrar o uso do mesmo código matricial desenvolvido para a classificação das Flores Íris, porém agora com o problema de classificação de dígitos manuscritos utilizando o dataset MNIST.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Importação das bibliotecas"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2017-10-08T21:50:47.712366Z",
     "start_time": "2017-10-08T21:50:45.983895Z"
    }
   },
   "outputs": [],
   "source": [
    "%matplotlib inline\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import pandas as pd\n",
    "\n",
    "import torch\n",
    "from torch.autograd import Variable"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Funções já discutidas em notebooks anteriores"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2017-10-08T21:50:47.723344Z",
     "start_time": "2017-10-08T21:50:47.714421Z"
    }
   },
   "outputs": [],
   "source": [
    "def predict(model, inputs):\n",
    "    outputs = model(Variable(inputs))\n",
    "    _, predicts = torch.max(outputs, 1)\n",
    "    \n",
    "    return predicts.data.numpy()\n",
    "\n",
    "def getAccuracy(model, inputs, targets):\n",
    "    outputs = model(Variable(inputs))\n",
    "    _, predicts = torch.max(outputs, 1)\n",
    "\n",
    "    predicts = predicts.data.numpy()\n",
    "    targets = targets.numpy()\n",
    "    \n",
    "    accuracy = (predicts == targets).mean()\n",
    "    return accuracy"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Carregamento dos dados do MNIST"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2017-10-08T21:50:47.804238Z",
     "start_time": "2017-10-08T21:50:47.725713Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Amostras para treinamento: 60000\n",
      "Amostras para validação    10000\n",
      "\n",
      "Dimensões dos dados das imagens:    torch.Size([60000, 28, 28])\n",
      "Valores mínimo e máximo dos pixels: 0 255\n",
      "Tipo dos dados das imagens:         <class 'torch.ByteTensor'>\n",
      "Tipo das classes das imagens:       <class 'torch.LongTensor'>\n"
     ]
    }
   ],
   "source": [
    "dataset_dir = '/data/datasets/MNIST/'\n",
    "\n",
    "x_train, y_train = torch.load(dataset_dir + 'processed/training.pt')\n",
    "x_test,  y_test  = torch.load(dataset_dir + 'processed/test.pt')\n",
    "\n",
    "print(\"Amostras para treinamento:\", x_train.size(0))\n",
    "print(\"Amostras para validação   \", x_test.size(0))\n",
    "\n",
    "print(\"\\nDimensões dos dados das imagens:   \", x_train.size())\n",
    "print(\"Valores mínimo e máximo dos pixels:\", torch.min(x_train), torch.max(x_train))\n",
    "print(\"Tipo dos dados das imagens:        \", type(x_train))\n",
    "print(\"Tipo das classes das imagens:      \", type(y_train))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Carregamento, normalização e seleção dos dados do MNIST\n",
    "\n",
    "Neste exemplo utilizaremos 500 amostras de treinamento e 100 amostras de validação."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2017-10-08T21:50:47.816803Z",
     "start_time": "2017-10-08T21:50:47.806580Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Amostras para treinamento: 1000\n",
      "Amostras para validação    500\n",
      "\n",
      "Dimensões dos dados das imagens:    torch.Size([1000, 28, 28])\n",
      "Valores mínimo e máximo dos pixels: 0.0 1.0\n",
      "Tipo dos dados das imagens:         <class 'torch.FloatTensor'>\n",
      "Tipo das classes das imagens:       <class 'torch.LongTensor'>\n"
     ]
    }
   ],
   "source": [
    "x_train = x_train.float()\n",
    "x_test = x_test.float()\n",
    "\n",
    "x_train = x_train / 255.\n",
    "x_test = x_test / 255.\n",
    "\n",
    "if True:\n",
    "    n_samples_train = 1000\n",
    "    n_samples_test  = 500\n",
    "\n",
    "    x_train = x_train[:n_samples_train]\n",
    "    y_train = y_train[:n_samples_train]\n",
    "    x_test  = x_test[:n_samples_test]\n",
    "    y_test  = y_test[:n_samples_test]\n",
    "\n",
    "print(\"Amostras para treinamento:\", x_train.size(0))\n",
    "print(\"Amostras para validação   \", x_test.size(0))\n",
    "\n",
    "print(\"\\nDimensões dos dados das imagens:   \", x_train.size())\n",
    "print(\"Valores mínimo e máximo dos pixels:\", torch.min(x_train), torch.max(x_train))\n",
    "print(\"Tipo dos dados das imagens:        \", type(x_train))\n",
    "print(\"Tipo das classes das imagens:      \", type(y_train))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Visualizando os dados"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2017-10-08T21:50:48.253906Z",
     "start_time": "2017-10-08T21:50:47.819324Z"
    }
   },
   "outputs": [
    {
     "ename": "AttributeError",
     "evalue": "module 'torch.utils' has no attribute 'data'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-5-be73ee6e4e12>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      2\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      3\u001b[0m \u001b[0;31m# cria um DataLoader temporario para pegar um batch de 'n_samples' imagens de treinamento\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 4\u001b[0;31m temp_dataloader = torch.utils.data.DataLoader(train_dataset, \n\u001b[0m\u001b[1;32m      5\u001b[0m                                               \u001b[0mbatch_size\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mn_samples\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      6\u001b[0m                                               shuffle=True)\n",
      "\u001b[0;31mAttributeError\u001b[0m: module 'torch.utils' has no attribute 'data'"
     ]
    }
   ],
   "source": [
    "n_samples = 24\n",
    "\n",
    "# cria um DataLoader temporario para pegar um batch de 'n_samples' imagens de treinamento\n",
    "temp_dataloader = torch.utils.data.DataLoader(train_dataset, \n",
    "                                              batch_size=n_samples,\n",
    "                                              shuffle=True)\n",
    "\n",
    "# pega um batch de imagens\n",
    "image_batch, labels = next(iter(temp_dataloader))\n",
    "\n",
    "# cria um grid com as imagens\n",
    "grid = torchvision.utils.make_grid(image_batch, normalize=True, pad_value=1.0, padding=1)\n",
    "\n",
    "plt.figure(figsize=(15, 10))\n",
    "plt.imshow(grid.numpy().transpose(1, 2, 0))\n",
    "plt.axis('off')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Visualizando uma imagem com o matplotlib"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2017-10-08T21:50:48.468090Z",
     "start_time": "2017-10-08T21:50:48.255527Z"
    }
   },
   "outputs": [],
   "source": [
    "image, target = train_dataset[0]\n",
    "\n",
    "plt.imshow(image.numpy().reshape(28,28), cmap='gray')\n",
    "print('class:', target)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Treinamento"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Inicialização dos parâmetros"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2017-10-08T22:20:57.541832Z",
     "start_time": "2017-10-08T22:20:57.529047Z"
    }
   },
   "outputs": [],
   "source": [
    "epochs = 100\n",
    "learningRate = 0.5\n",
    "\n",
    "# Cria um DataLoader de somente um batch\n",
    "train_dataloader = torch.utils.data.DataLoader(train_dataset, \n",
    "                                               batch_size=16,\n",
    "                                               shuffle=True)\n",
    "\n",
    "# Pega todas as imagens de uma vez\n",
    "\n",
    "\n",
    "# Cria uma operação linear com entrada de tamanho 28*28 e saída com 10 neurônios (classes)\n",
    "# O objeto criado armazenará os pesos\n",
    "model = torch.nn.Linear(28*28, 10)\n",
    "\n",
    "# Utilizaremos CrossEntropyLoss como função de perda\n",
    "criterion = torch.nn.CrossEntropyLoss(size_average=True)\n",
    "criterion2 = torch.nn.CrossEntropyLoss(size_average=False)\n",
    "\n",
    "# Nosso otomizador será SDG\n",
    "optimizer = torch.optim.SGD(model.parameters(), lr=learningRate)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Laço de treinamento dos pesos"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2017-10-08T22:24:12.268760Z",
     "start_time": "2017-10-08T22:24:06.125838Z"
    }
   },
   "outputs": [],
   "source": [
    "losses = []\n",
    "\n",
    "for i in range(epochs):\n",
    "    loss_sum = 0\n",
    "    loss2_sum= 0\n",
    "    \n",
    "    for batch in train_dataloader:\n",
    "        # separa os dados do batch\n",
    "        input_data, targets_data = batch\n",
    "        # Transforma a entrada para uma dimensão\n",
    "        input_data = input_data.view(-1, 28*28)\n",
    "    \n",
    "        # calcula a saída da operação linear\n",
    "        output = model(Variable(input_data))\n",
    "\n",
    "        # calcula a perda\n",
    "        loss = criterion(output, Variable(targets_data))\n",
    "        loss_sum += loss.data[0] * targets_data.size(0)\n",
    "        loss2 = criterion2(output, Variable(targets_data))\n",
    "        loss2_sum += loss2\n",
    "        \n",
    "        # zero, backpropagation, ajusta parâmetros pelo gradiente descendente\n",
    "        optimizer.zero_grad()\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "    \n",
    "    epoch_loss = loss_sum / len(train_dataset)\n",
    "    epoch2_loss = loss2_sum/ len(train_dataset)\n",
    "    losses.append(epoch_loss)\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2017-10-08T22:24:14.722302Z",
     "start_time": "2017-10-08T22:24:14.717734Z"
    }
   },
   "outputs": [],
   "source": [
    "print('Final loss:', epoch_loss, epoch2_loss.data[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2017-10-08T22:21:49.895233Z",
     "start_time": "2017-10-08T22:21:49.889169Z"
    }
   },
   "outputs": [],
   "source": [
    "1/(0.1506661695893854/ 2.3205604553222656)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Visualizando gráfico de perda durante o treinamento"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2017-10-08T11:42:55.078065Z",
     "start_time": "2017-10-08T11:42:54.837753Z"
    }
   },
   "outputs": [],
   "source": [
    "plt.plot(losses)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Avaliando a acurácia tanto no conjunto de treinamento como no conjunto de testes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2017-10-08T11:42:55.158664Z",
     "start_time": "2017-10-08T11:42:55.080122Z"
    }
   },
   "outputs": [],
   "source": [
    "def getAccuracy(model, inputs, targets):\n",
    "    outputs = model(Variable(inputs))\n",
    "    _, predicts = torch.max(outputs, 1)\n",
    "\n",
    "    predicts = predicts.data.numpy()\n",
    "    targets = targets.numpy()\n",
    "    \n",
    "    accuracy = (predicts == targets).mean()\n",
    "    return accuracy\n",
    "\n",
    "train_dataloader = torch.utils.data.DataLoader(train_dataset, \n",
    "                                              batch_size=len(train_dataset),\n",
    "                                              shuffle=False)\n",
    "train_input, targets_data = next(iter(train_dataloader))\n",
    "train_input = train_input.view(-1, 28*28)\n",
    "\n",
    "print('Training Accuracy: ', getAccuracy(model, train_input, targets_data))\n",
    "\n",
    "\n",
    "\n",
    "test_dataloader = torch.utils.data.DataLoader(test_dataset, \n",
    "                                              batch_size=len(test_dataset),\n",
    "                                              shuffle=False)\n",
    "test_input, test_labels = next(iter(test_dataloader))\n",
    "test_input = test_input.view(-1, 28*28)\n",
    "\n",
    "print('Test Accuracy: ', getAccuracy(model, test_input, test_labels))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Matriz de confusão com dados de treinamento e teste"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2017-10-08T11:42:55.198626Z",
     "start_time": "2017-10-08T11:42:55.160808Z"
    }
   },
   "outputs": [],
   "source": [
    "print('Matriz de confusão (Treino):')\n",
    "pd.crosstab(predict(model, train_input), targets_data.numpy())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2017-10-08T11:42:55.245516Z",
     "start_time": "2017-10-08T11:42:55.201314Z"
    },
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "print('Matriz de confusão (Teste):')\n",
    "pd.crosstab(predict(model, test_input), test_labels.numpy())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Visualizando a matriz de pesos treinados\n",
    "\n",
    "Observe que a matriz de peso treinado para cada classe mostra a importância dos pesos associados aos caracteres de cada classe."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2017-10-08T11:42:55.502413Z",
     "start_time": "2017-10-08T11:42:55.248318Z"
    }
   },
   "outputs": [],
   "source": [
    "weights = model.state_dict()['weight']\n",
    "print('weights:', weights.shape)\n",
    "\n",
    "bias = model.state_dict()['bias']\n",
    "print('bias:   ', bias.shape)\n",
    "\n",
    "# Visualizando pesos da classe 3\n",
    "plt.imshow(weights[3, :].numpy().reshape((28,28)),cmap = 'gray')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Visualizando os pesos de todas as classes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2017-10-08T11:42:55.803531Z",
     "start_time": "2017-10-08T11:42:55.505223Z"
    }
   },
   "outputs": [],
   "source": [
    "# cria um grid com as imagens\n",
    "grid = torchvision.utils.make_grid(weights.view(-1, 1, 28, 28), normalize=True, pad_value=1.0, padding=1, nrow=10)\n",
    "\n",
    "plt.figure(figsize=(15, 10))\n",
    "plt.imshow(grid.numpy().transpose(1, 2, 0))\n",
    "plt.axis('off')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "heading_collapsed": true
   },
   "source": [
    "## Diagrama da regressão softmax com visualização dos pesos W\n",
    "\n",
    "<img src=\"../figures/RegressaoSoftmaxArgmaxNMIST.png\",width = 400>\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Atividades"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Exercícios"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "1. Na configuração da figura acima, mostre os valores de z0 até z9, os valores das probabilidades y_oh_hat e o y_hat, quando a rede recebe como entrada a nona amostra que contém o manuscrito do dígito '4':"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2017-10-08T11:42:55.989480Z",
     "start_time": "2017-10-08T11:42:55.805172Z"
    }
   },
   "outputs": [],
   "source": [
    "image, target = train_dataset[9]\n",
    "\n",
    "plt.imshow(image.numpy().reshape(28,28), cmap='gray')\n",
    "print('class:', target)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "2. Insira código no laço do treinamento para que no final de cada época, \n",
    "seja impresso: o número da época e a perda e a acurácia\n",
    "3. Insira código no laço de treinamento para que seja impresso a contagem\n",
    "de mini-batches ocorrida em cada época."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Perguntas"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "1. Qual é o tamanho do mini-batch?\n",
    "2. Em uma época, quantos mini-batches existem?\n",
    "3. Por que no treino, a acurácia é 100%, mas no teste foi de 84,5%\n",
    "4. Por que no treino, a acurácia é 100%, porém a função de perda final não é zero, mas sim 0,015 ?\n",
    "5. O que se deve fazer para que a avaliação no conjunto de teste seja melhorado?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Conclusões sobre os experimentos deste notebook\n"
   ]
  }
 ],
 "metadata": {
  "anaconda-cloud": {},
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.1"
  },
  "toc": {
   "nav_menu": {
    "height": "318px",
    "width": "252px"
   },
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": false,
   "toc_cell": false,
   "toc_position": {},
   "toc_section_display": "block",
   "toc_window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
