{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Exercício MNIST com várias camadas"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "O objetivo deste notebook é treinar uma rede com várias camadas para o dataset MNIST. Para isso complete as partes de código sinalizadas que estão faltando."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Importação das bibliotecas"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "%matplotlib inline\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import pandas as pd\n",
    "\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "from torch.autograd import Variable\n",
    "\n",
    "import torchvision\n",
    "from torchvision.datasets import MNIST\n",
    "import torchvision.transforms as transforms"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Funções de predição e acurácia"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2017-07-31T20:54:23.718772",
     "start_time": "2017-07-31T20:54:23.700319"
    },
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def predict(model, inputs):\n",
    "    outputs = model(Variable(inputs))\n",
    "    _, predicts = torch.max(outputs, 1)\n",
    "\n",
    "    return predicts.data.numpy()\n",
    "\n",
    "def getAccuracy(model, inputs, targets):\n",
    "    outputs = model(Variable(inputs))\n",
    "    _, predicts = torch.max(outputs, 1)\n",
    "\n",
    "    predicts = predicts.data.numpy()\n",
    "    targets = targets.numpy()\n",
    "\n",
    "    accuracy = (predicts == targets).mean()\n",
    "    return accuracy"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Carregamento dos dados do MNIST"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2017-07-31T20:54:32.279408",
     "start_time": "2017-07-31T20:54:31.476464"
    },
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "dataset_dir = '/data/datasets/MNIST/'\n",
    "\n",
    "# Transformara os dados em tensores no intervalo [0.0, 1.0] (Os dados serão normalizados)\n",
    "data_transform = transforms.ToTensor()\n",
    "\n",
    "# carrega o conjunto de treinamento e de teste\n",
    "train_dataset = MNIST(dataset_dir, train=True, transform=data_transform)\n",
    "test_dataset = MNIST(dataset_dir, train=False, transform=data_transform)\n",
    "\n",
    "print(\"Tamanho do dataset de treino:\", len(train_dataset))\n",
    "print(\"Tamanho do dataset de teste: \", len(test_dataset))\n",
    "\n",
    "print(\"\\nDimensões dos dados das imagens:\", train_dataset[0][0].size())\n",
    "print(\"Tipo dos dados das imagens:     \", type(train_dataset[0][0]))\n",
    "print(\"Tipo das classes das imagens:   \", type(train_dataset[0][1]))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Organizando e normalizando os dados\n",
    "\n",
    "Neste exemplo utilizaremos 500 amostras de treinamento e 100 amostras para testes.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2017-07-31T20:54:42.014214",
     "start_time": "2017-07-31T20:54:41.989072"
    },
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "n_samples_train = 1000\n",
    "n_samples_test  = 500\n",
    "\n",
    "train_dataset.train_data   = train_dataset.train_data[:n_samples_train]\n",
    "train_dataset.train_labels = train_dataset.train_labels[:n_samples_train]\n",
    "test_dataset.test_data   = test_dataset.test_data[:n_samples_test]\n",
    "test_dataset.test_labels = test_dataset.test_labels[:n_samples_test]\n",
    "\n",
    "print('Amostras para treinamento:', len(train_dataset))\n",
    "print('Amostras para validação:',   len(test_dataset))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Visualizando os dados"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2017-07-31T20:54:44.792338",
     "start_time": "2017-07-31T20:54:44.748220"
    },
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "n_samples = 24\n",
    "\n",
    "# cria um DataLoader temporario para pegar um batch de 'n_samples' imagens de treinamento\n",
    "temp_dataloader = torch.utils.data.DataLoader(train_dataset, \n",
    "                                              batch_size=n_samples,\n",
    "                                              shuffle=True)\n",
    "\n",
    "# pega um batch de imagens\n",
    "image_batch, labels = next(iter(temp_dataloader))\n",
    "\n",
    "# cria um grid com as imagens\n",
    "grid = torchvision.utils.make_grid(image_batch, normalize=True, pad_value=1.0, padding=1)\n",
    "\n",
    "plt.figure(figsize=(15, 10))\n",
    "plt.imshow(grid.numpy().transpose(1, 2, 0))\n",
    "plt.axis('off')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Treinamento"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Exercício 1 - Criação dos DataLoaders"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Crie DataLoaders de treino e validação com somente um batch de dados."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "train_dataloader = torch.utils.data.DataLoader(dataset=, \n",
    "                                               batch_size=,\n",
    "                                               shuffle=True)\n",
    "\n",
    "test_dataloader = "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# verificação do exercício 1\n",
    "if len(train_dataloader) > 1:\n",
    "    print('train_dataloader tem mais de 1 batch')\n",
    "else:\n",
    "    print('train_dataloader está correto')\n",
    "    \n",
    "if len(test_dataloader) > 1:\n",
    "    print('train_dataloader tem mais de 1 batch')\n",
    "else:\n",
    "    print('train_dataloader está correto')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Exercício 2 - Complete a criação da rede"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "class Modelo(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(Modelo, self).__init__()\n",
    "\n",
    "    \n",
    "    def forward(self, x):\n",
    "        return x\n",
    "    \n",
    "model = Modelo()\n",
    "print(model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#Verificação do exercicio 2\n",
    "test_input  = torch.FloatTensor(3, 28, 28)\n",
    "test_output = model(Variable(test_input))\n",
    "\n",
    "if test_output.size(1) == 10 and test_output.size(0) == test_input.size(0):\n",
    "    print('Rede está funcionando corretamente')\n",
    "elif test_output.size(1) != 10:\n",
    "    print('Saída da rede deve ter dimensão (n_amostras, 10), mas tem dimensão ({}, {})'.format(\n",
    "        test_output.size(0), test_output.size(0)))\n",
    "elif test_output.size(0) != test_input.size(0):\n",
    "    print('Número de amostras na saída ({}) deve ser igual ao da entrada ({})'.format(\n",
    "        test_output.size(0), test_input.size(0)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Inicialização dos parâmetros"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "learningRate = 0.5\n",
    "\n",
    "# Utilizaremos CrossEntropyLoss como função de perda\n",
    "criterion = torch.nn.CrossEntropyLoss()\n",
    "\n",
    "# Nosso otomizador será SDG\n",
    "optimizer = torch.optim.SGD(model.parameters(), lr=learningRate)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Laço de treinamento dos pesos"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "epochs = 1000\n",
    "\n",
    "# Pega todas as imagens de uma vez\n",
    "input_data, targets_data = next(iter(train_dataloader))\n",
    "# Transforma em vetor\n",
    "input_data = input_data.view(-1, 28*28)\n",
    "\n",
    "losses = []\n",
    "\n",
    "for i in range(epochs):\n",
    "    \n",
    "    # calcula a saída da operação linear\n",
    "    output = model(Variable(input_data))\n",
    "\n",
    "    # calcula a perda\n",
    "    loss = criterion(output, Variable(targets_data))\n",
    "\n",
    "    # zero, backpropag gradientes, ajusta parâmetros gradiente descendente\n",
    "    optimizer.zero_grad()\n",
    "    loss.backward()\n",
    "    optimizer.step()\n",
    "        \n",
    "    losses.append(loss.data[0])\n",
    "    \n",
    "print('Final loss:', loss.data[0])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Visulizando gráfico de perda durante o treinamento"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2017-07-31T20:55:03.863907",
     "start_time": "2017-07-31T20:55:03.661629"
    },
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "plt.plot(losses)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Avaliando a acurácia tanto no conjunto de treinamento como no conjunto de testes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2017-07-31T20:55:10.946147",
     "start_time": "2017-07-31T20:55:10.932284"
    },
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "print('Training Accuracy: ', getAccuracy(model, input_data, targets_data))\n",
    "\n",
    "test_input, test_labels = next(iter(test_dataloader))\n",
    "print('Test Accuracy: ', getAccuracy(model, test_input, test_labels))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Matriz de confusão com dados de treinamento e teste"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2017-07-31T20:55:13.646669",
     "start_time": "2017-07-31T20:55:13.559163"
    },
    "collapsed": true,
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "print('Matriz de confusão (Treino):')\n",
    "display(pd.crosstab(predict(model, input_data), targets_data.numpy()))\n",
    "\n",
    "print('Matriz de confusão (Teste):')\n",
    "display(pd.crosstab(predict(model, test_input), test_labels.numpy()))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Conclusões sobre os experimentos deste notebook\n"
   ]
  }
 ],
 "metadata": {
  "anaconda-cloud": {},
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.0"
  },
  "toc": {
   "nav_menu": {
    "height": "318px",
    "width": "252px"
   },
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": false,
   "toc_cell": false,
   "toc_position": {},
   "toc_section_display": "block",
   "toc_window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
