{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Batch Normalization"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Introdução"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Batch Normalization é uma técnica que permite normalizar automaticamente os valores que atravessam uma camada da rede neural. Normalmente o uso do BatchNorm permite um treinamento mais rápido e com menores cuidados na inicialização dos pesos. Permite que redes profundas sejam treinadas mais facilmente. \n",
    "\n",
    "A normalização é feita para que o resultado tenha média zero e variância unitária, porém, em seguida, o resultado é\n",
    "escalado pelo fator $\\gamma$ e somado ao fator $\\beta$. Estes dois fatores são parâmetros que serão também otimizados durante o treinamento do gradiente descendente.\n",
    "\n",
    "Atualmente a técnica de batch normalization é utilizada em todas as redes profundas. \n",
    "\n",
    "A camada de batch normalization é colocada entre a camada densa ou convolucional e antes da camada de ativação."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Referência:**\n",
    "- Ioffe, S. and Szegedy, C. (2015), Batch Normalization: Accelerating Deep Network Training by Reducing Internal Covariate Shift., in Francis R. Bach & David M. Blei, ed., 'ICML' , JMLR.org, , pp. 448-456. \n",
    "    [PDF:arxiv](http://arxiv.org/pdf/1502.03167.pdf) "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<img src='../figures/batchnorm_neuronios.png', width=900></img>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<img src='../figures/batchnorm_equations.png',width=500></a>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Diferença entre fase de treinamento e fase de predição ou avaliação"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "A normalização ocorre de forma distinta na fase de treinamento e na fase de avaliação:\n",
    "- em treinamento: a média e variância ($\\mu$ e $\\sigma^2$) são estimados a partir dos valores\n",
    "das amostras no mini-batch:\n",
    "    - `running_mean`\n",
    "    - `running_var`\n",
    "- em avaliação: a média e variância é calculada pela média móvel, definida pelo parâmetro momentum ($\\lambda$):"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\\begin{align*} \n",
    "\\boldsymbol{m}_{t} &=  \\lambda \\boldsymbol{\\mu_t} + (1 - \\lambda) \\boldsymbol{m}_{t-1} &&\n",
    "\\boldsymbol{v}_{t} =   \\lambda \\boldsymbol{\\sigma^{2}_t} + (1 - \\lambda) \\boldsymbol{v}_{t-1} \n",
    "\\end{align*}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Importações"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2017-10-03T14:27:18.839311",
     "start_time": "2017-10-03T14:27:18.595038"
    }
   },
   "outputs": [],
   "source": [
    "%matplotlib inline\n",
    "import matplotlib.pyplot as plot\n",
    "from IPython import display\n",
    "\n",
    "import sys, copy\n",
    "import numpy as np\n",
    "import numpy.random as nr\n",
    "import pandas as pd\n",
    "\n",
    "import torch\n",
    "from torch.autograd import Variable\n",
    "\n",
    "np.set_printoptions(precision=2, suppress=True)\n",
    "nr.seed(23456)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Batch Norm: parâmetros"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### nn.BatchNorm1d - Entrada com dimensão 2"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- Documentação oficial: http://pytorch.org/docs/master/nn.html#normalization-layers\n",
    "\n",
    "Quando a entrada da camada tem duas dimensões (amostras e atributos) a normalização por atributo. Ou seja, calcula-se a estatística (média e variância) para cada coluna da matriz de dados, em cada *mini-batch*."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Experimento 1 - aplicação BatchNorm tanto para treino como para teste"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Criação da camada BatchNorm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "torch.manual_seed(1234)\n",
    "\n",
    "model = torch.nn.BatchNorm1d(5)        # Rede formada de apenas uma camada BatchNorm"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Parâmetros iniciais, mv_mean = 0. e mv_var = 1."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training: True\n",
      "weight\n",
      "[ 0.19  0.5   0.62  0.82  0.44]\n",
      "bias\n",
      "[ 0.  0.  0.  0.  0.]\n",
      "running_mean\n",
      "[ 0.  0.  0.  0.  0.]\n",
      "running_var\n",
      "[ 1.  1.  1.  1.  1.]\n"
     ]
    }
   ],
   "source": [
    "print('Training:', model.training)\n",
    "gamma, beta, mv_mean, mv_var = copy.deepcopy(model.state_dict()).values()\n",
    "param_dict = model.state_dict()\n",
    "for name,value in param_dict.items():\n",
    "    print(name)\n",
    "    print(value.numpy())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Entrada x (não normalizada)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "x:\n",
      " Variable containing:\n",
      "-133.6756 -113.6071   23.2839 -172.4477   51.1140\n",
      " -61.2595   47.0261   65.2737   57.1934  170.6041\n",
      " 100.2897 -231.1064  110.7505  171.6769   70.1500\n",
      "  62.7425  117.5225    9.5521 -151.1595   12.5337\n",
      "[torch.FloatTensor of size 4x5]\n",
      "\n"
     ]
    }
   ],
   "source": [
    "x = Variable(torch.randn(4, 5)) * 100. # Entrada x\n",
    "print('x:\\n',x)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Forward em treinamento: faz predict usando média e var do mini-batch e atualiza mv_mean e mv_var"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training: True\n"
     ]
    }
   ],
   "source": [
    "print('Training:', model.training)\n",
    "y = model(x)                           # Forward"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Parâmetros: running_mean e running_var estimados com momentum 10% atual e 90% do anterior"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training: True\n",
      "weight\n",
      "[ 0.19  0.5   0.62  0.82  0.44]\n",
      "bias\n",
      "[ 0.  0.  0.  0.  0.]\n",
      "running_mean\n",
      "[-0.8  -4.5   5.22 -2.37  7.61]\n",
      "running_var\n",
      "[ 1179.64  2475.06   209.37  2770.49   455.28]\n"
     ]
    }
   ],
   "source": [
    "print('Training:', model.training)\n",
    "param_dict = model.state_dict()\n",
    "for name,value in param_dict.items():\n",
    "    print(name)\n",
    "    print(value.numpy())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Conferindo os novos valores de running_mean e running_var"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\\begin{align*} \n",
    "\\boldsymbol{m}_{t} &=  \\lambda \\boldsymbol{\\mu_t} + (1 - \\lambda) \\boldsymbol{m}_{t-1} &&\n",
    "\\boldsymbol{v}_{t} =   \\lambda \\boldsymbol{\\sigma^{2}_t} + (1 - \\lambda) \\boldsymbol{v}_{t-1} \n",
    "\\end{align*}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "old mv_mean, mv_var: [ 0.  0.  0.  0.  0.] [ 1.  1.  1.  1.  1.]\n"
     ]
    },
    {
     "ename": "NameError",
     "evalue": "name 'momentum' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-7-11e0c2442ef8>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'old mv_mean, mv_var:'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmv_mean\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mnumpy\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmv_var\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mnumpy\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      2\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 3\u001b[0;31m \u001b[0mmv_mean_new\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmomentum\u001b[0m \u001b[0;34m*\u001b[0m \u001b[0mx\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdata\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmean\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0;36m1\u001b[0m \u001b[0;34m-\u001b[0m \u001b[0mmomentum\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m*\u001b[0m \u001b[0mmv_mean\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      4\u001b[0m \u001b[0mmv_var_new\u001b[0m  \u001b[0;34m=\u001b[0m \u001b[0mmomentum\u001b[0m \u001b[0;34m*\u001b[0m \u001b[0mx\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdata\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mvar\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0munbiased\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mTrue\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0;36m1\u001b[0m \u001b[0;34m-\u001b[0m \u001b[0mmomentum\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m*\u001b[0m \u001b[0mmv_var\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mNameError\u001b[0m: name 'momentum' is not defined"
     ]
    }
   ],
   "source": [
    "print('old mv_mean, mv_var:', mv_mean.numpy(), mv_var.numpy())\n",
    "\n",
    "mv_mean_new = momentum * x.data.mean(0) + (1 - momentum) * mv_mean\n",
    "mv_var_new  = momentum * x.data.var(0,unbiased=True) + (1 - momentum) * mv_var\n",
    "\n",
    "print('my new running mean:',mv_mean_new.numpy())\n",
    "print('my new running var :',mv_var_new.numpy())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Saída  y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "y"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Conferindo com código próprio"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Em treinamento, a normalização é feita com a estatística do mini-batch"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "$$  y = \\frac{x - mean[x]}{ \\sqrt{Var[x] + \\epsilon}} * gamma + beta $$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "mean = x.mean(dim=0).data\n",
    "var  = x.var(dim=0, unbiased=False).data\n",
    "print('mean:',mean.numpy())\n",
    "print('var: ',var.numpy())\n",
    "y2 = (x.data - mean) / torch.sqrt(var + model.eps) * gamma + beta\n",
    "\n",
    "print(y2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Modo predict sem treinamento"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.training = False\n",
    "y = model(x)                           # Forward"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Observe que agora, o running_mean e running_var serão utilizados"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print('Training:', model.training)\n",
    "param_dict = model.state_dict()\n",
    "for name,value in param_dict.items():\n",
    "    print(name)\n",
    "    print(value.numpy())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Resultado da rede no modo eval(), note que os valores não ficaram tão normalizados (por quê?)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "y"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Conferindo com código próprio, note que usa-se o running_mean e running_var"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "gamma, beta, mv_mean, mv_var = model.state_dict().values()\n",
    "\n",
    "mean = mv_mean\n",
    "var  = mv_var\n",
    "\n",
    "y2 = (x.data - mean) / torch.sqrt(var + model.eps) * gamma + beta\n",
    "\n",
    "print(y2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "## Exercícios"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "1. Coloque a rede no modo treinamento em um laço, de modo que a running_mean e running_var se aproximem da média e variância do mini-batch. Quantas execuções da rede serão necessárias?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.training = True\n",
    "#for i in range(100):\n",
    "    #y = model(x)\n",
    "    # Busque aqui os valores da média móvel da média e variância que estão sendo aprendidos\n",
    "    #\n",
    "    #\n",
    "    #print(mv_mean.numpy(), mv_var.numpy())"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.1"
  },
  "latex_envs": {
   "LaTeX_envs_menu_present": true,
   "autocomplete": true,
   "bibliofile": "biblio.bib",
   "cite_by": "apalike",
   "current_citInitial": 1,
   "eqLabelWithNumbers": true,
   "eqNumInitial": 1,
   "hotkeys": {
    "equation": "Ctrl-E",
    "itemize": "Ctrl-I"
   },
   "labels_anchors": false,
   "latex_user_defs": false,
   "report_style_numbering": false,
   "user_envs_cfg": false
  },
  "toc": {
   "nav_menu": {
    "height": "12px",
    "width": "252px"
   },
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": false,
   "toc_cell": false,
   "toc_position": {
    "height": "1260px",
    "left": "0px",
    "right": "2348px",
    "top": "106px",
    "width": "212px"
   },
   "toc_section_display": "block",
   "toc_window_display": false
  },
  "varInspector": {
   "cols": {
    "lenName": 16,
    "lenType": 16,
    "lenVar": 40
   },
   "kernels_config": {
    "python": {
     "delete_cmd_postfix": "",
     "delete_cmd_prefix": "del ",
     "library": "var_list.py",
     "varRefreshCmd": "print(var_dic_list())"
    },
    "r": {
     "delete_cmd_postfix": ") ",
     "delete_cmd_prefix": "rm(",
     "library": "var_list.r",
     "varRefreshCmd": "cat(var_dic_list()) "
    }
   },
   "types_to_exclude": [
    "module",
    "function",
    "builtin_function_or_method",
    "instance",
    "_Feature"
   ],
   "window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
