{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Batch Normalization"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Batch Normalization é uma técnica que permite normalizar automaticamente os valores que atravessam uma camada da rede neural. \n",
    "\n",
    "A normalização é feita para que o resultado tenha média zero e variância unitária, porém, em seguida, o resultado é\n",
    "escalado pelo fator $\\gamma$ e somado ao fator $\\beta$. Estes dois fatores são parâmetros que serão também otimizados duranteo treinamento do gradiente descendente.\n",
    "\n",
    "Atualmente a técnica de batch normalization é utilizada em todas as redes profundas. \n",
    "\n",
    "A camada de batch normalization é colocada entre a camada densa ou convolucional e antes da camada de ativação."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## O Algoritmo"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Para descrição do algoritmo, veja o artigo original:\n",
    "- Ioffe, S. & Szegedy, C. (2015), Batch Normalization: Accelerating Deep Network Training by Reducing Internal Covariate Shift., in Francis R. Bach & David M. Blei, ed., 'ICML' , JMLR.org, , pp. 448-456. [PDF:arxiv](https://arxiv.org/pdf/1502.03167.pdf) "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<img src='../figures/batchnorm_equations.png',width=500></a>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Equações"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\\begin{align*} \n",
    "\\boldsymbol{\\mu} &= \\frac{1}{m} \\sum_{i = 1}^{m} \\boldsymbol{x_i} &&\n",
    "\\boldsymbol{\\sigma^{2}} = \\frac{1}{m} \\sum_{i = 1}^{m} (\\boldsymbol{x_i} - \\boldsymbol{\\mu})^{2}\n",
    "\\\\[3mm]\n",
    "\\hat{\\boldsymbol{x}}_i &= \\frac{\\boldsymbol{x}_i - \\boldsymbol{\\mu}}{\\sqrt{\\boldsymbol{\\sigma^{2}} + \\epsilon}} &&\n",
    "\\boldsymbol{y_i} = \\gamma \\hat{\\boldsymbol{x}}_i + \\beta\n",
    "\\\\[3mm]\n",
    "\\boldsymbol{m}_{(t)} &=  \\lambda \\boldsymbol{m}_{(t-1)} + (1 - \\lambda) \\boldsymbol{\\mu} &&\n",
    "\\boldsymbol{v}_{(t)} =  \\lambda \\boldsymbol{v}_{(t-1)} + (1 - \\lambda) \\boldsymbol{\\sigma^{2}}\n",
    "\\end{align*}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Grafo de operações\n",
    "Figura obtida nesta página: [Understanding the backward pass through Batch Normalization Layer](https://kratzert.github.io/2016/02/12/understanding-the-gradient-flow-through-the-batch-normalization-layer.html)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Importações"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2017-10-03T14:27:18.839311",
     "start_time": "2017-10-03T14:27:18.595038"
    }
   },
   "outputs": [],
   "source": [
    "%matplotlib inline\n",
    "import matplotlib.pyplot as plot\n",
    "from IPython import display\n",
    "\n",
    "import sys\n",
    "import numpy as np\n",
    "import numpy.random as nr\n",
    "import pandas as pd\n",
    "\n",
    "import torch\n",
    "from torch.autograd import Variable\n",
    "\n",
    "np.set_printoptions(precision=2, suppress=True)\n",
    "nr.seed(23456)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Batch Norm: parâmetros"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### nn.BatchNorm1d - Entrada com dimensão 2"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- Documentação oficial: http://pytorch.org/docs/master/nn.html#normalization-layers\n",
    "\n",
    "Usualmente, quando a entrada da camada tem duas dimensões (amostras e atributos) a normalização é feita na dimensão dos atributos, *axis=1*. Ou seja, calcula-se a estatística (média e variância) para cada coluna da matriz de dados, em cada *mini-batch*."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 122,
   "metadata": {},
   "outputs": [],
   "source": [
    "torch.manual_seed(1234)\n",
    "model = torch.nn.BatchNorm1d(5)\n",
    "x = Variable(torch.randn(4, 5))\n",
    "model.training = False\n",
    "y = model(x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 123,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Variable containing:\n",
       "-1.3368 -1.1361  0.2328 -1.7245  0.5111\n",
       "-0.6126  0.4703  0.6527  0.5719  1.7060\n",
       " 1.0029 -2.3111  1.1075  1.7168  0.7015\n",
       " 0.6274  1.1752  0.0955 -1.5116  0.1253\n",
       "[torch.FloatTensor of size 4x5]"
      ]
     },
     "execution_count": 123,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 124,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "weight\n",
      "[ 0.19  0.5   0.62  0.82  0.44]\n",
      "bias\n",
      "[ 0.  0.  0.  0.  0.]\n",
      "running_mean\n",
      "[ 0.  0.  0.  0.  0.]\n",
      "running_var\n",
      "[ 1.  1.  1.  1.  1.]\n"
     ]
    }
   ],
   "source": [
    "param_dict = model.state_dict()\n",
    "for name,value in param_dict.items():\n",
    "    print(name)\n",
    "    print(value.numpy())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 125,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Variable containing:\n",
       "-0.2560 -0.5654  0.1449 -1.4103  0.2237\n",
       "-0.1173  0.2340  0.4061  0.4677  0.7468\n",
       " 0.1921 -1.1501  0.6890  1.4040  0.3071\n",
       " 0.1202  0.5849  0.0594 -1.2362  0.0549\n",
       "[torch.FloatTensor of size 4x5]"
      ]
     },
     "execution_count": 125,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Conferindo"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 126,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Variable containing:\n",
      "-0.2560 -0.5654  0.1449 -1.4103  0.2237\n",
      "-0.1173  0.2340  0.4061  0.4677  0.7468\n",
      " 0.1921 -1.1501  0.6890  1.4040  0.3071\n",
      " 0.1202  0.5849  0.0594 -1.2362  0.0549\n",
      "[torch.FloatTensor of size 4x5]\n",
      "\n"
     ]
    }
   ],
   "source": [
    "gamma, beta, mv_mean, mv_var = model.state_dict().values()\n",
    "\n",
    "if model.training:\n",
    "    y2 = (x - Variable(mv_mean)) / torch.sqrt(Variable(mv_var) + 1e-5)\n",
    "\n",
    "y3 = y2 * Variable(gamma) + Variable(beta)\n",
    "\n",
    "print(y3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 127,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([ 0.,  0.,  0.,  0.,  0.], dtype=float32)"
      ]
     },
     "execution_count": 127,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "mv_mean.numpy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2017-10-03T14:27:30.042757",
     "start_time": "2017-10-03T14:27:29.947714"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "batch_normalization_1 (Batch (None, 5)                 20        \n",
      "=================================================================\n",
      "Total params: 20\n",
      "Trainable params: 10\n",
      "Non-trainable params: 10\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "model = Sequential()\n",
    "model.add(BatchNormalization(axis=1, input_shape=(5,), \n",
    "                             momentum=0.9, \n",
    "                             epsilon=0.0001, \n",
    "                             gamma_initializer=Constant(10), \n",
    "                             beta_initializer=Constant(11), \n",
    "                             moving_mean_initializer=Constant(12), \n",
    "                             moving_variance_initializer=Constant(13)))\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Configuration:\n",
      "--------------\n",
      "  name                          : batch_normalization_1\n",
      "  trainable                     : True\n",
      "  batch_input_shape             : (None, 5)\n",
      "  dtype                         : float32\n",
      "  axis                          : 1\n",
      "  momentum                      : 0.9\n",
      "  epsilon                       : 0.0001\n",
      "  center                        : True\n",
      "  scale                         : True\n",
      "  beta_initializer              : {'class_name': 'Constant', 'config': {'value': 11}}\n",
      "  gamma_initializer             : {'class_name': 'Constant', 'config': {'value': 10}}\n",
      "  moving_mean_initializer       : {'class_name': 'Constant', 'config': {'value': 12}}\n",
      "  moving_variance_initializer   : {'class_name': 'Constant', 'config': {'value': 13}}\n",
      "  beta_regularizer              : None\n",
      "  gamma_regularizer             : None\n",
      "  beta_constraint               : None\n",
      "  gamma_constraint              : None\n",
      "\n",
      "Parameters:\n",
      "-----------\n",
      "  Trainable: batch_normalization_1/gamma:0\n",
      "  Trainable: batch_normalization_1/beta:0\n",
      "             batch_normalization_1/moving_mean:0\n",
      "             batch_normalization_1/moving_variance:0\n",
      "\n",
      "model.get_weights():\n",
      "--------------------\n",
      "   [ 10.  10.  10.  10.  10.] (5,)\n",
      "   [ 11.  11.  11.  11.  11.] (5,)\n",
      "   [ 12.  12.  12.  12.  12.] (5,)\n",
      "   [ 13.  13.  13.  13.  13.] (5,)\n"
     ]
    }
   ],
   "source": [
    "for layer in model.layers:\n",
    "    print('\\nConfiguration:')\n",
    "    print('--------------')\n",
    "    for k, v in layer.get_config().items():\n",
    "        print('  {:30s}: {}'.format(k, v))\n",
    "    print('\\nParameters:')\n",
    "    print('-----------')\n",
    "    for p in layer.weights:\n",
    "        if p in layer.trainable_weights:\n",
    "            print('  Trainable:', p.name)\n",
    "        else:\n",
    "            print('            ', p.name)\n",
    "print('\\nmodel.get_weights():')\n",
    "print('--------------------')\n",
    "for w in model.get_weights():\n",
    "    print('  ', w, w.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Entrada com dimensão 4\n",
    "\n",
    "Usualmente, quando a entrada da camada tem quatro dimensões (amostras, filtros, altura e largura), a normalização é feita na segunda dimensão, *axis=1*, que corresponde aos filtros (canais). Ou seja, calcula-se a estatística (média e variância) para cada *mapa de atributos* do tensor. Assim, preserva-se a propriedade da invariância à translação, característica importante das convoluções."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "batch_normalization_2 (Batch (None, 3, 10, 10)         12        \n",
      "=================================================================\n",
      "Total params: 12\n",
      "Trainable params: 6\n",
      "Non-trainable params: 6\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "model = Sequential()\n",
    "model.add(BatchNormalization(axis=1, input_shape=(3, 10, 10), \n",
    "                             gamma_initializer=Constant(0), \n",
    "                             beta_initializer=Constant(1), \n",
    "                             moving_mean_initializer=Constant(2), \n",
    "                             moving_variance_initializer=Constant(3)))\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Configuration:\n",
      "--------------\n",
      "  name                          : batch_normalization_2\n",
      "  trainable                     : True\n",
      "  batch_input_shape             : (None, 3, 10, 10)\n",
      "  dtype                         : float32\n",
      "  axis                          : 1\n",
      "  momentum                      : 0.99\n",
      "  epsilon                       : 0.001\n",
      "  center                        : True\n",
      "  scale                         : True\n",
      "  beta_initializer              : {'class_name': 'Constant', 'config': {'value': 1}}\n",
      "  gamma_initializer             : {'class_name': 'Constant', 'config': {'value': 0}}\n",
      "  moving_mean_initializer       : {'class_name': 'Constant', 'config': {'value': 2}}\n",
      "  moving_variance_initializer   : {'class_name': 'Constant', 'config': {'value': 3}}\n",
      "  beta_regularizer              : None\n",
      "  gamma_regularizer             : None\n",
      "  beta_constraint               : None\n",
      "  gamma_constraint              : None\n",
      "\n",
      "Parameters:\n",
      "-----------\n",
      "  Trainable: batch_normalization_2/gamma:0\n",
      "  Trainable: batch_normalization_2/beta:0\n",
      "             batch_normalization_2/moving_mean:0\n",
      "             batch_normalization_2/moving_variance:0\n",
      "\n",
      "model.get_weights():\n",
      "--------------------\n",
      "   [ 0.  0.  0.] (3,)\n",
      "   [ 1.  1.  1.] (3,)\n",
      "   [ 2.  2.  2.] (3,)\n",
      "   [ 3.  3.  3.] (3,)\n"
     ]
    }
   ],
   "source": [
    "for layer in model.layers:\n",
    "    print('\\nConfiguration:')\n",
    "    print('--------------')\n",
    "    for k, v in layer.get_config().items():\n",
    "        print('  {:30s}: {}'.format(k, v))\n",
    "    print('\\nParameters:')\n",
    "    print('-----------')\n",
    "    for p in layer.weights:\n",
    "        if p in layer.trainable_weights:\n",
    "            print('  Trainable:', p.name)\n",
    "        else:\n",
    "            print('            ', p.name)\n",
    "print('\\nmodel.get_weights():')\n",
    "print('--------------------')\n",
    "for w in model.get_weights():\n",
    "    print('  ', w, w.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Keras: Execução na fase de treinamento"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[  6.44   6.55  18.55   6.23   3.24]\n",
      " [  7.28  10.58  15.78  17.51  12.73]\n",
      " [ 19.79  16.32   0.83   4.06   3.05]\n",
      " [ 15.06   9.1   19.09  18.75   2.71]\n",
      " [  4.72   6.3   13.45  12.41  12.44]\n",
      " [ 16.76  12.62  11.22  19.74  13.66]\n",
      " [  2.03  18.8   13.03   4.55   8.64]\n",
      " [  7.8   15.12   2.85   0.2   16.76]\n",
      " [  2.18   4.98   9.52  17.68   3.55]\n",
      " [ 15.72   0.7   12.17   6.17  15.4 ]] [  9.78  10.11  11.65  10.73   9.22] [ 6.14  5.37  5.7   6.91  5.35]\n",
      "\n",
      "[[  7.28  -0.66   1.21  -0.65  -1.12]\n",
      " [  7.97   0.09   0.73   0.98   0.66]\n",
      " [ 18.16   1.16  -1.9   -0.97  -1.15]\n",
      " [ 14.3   -0.19   1.31   1.16  -1.22]\n",
      " [  5.88  -0.71   0.32   0.24   0.6 ]\n",
      " [ 15.68   0.47  -0.08   1.3    0.83]\n",
      " [  3.69   1.62   0.24  -0.89  -0.11]\n",
      " [  8.39   0.93  -1.54  -1.52   1.41]\n",
      " [  3.81  -0.95  -0.37   1.01  -1.06]\n",
      " [ 14.84  -1.75   0.09  -0.66   1.16]] [ 10.   0.   0.  -0.  -0.] [ 5.  1.  1.  1.  1.]\n"
     ]
    }
   ],
   "source": [
    "K.set_learning_phase(1)\n",
    "\n",
    "model = Sequential()\n",
    "model.add(BatchNormalization(axis=1, input_shape=(5,), momentum=0.5, epsilon=0.0001))\n",
    "\n",
    "model.set_weights([[ 5., 1., 1., 1., 1.],     # gamma\n",
    "                   [ 10., 0., 0., 0., 0.],     # beta\n",
    "                   [ 0., 0., 0., 0., 0.],\n",
    "                   [ 1., 1., 1., 1., 1.]])\n",
    "\n",
    "x = nr.random(size=(10, 5)) * 20\n",
    "print(x, x.mean(0), x.std(0))\n",
    "print()\n",
    "\n",
    "y = model.predict(x, batch_size=10)\n",
    "print(y, y.mean(0), y.std(0))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[  7.28  -0.66   1.21  -0.65  -1.12]\n",
      " [  7.97   0.09   0.73   0.98   0.66]\n",
      " [ 18.16   1.16  -1.9   -0.97  -1.15]\n",
      " [ 14.3   -0.19   1.31   1.16  -1.22]\n",
      " [  5.88  -0.71   0.32   0.24   0.6 ]\n",
      " [ 15.68   0.47  -0.08   1.3    0.83]\n",
      " [  3.69   1.62   0.24  -0.89  -0.11]\n",
      " [  8.39   0.93  -1.54  -1.52   1.41]\n",
      " [  3.81  -0.95  -0.37   1.01  -1.06]\n",
      " [ 14.84  -1.75   0.09  -0.66   1.16]] [ 10.  -0.   0.  -0.   0.] [ 5.  1.  1.  1.  1.]\n"
     ]
    }
   ],
   "source": [
    "gamma, beta, mv_mean, mv_var = model.get_weights()\n",
    "\n",
    "x2 = x - x.mean(0)\n",
    "x2 /= x2.std(0)\n",
    "\n",
    "x3 = x2 * gamma + beta\n",
    "\n",
    "print(x3, x3.mean(0), x3.std(0))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Keras: Execução na fase de testes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[  6.44   6.55  18.55   6.23   3.24]\n",
      " [  7.28  10.58  15.78  17.51  12.73]\n",
      " [ 19.79  16.32   0.83   4.06   3.05]\n",
      " [ 15.06   9.1   19.09  18.75   2.71]\n",
      " [  4.72   6.3   13.45  12.41  12.44]\n",
      " [ 16.76  12.62  11.22  19.74  13.66]\n",
      " [  2.03  18.8   13.03   4.55   8.64]\n",
      " [  7.8   15.12   2.85   0.2   16.76]\n",
      " [  2.18   4.98   9.52  17.68   3.55]\n",
      " [ 15.72   0.7   12.17   6.17  15.4 ]] [  9.78  10.11  11.65  10.73   9.22] [ 6.14  5.37  5.7   6.91  5.35]\n",
      "\n",
      "[[  6.44   6.55  18.55   6.23   3.24]\n",
      " [  7.28  10.58  15.78  17.51  12.73]\n",
      " [ 19.79  16.32   0.83   4.06   3.05]\n",
      " [ 15.06   9.1   19.09  18.75   2.71]\n",
      " [  4.72   6.3   13.45  12.41  12.44]\n",
      " [ 16.76  12.62  11.22  19.74  13.66]\n",
      " [  2.03  18.8   13.03   4.55   8.63]\n",
      " [  7.8   15.11   2.85   0.2   16.76]\n",
      " [  2.18   4.98   9.52  17.68   3.55]\n",
      " [ 15.72   0.7   12.17   6.17  15.4 ]] [  9.78  10.11  11.65  10.73   9.22] [ 6.14  5.37  5.7   6.91  5.35]\n"
     ]
    }
   ],
   "source": [
    "K.set_learning_phase(0)\n",
    "\n",
    "model = Sequential()\n",
    "model.add(BatchNormalization(axis=1, input_shape=(5,), momentum=0.999, epsilon=0.0001))\n",
    "\n",
    "model.set_weights([[ 1., 1., 1., 1., 1.],     # gamma\n",
    "                   [ 0., 0., 0., 0., 0.],     # beta\n",
    "                   [ 0., 0., 0., 0., 0.],     # moving_mean\n",
    "                   [ 1., 1., 1., 1., 1.]])    # moving_variance\n",
    "\n",
    "x = nr.random(size=(10, 5)) * 20\n",
    "print(x, x.mean(0), x.std(0))\n",
    "print()\n",
    "\n",
    "y = model.predict(x, batch_size=10)\n",
    "print(y, y.mean(0), y.std(0))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[  6.44   6.55  18.55   6.23   3.24]\n",
      " [  7.28  10.58  15.78  17.51  12.73]\n",
      " [ 19.79  16.32   0.83   4.06   3.05]\n",
      " [ 15.06   9.1   19.09  18.75   2.71]\n",
      " [  4.72   6.3   13.45  12.41  12.44]\n",
      " [ 16.76  12.62  11.22  19.74  13.66]\n",
      " [  2.03  18.8   13.03   4.55   8.64]\n",
      " [  7.8   15.12   2.85   0.2   16.76]\n",
      " [  2.18   4.98   9.52  17.68   3.55]\n",
      " [ 15.72   0.7   12.17   6.17  15.4 ]] [  9.78  10.11  11.65  10.73   9.22] [ 6.14  5.37  5.7   6.91  5.35]\n"
     ]
    }
   ],
   "source": [
    "gamma, beta, mv_mean, mv_var = model.get_weights()\n",
    "\n",
    "x2 = x - mv_mean\n",
    "x2 /= np.sqrt(mv_var)\n",
    "\n",
    "x3 = x2 * gamma + beta\n",
    "\n",
    "print(x3, x3.mean(0), x3.std(0))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Keras: Verificando o cálculo das médias móveis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[(5,), (5,), (5,), (5,), (5, 1), (1,)]\n",
      "\n",
      "[[  1.74   4.4    7.11  15.93   7.74]\n",
      " [ 15.79  16.52   3.59   8.45   0.57]\n",
      " [  6.19   1.2   19.06   9.33   6.74]\n",
      " [ 14.86   8.33  19.11  12.7   10.43]\n",
      " [  6.52  11.71   0.5   11.32  17.42]\n",
      " [  2.81   6.7   15.46  13.86  18.72]\n",
      " [ 19.9    5.29  15.4    6.41   5.52]\n",
      " [ 15.81   4.68   0.07   0.84  11.68]\n",
      " [ 13.75  17.97  17.19   6.23  12.38]\n",
      " [  1.05  18.93   1.34   6.03   2.17]] [ 9.84  9.57  9.88  9.11  9.34] [ 6.55  6.    7.67  4.25  5.67]\n",
      "\n",
      "lambda: [ 1.    0.98  0.98  1.    1.  ]\n",
      "beta:   [-0.03 -0.02  0.03  0.   -0.02]\n",
      "\n",
      "mv_mean: [ 7.87  7.66  7.91  7.29  7.47]\n",
      "         [ 7.87  7.66  7.91  7.29  7.47]\n",
      "mv_var:  [ 34.54  28.98  47.32  14.66  25.91]\n",
      "         [ 34.54  28.98  47.32  14.66  25.91]\n"
     ]
    }
   ],
   "source": [
    "nr.seed(234588)\n",
    "K.set_learning_phase(1)\n",
    "mom = 0.2\n",
    "\n",
    "model = Sequential()\n",
    "model.add(BatchNormalization(axis=1, input_shape=(5,), momentum=mom, epsilon=0.0001))\n",
    "model.add(Dense(1, activation='sigmoid'))\n",
    "\n",
    "print([x.shape for x in model.get_weights()], end='\\n\\n')\n",
    "model.set_weights([[ 1., 1., 1., 1., 1.],     # gamma\n",
    "                   [ 0., 0., 0., 0., 0.],     # beta\n",
    "                   [ 0., 0., 0., 0., 0.],     # moving_mean\n",
    "                   [ 1., 1., 1., 1., 1.]])    # moving_variance\n",
    "\n",
    "gamma, beta, mv_mean, mv_var, w, b = model.get_weights()\n",
    "\n",
    "x = nr.random(size=(10, 5)) * 20\n",
    "y = nr.random(size=(10, 1))\n",
    "print(x, x.mean(0), x.std(0))\n",
    "print()\n",
    "\n",
    "mv_mean_new = (1 - mom) * x.mean(0) + mom * mv_mean\n",
    "mv_var_new  = (1 - mom) * x.std(0) * x.std(0) + mom * mv_var\n",
    "\n",
    "sgd = SGD(0.5)\n",
    "model.compile(sgd, loss='mse')\n",
    "h = model.fit(x, y, batch_size=10, epochs=1, verbose=0)\n",
    "\n",
    "new_weights = model.get_weights()\n",
    "\n",
    "print('lambda:', new_weights[0])\n",
    "print('beta:  ', new_weights[1])\n",
    "print()\n",
    "print('mv_mean:', new_weights[2])\n",
    "print('        ', mv_mean_new)\n",
    "print('mv_var: ', new_weights[3])\n",
    "print('        ', mv_var_new)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.1"
  },
  "latex_envs": {
   "LaTeX_envs_menu_present": true,
   "autocomplete": true,
   "bibliofile": "biblio.bib",
   "cite_by": "apalike",
   "current_citInitial": 1,
   "eqLabelWithNumbers": true,
   "eqNumInitial": 1,
   "hotkeys": {
    "equation": "Ctrl-E",
    "itemize": "Ctrl-I"
   },
   "labels_anchors": false,
   "latex_user_defs": false,
   "report_style_numbering": false,
   "user_envs_cfg": false
  },
  "toc": {
   "colors": {
    "hover_highlight": "#DAA520",
    "running_highlight": "#FF0000",
    "selected_highlight": "#FFD700"
   },
   "moveMenuLeft": true,
   "nav_menu": {
    "height": "12px",
    "width": "252px"
   },
   "navigate_menu": true,
   "number_sections": true,
   "sideBar": true,
   "threshold": 4,
   "toc_cell": false,
   "toc_position": {
    "height": "1260px",
    "left": "0px",
    "right": "2348px",
    "top": "106px",
    "width": "212px"
   },
   "toc_section_display": "block",
   "toc_window_display": false,
   "widenNotebook": false
  },
  "varInspector": {
   "cols": {
    "lenName": 16,
    "lenType": 16,
    "lenVar": 40
   },
   "kernels_config": {
    "python": {
     "delete_cmd_postfix": "",
     "delete_cmd_prefix": "del ",
     "library": "var_list.py",
     "varRefreshCmd": "print(var_dic_list())"
    },
    "r": {
     "delete_cmd_postfix": ") ",
     "delete_cmd_prefix": "rm(",
     "library": "var_list.r",
     "varRefreshCmd": "cat(var_dic_list()) "
    }
   },
   "types_to_exclude": [
    "module",
    "function",
    "builtin_function_or_method",
    "instance",
    "_Feature"
   ],
   "window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
