{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "toc": "true"
   },
   "source": [
    "# Table of Contents\n",
    " <p><div class=\"lev1 toc-item\"><a href=\"#Classificação-de-Textos\" data-toc-modified-id=\"Classificação-de-Textos-1\"><span class=\"toc-item-num\">1&nbsp;&nbsp;</span>Classificação de Textos</a></div><div class=\"lev2 toc-item\"><a href=\"#Preâmbulo\" data-toc-modified-id=\"Preâmbulo-11\"><span class=\"toc-item-num\">1.1&nbsp;&nbsp;</span>Preâmbulo</a></div><div class=\"lev2 toc-item\"><a href=\"#Preparando-o-dataset\" data-toc-modified-id=\"Preparando-o-dataset-12\"><span class=\"toc-item-num\">1.2&nbsp;&nbsp;</span>Preparando o dataset</a></div><div class=\"lev3 toc-item\"><a href=\"#Buscando-o-texto-dos-livros-e-definindo-os-rótulos\" data-toc-modified-id=\"Buscando-o-texto-dos-livros-e-definindo-os-rótulos-121\"><span class=\"toc-item-num\">1.2.1&nbsp;&nbsp;</span>Buscando o texto dos livros e definindo os rótulos</a></div><div class=\"lev3 toc-item\"><a href=\"#Representando-as-palavras-através-de-índices-inteiros\" data-toc-modified-id=\"Representando-as-palavras-através-de-índices-inteiros-122\"><span class=\"toc-item-num\">1.2.2&nbsp;&nbsp;</span>Representando as palavras através de índices inteiros</a></div><div class=\"lev3 toc-item\"><a href=\"#Palavras-características-de-cada-livro\" data-toc-modified-id=\"Palavras-características-de-cada-livro-123\"><span class=\"toc-item-num\">1.2.3&nbsp;&nbsp;</span>Palavras características de cada livro</a></div><div class=\"lev2 toc-item\"><a href=\"#Dividindo-o-dataset-entre-treinamento-e-validação\" data-toc-modified-id=\"Dividindo-o-dataset-entre-treinamento-e-validação-13\"><span class=\"toc-item-num\">1.3&nbsp;&nbsp;</span>Dividindo o dataset entre treinamento e validação</a></div><div class=\"lev3 toc-item\"><a href=\"#Divisão-simples\" data-toc-modified-id=\"Divisão-simples-131\"><span class=\"toc-item-num\">1.3.1&nbsp;&nbsp;</span>Divisão simples</a></div><div class=\"lev3 toc-item\"><a href=\"#Divisão-para-uso-com-geradores-e-aumento-de-dados\" data-toc-modified-id=\"Divisão-para-uso-com-geradores-e-aumento-de-dados-132\"><span class=\"toc-item-num\">1.3.2&nbsp;&nbsp;</span>Divisão para uso com geradores e aumento de dados</a></div><div class=\"lev4 toc-item\"><a href=\"#Criando--geradores-para-treino-e-validação\" data-toc-modified-id=\"Criando--geradores-para-treino-e-validação-1321\"><span class=\"toc-item-num\">1.3.2.1&nbsp;&nbsp;</span>Criando  geradores para treino e validação</a></div>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Classificação de Textos"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Preâmbulo"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2017-10-25T16:31:19.172031Z",
     "start_time": "2017-10-25T16:31:19.144712Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "GPU available: True\n",
      "torch 0.2.0_4\n",
      "Python 3.6.1 |Anaconda custom (64-bit)| (default, May 11 2017, 13:09:58) \n",
      "[GCC 4.4.7 20120313 (Red Hat 4.4.7-1)]\n"
     ]
    }
   ],
   "source": [
    "%matplotlib inline\n",
    "import matplotlib.pyplot as plt\n",
    "from IPython import display\n",
    "\n",
    "import os\n",
    "import sys\n",
    "import imp\n",
    "import time\n",
    "import glob\n",
    "import numpy as np\n",
    "import numpy.random as nr\n",
    "\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "from torch.optim.lr_scheduler import MultiStepLR, StepLR\n",
    "from torch.utils.data import DataLoader, TensorDataset\n",
    "from torch.autograd import Variable\n",
    "\n",
    "import torchvision as tv\n",
    "import lib.pytorch_trainer as ptt\n",
    "from lib.tokenizer import Tokenizer\n",
    "\n",
    "use_gpu = torch.cuda.is_available()\n",
    "print('GPU available:', use_gpu)\n",
    "print('torch', torch.version.__version__)\n",
    "print('Python', sys.version)\n",
    "\n",
    "np.set_printoptions(precision=3, linewidth=120)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Preparando o dataset"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Buscando o texto dos livros e definindo os rótulos"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2017-10-25T16:31:19.210724Z",
     "start_time": "2017-10-25T16:31:19.173750Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1030735  Jorge_Amado        Dona_flor_seus_dois_maridos\n",
      " 828417  Jorge_Amado        Gabriela\n",
      " 427711  Jorge_Amado        Capitães_de_Areia\n",
      "1001226  Jorge_Amado        Tereza_Batista_Cansada_de_Guerra\n",
      " 372459  Machado_de_Assis   Dom_Casmurro\n",
      " 443778  Machado_de_Assis   Quincas_Borba\n",
      " 337533  Machado_de_Assis   Helena\n",
      " 336677  Machado_de_Assis   Iaiá_Garcia\n",
      " 411043  Machado_de_Assis   Esaú_e_Jacó\n",
      " 352965  Machado_de_Assis   Memórias_Póstumas_de_Brás_Cubas\n",
      " 280683  Machado_de_Assis   Memorial_de_Aires\n",
      " 749265  Érico_Veríssimo    O_Tempo_e_o_Vento_-_O_Continente\n",
      " 890215  Érico_Veríssimo    Incidente_em_Antares\n",
      " 294049  Érico_Veríssimo    Clarissa\n",
      " 699390  Érico_Veríssimo    O_Tempo_e_o_Vento_-_O_Arquipélago\n",
      "\n",
      "3 Labels:\n",
      "     0: Érico_Veríssimo\n",
      "     1: Machado_de_Assis\n",
      "     2: Jorge_Amado\n"
     ]
    }
   ],
   "source": [
    "data_dir = '/data/datasets/livros/'\n",
    "\n",
    "autores = [\n",
    "    'Jorge_Amado',\n",
    "    'Machado_de_Assis',\n",
    "    'Érico_Veríssimo',\n",
    "]\n",
    "\n",
    "book_text = []\n",
    "book_author = []\n",
    "book_title = []\n",
    "for aut in autores:\n",
    "    for fn in glob.glob(data_dir + 'processed/' + aut + '*.txt'):\n",
    "        author, book = os.path.basename(fn).split('__')\n",
    "        txt = open(fn, encoding='utf-8').read().replace('\\x97', '')\n",
    "        book_text.append(txt)\n",
    "        book_author.append(author)\n",
    "        book_title.append(book[:-4])\n",
    "        print('{:7d}  {:18s} {}'.format(len(txt), author, book[:-4]))\n",
    "\n",
    "author_list = list(set(book_author))\n",
    "n_labels = len(author_list)\n",
    "n_books = len(book_title)\n",
    "book_label = [author_list.index(a) for a in book_author]\n",
    "print('\\n{} Labels:'.format(n_labels))\n",
    "for i, autor in enumerate(author_list):\n",
    "    print('    {:2d}: {}'.format(i, autor))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Representando as palavras através de índices inteiros"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2017-10-25T16:31:23.203532Z",
     "start_time": "2017-10-25T16:31:19.212338Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 61707 unique tokens.\n",
      "Using the first 19999 words.\n"
     ]
    }
   ],
   "source": [
    "MAX_NB_WORDS = 20000\n",
    "\n",
    "tokenizer = Tokenizer(num_words=MAX_NB_WORDS)\n",
    "tokenizer.fit_on_texts(book_text)\n",
    "sequences = tokenizer.texts_to_sequences(book_text)\n",
    "\n",
    "w2i = tokenizer.word_index\n",
    "i2w = dict([(v, k) for k, v in w2i.items()])\n",
    "\n",
    "i2w_vec = np.array([i2w[i+1] for i in range(len(i2w))])\n",
    "\n",
    "print('Found %d unique tokens.' % len(i2w))\n",
    "print('Using the first %d words.' % max([max(s) for s in sequences]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2017-10-25T16:31:23.218538Z",
     "start_time": "2017-10-25T16:31:23.205757Z"
    },
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Jorge Amado: Dona flor seus dois maridos -- 166625 palavras\n",
      "odioso assim apenas dona rozilda lhe contou a história de c detalhes lhe o aleijão mesmo se quisesse não podia aceitar os convites dos canalhas da repartição não tinha alicerces para tanto ampliando as injustiças multiplicando a fome da moça e de seus cinco da mãe reumática e do pai guarda noturno logo vadinho com a nobre causa e fez se seu campeão decidido realmente a falar sobre o assunto com seus conhecidos de jogo alguns dos quais tinham certa jurou veemente a dona da e a flor exigir do diretor do ensino no dia seguinte pela manhã na hora\n",
      "\n",
      "Jorge Amado: Gabriela -- 134498 palavras\n",
      "a pedagogia moderna o que que a palmatória é necessária olhem que é vocês estão atrasados de um século nos estados unidos as meninas boto no colégio das freiras está certo mas os meninos é com dona guilhermina a pedagogia moderna a palmatória e os castigos físicos conseguiu explicar joão fulgêncio não sei de quem você está falando joão fulgêncio mas lhe garanto que foi muito mal feito se eu sei ler e escrever assim discutindo sobre os métodos do dr enoch e da famosa dona por sua severidade foram andando para a ponte das ruas algumas outras pessoas apareciam\n",
      "\n",
      "Jorge Amado: Capitães de Areia -- 76132 palavras\n",
      "homens como a amigos e assim conquistou a confiança deles se fez amigo de todos mesmo daqueles que como pedro bala e o não gostavam de rezar dificuldade grande só teve mesmo com o sem pernas enquanto que o professor pedro bala o gato eram indiferentes às palavras do padre o professor no entanto gostava dele pois lhe trazia livros pirulito volta seca e joão g rande principalmente o primeiro muito atentos ao que ele dizia o sem pernas lhe fazia uma oposição que a princípio tinha sido muito tenaz porém o padre josé pedro terminara por conquistara confiança de\n",
      "\n",
      "Jorge Amado: Tereza Batista Cansada de Guerra -- 164906 palavras\n",
      "banda de música cortejo soberbo os alunos do grupo escolar os soldados do posto da polícia militar os membros da confraria e os da loja as jorge amado s demais personalidades discursos as virtudes do falecido não é todos os dias que se têm a chance de levar ao cemitério prefeito morto em pleno exercício do cargo magro acompanhamento breves palavras do presidente da câmara municipal — ao dever afirmou ele referindo se ao pungente fim do astuto administrador nos últimos dias verdadeiramente desagradável à vista e ao olfato pois carreiras de se ao longo de seu corpo em grandes\n",
      "\n",
      "Machado de Assis: Dom Casmurro -- 64547 palavras\n",
      "parede e me atirasse a ela com mil palavras cálidas e não dos meus quinze anos leitor precoce com dezessete des e mais era des não pensava ainda na diferença dos sexos capítulo xxxiv sou homem ouvimos passos no corredor era d fortunata capitu compôs se depressa tão depressa que quando a mãe apontou à porta ela abanava a cabeça e ria nenhum amarelo nenhuma de acanhamento um riso espontâneo e claro que ela explicou por estas palavras alegres mamãe olhe como este senhor cabeleireiro me pediu me para acabar o penteado e fez isto veja que tranças que tem\n",
      "\n",
      "Machado de Assis: Quincas Borba -- 74965 palavras\n",
      "o engano parou olhou para trás viu ir a moça tique tique e o menino ao pé dela as para ajustar se ao passo da mãe depois foi andando lentamente pensando em várias mulheres que podia escolher muito bem para executar a quatro mãos a sonata conjugal música séria regular e clássica chegou a pensar na filha do major que apenas sabia umas velhas de repente ouvia a do pecado pelos dedos de sofia que o que o a um tempo e lá se ia toda a castidade do plano anterior teimava novamente forcejava por trocar as composições pensava na\n",
      "\n",
      "Machado de Assis: Helena -- 54778 palavras\n",
      "e afetos de família me de que ela saberá corresponder lhes com verdadeira dedicação conhece a inquiriu estácio no médico uns olhos impacientes de curiosidade vi a três ou quatro vezes disse este no fim de alguns segundos mas era então muito criança seu pai falava me dela como de pessoa extremamente afetuosa e digna de ser amada e admirada talvez fossem olhos de pai estácio desejara ainda saber alguma coisa acerca da mãe de helena mas lhe entrar em novas e tentou a conversa para outro assunto camargo entretanto insistiu o conselheiro falou me algumas vezes no projeto de\n",
      "\n",
      "Machado de Assis: Iaiá Garcia -- 55342 palavras\n",
      "rir com uma espontaneidade que não tinham a falar com jorge obedecia aos desejos da madrasta e aos caprichos da enteada quaisquer que fossem com tamanha tolerância e bom humor que fazia o outro sem o saber jorge atentou nos ditos e ações do intruso e com o tempo veio a tranqüilizar se é um celibatário necessitado da companhia de mulheres disse consigo procópio dias não parecia outra coisa a atmosfera feminina era para ele uma necessidade o ruge ruge das saias a melhor música a seus ouvidos graças à idade iaiá era mais familiar do que estela às vezes\n",
      "\n",
      "Machado de Assis: Esaú e Jacó -- 70153 palavras\n",
      "os olhos não lhe importe o mistério há outros mais escuros parece que vai entrar a cerimônia disse perpétua que olhava para o recinto chegue se para a frente conselheiro a cerimônia era a do costume natividade cuidou que ia vê los entrar juntos e juntos o compromisso viriam assim como os trouxera no ventre e na vida contentou se de os admirar separadamente paulo primeiro pedro depois ambos graves e ouviu lhes cá de cima repetir a fórmula com voz clara e segura a cerimônia foi curiosa para as galerias graças à semelhança dos dois para a mãe foi\n",
      "\n",
      "Machado de Assis: Memórias Póstumas de Brás Cubas -- 58580 palavras\n",
      "vos ia uma lágrima de saudade esta é a grande vantagem da morte que se não deixa boca para rir também não deixa olhos para chorar de cair capítulo lxxii o talvez o capítulo anterior entre outros motivos há aí nas últimas linhas uma frase muito parecida com despropósito e eu não quero dar pasto à crítica do futuro daqui a setenta anos um sujeito magro amarelo grisalho que não ama nenhuma outra coisa além dos livros inclina se sobre a página anterior a ver se lhe descobre o despropósito lê relê as palavras uma sílaba depois outra mais outra\n",
      "\n",
      "Machado de Assis: Memorial de Aires -- 50033 palavras\n",
      "viam as lágrimas e os sinais delas e de amores até que a pessoa se não foi palavra que ouviram aos próprios senhores enfim a moça entrou a não querer comer vendo isto a mãe com receio de algum acesso de moléstia começou a pedir por ela mas o marido declarou que não lhe importava vê la morta ou até doida antes isso que consentir na mistura do seu sangue com o da gente noronha a oposição da gente noronha não foi menor ao saber da paixão do filho pela filha do fazendeiro o pai de eduardo mandou lhe dizer\n",
      "\n",
      "Érico Veríssimo: O Tempo e o Vento - O Continente -- 129346 palavras\n",
      "invadiu quando ela imaginou o filho vivendo naquele descampado ouvindo o vento tomando chimarrão com os outros num silêncio de pedra a cara as mãos os pés de terra a camisa cheirando a sangue de boi ou sangue de gente o filho ia ser como o avô como os tios e um dia talvez se voltasse também contra ela porque era das porque não tinha pai tremendo de frio ana terra puxou as cobertas até o queixo e fechou os olhos quando o sol saiu os três homens foram trabalhar na lavoura d henriqueta aproximou se do catre da filha\n",
      "\n",
      "Érico Veríssimo: Incidente em Antares -- 144785 palavras\n",
      "homens com as cabeças metidas em máscaras elementos dum puseram em prática o plano do prefeito as bombas explodiam produzindo uma densa fumaça que se erguia no ar os ratos alguns fugiam às outros caíam mortos enquanto os urubus batiam asas as alturas a todas essas os defuntos continuavam sentados dentro do coreto silenciosos e os guardas retiraram se do campo de batalha depois de contar o número de inimigos mortos e por longo tempo ninguém pôde caminhar na praça da república e arredores sem tossir sentir e tonturas e finalmente ser obrigado a fugir a passo acelerado ou mesmo\n",
      "\n",
      "Érico Veríssimo: Clarissa -- 47827 palavras\n",
      "é tão perfeita que clarissa sente o sangue subir lhe às faces no entanto ela vai partir e se não voltar mais nunca mais não tornará a ver esta gente as pessoas desta casa o príncipe encantado uma bola sobe lhe à garganta vontade de chorar e as lágrimas lhe escorrem pelo rosto quentes e pingam no travesseiro ajoelhada na frente da mala aberta clarissa vai dentro dela as suas coisas com um cuidado cheio de ternura o vestido novo vai bem em cima para não ficar amassado no fundo podem ir as meias os lençóis as e algumas bugigangas\n",
      "\n",
      "Érico Veríssimo: O Tempo e o Vento - O Arquipélago -- 115533 palavras\n",
      "dr alfaro sacudiu negativamente a cabeça — não obrigado nunca entrei naquele salão fui jogador isso sim mas nunca estou um pouco velho para começar mas vá e que lhe faça bom proveito apertaram se as mãos os olhos do dr alfaro se voltaram para a mesa de bacará 14 como de costume rodrigo sentou se à mesa que ficava perto do palco a um canto do salão pediu uma garrafa de champanha e ficou a beber a fumar e a olhar os pares que dançavam a orquestra tocava um tango argentino que espalhava no ar uma melancolia permitindo àqueles\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# escolhe e imprime uma sequencia aleatoria de cada livro\n",
    "rseq_len = 100\n",
    "for i, seq in enumerate(sequences):\n",
    "    k = nr.randint(len(seq) - rseq_len)\n",
    "    print('{}: {} -- {} palavras'.format(book_author[i], book_title[i], len(seq)).replace('_', ' '))\n",
    "    print(' '.join([i2w[x] for x in seq[k:k+rseq_len]]), end='\\n\\n')\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Palavras características de cada livro"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2017-10-25T16:31:23.845028Z",
     "start_time": "2017-10-25T16:31:23.220286Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[['marilda' 'dinorá' 'teodoro' 'pelancchi' 'gisa' 'mirandão' 'rozilda' 'vadinho']\n",
      " ['tuísca' 'tonico' 'ribeirinho' 'malvina' 'amâncio' 'fulgêncio' 'gabriela' 'nacib']\n",
      " ['trapiche' 'bedel' 'ester' 'barandão' 'almiro' 'dora' '–' 'pirulito']\n",
      " ['vavá' 'januário' 'almério' '—' 'dóris' 'brígida' 'justiniano' 'tereza']\n",
      " ['manduca' 'protonotário' 'bentinho' 'sancha' 'pádua' 'justina' 'escobar' 'capitu']\n",
      " ['camacho' 'teófilo' 'tonica' 'borba' 'sofia' 'fernanda' 'benedita' 'rubião']\n",
      " ['ângela' 'eugênia' 'tomásia' 'melchior' 'helena' 'camargo' 'estácio' 'úrsula']\n",
      " ['procópio' 'valéria' 'jorge' 'garcia' 'madrasta' 'enteada' 'iaiá' 'estela']\n",
      " ['coupé' 'gêmeos' 'excia' 'custódio' 'nóbrega' 'natividade' 'flora' 'cláudia']\n",
      " ['loló' 'eusébia' 'cubas' 'borba' 'sabina' 'cotrim' 'marcela' 'virgília']\n",
      " ['carmo' 'libertos' 'prainha' 'noronha' 'cesária' 'aguiar' 'fidélia' 'tristão']\n",
      " ['maneco' 'amaral' 'lara' 'vosmecê' 'bibiana' '—' 'alonzo' 'rodrigo']\n",
      " ['campolargo' 'vacariano' 'vivaldino' 'getúlio' 'quitéria' '–' 'tibério' 'antares']\n",
      " ['gamaliel' 'dudu' 'eufrasina' 'tatá' 'belmira' 'tónico' 'zina' 'clarissa']\n",
      " ['dinda' 'alicinha' 'toríbio' 'chiru' 'stein' 'camerino' '—' 'rodrigo']]\n"
     ]
    }
   ],
   "source": [
    "tfidf = tokenizer.sequences_to_matrix(sequences, mode='tfidf')\n",
    "ww = np.argsort(tfidf, axis=1)[:, -8:]\n",
    "print(i2w_vec[ww-1])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Dividindo o dataset entre treinamento e validação"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2017-10-25T16:31:23.850225Z",
     "start_time": "2017-10-25T16:31:23.846786Z"
    },
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "nr.seed(20170607)\n",
    "\n",
    "batch_size  = 32\n",
    "seq_size    = 50\n",
    "valid_split = 0.2"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Divisão simples"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2017-10-25T16:31:24.005654Z",
     "start_time": "2017-10-25T16:31:23.851986Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Sequencias obtidas para cada autor: [8747, 8564, 10841]\n",
      "O dataset conterá 8564 sequencias por autor, totalizando 25692 sequencias.\n",
      "\n",
      "Dataset shapes: (25692, 50) (25692,)\n"
     ]
    }
   ],
   "source": [
    "all_data = [[] for i in range(n_labels)]\n",
    "\n",
    "# divide cada livro em sequencias de 'seq_size' words\n",
    "# 'all_data' contem as sequencias agrupadas por autor\n",
    "for sequence, label in zip(sequences, book_label):\n",
    "    n_seqs = len(sequence) // seq_size\n",
    "    for i in range(n_seqs):\n",
    "        beg = i * seq_size\n",
    "        all_data[label].append(sequence[beg:beg+seq_size])\n",
    "\n",
    "print('Sequencias obtidas para cada autor:', [len(x) for x in all_data])\n",
    "\n",
    "# balanceando o dataset:\n",
    "# calcula o numero de sequencias, N, de forma que o dataset \n",
    "# contenha N sequencias para cada autor\n",
    "N = min([len(x) for x in all_data])\n",
    "print('O dataset conterá {} sequencias por autor, totalizando {} sequencias.'.format(N, 3*N))\n",
    "\n",
    "all_data = np.array([seq[:N] for seq in all_data], np.int32).reshape(-1, seq_size)\n",
    "all_labels = np.array([[i] * N for i in range(n_labels)], np.int32).reshape(-1)\n",
    "print('\\nDataset shapes:', all_data.shape, all_labels.shape)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2017-10-25T16:31:24.014308Z",
     "start_time": "2017-10-25T16:31:24.007302Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(20553, 50) (20553,) (5139, 50) (5139,)\n"
     ]
    }
   ],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "Xtra, Xval, ytra, yval = train_test_split(all_data, all_labels, test_size=valid_split)\n",
    "print(Xtra.shape, ytra.shape, Xval.shape, yval.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2017-10-25T16:31:25.071214Z",
     "start_time": "2017-10-25T16:31:24.016159Z"
    }
   },
   "outputs": [],
   "source": [
    "fn = data_dir + 'livros_sequences_{}.npz'.format(seq_size)\n",
    "np.savez_compressed(fn, Xtra=Xtra, Xval=Xval, ytra=ytra, yval=yval, i2w=i2w_vec[:MAX_NB_WORDS])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Divisão para uso com geradores e aumento de dados"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2017-10-25T16:31:25.122295Z",
     "start_time": "2017-10-25T16:31:25.072696Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training sequences:\n",
      "-------------------\n",
      " 1. Jorge_Amado      (2) -- 116879 palavras do início do livro Dona_flor_seus_dois_maridos\n",
      " 2. Jorge_Amado      (2) --  58438 palavras do início do livro Gabriela\n",
      " 3. Jorge_Amado      (2) --  34178 palavras do início do livro Capitães_de_Areia\n",
      " 4. Jorge_Amado      (2) --  33045 palavras do início do livro Tereza_Batista_Cansada_de_Guerra\n",
      " 5. Machado_de_Assis (1) --   3266 palavras do início do livro Dom_Casmurro\n",
      " 6. Machado_de_Assis (1) --  37666 palavras do início do livro Quincas_Borba\n",
      " 7. Machado_de_Assis (1) --  10817 palavras do início do livro Helena\n",
      " 8. Machado_de_Assis (1) --  33350 palavras do início do livro Iaiá_Garcia\n",
      " 9. Machado_de_Assis (1) --   3461 palavras do início do livro Esaú_e_Jacó\n",
      "10. Machado_de_Assis (1) --  11576 palavras do início do livro Memórias_Póstumas_de_Brás_Cubas\n",
      "11. Machado_de_Assis (1) --  26516 palavras do início do livro Memorial_de_Aires\n",
      "12. Érico_Veríssimo  (0) --  22847 palavras do início do livro O_Tempo_e_o_Vento_-_O_Continente\n",
      "13. Érico_Veríssimo  (0) --  42800 palavras do início do livro Incidente_em_Antares\n",
      "14. Érico_Veríssimo  (0) --  17350 palavras do início do livro Clarissa\n",
      "15. Érico_Veríssimo  (0) --  57841 palavras do início do livro O_Tempo_e_o_Vento_-_O_Arquipélago\n",
      "16. Jorge_Amado      (2) --  16421 palavras do final do livro  Dona_flor_seus_dois_maridos\n",
      "17. Jorge_Amado      (2) --  49161 palavras do final do livro  Gabriela\n",
      "18. Jorge_Amado      (2) --  26728 palavras do final do livro  Capitães_de_Areia\n",
      "19. Jorge_Amado      (2) --  98880 palavras do final do livro  Tereza_Batista_Cansada_de_Guerra\n",
      "20. Machado_de_Assis (1) --  48372 palavras do final do livro  Dom_Casmurro\n",
      "21. Machado_de_Assis (1) --  22306 palavras do final do livro  Quincas_Borba\n",
      "22. Machado_de_Assis (1) --  33006 palavras do final do livro  Helena\n",
      "23. Machado_de_Assis (1) --  10924 palavras do final do livro  Iaiá_Garcia\n",
      "24. Machado_de_Assis (1) --  52662 palavras do final do livro  Esaú_e_Jacó\n",
      "25. Machado_de_Assis (1) --  35288 palavras do final do livro  Memórias_Póstumas_de_Brás_Cubas\n",
      "26. Machado_de_Assis (1) --  13511 palavras do final do livro  Memorial_de_Aires\n",
      "27. Érico_Veríssimo  (0) --  80630 palavras do final do livro  O_Tempo_e_o_Vento_-_O_Continente\n",
      "28. Érico_Veríssimo  (0) --  73028 palavras do final do livro  Incidente_em_Antares\n",
      "29. Érico_Veríssimo  (0) --  20912 palavras do final do livro  Clarissa\n",
      "30. Érico_Veríssimo  (0) --  34586 palavras do final do livro  O_Tempo_e_o_Vento_-_O_Arquipélago\n",
      "\n",
      "Validation sequences:\n",
      "---------------------\n",
      " 1. Jorge_Amado      (2) --  33325 palavras do meio do livro Dona_flor_seus_dois_maridos\n",
      " 2. Jorge_Amado      (2) --  26899 palavras do meio do livro Gabriela\n",
      " 3. Jorge_Amado      (2) --  15226 palavras do meio do livro Capitães_de_Areia\n",
      " 4. Jorge_Amado      (2) --  32981 palavras do meio do livro Tereza_Batista_Cansada_de_Guerra\n",
      " 5. Machado_de_Assis (1) --  12909 palavras do meio do livro Dom_Casmurro\n",
      " 6. Machado_de_Assis (1) --  14993 palavras do meio do livro Quincas_Borba\n",
      " 7. Machado_de_Assis (1) --  10955 palavras do meio do livro Helena\n",
      " 8. Machado_de_Assis (1) --  11068 palavras do meio do livro Iaiá_Garcia\n",
      " 9. Machado_de_Assis (1) --  14030 palavras do meio do livro Esaú_e_Jacó\n",
      "10. Machado_de_Assis (1) --  11716 palavras do meio do livro Memórias_Póstumas_de_Brás_Cubas\n",
      "11. Machado_de_Assis (1) --  10006 palavras do meio do livro Memorial_de_Aires\n",
      "12. Érico_Veríssimo  (0) --  25869 palavras do meio do livro O_Tempo_e_o_Vento_-_O_Continente\n",
      "13. Érico_Veríssimo  (0) --  28957 palavras do meio do livro Incidente_em_Antares\n",
      "14. Érico_Veríssimo  (0) --   9565 palavras do meio do livro Clarissa\n",
      "15. Érico_Veríssimo  (0) --  23106 palavras do meio do livro O_Tempo_e_o_Vento_-_O_Arquipélago\n",
      "\n",
      "Total number of training words:   1126445\n",
      "Total number of validation words: 281605\n"
     ]
    }
   ],
   "source": [
    "valid_length = [int(0.2 * len(x)) for x in sequences]\n",
    "valid_start = [nr.randint(2000, len(x) - 2000 - n) for x, n in zip(sequences, valid_length)]\n",
    "\n",
    "valid_sequences = [seq[x0:x0+n] for seq, x0, n in zip(sequences, valid_start, valid_length)]\n",
    "\n",
    "train_sequences = [seq[:x0] for seq, x0 in zip(sequences, valid_start)] + \\\n",
    "                  [seq[x0+n:] for seq, x0, n in zip(sequences, valid_start, valid_length)]\n",
    "\n",
    "valid_labels = book_label\n",
    "train_labels = book_label + book_label\n",
    "\n",
    "n_train_words = sum([len(x) for x in train_sequences])\n",
    "n_valid_words = sum([len(x) for x in valid_sequences])\n",
    "\n",
    "print('Training sequences:')\n",
    "print('-------------------')\n",
    "for i, (seq, lab) in enumerate(zip(train_sequences, train_labels)):\n",
    "    if i < n_books:\n",
    "        print('{:2d}. {:16s} ({}) -- {:6d} palavras do início do livro {}'.format(i+1, book_author[i%n_books], lab,\n",
    "                                                                                  len(seq), book_title[i%n_books]))\n",
    "    else:\n",
    "        print('{:2d}. {:16s} ({}) -- {:6d} palavras do final do livro  {}'.format(i+1, book_author[i%n_books], lab,\n",
    "                                                                                  len(seq), book_title[i%n_books]))\n",
    "print()\n",
    "print('Validation sequences:')\n",
    "print('---------------------')\n",
    "for i, (seq, lab) in enumerate(zip(valid_sequences, valid_labels)):\n",
    "    print('{:2d}. {:16s} ({}) -- {:6d} palavras do meio do livro {}'.format(i+1, book_author[i%n_books], lab,\n",
    "                                                                            len(seq), book_title[i%n_books]))\n",
    "print()\n",
    "print('Total number of training words:  ', n_train_words)\n",
    "print('Total number of validation words:', n_valid_words)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Criando  geradores para treino e validação"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2017-10-25T16:31:25.146714Z",
     "start_time": "2017-10-25T16:31:25.124022Z"
    },
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "class MyDataGenerator:\n",
    "    def __init__(self, batch_size, seq_size, sequences, labels):\n",
    "        self.batch_size = batch_size\n",
    "        self.length = seq_size\n",
    "        self.sequences = sequences\n",
    "        self.labels = labels\n",
    "        sizes = np.array([len(seq) for seq in sequences])\n",
    "        self.p = 1.0 * sizes / sizes.sum()        # probabilidade de escolha para cada sequencia\n",
    "        self.n = np.arange(len(sequences))        # indices de cada sequencia (para o choice abaixo)\n",
    "        \n",
    "    def __call__(self):\n",
    "        while True:\n",
    "            batch = np.empty((self.batch_size, self.length), np.int32)\n",
    "            label = np.empty((self.batch_size, n_labels), np.int32)\n",
    "            for i in range(self.batch_size):\n",
    "                k = nr.choice(self.n, p=self.p)\n",
    "                p = nr.randint(0, len(self.sequences[k]) - self.length)\n",
    "                batch[i] = self.sequences[k][p:p+self.length]\n",
    "                label[i] = to_categorical(self.labels[k], num_classes=n_labels)\n",
    "            yield batch, label\n",
    "\n",
    "            \n",
    "train_gen = MyDataGenerator(batch_size, seq_size, train_sequences, train_labels)\n",
    "valid_gen = MyDataGenerator(batch_size, seq_size, valid_sequences, valid_labels)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2017-10-25T16:31:25.206961Z",
     "start_time": "2017-10-25T16:31:25.148375Z"
    }
   },
   "outputs": [],
   "source": [
    "import pickle\n",
    "fn = data_dir + 'livros_generators_{}.pkl'.format(seq_size)\n",
    "pickle.dump([train_gen, valid_gen, i2w_vec[:MAX_NB_WORDS]], open(fn, 'wb'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.1"
  },
  "latex_envs": {
   "LaTeX_envs_menu_present": true,
   "autocomplete": true,
   "bibliofile": "biblio.bib",
   "cite_by": "apalike",
   "current_citInitial": 1,
   "eqLabelWithNumbers": true,
   "eqNumInitial": 1,
   "hotkeys": {
    "equation": "Ctrl-E",
    "itemize": "Ctrl-I"
   },
   "labels_anchors": false,
   "latex_user_defs": false,
   "report_style_numbering": false,
   "user_envs_cfg": false
  },
  "toc": {
   "colors": {
    "hover_highlight": "#DAA520",
    "navigate_num": "#000000",
    "navigate_text": "#333333",
    "running_highlight": "#FF0000",
    "selected_highlight": "#FFD700",
    "sidebar_border": "#EEEEEE",
    "wrapper_background": "#FFFFFF"
   },
   "moveMenuLeft": true,
   "nav_menu": {
    "height": "264px",
    "width": "252px"
   },
   "navigate_menu": true,
   "number_sections": true,
   "sideBar": true,
   "threshold": 4,
   "toc_cell": true,
   "toc_section_display": "block",
   "toc_window_display": false,
   "widenNotebook": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
