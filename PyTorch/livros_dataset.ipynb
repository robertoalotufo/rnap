{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Classificação de Textos"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Preâmbulo"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-02-04T20:09:38.343108Z",
     "start_time": "2018-02-04T20:09:36.992315Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "GPU available: False\n",
      "torch 0.3.0.post4\n",
      "Python 3.6.0 |Anaconda custom (x86_64)| (default, Dec 23 2016, 13:19:00) \n",
      "[GCC 4.2.1 Compatible Apple LLVM 6.0 (clang-600.0.57)]\n"
     ]
    }
   ],
   "source": [
    "%matplotlib inline\n",
    "import matplotlib.pyplot as plt\n",
    "from IPython import display\n",
    "\n",
    "import os\n",
    "import sys\n",
    "import imp\n",
    "import time\n",
    "import glob\n",
    "import numpy as np\n",
    "import numpy.random as nr\n",
    "\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "from torch.optim.lr_scheduler import MultiStepLR, StepLR\n",
    "from torch.utils.data import DataLoader, TensorDataset\n",
    "from torch.autograd import Variable\n",
    "\n",
    "import torchvision as tv\n",
    "import lib.pytorch_trainer as ptt\n",
    "from lib.tokenizer import Tokenizer\n",
    "\n",
    "use_gpu = torch.cuda.is_available()\n",
    "print('GPU available:', use_gpu)\n",
    "print('torch', torch.version.__version__)\n",
    "print('Python', sys.version)\n",
    "\n",
    "np.set_printoptions(precision=3, linewidth=120)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Preparando o dataset"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Buscando o texto dos livros e definindo os rótulos"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-02-04T20:09:42.077123Z",
     "start_time": "2018-02-04T20:09:41.984490Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " 427711  Jorge_Amado        Capitães_de_Areia\n",
      "1030735  Jorge_Amado        Dona_flor_seus_dois_maridos\n",
      " 828417  Jorge_Amado        Gabriela\n",
      "1001226  Jorge_Amado        Tereza_Batista_Cansada_de_Guerra\n",
      " 372459  Machado_de_Assis   Dom_Casmurro\n",
      " 411043  Machado_de_Assis   Esaú_e_Jacó\n",
      " 337533  Machado_de_Assis   Helena\n",
      " 336677  Machado_de_Assis   Iaiá_Garcia\n",
      " 280683  Machado_de_Assis   Memorial_de_Aires\n",
      " 352965  Machado_de_Assis   Memórias_Póstumas_de_Brás_Cubas\n",
      " 443778  Machado_de_Assis   Quincas_Borba\n",
      "\n",
      "2 Labels:\n",
      "     0: Jorge_Amado\n",
      "     1: Machado_de_Assis\n"
     ]
    }
   ],
   "source": [
    "data_dir = '/data/datasets/livros/'\n",
    "\n",
    "autores = [\n",
    "    'Jorge_Amado',\n",
    "    'Machado_de_Assis',\n",
    "    'Érico_Veríssimo',\n",
    "]\n",
    "\n",
    "book_text = []\n",
    "book_author = []\n",
    "book_title = []\n",
    "for aut in autores:\n",
    "    for fn in glob.glob(data_dir + 'processed/' + aut + '*.txt'):\n",
    "        author, book = os.path.basename(fn).split('__')\n",
    "        txt = open(fn, encoding='utf-8').read().replace('\\x97', '')\n",
    "        book_text.append(txt)\n",
    "        book_author.append(author)\n",
    "        book_title.append(book[:-4])\n",
    "        print('{:7d}  {:18s} {}'.format(len(txt), author, book[:-4]))\n",
    "\n",
    "author_list = list(set(book_author))\n",
    "n_labels = len(author_list)\n",
    "n_books = len(book_title)\n",
    "book_label = [author_list.index(a) for a in book_author]\n",
    "print('\\n{} Labels:'.format(n_labels))\n",
    "for i, autor in enumerate(author_list):\n",
    "    print('    {:2d}: {}'.format(i, autor))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Representando as palavras através de índices inteiros"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-02-04T20:09:47.705138Z",
     "start_time": "2018-02-04T20:09:44.590922Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 49047 unique tokens.\n",
      "Using the first 19999 words.\n"
     ]
    }
   ],
   "source": [
    "MAX_NB_WORDS = 20000\n",
    "\n",
    "tokenizer = Tokenizer(num_words=MAX_NB_WORDS)\n",
    "tokenizer.fit_on_texts(book_text)\n",
    "sequences = tokenizer.texts_to_sequences(book_text)\n",
    "\n",
    "w2i = tokenizer.word_index\n",
    "i2w = dict([(v, k) for k, v in w2i.items()])\n",
    "\n",
    "i2w_vec = np.array([i2w[i+1] for i in range(len(i2w))])\n",
    "\n",
    "print('Found %d unique tokens.' % len(i2w))\n",
    "print('Using the first %d words.' % max([max(s) for s in sequences]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-02-04T20:09:47.719342Z",
     "start_time": "2018-02-04T20:09:47.707660Z"
    },
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Jorge Amado: Capitães de Areia -- 76252 palavras\n",
      "nas noites da bahia numa praça de itapagipe as luzes do carrossel movimentadas pelo sem pernas era como num sonho sonho muito diverso dos que o sem pernas costumava ter nas suas noites e pela primeira vez seus olhos sentiram se úmidos de lágrimas que não eram pela dor ou pela raiva e seus olhos úmidos miravam inho frança como a um por ele até a garganta de um homem o sem pernas abriria com a navalha que traz entre a calça e o velho colete preto que lhe serve de paletó – é uma beleza – disse pedro bala\n",
      "\n",
      "Jorge Amado: Dona flor seus dois maridos -- 167568 palavras\n",
      "oxóssi mas foi em vão como se verá mais adiante não se diga que cardoso e só se não é ele cidadão de se assombrar nem tampouco de sustos e espantos s mas sofreu um abalo ah isso sofreu não há como esconder a realidade e dizendo se que mestre cardoso e só se surpreendera tudo está definitivamente dito e dada a medida desmedida do insólito do absurdo clima da cidade foi naqueles dias que o po vo em lucidez e raiva atacou a sede do estrangeiro da energia elétrica exigiu a das minas e do petróleo pôs a polícia\n",
      "\n",
      "Jorge Amado: Gabriela -- 135032 palavras\n",
      "percebi tudo e o marido inteiramente do coronel já sabe tudo sobre ribeirinho e comigo não q uer nada que a mulher ria pra ribeirinho saia dançando com ele que segure a testa para ele o crápula acha uma beleza mas basta eu me aproximar e ele se mete no meio aquilo não passa de um cafetão emérito tem medo que você estr ague o negócio dele eu só quero as sobras que ribeirinho pague e me contento com os dias feriados quanto ao marido não se preocupe a essas horas ele já deve saber que sou filho do chefe\n",
      "\n",
      "Jorge Amado: Tereza Batista Cansada de Guerra -- 166300 palavras\n",
      "dalmo co ca desaparecido envolto em bosta o comissário e peixe cação nada sabem sobre o destino da maconha última esperança de evitar o prejuízo total igual ao dólar a maconha não se no alto da escadaria durante um segundo todas se detive ram a voz partida de vovó — não fosse prostituta na bahia seria beata na matriz de cruz das almas — eleva se puxando uma ladainha ave ave maria ave ave maria em coro as raparigas respondem e a imagem se movimenta adiantando se para os de graus da o cansado acento de vovó prossegue na vestida\n",
      "\n",
      "Machado de Assis: Dom Casmurro -- 65114 palavras\n",
      "padre nem seria padre ao contrário deus protegia os sinceros uma vez que eu só podia servi lo no mundo aí me cumpria ficar não o prazer que me deu a confidência que lhe fiz era como que uma felicidade mais aquele coração moço que me ouvia e me dava razão trazia a este mundo um aspecto extraordinário era um grande e belo mundo a vida uma carreira excelente e eu nem mais nem menos um mimoso do céu eis a minha sensação nota que eu não lhe disse tudo nem o melhor não lhe referi o capítulo do penteado\n",
      "\n",
      "Machado de Assis: Esaú e Jacó -- 70383 palavras\n",
      "ele é que nem as queria à força nem curava de as persuadir não era general para escala à vista nem para demorados contentava se de simples passeios militares longos ou breves conforme o tempo fosse claro ou turvo em suma extremamente cordato coincidência interessante foi por esse tempo que santos pensou em casá lo com a cunhada recentemente viúva esta parece que queria natividade opôs se nunca se soube por quê não eram ciúmes invejas não creio que fossem o simples desejo de o não ver entrar na família pela porta é apenas uma figura que vale qualquer das\n",
      "\n",
      "Machado de Assis: Helena -- 55009 palavras\n",
      "não estava ligado a nenhum dos dois partidos conservando em ambos preciosas amizades que ali se acharam na ocasião de o dar à sepultura tinha entretanto tais ou quais idéias políticas colhidas nas fronteiras conservadoras e liberais justamente no ponto em que os dois podem confundir se se nenhuma saudade lhe deitou a última pá de terra matrona houve e não só uma que viu ir a enterrar com ele a melhor página da sua mocidade a família do conselheiro compunha se de duas pessoas um filho o dr estácio e uma irmã d úrsula contava esta cinqüenta e poucos\n",
      "\n",
      "Machado de Assis: Iaiá Garcia -- 55534 palavras\n",
      "sorria tristemente leu a toda releu alguns trechos depois fez um gesto de desdém rasgou a e deitou os pedaços à cesta iaiá foi sentar se do outro lado a poucos passos do pai na secretária ao pé deste havia um maço de coisas que serviam um maço pequeno a grande maioria era a dos destroços inúteis não é isso mesmo a imagem do passado luís garcia desdobrava às vezes um jornal guardado havia anos duas cruzes ou alguns traços o trecho que nesse tempo lhe chamara a atenção relia o agora buscava o motivo da reserva e sorria a\n",
      "\n",
      "Machado de Assis: Memorial de Aires -- 50149 palavras\n",
      "idéias tristes carmo tem razão interveio o marido o tempo acabará depressa para que ele se vá e não ficará às nossas ordens para que fiquemos eternamente na vida todos nós lá vamos disse eu a morte é outro desembargador conta muitos amigos que lá passam as noites e os que têm filhas levam as filhas isto é certo mas o melhor é não pensar nela não é nela é nele emendou d carmo falo do nosso tristão que se irá brevemente sorri e disse ele se irá creio mas ficará ela bem os e não seria preciso carmo entendeu\n",
      "\n",
      "Machado de Assis: Memórias Póstumas de Brás Cubas -- 58857 palavras\n",
      "a mulher a mulher ia quase sempre numa rasa a tossir muito e a afiançar que me havia de mostrar os arredores de lisboa não estava magra estava transparente era impossível que não morresse de uma hora para outra o capitão fingia não crer na morte próxima talvez por enganar se a si mesmo eu não sabia nem pensava nada que me importava a mim o destino de uma mulher tísica no meio do oceano o mundo para mim era marcela uma noite logo no fim de uma semana achei ensejo para morrer subi cauteloso mas encontrei o capitão que\n",
      "\n",
      "Machado de Assis: Quincas Borba -- 75252 palavras\n",
      "mulher para atraí la a si um e outro se logo depois rubião cruzando a perna esquerda sobre a direita voltou se para o palha e perguntou lhe sabe que vou deixá los capítulo lv tudo esperava o outro menos isto daí o espanto em que se dissolveu a cólera daí também uma sombrinha de pesar que é o que o leitor menos espera deixá los naturalmente ia se embora do rio de janeiro era o castigo que a si mesmo impunha pela ação ruim que em santa teresa logo se arrependera se não tinha cara de aparecer à esposa\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# escolhe e imprime uma sequencia aleatoria de cada livro\n",
    "rseq_len = 100\n",
    "for i, seq in enumerate(sequences):\n",
    "    k = nr.randint(len(seq) - rseq_len)\n",
    "    print('{}: {} -- {} palavras'.format(book_author[i], book_title[i], len(seq)).replace('_', ' '))\n",
    "    print(' '.join([i2w[x] for x in seq[k:k+rseq_len]]), end='\\n\\n')\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Palavras características de cada livro"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-02-04T20:09:50.951193Z",
     "start_time": "2018-02-04T20:09:50.403097Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[['dalva' 'ester' 'barandão' 'almiro' 'dora' 'pirulito' 'trapiche' '–']\n",
      " ['marilda' 'dinorá' 'teodoro' 'pelancchi' 'gisa' 'mirandão' 'rozilda' 'vadinho']\n",
      " ['arminda' 'malvina' 'mundinho' 'amâncio' 'fulgêncio' 'tonico' 'gabriela' 'nacib']\n",
      " ['vavá' 'almério' 'januário' 'dóris' 'brígida' 'justiniano' 'tereza' '—']\n",
      " ['bentinho' 'protonotário' 'cabral' 'sancha' 'pádua' 'justina' 'escobar' 'capitu']\n",
      " ['aires' 'gêmeos' 'excia' 'custódio' 'nóbrega' 'natividade' 'cláudia' 'flora']\n",
      " ['eugênia' 'ângela' 'tomásia' 'melchior' 'helena' 'camargo' 'úrsula' 'estácio']\n",
      " ['garcia' 'procópio' 'madrasta' 'jorge' 'iaiá' 'enteada' 'estela' 'valéria']\n",
      " ['lisboa' 'prainha' 'noronha' 'osório' 'cesária' 'aguiar' 'fidélia' 'tristão']\n",
      " ['cubas' 'quincas' 'borba' 'sabina' 'cotrim' 'lobo' 'marcela' 'virgília']\n",
      " ['quincas' 'teófilo' 'tonica' 'camacho' 'fernanda' 'sofia' 'benedita' 'rubião']]\n"
     ]
    }
   ],
   "source": [
    "tfidf = tokenizer.sequences_to_matrix(sequences, mode='tfidf')\n",
    "ww = np.argsort(tfidf, axis=1)[:, -8:]\n",
    "print(i2w_vec[ww-1])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Dividindo o dataset entre treinamento e validação"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-02-04T20:09:54.435221Z",
     "start_time": "2018-02-04T20:09:54.430831Z"
    },
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "nr.seed(20170607)\n",
    "\n",
    "batch_size  = 32\n",
    "seq_size    = 50\n",
    "valid_split = 0.2"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Divisão simples"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-02-04T20:10:08.546365Z",
     "start_time": "2018-02-04T20:10:08.384400Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Sequencias obtidas para cada autor: [10902, 8603]\n",
      "O dataset conterá 8603 sequencias por autor, totalizando 25809 sequencias.\n",
      "\n",
      "Dataset shapes: (17206, 50) (17206,)\n"
     ]
    }
   ],
   "source": [
    "all_data = [[] for i in range(n_labels)]\n",
    "\n",
    "# divide cada livro em sequencias de 'seq_size' words\n",
    "# 'all_data' contem as sequencias agrupadas por autor\n",
    "for sequence, label in zip(sequences, book_label):\n",
    "    n_seqs = len(sequence) // seq_size\n",
    "    for i in range(n_seqs):\n",
    "        beg = i * seq_size\n",
    "        all_data[label].append(sequence[beg:beg+seq_size])\n",
    "\n",
    "print('Sequencias obtidas para cada autor:', [len(x) for x in all_data])\n",
    "\n",
    "# balanceando o dataset:\n",
    "# calcula o numero de sequencias, N, de forma que o dataset \n",
    "# contenha N sequencias para cada autor\n",
    "N = min([len(x) for x in all_data])\n",
    "print('O dataset conterá {} sequencias por autor, totalizando {} sequencias.'.format(N, 3*N))\n",
    "\n",
    "all_data = np.array([seq[:N] for seq in all_data], np.int32).reshape(-1, seq_size)\n",
    "all_labels = np.array([[i] * N for i in range(n_labels)], np.int32).reshape(-1)\n",
    "print('\\nDataset shapes:', all_data.shape, all_labels.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-02-04T20:10:11.092022Z",
     "start_time": "2018-02-04T20:10:10.426066Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(13764, 50) (13764,) (3442, 50) (3442,)\n"
     ]
    }
   ],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "Xtra, Xval, ytra, yval = train_test_split(all_data, all_labels, test_size=valid_split)\n",
    "print(Xtra.shape, ytra.shape, Xval.shape, yval.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-02-04T20:10:15.072614Z",
     "start_time": "2018-02-04T20:10:13.826352Z"
    },
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "fn = data_dir + 'livros_sequences_{}.npz'.format(seq_size)\n",
    "np.savez_compressed(fn, Xtra=Xtra, Xval=Xval, ytra=ytra, yval=yval, i2w=i2w_vec[:MAX_NB_WORDS])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Divisão para uso com geradores e aumento de dados"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-02-04T20:10:17.427408Z",
     "start_time": "2018-02-04T20:10:17.365012Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training sequences:\n",
      "-------------------\n",
      " 1. Jorge_Amado      (0) --  26526 palavras do início do livro Capitães_de_Areia\n",
      " 2. Jorge_Amado      (0) --  37137 palavras do início do livro Dona_flor_seus_dois_maridos\n",
      " 3. Jorge_Amado      (0) --   8007 palavras do início do livro Gabriela\n",
      " 4. Jorge_Amado      (0) --  87453 palavras do início do livro Tereza_Batista_Cansada_de_Guerra\n",
      " 5. Machado_de_Assis (1) --  34509 palavras do início do livro Dom_Casmurro\n",
      " 6. Machado_de_Assis (1) --  18786 palavras do início do livro Esaú_e_Jacó\n",
      " 7. Machado_de_Assis (1) --  41517 palavras do início do livro Helena\n",
      " 8. Machado_de_Assis (1) --  40801 palavras do início do livro Iaiá_Garcia\n",
      " 9. Machado_de_Assis (1) --   3347 palavras do início do livro Memorial_de_Aires\n",
      "10. Machado_de_Assis (1) --  27751 palavras do início do livro Memórias_Póstumas_de_Brás_Cubas\n",
      "11. Machado_de_Assis (1) --  29210 palavras do início do livro Quincas_Borba\n",
      "12. Jorge_Amado      (0) --  34476 palavras do final do livro  Capitães_de_Areia\n",
      "13. Jorge_Amado      (0) --  96918 palavras do final do livro  Dona_flor_seus_dois_maridos\n",
      "14. Jorge_Amado      (0) -- 100019 palavras do final do livro  Gabriela\n",
      "15. Jorge_Amado      (0) --  45587 palavras do final do livro  Tereza_Batista_Cansada_de_Guerra\n",
      "16. Machado_de_Assis (1) --  17583 palavras do final do livro  Dom_Casmurro\n",
      "17. Machado_de_Assis (1) --  37521 palavras do final do livro  Esaú_e_Jacó\n",
      "18. Machado_de_Assis (1) --   2491 palavras do final do livro  Helena\n",
      "19. Machado_de_Assis (1) --   3627 palavras do final do livro  Iaiá_Garcia\n",
      "20. Machado_de_Assis (1) --  36773 palavras do final do livro  Memorial_de_Aires\n",
      "21. Machado_de_Assis (1) --  19335 palavras do final do livro  Memórias_Póstumas_de_Brás_Cubas\n",
      "22. Machado_de_Assis (1) --  30992 palavras do final do livro  Quincas_Borba\n",
      "\n",
      "Validation sequences:\n",
      "---------------------\n",
      " 1. Jorge_Amado      (0) --  15250 palavras do meio do livro Capitães_de_Areia\n",
      " 2. Jorge_Amado      (0) --  33513 palavras do meio do livro Dona_flor_seus_dois_maridos\n",
      " 3. Jorge_Amado      (0) --  27006 palavras do meio do livro Gabriela\n",
      " 4. Jorge_Amado      (0) --  33260 palavras do meio do livro Tereza_Batista_Cansada_de_Guerra\n",
      " 5. Machado_de_Assis (1) --  13022 palavras do meio do livro Dom_Casmurro\n",
      " 6. Machado_de_Assis (1) --  14076 palavras do meio do livro Esaú_e_Jacó\n",
      " 7. Machado_de_Assis (1) --  11001 palavras do meio do livro Helena\n",
      " 8. Machado_de_Assis (1) --  11106 palavras do meio do livro Iaiá_Garcia\n",
      " 9. Machado_de_Assis (1) --  10029 palavras do meio do livro Memorial_de_Aires\n",
      "10. Machado_de_Assis (1) --  11771 palavras do meio do livro Memórias_Póstumas_de_Brás_Cubas\n",
      "11. Machado_de_Assis (1) --  15050 palavras do meio do livro Quincas_Borba\n",
      "\n",
      "Total number of training words:   780366\n",
      "Total number of validation words: 195084\n"
     ]
    }
   ],
   "source": [
    "valid_length = [int(0.2 * len(x)) for x in sequences]\n",
    "valid_start = [nr.randint(2000, len(x) - 2000 - n) for x, n in zip(sequences, valid_length)]\n",
    "\n",
    "valid_sequences = [seq[x0:x0+n] for seq, x0, n in zip(sequences, valid_start, valid_length)]\n",
    "\n",
    "train_sequences = [seq[:x0] for seq, x0 in zip(sequences, valid_start)] + \\\n",
    "                  [seq[x0+n:] for seq, x0, n in zip(sequences, valid_start, valid_length)]\n",
    "\n",
    "valid_labels = book_label\n",
    "train_labels = book_label + book_label\n",
    "\n",
    "n_train_words = sum([len(x) for x in train_sequences])\n",
    "n_valid_words = sum([len(x) for x in valid_sequences])\n",
    "\n",
    "print('Training sequences:')\n",
    "print('-------------------')\n",
    "for i, (seq, lab) in enumerate(zip(train_sequences, train_labels)):\n",
    "    if i < n_books:\n",
    "        print('{:2d}. {:16s} ({}) -- {:6d} palavras do início do livro {}'.format(i+1, book_author[i%n_books], lab,\n",
    "                                                                                  len(seq), book_title[i%n_books]))\n",
    "    else:\n",
    "        print('{:2d}. {:16s} ({}) -- {:6d} palavras do final do livro  {}'.format(i+1, book_author[i%n_books], lab,\n",
    "                                                                                  len(seq), book_title[i%n_books]))\n",
    "print()\n",
    "print('Validation sequences:')\n",
    "print('---------------------')\n",
    "for i, (seq, lab) in enumerate(zip(valid_sequences, valid_labels)):\n",
    "    print('{:2d}. {:16s} ({}) -- {:6d} palavras do meio do livro {}'.format(i+1, book_author[i%n_books], lab,\n",
    "                                                                            len(seq), book_title[i%n_books]))\n",
    "print()\n",
    "print('Total number of training words:  ', n_train_words)\n",
    "print('Total number of validation words:', n_valid_words)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Criando  geradores para treino e validação"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2017-12-12T20:00:20.167820Z",
     "start_time": "2017-12-12T20:00:20.137813Z"
    },
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "class MyDataGenerator:\n",
    "    def __init__(self, batch_size, seq_size, sequences, labels):\n",
    "        self.batch_size = batch_size\n",
    "        self.length = seq_size\n",
    "        self.sequences = sequences\n",
    "        self.labels = labels\n",
    "        sizes = np.array([len(seq) for seq in sequences])\n",
    "        self.p = 1.0 * sizes / sizes.sum()        # probabilidade de escolha para cada sequencia\n",
    "        self.n = np.arange(len(sequences))        # indices de cada sequencia (para o choice abaixo)\n",
    "        \n",
    "    def __call__(self):\n",
    "        while True:\n",
    "            batch = np.empty((self.batch_size, self.length), np.int32)\n",
    "            label = np.empty((self.batch_size, n_labels), np.int32)\n",
    "            for i in range(self.batch_size):\n",
    "                k = nr.choice(self.n, p=self.p)\n",
    "                p = nr.randint(0, len(self.sequences[k]) - self.length)\n",
    "                batch[i] = self.sequences[k][p:p+self.length]\n",
    "                label[i] = to_categorical(self.labels[k], num_classes=n_labels)\n",
    "            yield batch, label\n",
    "\n",
    "            \n",
    "train_gen = MyDataGenerator(batch_size, seq_size, train_sequences, train_labels)\n",
    "valid_gen = MyDataGenerator(batch_size, seq_size, valid_sequences, valid_labels)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2017-12-12T20:00:20.223618Z",
     "start_time": "2017-12-12T20:00:20.169134Z"
    },
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import pickle\n",
    "fn = data_dir + 'livros_generators_{}.pkl'.format(seq_size)\n",
    "pickle.dump([train_gen, valid_gen, i2w_vec[:MAX_NB_WORDS]], open(fn, 'wb'))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.0"
  },
  "latex_envs": {
   "LaTeX_envs_menu_present": true,
   "autocomplete": true,
   "bibliofile": "biblio.bib",
   "cite_by": "apalike",
   "current_citInitial": 1,
   "eqLabelWithNumbers": true,
   "eqNumInitial": 1,
   "hotkeys": {
    "equation": "Ctrl-E",
    "itemize": "Ctrl-I"
   },
   "labels_anchors": false,
   "latex_user_defs": false,
   "report_style_numbering": false,
   "user_envs_cfg": false
  },
  "toc": {
   "nav_menu": {
    "height": "264px",
    "width": "252px"
   },
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": false,
   "toc_cell": false,
   "toc_position": {},
   "toc_section_display": "block",
   "toc_window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
