{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2017-10-24T13:18:44.082887",
     "start_time": "2017-10-24T13:18:43.321720"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "GPU available: False\n",
      "torch 0.2.0_4\n",
      "Python 3.6.0 |Anaconda custom (x86_64)| (default, Dec 23 2016, 13:19:00) \n",
      "[GCC 4.2.1 Compatible Apple LLVM 6.0 (clang-600.0.57)]\n"
     ]
    }
   ],
   "source": [
    "%matplotlib inline\n",
    "import matplotlib.pyplot as plt\n",
    "from IPython import display\n",
    "\n",
    "import os\n",
    "import sys\n",
    "import imp\n",
    "import time\n",
    "import numpy as np\n",
    "\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "from torch.optim.lr_scheduler import MultiStepLR, StepLR\n",
    "from torch.utils.data import DataLoader, TensorDataset\n",
    "from torch.autograd import Variable\n",
    "\n",
    "import torchvision as tv\n",
    "import lib.pytorch_trainer as ptt\n",
    "\n",
    "use_gpu = torch.cuda.is_available()\n",
    "print('GPU available:', use_gpu)\n",
    "print('torch', torch.version.__version__)\n",
    "print('Python', sys.version)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2017-10-24T13:19:28.324381",
     "start_time": "2017-10-24T13:19:28.016982"
    },
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from sklearn.base import BaseEstimator\n",
    "from sklearn.model_selection import RandomizedSearchCV\n",
    "from sklearn.model_selection import PredefinedSplit\n",
    "import scipy.stats as st\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2017-10-24T13:19:38.573893",
     "start_time": "2017-10-24T13:19:29.513672"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(6000, 1, 28, 28) 0.0 1.0 *** (6000,) 0 9\n"
     ]
    }
   ],
   "source": [
    "# MNIST Dataset\n",
    "# =============\n",
    "use_test_dataset = False\n",
    "n_samples = 6000\n",
    "n_splits = 6\n",
    "\n",
    "def torch_datasets_to_sklearn_cv_data(train_ds, valid_ds):\n",
    "    n_train, n_valid = len(train_ds), len(valid_ds)\n",
    "    x, y = train_ds[0]\n",
    "    all_tuples = list(train_ds) + list(valid_ds)\n",
    "    all_labels = np.array([y for _, y in all_tuples], np.int)\n",
    "    all_data = torch.cat([w.view(1, *x.shape) for w, _ in all_tuples], 0).numpy()\n",
    "    valid_fold = np.zeros_like(all_labels)\n",
    "    valid_fold[:n_train] = -1\n",
    "    psplit = PredefinedSplit(valid_fold)\n",
    "    return all_data, all_labels, psplit\n",
    "\n",
    "train_ds = tv.datasets.MNIST('/data/datasets/MNIST/', train=True, \n",
    "                             transform=tv.transforms.ToTensor(), \n",
    "                             target_transform=None, \n",
    "                             download=True)\n",
    "\n",
    "test_ds = tv.datasets.MNIST('/data/datasets/MNIST/', train=False, \n",
    "                             transform=tv.transforms.ToTensor(), \n",
    "                             target_transform=None, \n",
    "                             download=True)\n",
    "\n",
    "if use_test_dataset:\n",
    "    # using the test dataset as a fixed validation set (only one split)\n",
    "    all_data, all_labels, psplit = torch_datasets_to_sklearn_cv_data(train_ds, valid_ds)\n",
    "    \n",
    "else:\n",
    "    all_labels = np.array([y for _, y in list(train_ds)], np.int)[:n_samples]\n",
    "    all_data = torch.cat([w.view(1, 1, 28, 28) for w, _ in list(train_ds)], 0).numpy()[:n_samples]\n",
    "    psplit = n_splits\n",
    "    \n",
    "print(all_data.shape, all_data.min(), all_data.max(), '***', \n",
    "      all_labels.shape, all_labels.min(), all_labels.max())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2017-10-24T13:19:38.724636",
     "start_time": "2017-10-24T13:19:38.575649"
    },
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "class MyNet(nn.Module):\n",
    "    # Input size is (-1, 1, 28, 28)\n",
    "    def __init__(self):\n",
    "        super().__init__()\n",
    "        self.relu = nn.ReLU()\n",
    "        self.pool = nn.MaxPool2d(2, 2)\n",
    "        self.conv1 = nn.Conv2d(1, 6, 5)         # in_channels, out_channels, kernel_size\n",
    "        self.conv2 = nn.Conv2d(6, 16, 5)\n",
    "        self.fc1 = nn.Linear(16 * 4 * 4, 120)\n",
    "        self.fc2 = nn.Linear(120, 84)\n",
    "        self.fc3 = nn.Linear(84, 10)\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = self.conv1(x)\n",
    "        x = self.relu(x)\n",
    "        x = self.pool(x)\n",
    "        x = self.conv2(x)\n",
    "        x = self.relu(x)\n",
    "        x = self.pool(x)\n",
    "        x = x.view(-1, 16 * 4 * 4)\n",
    "        x = self.fc1(x)\n",
    "        x = self.relu(x)\n",
    "        x = self.fc2(x)\n",
    "        x = self.relu(x)\n",
    "        x = self.fc3(x)\n",
    "        return x\n",
    "\n",
    "    \n",
    "class SklEstimator(BaseEstimator):\n",
    "    \n",
    "    skl_id = 0\n",
    "    fit_num = 0\n",
    "    \n",
    "    def __init__(self, model_class=None, criterion_class='CrossEntropyLoss', optim_class='SGD', \n",
    "                 optim_lr=0.001, optim_momentum=0.9, weight_decay=0, \n",
    "                 sched_step=10, sched_gamma=1.0, mb_size=16, n_epochs=100, verbose=True):\n",
    "        self.par_model_class = model_class\n",
    "        self.par_criterion_class = criterion_class\n",
    "        self.par_optim_class = optim_class\n",
    "        self.par_optim_lr = optim_lr\n",
    "        self.par_optim_momentum = optim_momentum\n",
    "        self.par_weight_decay = weight_decay\n",
    "        self.par_sched_step = sched_step\n",
    "        self.par_sched_gamma = sched_gamma\n",
    "        self.par_mb_size = mb_size\n",
    "        self.par_n_epochs = n_epochs\n",
    "        self.par_verbose = verbose\n",
    "        \n",
    "    def _initialize(self):\n",
    "        SklEstimator.skl_id += 1\n",
    "        self.idd = 'skl_model_{}'.format(SklEstimator.skl_id)\n",
    "        \n",
    "        if self.par_model_class is None:\n",
    "            raise Exception('Model not specified.')\n",
    "        \n",
    "        self.model = self.par_model_class()\n",
    "        \n",
    "        if self.par_criterion_class == 'CrossEntropyLoss':\n",
    "            self.criterion = nn.CrossEntropyLoss()\n",
    "        elif self.par_criterion_class == 'MSELoss':\n",
    "            self.criterion = nn.MSELoss()\n",
    "        else:\n",
    "            self.criterion = None\n",
    "            raise Exception(\"Calma...\")\n",
    "            \n",
    "        if self.par_optim_class == 'Adam':\n",
    "            self.optim = torch.optim.Adam(self.model.parameters(), lr=self.par_optim_lr, \n",
    "                                          weight_decay=self.par_weight_decay)\n",
    "        elif self.par_optim_class == 'SGD':\n",
    "            self.optim = torch.optim.SGD(self.model.parameters(), lr=self.par_optim_lr, \n",
    "                                         momentum=self.par_optim_momentum, nesterov=True,\n",
    "                                         weight_decay=self.par_weight_decay)\n",
    "        else:\n",
    "            self.optim = None\n",
    "            raise Exception(\"Calma...\")\n",
    "            \n",
    "        if self.par_sched_gamma < 1.0:\n",
    "            self.lr_sched = StepLR(self.optim, step_size=self.par_sched_step, gamma=self.par_sched_gamma)\n",
    "        else:\n",
    "            self.lr_sched = None\n",
    "        \n",
    "        if self.par_verbose > 0:\n",
    "            callbacks = [ptt.PrintCallback()]\n",
    "        else:\n",
    "            callbacks = None\n",
    "        \n",
    "        self.trainer = ptt.DeepNetTrainer(model=self.model, \n",
    "                                          criterion=self.criterion, \n",
    "                                          optimizer=self.optim, \n",
    "                                          lr_scheduler=self.lr_sched, \n",
    "                                          callbacks=callbacks)\n",
    "    \n",
    "    def get_params(self, deep):\n",
    "        params = []\n",
    "        for k, v in self.__dict__.items():\n",
    "            if k.startswith('par_'):\n",
    "                params.append((k[4:], v))\n",
    "        return dict(params)\n",
    "    \n",
    "    def set_params(self, **params):\n",
    "        for k, v in params.items():\n",
    "            setattr(self, 'par_' + k, v)\n",
    "        self._initialize()\n",
    "        return self\n",
    "    \n",
    "    def fit(self, Xtrain, ytrain):\n",
    "        SklEstimator.fit_num += 1\n",
    "        print('\\n***** Fit #{} *****'.format(SklEstimator.fit_num))\n",
    "        Xtra = torch.from_numpy(Xtrain)\n",
    "        ytra = torch.from_numpy(ytrain)\n",
    "        self.trainer.fit(self.par_n_epochs, Xtra, ytra, batch_size=self.par_mb_size, shuffle=True)\n",
    "    \n",
    "    def score(self, Xtrain, ytrain):\n",
    "        Xtra = torch.from_numpy(Xtrain)\n",
    "        ytra = torch.from_numpy(ytrain)\n",
    "        loss = self.trainer.score(Xtra, ytra, batch_size=self.par_mb_size)\n",
    "        print('***** Score = {:.5f} [{} samples] *****'.format(loss, ytra.shape[0]))\n",
    "        return loss\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2017-10-24T13:19:38.733221",
     "start_time": "2017-10-24T13:19:38.726895"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'criterion_class': 'CrossEntropyLoss',\n",
       " 'mb_size': 16,\n",
       " 'model_class': __main__.MyNet,\n",
       " 'n_epochs': 100,\n",
       " 'optim_class': 'SGD',\n",
       " 'optim_lr': 0.001,\n",
       " 'optim_momentum': 0.9,\n",
       " 'sched_gamma': 1.0,\n",
       " 'sched_step': 10,\n",
       " 'verbose': True,\n",
       " 'weight_decay': 0}"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "skl = SklEstimator(MyNet)\n",
    "skl.get_params(0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2017-10-24T13:19:40.378365",
     "start_time": "2017-10-24T13:19:40.369840"
    },
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# st.uniform(loc, scale)  ==> This distribution is constant between loc and loc + scale.\n",
    "\n",
    "parameters = {\n",
    "    'model_class':     [MyNet],\n",
    "    'optim_class':     ['Adam', 'SGD'], \n",
    "    'optim_lr':        st.uniform(1e-4, 5e-3),    # 0.0001:0.0051\n",
    "    'sched_step':      [10], \n",
    "    'sched_gamma':     st.uniform(0.50, 0.45),    # 0.5:0.95\n",
    "    'mb_size':         [50, 100],\n",
    "    'n_epochs':        [10],\n",
    "}\n",
    "validator = RandomizedSearchCV(SklEstimator(verbose=0), \n",
    "                               param_distributions=parameters, \n",
    "                               cv=psplit,\n",
    "                               n_iter=3, \n",
    "                               verbose=1)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2017-10-24T13:25:10.810531",
     "start_time": "2017-10-24T13:19:42.799985"
    },
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 6 folds for each of 3 candidates, totalling 18 fits\n",
      "\n",
      "***** Fit #1 *****\n",
      "***** Score = -2.29325 [1000 samples] *****\n",
      "***** Score = -2.29310 [5000 samples] *****\n",
      "\n",
      "***** Fit #2 *****\n",
      "***** Score = -2.28175 [1000 samples] *****\n",
      "***** Score = -2.28125 [5000 samples] *****\n",
      "\n",
      "***** Fit #3 *****\n",
      "***** Score = -2.27691 [1000 samples] *****\n",
      "***** Score = -2.27611 [5000 samples] *****\n",
      "\n",
      "***** Fit #4 *****\n",
      "***** Score = -2.29336 [1000 samples] *****\n",
      "***** Score = -2.29033 [5000 samples] *****\n",
      "\n",
      "***** Fit #5 *****\n",
      "***** Score = -2.28387 [1000 samples] *****\n",
      "***** Score = -2.28515 [5000 samples] *****\n",
      "\n",
      "***** Fit #6 *****\n",
      "***** Score = -2.28599 [1000 samples] *****\n",
      "***** Score = -2.28813 [5000 samples] *****\n",
      "\n",
      "***** Fit #7 *****\n",
      "***** Score = -0.40038 [1000 samples] *****\n",
      "***** Score = -0.32466 [5000 samples] *****\n",
      "\n",
      "***** Fit #8 *****\n",
      "***** Score = -0.47856 [1000 samples] *****\n",
      "***** Score = -0.42569 [5000 samples] *****\n",
      "\n",
      "***** Fit #9 *****\n",
      "***** Score = -0.57728 [1000 samples] *****\n",
      "***** Score = -0.61179 [5000 samples] *****\n",
      "\n",
      "***** Fit #10 *****\n",
      "***** Score = -0.56587 [1000 samples] *****\n",
      "***** Score = -0.55195 [5000 samples] *****\n",
      "\n",
      "***** Fit #11 *****\n",
      "***** Score = -0.42068 [1000 samples] *****\n",
      "***** Score = -0.38786 [5000 samples] *****\n",
      "\n",
      "***** Fit #12 *****\n",
      "***** Score = -0.44335 [1000 samples] *****\n",
      "***** Score = -0.39862 [5000 samples] *****\n",
      "\n",
      "***** Fit #13 *****\n",
      "***** Score = -0.26577 [1000 samples] *****\n",
      "***** Score = -0.18739 [5000 samples] *****\n",
      "\n",
      "***** Fit #14 *****\n",
      "***** Score = -0.31185 [1000 samples] *****\n",
      "***** Score = -0.22475 [5000 samples] *****\n",
      "\n",
      "***** Fit #15 *****\n",
      "***** Score = -0.22893 [1000 samples] *****\n",
      "***** Score = -0.21774 [5000 samples] *****\n",
      "\n",
      "***** Fit #16 *****\n",
      "***** Score = -0.18336 [1000 samples] *****\n",
      "***** Score = -0.18188 [5000 samples] *****\n",
      "\n",
      "***** Fit #17 *****\n",
      "***** Score = -0.28382 [1000 samples] *****\n",
      "***** Score = -0.19818 [5000 samples] *****\n",
      "\n",
      "***** Fit #18 *****\n",
      "***** Score = -0.25843 [1000 samples] *****\n",
      "***** Score = -0.22046 [5000 samples] *****\n",
      "\n",
      "***** Fit #19 *****\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=1)]: Done  18 out of  18 | elapsed:  5.1min finished\n"
     ]
    }
   ],
   "source": [
    "try:\n",
    "    validator.fit(all_data, all_labels)\n",
    "\n",
    "except KeyboardInterrupt:\n",
    "    print('Interrupted!')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2017-10-24T13:44:27.876595",
     "start_time": "2017-10-24T13:44:27.871854"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'mb_size': 50,\n",
       " 'model_class': __main__.MyNet,\n",
       " 'n_epochs': 10,\n",
       " 'optim_class': 'SGD',\n",
       " 'optim_lr': 0.0029121376750100353,\n",
       " 'sched_gamma': 0.86446472221909865,\n",
       " 'sched_step': 10}"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "validator.best_params_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2017-10-24T13:45:13.730957",
     "start_time": "2017-10-24T13:45:13.726630"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(2, -0.2553615566963951)"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "validator.best_index_, validator.best_score_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2017-10-24T13:45:51.272229",
     "start_time": "2017-10-24T13:45:50.582130"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "***** Score = -0.18972 [6000 samples] *****\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "-0.18972252715999882"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "validator.best_estimator_.score(all_data, all_labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2017-10-24T13:45:59.638981",
     "start_time": "2017-10-24T13:45:59.627067"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'mean_fit_time': array([ 15.75113988,  16.45204739,  16.95270749]),\n",
       " 'mean_score_time': array([ 0.14573598,  0.19698481,  0.13030883]),\n",
       " 'mean_test_score': array([-2.28585592, -0.48102179, -0.25536156]),\n",
       " 'mean_train_score': array([-2.28567681, -0.45009571, -0.2050667 ]),\n",
       " 'param_mb_size': masked_array(data = [100 100 50],\n",
       "              mask = [False False False],\n",
       "        fill_value = ?),\n",
       " 'param_model_class': masked_array(data = [<class '__main__.MyNet'> <class '__main__.MyNet'> <class '__main__.MyNet'>],\n",
       "              mask = [False False False],\n",
       "        fill_value = ?),\n",
       " 'param_n_epochs': masked_array(data = [10 10 10],\n",
       "              mask = [False False False],\n",
       "        fill_value = ?),\n",
       " 'param_optim_class': masked_array(data = ['SGD' 'SGD' 'SGD'],\n",
       "              mask = [False False False],\n",
       "        fill_value = ?),\n",
       " 'param_optim_lr': masked_array(data = [0.00091694046720705471 0.0037516121906576104 0.0029121376750100353],\n",
       "              mask = [False False False],\n",
       "        fill_value = ?),\n",
       " 'param_sched_gamma': masked_array(data = [0.82345453364602106 0.65511368508612489 0.86446472221909865],\n",
       "              mask = [False False False],\n",
       "        fill_value = ?),\n",
       " 'param_sched_step': masked_array(data = [10 10 10],\n",
       "              mask = [False False False],\n",
       "        fill_value = ?),\n",
       " 'params': [{'mb_size': 100,\n",
       "   'model_class': __main__.MyNet,\n",
       "   'n_epochs': 10,\n",
       "   'optim_class': 'SGD',\n",
       "   'optim_lr': 0.00091694046720705471,\n",
       "   'sched_gamma': 0.82345453364602106,\n",
       "   'sched_step': 10},\n",
       "  {'mb_size': 100,\n",
       "   'model_class': __main__.MyNet,\n",
       "   'n_epochs': 10,\n",
       "   'optim_class': 'SGD',\n",
       "   'optim_lr': 0.0037516121906576104,\n",
       "   'sched_gamma': 0.65511368508612489,\n",
       "   'sched_step': 10},\n",
       "  {'mb_size': 50,\n",
       "   'model_class': __main__.MyNet,\n",
       "   'n_epochs': 10,\n",
       "   'optim_class': 'SGD',\n",
       "   'optim_lr': 0.0029121376750100353,\n",
       "   'sched_gamma': 0.86446472221909865,\n",
       "   'sched_step': 10}],\n",
       " 'rank_test_score': array([3, 2, 1], dtype=int32),\n",
       " 'split0_test_score': array([-2.29324946, -0.40038467, -0.26577399]),\n",
       " 'split0_train_score': array([-2.29309551, -0.32466423, -0.18739378]),\n",
       " 'split1_test_score': array([-2.28174942, -0.47856355, -0.31184911]),\n",
       " 'split1_train_score': array([-2.2812482 , -0.42569281, -0.22474915]),\n",
       " 'split2_test_score': array([-2.27690656, -0.57727994, -0.22892956]),\n",
       " 'split2_train_score': array([-2.27611421, -0.61178578, -0.21773998]),\n",
       " 'split3_test_score': array([-2.29336159, -0.56587497, -0.18336321]),\n",
       " 'split3_train_score': array([-2.29032941, -0.55194992, -0.18187864]),\n",
       " 'split4_test_score': array([-2.28387399, -0.42067972, -0.28382207]),\n",
       " 'split4_train_score': array([-2.28514717, -0.38785782, -0.19817586]),\n",
       " 'split5_test_score': array([-2.28599451, -0.44334787, -0.2584314 ]),\n",
       " 'split5_train_score': array([-2.28812635, -0.39862372, -0.22046279]),\n",
       " 'std_fit_time': array([ 0.78713922,  0.34630103,  0.72366199]),\n",
       " 'std_score_time': array([ 0.02132153,  0.07853721,  0.00246289]),\n",
       " 'std_test_score': array([ 0.0059428 ,  0.06835517,  0.04082707]),\n",
       " 'std_train_score': array([ 0.00568654,  0.09947314,  0.01674591])}"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "validator.cv_results_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.0"
  },
  "toc": {
   "colors": {
    "hover_highlight": "#DAA520",
    "running_highlight": "#FF0000",
    "selected_highlight": "#FFD700"
   },
   "moveMenuLeft": true,
   "nav_menu": {},
   "navigate_menu": true,
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": false,
   "threshold": 4,
   "toc_cell": false,
   "toc_position": {},
   "toc_section_display": "block",
   "toc_window_display": false
  },
  "varInspector": {
   "cols": {
    "lenName": 16,
    "lenType": 16,
    "lenVar": 40
   },
   "kernels_config": {
    "python": {
     "delete_cmd_postfix": "",
     "delete_cmd_prefix": "del ",
     "library": "var_list.py",
     "varRefreshCmd": "print(var_dic_list())"
    },
    "r": {
     "delete_cmd_postfix": ") ",
     "delete_cmd_prefix": "rm(",
     "library": "var_list.r",
     "varRefreshCmd": "cat(var_dic_list()) "
    }
   },
   "types_to_exclude": [
    "module",
    "function",
    "builtin_function_or_method",
    "instance",
    "_Feature"
   ],
   "window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
