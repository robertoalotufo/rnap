{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Seleção dos hyperparâmetros "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2017-10-25T14:42:06.358993",
     "start_time": "2017-10-25T14:42:06.342896"
    }
   },
   "source": [
    "Hyperparâmetros são os parâmetros que não são aprendidos no processo de treinamento da rede neural. São parâmetros tanto do modelo, como número e tipo de camadas, \n",
    "número de neurônios ou canais em cada camada, como parâmetros do processo de otimização, tais como tipo do otimizador, taxa de aprendizado (learning rate), tamanho\n",
    "do mini-batch, entre outros.\n",
    "\n",
    "Uma opção é disparar um processo automático de busca no espaço de hyperparâmetros para buscar o melhor índice de validação cruzada. \n",
    "\n",
    "Normalmente a busca neste espaço de hyperparâmetros consiste de:\n",
    "- o modelo da rede;\n",
    "- o espaço de hyperparâmetros;\n",
    "- o método de busca e amostragem neste espaço;\n",
    "- o esquema de validação cruzada; e\n",
    "- uma função alvo (*score function*)\n",
    "\n",
    "Este exemplo utiliza a função do sklearn (scikit-learn) `RandomizedSearchCV` para fazer a busca aleatória no espaço de parâmetros."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2017-10-25T14:47:19.785475",
     "start_time": "2017-10-25T14:47:19.781571"
    }
   },
   "source": [
    "<img src='../figures/model_selection.png', width=600></img>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Validação cruzada"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2017-10-25T14:43:06.568757",
     "start_time": "2017-10-25T14:43:06.564456"
    }
   },
   "source": [
    "<img src='../figures/cross_validation.png', width=600></img>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Objetivos desse experimento"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Este experimento utiliza como:\n",
    "- **modelo da rede:** fixa - Fully connected, já usada anteriormente\n",
    "- **espaço de hyperparâmetros:** variando learning rate e decay\n",
    "- **método de busca:** RandomizedSearch, onde número de iterações é especificado\n",
    "- **validação cruzada:** n. de folds especificado, opção se usar ou não dados de teste\n",
    "- **função alvo:** negativo do loss (tem que ser alvo a ser maximizado)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Importação dos pacotes tradicionais"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2017-10-25T19:30:34.636490Z",
     "start_time": "2017-10-25T19:30:33.493208Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "GPU available: False\n"
     ]
    }
   ],
   "source": [
    "%matplotlib inline\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "import os, sys\n",
    "import time\n",
    "import numpy as np\n",
    "\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "from torch.utils.data import DataLoader, TensorDataset\n",
    "\n",
    "import torchvision as tv\n",
    "import lib.pytorch_trainer as ptt\n",
    "\n",
    "use_gpu = torch.cuda.is_available()\n",
    "print('GPU available:', use_gpu)\n",
    "\n",
    "np.set_printoptions(precision=3)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Importação dos pacotes de seleção de modelo do scikit-learn"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2017-10-25T19:30:36.882462Z",
     "start_time": "2017-10-25T19:30:36.291137Z"
    }
   },
   "outputs": [],
   "source": [
    "from sklearn.base import BaseEstimator\n",
    "from sklearn.model_selection import RandomizedSearchCV\n",
    "from sklearn.model_selection import PredefinedSplit\n",
    "import scipy.stats as st\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Carregamento dos dados - MNIST"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2017-10-25T19:30:38.706641Z",
     "start_time": "2017-10-25T19:30:38.619346Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Número de amostras no dataset (treino): 60000\n",
      "Número de amostras no dataset (teste ): 10000\n"
     ]
    }
   ],
   "source": [
    "train_ds = tv.datasets.MNIST('/data/datasets/MNIST/', train=True, \n",
    "                             transform=tv.transforms.ToTensor())\n",
    "valid_ds = tv.datasets.MNIST('/data/datasets/MNIST/', train=False, \n",
    "                             transform=tv.transforms.ToTensor())\n",
    "n_train = len(train_ds)\n",
    "n_valid = len(valid_ds)\n",
    "print('Número de amostras no dataset (treino):', n_train)\n",
    "print('Número de amostras no dataset (teste ):', n_valid)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Reduzindo o tamanho do dataset apenas para acelerar e testar"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2017-10-25T19:30:40.658300Z",
     "start_time": "2017-10-25T19:30:40.650845Z"
    }
   },
   "outputs": [],
   "source": [
    "if True:\n",
    "    fator_reduc = 0.02\n",
    "    n_train = int(fator_reduc * n_train)\n",
    "    n_valid = int(fator_reduc * n_valid)\n",
    "    train_ds.train_data   = train_ds.train_data[:n_train]\n",
    "    train_ds.train_labels = train_ds.train_labels[:n_train]\n",
    "    valid_ds.test_data   = valid_ds.test_data[:n_valid]\n",
    "    valid_ds.test_labels = valid_ds.test_labels[:n_valid]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2017-10-25T19:30:41.313236Z",
     "start_time": "2017-10-25T19:30:41.306683Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Número de amostras no dataset (treino): 1200\n",
      "Número de amostras no dataset (teste ): 200\n"
     ]
    }
   ],
   "source": [
    "print('Número de amostras no dataset (treino):', len(train_ds))\n",
    "print('Número de amostras no dataset (teste ):', len(valid_ds))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Função de criar um split predefinido utilizando o conjunto de treino concatenado com o conjunto de teste"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2017-10-25T19:30:50.707809Z",
     "start_time": "2017-10-25T19:30:50.691165Z"
    }
   },
   "outputs": [],
   "source": [
    "def torch_datasets_to_sklearn_cv_data(train_ds, valid_ds):\n",
    "    n_train, n_valid = len(train_ds), len(valid_ds)\n",
    "    x, y = train_ds[0]\n",
    "    all_tuples = list(train_ds) + list(valid_ds)\n",
    "    all_labels = np.array([y for _, y in all_tuples], np.int)\n",
    "    all_data = torch.cat([w.view(1, *x.shape) for w, _ in all_tuples], 0).numpy()\n",
    "    valid_fold = np.zeros_like(all_labels)\n",
    "    valid_fold[:n_train] = -1\n",
    "    psplit = PredefinedSplit(valid_fold)\n",
    "    return all_data, all_labels, psplit"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Função para montar o dataset já apropriado para o scikit-learn"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2017-10-25T19:30:50.722094Z",
     "start_time": "2017-10-25T19:30:50.710184Z"
    }
   },
   "outputs": [],
   "source": [
    "def get_dataset(use_test_dataset=False, n_splits=6):\n",
    "    if use_test_dataset:\n",
    "        # using the test dataset as a fixed validation set (only one split)\n",
    "        all_data, all_labels, psplit = torch_datasets_to_sklearn_cv_data(train_ds, valid_ds)\n",
    "\n",
    "    else:\n",
    "        all_labels = np.array([y for _, y in list(train_ds)], np.int)\n",
    "        all_data = torch.cat([w.view(1, 1, 28, 28) for w, _ in list(train_ds)], 0).numpy()\n",
    "        psplit = n_splits\n",
    "\n",
    "    # print(all_data.shape, all_data.min(), all_data.max(), '***', all_labels.shape, all_labels.min(), all_labels.max())\n",
    "    return all_data, all_labels, psplit"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Cria os dados prontos para o scikit-learn usar no `RandomizedSearchCV` e `fit`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2017-10-25T19:30:50.977174Z",
     "start_time": "2017-10-25T19:30:50.724756Z"
    }
   },
   "outputs": [],
   "source": [
    "use_test_dataset = False\n",
    "n_splits = 3\n",
    "\n",
    "all_data, all_labels, psplit = get_dataset(use_test_dataset=use_test_dataset, \n",
    "                                           n_splits=n_splits)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2017-10-25T19:30:50.987592Z",
     "start_time": "2017-10-25T19:30:50.979805Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "shape: (1200, 1, 28, 28) (1200,)\n",
      "psplit: 3\n"
     ]
    }
   ],
   "source": [
    "print('shape:',all_data.shape, all_labels.shape)\n",
    "print('psplit:', psplit) # psplit está associado ao número de folders para o cross-validation (CV)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Definição de rede"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2017-10-25T19:30:51.004484Z",
     "start_time": "2017-10-25T19:30:50.992176Z"
    }
   },
   "outputs": [],
   "source": [
    "class Model(nn.Module):\n",
    "    def __init__(self):\n",
    "        super().__init__()\n",
    "        self.fc1 = nn.Linear(28 * 28, 50)\n",
    "        self.at1 = nn.ReLU()\n",
    "        self.fc2 = nn.Linear(50, 10)\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = x.view(-1, 28 * 28)\n",
    "        x = self.fc1(x)\n",
    "        x = self.at1(x)\n",
    "        x = self.fc2(x)\n",
    "        return x"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Classe para ser chamada pelo `RandomizedSearchCV`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2017-10-25T19:30:51.159007Z",
     "start_time": "2017-10-25T19:30:51.007228Z"
    }
   },
   "outputs": [],
   "source": [
    "class SklEstimator(BaseEstimator):\n",
    "    \n",
    "    skl_id = 0\n",
    "    fit_num = 0\n",
    "    \n",
    "    def __init__(self, model_class=None, criterion_class='CrossEntropyLoss', optim_class='SGD', \n",
    "                 optim_lr=0.001, optim_momentum=0.9, weight_decay=0, \n",
    "                 sched_step=10, sched_gamma=1.0, mb_size=16, n_epochs=100, verbose=True):\n",
    "        self.par_model_class = model_class\n",
    "        self.par_criterion_class = criterion_class\n",
    "        self.par_optim_class = optim_class\n",
    "        self.par_optim_lr = optim_lr\n",
    "        self.par_optim_momentum = optim_momentum\n",
    "        self.par_weight_decay = weight_decay\n",
    "        self.par_sched_step = sched_step\n",
    "        self.par_sched_gamma = sched_gamma\n",
    "        self.par_mb_size = mb_size\n",
    "        self.par_n_epochs = n_epochs\n",
    "        self.par_verbose = verbose\n",
    "        \n",
    "    def _initialize(self):\n",
    "        SklEstimator.skl_id += 1\n",
    "        self.idd = 'skl_model_{}'.format(SklEstimator.skl_id)\n",
    "        \n",
    "        if self.par_model_class is None:\n",
    "            raise Exception('Model not specified.')\n",
    "        \n",
    "        self.model = self.par_model_class()\n",
    "        \n",
    "        if self.par_criterion_class == 'CrossEntropyLoss':\n",
    "            self.criterion = nn.CrossEntropyLoss()\n",
    "        elif self.par_criterion_class == 'MSELoss':\n",
    "            self.criterion = nn.MSELoss()\n",
    "        else:\n",
    "            self.criterion = None\n",
    "            raise Exception(\"A ser implementado ...\")\n",
    "            \n",
    "        if self.par_optim_class == 'Adam':\n",
    "            self.optim = torch.optim.Adam(self.model.parameters(), lr=self.par_optim_lr, \n",
    "                                          weight_decay=self.par_weight_decay)\n",
    "        elif self.par_optim_class == 'SGD':\n",
    "            self.optim = torch.optim.SGD(self.model.parameters(), lr=self.par_optim_lr, \n",
    "                                         momentum=self.par_optim_momentum, nesterov=True,\n",
    "                                         weight_decay=self.par_weight_decay)\n",
    "        else:\n",
    "            self.optim = None\n",
    "            raise Exception(\"A ser implementado ...\")\n",
    "            \n",
    "        if self.par_verbose > 0:\n",
    "            callbacks = [ptt.PrintCallback()]\n",
    "        else:\n",
    "            callbacks = None\n",
    "        \n",
    "        self.trainer = ptt.DeepNetTrainer(model     = self.model, \n",
    "                                          criterion = self.criterion, \n",
    "                                          optimizer = self.optim, \n",
    "                                          callbacks = callbacks)\n",
    "    \n",
    "    def get_params(self, deep):\n",
    "        params = []\n",
    "        for k, v in self.__dict__.items():\n",
    "            if k.startswith('par_'):\n",
    "                params.append((k[4:], v))\n",
    "        return dict(params)\n",
    "    \n",
    "    def set_params(self, **params):\n",
    "        for k, v in params.items():\n",
    "            setattr(self, 'par_' + k, v)\n",
    "        self._initialize()\n",
    "        return self\n",
    "    \n",
    "    def fit(self, Xtrain, ytrain):\n",
    "        SklEstimator.fit_num += 1\n",
    "        self.t0 = time.time()\n",
    "        print('\\n***** Fit #{} '.format(SklEstimator.fit_num))\n",
    "        Xtra = torch.from_numpy(Xtrain)\n",
    "        ytra = torch.from_numpy(ytrain)\n",
    "        self.trainer.fit(self.par_n_epochs, Xtra, ytra, batch_size=self.par_mb_size, shuffle=True)\n",
    "    \n",
    "    def score(self, Xtrain, ytrain):\n",
    "        Xtra = torch.from_numpy(Xtrain)\n",
    "        ytra = torch.from_numpy(ytrain)\n",
    "        mdict = self.trainer.evaluate(Xtra, ytra, batch_size=self.par_mb_size)\n",
    "        score = - mdict['losses'] # negativo pois é busca por máximo score\n",
    "        print('***** Score = {:.5f} [{} samples]  {:.2f}s'.format(score, ytra.shape[0], time.time() - self.t0))\n",
    "        return score"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Espaço de parâmetro para a busca"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2017-10-25T19:30:51.168828Z",
     "start_time": "2017-10-25T19:30:51.162088Z"
    }
   },
   "outputs": [],
   "source": [
    "parameters_space = {\n",
    "    'optim_lr':        st.uniform(0.0001, 0.005),\n",
    "    'weight_decay':    st.uniform(0.0, 0.01),\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2017-10-25T19:30:51.178065Z",
     "start_time": "2017-10-25T19:30:51.171246Z"
    }
   },
   "outputs": [],
   "source": [
    "parameters = {\n",
    "    'model_class':     [Model],\n",
    "    'optim_class':     ['Adam'], \n",
    "    'mb_size':         [100],\n",
    "    'n_epochs':        [50],\n",
    "}\n",
    "\n",
    "parameters.update(parameters_space) # Junção dos parâmetros fixos e dos a sintonizar"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Inicialização do validator e busca dos melhores parâmetros"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2017-10-25T19:31:35.889932Z",
     "start_time": "2017-10-25T19:30:51.180517Z"
    },
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 3 folds for each of 10 candidates, totalling 30 fits\n",
      "\n",
      "***** Fit #1 \n",
      "evaluate: 3/3 ok\n",
      "***** Score = -0.42616 [400 samples]  0.93s\n",
      "evaluate: 7/7 ok\n",
      "***** Score = -0.11600 [800 samples]  0.94s\n",
      "\n",
      "***** Fit #2 \n",
      "evaluate: 3/3 ok\n",
      "***** Score = -0.54814 [400 samples]  0.92s\n",
      "evaluate: 7/7 ok\n",
      "***** Score = -0.11356 [800 samples]  0.93s\n",
      "\n",
      "***** Fit #3 \n",
      "evaluate: 3/3 ok\n",
      "***** Score = -0.58078 [400 samples]  0.91s\n",
      "evaluate: 7/7 ok\n",
      "***** Score = -0.10554 [800 samples]  0.92s\n",
      "\n",
      "***** Fit #4 \n",
      "evaluate: 3/3 ok\n",
      "***** Score = -0.44682 [400 samples]  0.91s\n",
      "evaluate: 7/7 ok\n",
      "***** Score = -0.11696 [800 samples]  0.92s\n",
      "\n",
      "***** Fit #5 \n",
      "evaluate: 3/3 ok\n",
      "***** Score = -0.52293 [400 samples]  0.91s\n",
      "evaluate: 7/7 ok\n",
      "***** Score = -0.10789 [800 samples]  0.91s\n",
      "\n",
      "***** Fit #6 \n",
      "evaluate: 3/3 ok\n",
      "***** Score = -0.57064 [400 samples]  0.92s\n",
      "evaluate: 7/7 ok\n",
      "***** Score = -0.10783 [800 samples]  0.93s\n",
      "\n",
      "***** Fit #7 \n",
      "evaluate: 3/3 ok\n",
      "***** Score = -0.47501 [400 samples]  0.93s\n",
      "evaluate: 7/7 ok\n",
      "***** Score = -0.02488 [800 samples]  0.94s\n",
      "\n",
      "***** Fit #8 \n",
      "evaluate: 3/3 ok\n",
      "***** Score = -0.61357 [400 samples]  0.91s\n",
      "evaluate: 7/7 ok\n",
      "***** Score = -0.02192 [800 samples]  0.92s\n",
      "\n",
      "***** Fit #9 \n",
      "evaluate: 3/3 ok\n",
      "***** Score = -0.69093 [400 samples]  0.90s\n",
      "evaluate: 7/7 ok\n",
      "***** Score = -0.01911 [800 samples]  0.91s\n",
      "\n",
      "***** Fit #10 \n",
      "evaluate: 3/3 ok\n",
      "***** Score = -0.42578 [400 samples]  0.92s\n",
      "evaluate: 7/7 ok\n",
      "***** Score = -0.11464 [800 samples]  0.92s\n",
      "\n",
      "***** Fit #11 \n",
      "evaluate: 3/3 ok\n",
      "***** Score = -0.53958 [400 samples]  0.91s\n",
      "evaluate: 7/7 ok\n",
      "***** Score = -0.10390 [800 samples]  0.92s\n",
      "\n",
      "***** Fit #12 \n",
      "evaluate: 3/3 ok\n",
      "***** Score = -0.57342 [400 samples]  0.94s\n",
      "evaluate: 7/7 ok\n",
      "***** Score = -0.09983 [800 samples]  0.95s\n",
      "\n",
      "***** Fit #13 \n",
      "evaluate: 3/3 ok\n",
      "***** Score = -0.44119 [400 samples]  0.92s\n",
      "evaluate: 7/7 ok\n",
      "***** Score = -0.12150 [800 samples]  0.93s\n",
      "\n",
      "***** Fit #14 \n",
      "evaluate: 3/3 ok\n",
      "***** Score = -0.55103 [400 samples]  0.91s\n",
      "evaluate: 7/7 ok\n",
      "***** Score = -0.11398 [800 samples]  0.92s\n",
      "\n",
      "***** Fit #15 \n",
      "evaluate: 3/3 ok\n",
      "***** Score = -0.56820 [400 samples]  0.93s\n",
      "evaluate: 7/7 ok\n",
      "***** Score = -0.10938 [800 samples]  0.94s\n",
      "\n",
      "***** Fit #16 \n",
      "evaluate: 3/3 ok\n",
      "***** Score = -0.47606 [400 samples]  0.94s\n",
      "evaluate: 7/7 ok\n",
      "***** Score = -0.08225 [800 samples]  0.95s\n",
      "\n",
      "***** Fit #17 \n",
      "evaluate: 3/3 ok\n",
      "***** Score = -0.52037 [400 samples]  0.93s\n",
      "evaluate: 7/7 ok\n",
      "***** Score = -0.07558 [800 samples]  0.93s\n",
      "\n",
      "***** Fit #18 \n",
      "evaluate: 3/3 ok\n",
      "***** Score = -0.57715 [400 samples]  0.93s\n",
      "evaluate: 7/7 ok\n",
      "***** Score = -0.06449 [800 samples]  0.94s\n",
      "\n",
      "***** Fit #19 \n",
      "evaluate: 3/3 ok\n",
      "***** Score = -0.45966 [400 samples]  0.90s\n",
      "evaluate: 7/7 ok\n",
      "***** Score = -0.28152 [800 samples]  0.90s\n",
      "\n",
      "***** Fit #20 \n",
      "evaluate: 3/3 ok\n",
      "***** Score = -0.57542 [400 samples]  0.91s\n",
      "evaluate: 7/7 ok\n",
      "***** Score = -0.27696 [800 samples]  0.92s\n",
      "\n",
      "***** Fit #21 \n",
      "evaluate: 3/3 ok\n",
      "***** Score = -0.59347 [400 samples]  0.93s\n",
      "evaluate: 7/7 ok\n",
      "***** Score = -0.25470 [800 samples]  0.94s\n",
      "\n",
      "***** Fit #22 \n",
      "evaluate: 3/3 ok\n",
      "***** Score = -0.56264 [400 samples]  0.93s\n",
      "evaluate: 7/7 ok\n",
      "***** Score = -0.00452 [800 samples]  0.94s\n",
      "\n",
      "***** Fit #23 \n",
      "evaluate: 3/3 ok\n",
      "***** Score = -0.68010 [400 samples]  0.92s\n",
      "evaluate: 7/7 ok\n",
      "***** Score = -0.00359 [800 samples]  0.93s\n",
      "\n",
      "***** Fit #24 \n",
      "evaluate: 3/3 ok\n",
      "***** Score = -0.80555 [400 samples]  0.92s\n",
      "evaluate: 7/7 ok\n",
      "***** Score = -0.00377 [800 samples]  0.92s\n",
      "\n",
      "***** Fit #25 \n",
      "evaluate: 3/3 ok\n",
      "***** Score = -0.46627 [400 samples]  0.93s\n",
      "evaluate: 7/7 ok\n",
      "***** Score = -0.07139 [800 samples]  0.93s\n",
      "\n",
      "***** Fit #26 \n",
      "evaluate: 3/3 ok\n",
      "***** Score = -0.52591 [400 samples]  0.91s\n",
      "evaluate: 7/7 ok\n",
      "***** Score = -0.06299 [800 samples]  0.92s\n",
      "\n",
      "***** Fit #27 \n",
      "evaluate: 3/3 ok\n",
      "***** Score = -0.60893 [400 samples]  0.92s\n",
      "evaluate: 7/7 ok\n",
      "***** Score = -0.06890 [800 samples]  0.93s\n",
      "\n",
      "***** Fit #28 \n",
      "evaluate: 3/3 ok\n",
      "***** Score = -0.43515 [400 samples]  0.91s\n",
      "evaluate: 7/7 ok\n",
      "***** Score = -0.11563 [800 samples]  0.92s\n",
      "\n",
      "***** Fit #29 \n",
      "evaluate: 3/3 ok\n",
      "***** Score = -0.55634 [400 samples]  0.91s\n",
      "evaluate: 7/7 ok\n",
      "***** Score = -0.12804 [800 samples]  0.92s\n",
      "\n",
      "***** Fit #30 \n",
      "evaluate: 3/3 ok\n",
      "***** Score = -0.59087 [400 samples]  0.92s\n",
      "evaluate: 7/7 ok\n",
      "***** Score = -0.11625 [800 samples]  0.93s\n",
      "\n",
      "***** Fit #31 \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=1)]: Done  30 out of  30 | elapsed:   27.9s finished\n"
     ]
    }
   ],
   "source": [
    "n_iterations = 10\n",
    "validator = RandomizedSearchCV(SklEstimator(verbose=0), \n",
    "                               param_distributions = parameters, \n",
    "                               cv                  = psplit,\n",
    "                               n_iter              = n_iterations, \n",
    "                               verbose             = 1)\n",
    "\n",
    "try:\n",
    "    validator.fit(all_data, all_labels)\n",
    "\n",
    "except KeyboardInterrupt:\n",
    "    print('Interrupted!')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Avaliação dos resultados"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Scores das iterações"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2017-10-25T19:31:35.904204Z",
     "start_time": "2017-10-25T19:31:35.893808Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "mean_test_score: [-0.518 -0.513 -0.593 -0.513 -0.52  -0.525 -0.543 -0.683 -0.534 -0.527]\n",
      "rank_test_score: [ 3  2  9  1  4  5  8 10  7  6]\n"
     ]
    }
   ],
   "source": [
    "print('mean_test_score:',validator.cv_results_['mean_test_score'])\n",
    "print('rank_test_score:',validator.cv_results_['rank_test_score'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Parâmetros utilizados em cada iteração"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2017-10-25T19:31:35.913825Z",
     "start_time": "2017-10-25T19:31:35.906854Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "optim_lr ['0.0012', '0.0027', '0.0017', '0.0016', '0.0016', '0.0047', '0.00048', '0.0049', '0.0038', '0.004']\n",
      "weight_decay ['0.0057', '0.0089', '0.00019', '0.0066', '0.0076', '0.0058', '0.0095', '9.4e-05', '0.0053', '0.0099']\n"
     ]
    }
   ],
   "source": [
    "for par in parameters_space:\n",
    "    print(par,[ '{:.2}'.format(fit[par]) for fit in validator.cv_results_['params']])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Parâmetros de melhor score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2017-10-25T19:31:35.926637Z",
     "start_time": "2017-10-25T19:31:35.917000Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'mb_size': 100,\n",
       " 'model_class': __main__.Model,\n",
       " 'n_epochs': 50,\n",
       " 'optim_class': 'Adam',\n",
       " 'optim_lr': 0.0015750114316886265,\n",
       " 'weight_decay': 0.0065905892568397283}"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "validator.best_params_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2017-10-25T19:31:35.936896Z",
     "start_time": "2017-10-25T19:31:35.930121Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(3, -0.51292374730110168)"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "validator.best_index_, validator.best_score_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2017-10-25T19:31:35.978780Z",
     "start_time": "2017-10-25T19:31:35.939801Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\r",
      "evaluate: 0/11\r",
      "evaluate: 1/11\r",
      "evaluate: 2/11\r",
      "evaluate: 3/11\r",
      "evaluate: 4/11\r",
      "evaluate: 5/11\r",
      "evaluate: 6/11\r",
      "evaluate: 7/11\r",
      "evaluate: 8/11\r",
      "evaluate: 9/11\r",
      "evaluate: 10/11\r",
      "evaluate: 11/11 ok\n",
      "***** Score = -0.12260 [1200 samples]  1.40s\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "-0.12260216847062111"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "validator.best_estimator_.score(all_data, all_labels)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Dicionário completo da busca `RandomizedSearchCV`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2017-10-25T19:31:36.002443Z",
     "start_time": "2017-10-25T19:31:35.981716Z"
    },
    "scrolled": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'mean_fit_time': array([ 0.917,  0.907,  0.913,  0.918,  0.917,  0.928,  0.909,  0.918,\n",
       "         0.916,  0.913]),\n",
       " 'mean_score_time': array([ 0.005,  0.004,  0.005,  0.004,  0.005,  0.004,  0.004,  0.004,\n",
       "         0.005,  0.004]),\n",
       " 'mean_test_score': array([-0.518, -0.513, -0.593, -0.513, -0.52 , -0.525, -0.543, -0.683,\n",
       "        -0.534, -0.527]),\n",
       " 'mean_train_score': array([-0.112, -0.111, -0.022, -0.106, -0.115, -0.074, -0.271, -0.004,\n",
       "        -0.068, -0.12 ]),\n",
       " 'param_mb_size': masked_array(data = [100 100 100 100 100 100 100 100 100 100],\n",
       "              mask = [False False False False False False False False False False],\n",
       "        fill_value = ?),\n",
       " 'param_model_class': masked_array(data = [<class '__main__.Model'> <class '__main__.Model'> <class '__main__.Model'>\n",
       "  <class '__main__.Model'> <class '__main__.Model'> <class '__main__.Model'>\n",
       "  <class '__main__.Model'> <class '__main__.Model'> <class '__main__.Model'>\n",
       "  <class '__main__.Model'>],\n",
       "              mask = [False False False False False False False False False False],\n",
       "        fill_value = ?),\n",
       " 'param_n_epochs': masked_array(data = [50 50 50 50 50 50 50 50 50 50],\n",
       "              mask = [False False False False False False False False False False],\n",
       "        fill_value = ?),\n",
       " 'param_optim_class': masked_array(data = ['Adam' 'Adam' 'Adam' 'Adam' 'Adam' 'Adam' 'Adam' 'Adam' 'Adam' 'Adam'],\n",
       "              mask = [False False False False False False False False False False],\n",
       "        fill_value = ?),\n",
       " 'param_optim_lr': masked_array(data = [0.0012242268161179136 0.002701460079503649 0.0016872035047333473\n",
       "  0.0015750114316886265 0.0016486022216633505 0.0046628477566013245\n",
       "  0.00047877958356538452 0.0048558901109939014 0.0037758260524670506\n",
       "  0.004033149847927236],\n",
       "              mask = [False False False False False False False False False False],\n",
       "        fill_value = ?),\n",
       " 'param_weight_decay': masked_array(data = [0.005667207748252614 0.0088932317267732854 0.00019324691771629209\n",
       "  0.0065905892568397283 0.007640683602940436 0.0057542609535342426\n",
       "  0.0095343743394090529 9.4392026708872703e-05 0.0052747311991227811\n",
       "  0.0099175592080052756],\n",
       "              mask = [False False False False False False False False False False],\n",
       "        fill_value = ?),\n",
       " 'params': [{'mb_size': 100,\n",
       "   'model_class': __main__.Model,\n",
       "   'n_epochs': 50,\n",
       "   'optim_class': 'Adam',\n",
       "   'optim_lr': 0.0012242268161179136,\n",
       "   'weight_decay': 0.005667207748252614},\n",
       "  {'mb_size': 100,\n",
       "   'model_class': __main__.Model,\n",
       "   'n_epochs': 50,\n",
       "   'optim_class': 'Adam',\n",
       "   'optim_lr': 0.002701460079503649,\n",
       "   'weight_decay': 0.0088932317267732854},\n",
       "  {'mb_size': 100,\n",
       "   'model_class': __main__.Model,\n",
       "   'n_epochs': 50,\n",
       "   'optim_class': 'Adam',\n",
       "   'optim_lr': 0.0016872035047333473,\n",
       "   'weight_decay': 0.00019324691771629209},\n",
       "  {'mb_size': 100,\n",
       "   'model_class': __main__.Model,\n",
       "   'n_epochs': 50,\n",
       "   'optim_class': 'Adam',\n",
       "   'optim_lr': 0.0015750114316886265,\n",
       "   'weight_decay': 0.0065905892568397283},\n",
       "  {'mb_size': 100,\n",
       "   'model_class': __main__.Model,\n",
       "   'n_epochs': 50,\n",
       "   'optim_class': 'Adam',\n",
       "   'optim_lr': 0.0016486022216633505,\n",
       "   'weight_decay': 0.007640683602940436},\n",
       "  {'mb_size': 100,\n",
       "   'model_class': __main__.Model,\n",
       "   'n_epochs': 50,\n",
       "   'optim_class': 'Adam',\n",
       "   'optim_lr': 0.0046628477566013245,\n",
       "   'weight_decay': 0.0057542609535342426},\n",
       "  {'mb_size': 100,\n",
       "   'model_class': __main__.Model,\n",
       "   'n_epochs': 50,\n",
       "   'optim_class': 'Adam',\n",
       "   'optim_lr': 0.00047877958356538452,\n",
       "   'weight_decay': 0.0095343743394090529},\n",
       "  {'mb_size': 100,\n",
       "   'model_class': __main__.Model,\n",
       "   'n_epochs': 50,\n",
       "   'optim_class': 'Adam',\n",
       "   'optim_lr': 0.0048558901109939014,\n",
       "   'weight_decay': 9.4392026708872703e-05},\n",
       "  {'mb_size': 100,\n",
       "   'model_class': __main__.Model,\n",
       "   'n_epochs': 50,\n",
       "   'optim_class': 'Adam',\n",
       "   'optim_lr': 0.0037758260524670506,\n",
       "   'weight_decay': 0.0052747311991227811},\n",
       "  {'mb_size': 100,\n",
       "   'model_class': __main__.Model,\n",
       "   'n_epochs': 50,\n",
       "   'optim_class': 'Adam',\n",
       "   'optim_lr': 0.004033149847927236,\n",
       "   'weight_decay': 0.0099175592080052756}],\n",
       " 'rank_test_score': array([ 3,  2,  9,  1,  4,  5,  8, 10,  7,  6], dtype=int32),\n",
       " 'split0_test_score': array([-0.426, -0.447, -0.475, -0.426, -0.441, -0.476, -0.46 , -0.563,\n",
       "        -0.466, -0.435]),\n",
       " 'split0_train_score': array([-0.116, -0.117, -0.025, -0.115, -0.122, -0.082, -0.282, -0.005,\n",
       "        -0.071, -0.116]),\n",
       " 'split1_test_score': array([-0.548, -0.523, -0.614, -0.54 , -0.551, -0.52 , -0.575, -0.68 ,\n",
       "        -0.526, -0.556]),\n",
       " 'split1_train_score': array([-0.114, -0.108, -0.022, -0.104, -0.114, -0.076, -0.277, -0.004,\n",
       "        -0.063, -0.128]),\n",
       " 'split2_test_score': array([-0.581, -0.571, -0.691, -0.573, -0.568, -0.577, -0.593, -0.806,\n",
       "        -0.609, -0.591]),\n",
       " 'split2_train_score': array([-0.106, -0.108, -0.019, -0.1  , -0.109, -0.064, -0.255, -0.004,\n",
       "        -0.069, -0.116]),\n",
       " 'std_fit_time': array([ 0.009,  0.004,  0.013,  0.01 ,  0.01 ,  0.004,  0.015,  0.006,\n",
       "         0.004,  0.005]),\n",
       " 'std_score_time': array([  4.690e-04,   3.551e-04,   3.834e-04,   3.981e-04,   4.387e-04,\n",
       "          3.497e-04,   4.429e-04,   8.803e-05,   4.245e-04,   4.430e-04]),\n",
       " 'std_test_score': array([ 0.067,  0.051,  0.089,  0.063,  0.056,  0.041,  0.059,  0.099,\n",
       "         0.059,  0.067]),\n",
       " 'std_train_score': array([ 0.004,  0.004,  0.002,  0.006,  0.005,  0.007,  0.012,  0.   ,\n",
       "         0.004,  0.006])}"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "validator.cv_results_"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "# Exercícios"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "1. Adicione um parâmetro adicional na escolha do otimizador: 'SGV' e o 'Adam'.\n",
    "2. Adicione agora um parâmetro na rede, por exemplo trocar a função de ativação de 'ReLU' para 'Sigmoid'.\n",
    "3. Adicione um parâmetro a sua escolha."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.2"
  },
  "toc": {
   "nav_menu": {},
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": false,
   "toc_cell": false,
   "toc_position": {},
   "toc_section_display": "block",
   "toc_window_display": false
  },
  "varInspector": {
   "cols": {
    "lenName": 16,
    "lenType": 16,
    "lenVar": 40
   },
   "kernels_config": {
    "python": {
     "delete_cmd_postfix": "",
     "delete_cmd_prefix": "del ",
     "library": "var_list.py",
     "varRefreshCmd": "print(var_dic_list())"
    },
    "r": {
     "delete_cmd_postfix": ") ",
     "delete_cmd_prefix": "rm(",
     "library": "var_list.r",
     "varRefreshCmd": "cat(var_dic_list()) "
    }
   },
   "types_to_exclude": [
    "module",
    "function",
    "builtin_function_or_method",
    "instance",
    "_Feature"
   ],
   "window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
