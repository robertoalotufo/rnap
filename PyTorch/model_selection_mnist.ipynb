{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "GPU available: False\n",
      "torch 0.2.0_4\n",
      "Python 3.6.2 |Anaconda custom (x86_64)| (default, Sep 21 2017, 18:29:43) \n",
      "[GCC 4.2.1 Compatible Clang 4.0.1 (tags/RELEASE_401/final)]\n"
     ]
    }
   ],
   "source": [
    "%matplotlib inline\n",
    "import matplotlib.pyplot as plt\n",
    "from IPython import display\n",
    "\n",
    "import os\n",
    "import sys\n",
    "import imp\n",
    "import time\n",
    "import numpy as np\n",
    "\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "from torch.optim.lr_scheduler import MultiStepLR, StepLR\n",
    "from torch.utils.data import DataLoader, TensorDataset\n",
    "from torch.autograd import Variable\n",
    "\n",
    "import torchvision as tv\n",
    "import lib.pytorch_trainer as ptt\n",
    "\n",
    "use_gpu = torch.cuda.is_available()\n",
    "print('GPU available:', use_gpu)\n",
    "print('torch', torch.version.__version__)\n",
    "print('Python', sys.version)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from sklearn.base import BaseEstimator\n",
    "from sklearn.model_selection import RandomizedSearchCV\n",
    "from sklearn.model_selection import PredefinedSplit\n",
    "import scipy.stats as st\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(6000, 1, 28, 28) 0.0 1.0 *** (6000,) 0 9\n"
     ]
    }
   ],
   "source": [
    "# MNIST Dataset\n",
    "# =============\n",
    "use_test_dataset = False\n",
    "n_samples = 6000\n",
    "n_splits = 6\n",
    "\n",
    "def torch_datasets_to_sklearn_cv_data(train_ds, valid_ds):\n",
    "    n_train, n_valid = len(train_ds), len(valid_ds)\n",
    "    x, y = train_ds[0]\n",
    "    all_tuples = list(train_ds) + list(valid_ds)\n",
    "    all_labels = np.array([y for _, y in all_tuples], np.int)\n",
    "    all_data = torch.cat([w.view(1, *x.shape) for w, _ in all_tuples], 0).numpy()\n",
    "    valid_fold = np.zeros_like(all_labels)\n",
    "    valid_fold[:n_train] = -1\n",
    "    psplit = PredefinedSplit(valid_fold)\n",
    "    return all_data, all_labels, psplit\n",
    "\n",
    "train_ds = tv.datasets.MNIST('/data/datasets/MNIST/', train=True, \n",
    "                             transform=tv.transforms.ToTensor(), \n",
    "                             target_transform=None, \n",
    "                             download=True)\n",
    "\n",
    "test_ds = tv.datasets.MNIST('/data/datasets/MNIST/', train=False, \n",
    "                             transform=tv.transforms.ToTensor(), \n",
    "                             target_transform=None, \n",
    "                             download=True)\n",
    "\n",
    "if use_test_dataset:\n",
    "    # using the test dataset as a fixed validation set (only one split)\n",
    "    all_data, all_labels, psplit = torch_datasets_to_sklearn_cv_data(train_ds, valid_ds)\n",
    "    \n",
    "else:\n",
    "    all_labels = np.array([y for _, y in list(train_ds)], np.int)[:n_samples]\n",
    "    all_data = torch.cat([w.view(1, 1, 28, 28) for w, _ in list(train_ds)], 0).numpy()[:n_samples]\n",
    "    psplit = n_splits\n",
    "    \n",
    "print(all_data.shape, all_data.min(), all_data.max(), '***', \n",
    "      all_labels.shape, all_labels.min(), all_labels.max())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "class MyNet(nn.Module):\n",
    "    # Input size is (-1, 1, 28, 28)\n",
    "    def __init__(self):\n",
    "        super().__init__()\n",
    "        self.relu = nn.ReLU()\n",
    "        self.pool = nn.MaxPool2d(2, 2)\n",
    "        self.conv1 = nn.Conv2d(1, 6, 5)         # in_channels, out_channels, kernel_size\n",
    "        self.conv2 = nn.Conv2d(6, 16, 5)\n",
    "        self.fc1 = nn.Linear(16 * 4 * 4, 120)\n",
    "        self.fc2 = nn.Linear(120, 84)\n",
    "        self.fc3 = nn.Linear(84, 10)\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = self.conv1(x)\n",
    "        x = self.relu(x)\n",
    "        x = self.pool(x)\n",
    "        x = self.conv2(x)\n",
    "        x = self.relu(x)\n",
    "        x = self.pool(x)\n",
    "        x = x.view(-1, 16 * 4 * 4)\n",
    "        x = self.fc1(x)\n",
    "        x = self.relu(x)\n",
    "        x = self.fc2(x)\n",
    "        x = self.relu(x)\n",
    "        x = self.fc3(x)\n",
    "        return x\n",
    "\n",
    "    \n",
    "class SklEstimator(BaseEstimator):\n",
    "    \n",
    "    skl_id = 0\n",
    "    fit_num = 0\n",
    "    \n",
    "    def __init__(self, model_class=None, criterion_class='CrossEntropyLoss', optim_class='SGD', \n",
    "                 optim_lr=0.001, optim_momentum=0.9, weight_decay=0, \n",
    "                 sched_step=10, sched_gamma=1.0, mb_size=16, n_epochs=100, verbose=True):\n",
    "        self.par_model_class = model_class\n",
    "        self.par_criterion_class = criterion_class\n",
    "        self.par_optim_class = optim_class\n",
    "        self.par_optim_lr = optim_lr\n",
    "        self.par_optim_momentum = optim_momentum\n",
    "        self.par_weight_decay = weight_decay\n",
    "        self.par_sched_step = sched_step\n",
    "        self.par_sched_gamma = sched_gamma\n",
    "        self.par_mb_size = mb_size\n",
    "        self.par_n_epochs = n_epochs\n",
    "        self.par_verbose = verbose\n",
    "        \n",
    "    def _initialize(self):\n",
    "        SklEstimator.skl_id += 1\n",
    "        self.idd = 'skl_model_{}'.format(SklEstimator.skl_id)\n",
    "        \n",
    "        if self.par_model_class is None:\n",
    "            raise Exception('Model not specified.')\n",
    "        \n",
    "        self.model = self.par_model_class()\n",
    "        \n",
    "        if self.par_criterion_class == 'CrossEntropyLoss':\n",
    "            self.criterion = nn.CrossEntropyLoss()\n",
    "        elif self.par_criterion_class == 'MSELoss':\n",
    "            self.criterion = nn.MSELoss()\n",
    "        else:\n",
    "            self.criterion = None\n",
    "            raise Exception(\"Calma...\")\n",
    "            \n",
    "        if self.par_optim_class == 'Adam':\n",
    "            self.optim = torch.optim.Adam(self.model.parameters(), lr=self.par_optim_lr, \n",
    "                                          weight_decay=self.par_weight_decay)\n",
    "        elif self.par_optim_class == 'SGD':\n",
    "            self.optim = torch.optim.SGD(self.model.parameters(), lr=self.par_optim_lr, \n",
    "                                         momentum=self.par_optim_momentum, nesterov=True,\n",
    "                                         weight_decay=self.par_weight_decay)\n",
    "        else:\n",
    "            self.optim = None\n",
    "            raise Exception(\"Calma...\")\n",
    "            \n",
    "        if self.par_sched_gamma < 1.0:\n",
    "            self.lr_sched = StepLR(self.optim, step_size=self.par_sched_step, gamma=self.par_sched_gamma)\n",
    "        else:\n",
    "            self.lr_sched = None\n",
    "        \n",
    "        if self.par_verbose > 0:\n",
    "            callbacks = [ptt.PrintCallback()]\n",
    "        else:\n",
    "            callbacks = None\n",
    "        \n",
    "        self.trainer = ptt.DeepNetTrainer(model=self.model, \n",
    "                                          criterion=self.criterion, \n",
    "                                          optimizer=self.optim, \n",
    "                                          lr_scheduler=self.lr_sched, \n",
    "                                          callbacks=callbacks)\n",
    "    \n",
    "    def get_params(self, deep):\n",
    "        params = []\n",
    "        for k, v in self.__dict__.items():\n",
    "            if k.startswith('par_'):\n",
    "                params.append((k[4:], v))\n",
    "        return dict(params)\n",
    "    \n",
    "    def set_params(self, **params):\n",
    "        for k, v in params.items():\n",
    "            setattr(self, 'par_' + k, v)\n",
    "        self._initialize()\n",
    "        return self\n",
    "    \n",
    "    def fit(self, Xtrain, ytrain):\n",
    "        SklEstimator.fit_num += 1\n",
    "        print('\\n***** Fit #{} *****'.format(SklEstimator.fit_num))\n",
    "        Xtra = torch.from_numpy(Xtrain)\n",
    "        ytra = torch.from_numpy(ytrain)\n",
    "        self.trainer.fit(self.par_n_epochs, Xtra, ytra, batch_size=self.par_mb_size, shuffle=True)\n",
    "    \n",
    "    def score(self, Xtrain, ytrain):\n",
    "        Xtra = torch.from_numpy(Xtrain)\n",
    "        ytra = torch.from_numpy(ytrain)\n",
    "        loss = self.trainer.score(Xtra, ytra, batch_size=self.par_mb_size)\n",
    "        print('***** Score = {:.5f} [{} samples] *****'.format(loss, ytra.shape[0]))\n",
    "        return loss\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'criterion_class': 'CrossEntropyLoss',\n",
       " 'mb_size': 16,\n",
       " 'model_class': __main__.MyNet,\n",
       " 'n_epochs': 100,\n",
       " 'optim_class': 'SGD',\n",
       " 'optim_lr': 0.001,\n",
       " 'optim_momentum': 0.9,\n",
       " 'sched_gamma': 1.0,\n",
       " 'sched_step': 10,\n",
       " 'verbose': True,\n",
       " 'weight_decay': 0}"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "skl = SklEstimator(MyNet)\n",
    "skl.get_params(0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# st.uniform(loc, scale)  ==> This distribution is constant between loc and loc + scale.\n",
    "\n",
    "parameters = {\n",
    "    'model_class':     [MyNet],\n",
    "    'optim_class':     ['Adam', 'SGD'], \n",
    "    'optim_lr':        st.uniform(1e-4, 5e-3),    # 0.0001:0.0051\n",
    "    'sched_step':      [10], \n",
    "    'sched_gamma':     st.uniform(0.50, 0.45),    # 0.5:0.95\n",
    "    'mb_size':         [50, 100],\n",
    "    'n_epochs':        [10],\n",
    "}\n",
    "validator = RandomizedSearchCV(SklEstimator(verbose=0), \n",
    "                               param_distributions=parameters, \n",
    "                               cv=psplit,\n",
    "                               n_iter=3, \n",
    "                               verbose=1)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 6 folds for each of 3 candidates, totalling 18 fits\n",
      "\n",
      "***** Fit #1 *****\n",
      "***** Score = -0.42374 [1000 samples] *****\n",
      "***** Score = -0.36485 [5000 samples] *****\n",
      "\n",
      "***** Fit #2 *****\n",
      "***** Score = -0.38021 [1000 samples] *****\n",
      "***** Score = -0.32802 [5000 samples] *****\n",
      "\n",
      "***** Fit #3 *****\n",
      "***** Score = -0.35530 [1000 samples] *****\n",
      "***** Score = -0.35798 [5000 samples] *****\n",
      "\n",
      "***** Fit #4 *****\n",
      "***** Score = -0.40117 [1000 samples] *****\n",
      "Interrupted!\n"
     ]
    }
   ],
   "source": [
    "try:\n",
    "    validator.fit(all_data, all_labels)\n",
    "\n",
    "except KeyboardInterrupt:\n",
    "    print('Interrupted!')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "ename": "AttributeError",
     "evalue": "'RandomizedSearchCV' object has no attribute 'best_params_'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-8-b8a092250282>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mvalidator\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbest_params_\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;31mAttributeError\u001b[0m: 'RandomizedSearchCV' object has no attribute 'best_params_'"
     ]
    }
   ],
   "source": [
    "validator.best_params_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "validator.best_index_, validator.best_score_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "validator.best_estimator_.score(all_data, all_labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "validator.cv_results_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.2"
  },
  "toc": {
   "nav_menu": {},
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": false,
   "toc_cell": false,
   "toc_position": {},
   "toc_section_display": "block",
   "toc_window_display": false
  },
  "varInspector": {
   "cols": {
    "lenName": 16,
    "lenType": 16,
    "lenVar": 40
   },
   "kernels_config": {
    "python": {
     "delete_cmd_postfix": "",
     "delete_cmd_prefix": "del ",
     "library": "var_list.py",
     "varRefreshCmd": "print(var_dic_list())"
    },
    "r": {
     "delete_cmd_postfix": ") ",
     "delete_cmd_prefix": "rm(",
     "library": "var_list.r",
     "varRefreshCmd": "cat(var_dic_list()) "
    }
   },
   "types_to_exclude": [
    "module",
    "function",
    "builtin_function_or_method",
    "instance",
    "_Feature"
   ],
   "window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
