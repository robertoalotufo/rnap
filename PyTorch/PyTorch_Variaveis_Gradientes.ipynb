{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# PyTorch: Variable e Gradientes e Grafo Computacional"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Um dos principais fundamentos para que o PyTorch seja adequado para deep learning é a sua habilidade de\n",
    "calcular o gradiente automaticamente a partir da expressões definidas. Essa facilidade é implementada\n",
    "pelo tipo Variable do PyTorch, que adiciona ao tensor a facilidade de cálculo automático do gradiente pela construção dinâmica do grafo computacional."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<img src='../figures/GrafoComputacional.png', width=600pt></img>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Variable possui 3 campos: o dado em si (data), o gradiente (grad) e um apontador (creator) para construir o grafo da backpropagation. Uma expressão utilizada para o cálculo do gradiente exige que todas suas expressões sejam calculadas com Variables, caso contrário não é possível construir o grafo computacional."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<img src='../figures/variables.png'></a>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2017-10-04T16:00:39.757858",
     "start_time": "2017-10-04T16:00:38.706322"
    },
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import torch\n",
    "from torch.autograd import Variable"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Variable é criada a partir de um tensor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2017-10-04T16:00:39.773444",
     "start_time": "2017-10-04T16:00:39.759378"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Variable containing:\n",
       " 0\n",
       " 2\n",
       " 4\n",
       " 6\n",
       "[torch.FloatTensor of size 4]"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_t = 2 * torch.arange(0,4)\n",
    "y = Variable(y_t); y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2017-10-04T16:00:39.780502",
     "start_time": "2017-10-04T16:00:39.775176"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Variable containing:\n",
       " 0\n",
       " 1\n",
       " 2\n",
       " 3\n",
       "[torch.FloatTensor of size 4]"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x = Variable(torch.arange(0,4)); x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2017-10-04T16:00:39.787541",
     "start_time": "2017-10-04T16:00:39.782447"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Variable containing:\n",
       " 1\n",
       "[torch.FloatTensor of size 1]"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "w = Variable(torch.ones(1),requires_grad=True); w"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Variable possui as mesmas funcionalidades dos tensores"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Cálculo automático do gradiente da função perda J"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Seja a expressão: $$ J = ((x  w) - y)^2 $$\n",
    "\n",
    "Queremos calcular a derivada de $J$ em relação a $w$."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Montagem do grafo computacional"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2017-10-04T16:00:39.826695",
     "start_time": "2017-10-04T16:00:39.789312"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Variable containing:\n",
       " 14\n",
       "[torch.FloatTensor of size 1]"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# predict (forward)\n",
    "y_pred = x * w\n",
    "\n",
    "# cálculo da perda J: loss\n",
    "e = y_pred - y\n",
    "e2 = e.pow(2)\n",
    "J = (e2).sum()\n",
    "J"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Auto grad - processa o grafo computacional backwards"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2017-10-04T15:55:45.308858",
     "start_time": "2017-10-04T15:55:45.304654"
    }
   },
   "source": [
    "O `backward()` varre o grafo computacional a partir da variável a ele associada e calcula o gradiente para todas as `Variables` que possuem o atributo `requires_grad` como verdadeiro.\n",
    "O `backward()` destroi o grafo após sua execução. Isso é intrínsico ao PyTorch pelo fato dele ser uma rede dinâmica."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2017-10-04T16:00:39.833367",
     "start_time": "2017-10-04T16:00:39.828691"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Variable containing:\n",
      "-28\n",
      "[torch.FloatTensor of size 1]\n",
      "\n"
     ]
    }
   ],
   "source": [
    "J.backward()\n",
    "print(w.grad)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2017-10-04T16:00:39.840192",
     "start_time": "2017-10-04T16:00:39.835129"
    },
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "w.grad.data.zero_();"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Interpretação do Gradiente"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "O gradiente de uma variável final (J) com respeito à outra variável de entrada (w) pode ser interpretado como o quanto a variável final J vai aumentar se houver um pequeno aumento na variável de entrada (w).\n",
    "Por exemplo suponha que o gradiente seja 28. Isto significa se aumentarmos a variável w de 0.001, então J vai aumentar de 0.028."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2017-10-04T16:01:40.318675",
     "start_time": "2017-10-04T16:01:40.312640"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Variable containing:\n",
       " 13.9720\n",
       "[torch.FloatTensor of size 1]"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "eps = 0.001\n",
    "y_pred = x * (w+eps)\n",
    "J = (y_pred - y).pow(2).sum()\n",
    "J"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Back propagation"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Uma forma equivalente explícita de calcular o gradiente é fazendo o processamento do backpropagation no grafo computacional, de forma explícita.\n",
    "Apenas como ilustração."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2017-10-04T16:00:39.870514",
     "start_time": "2017-10-04T16:00:39.859615"
    },
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1.0\n",
      "[ 1.  1.  1.  1.]\n",
      "[ 0. -2. -4. -6.]\n",
      "-28.0\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "\n",
    "dJ = 1.\n",
    "de2 = dJ * np.ones((4,))\n",
    "de = de2 * 2 * e.data.numpy()\n",
    "dy_pred = de\n",
    "dw = (dy_pred * x.data.numpy()).sum()\n",
    "print(dJ)\n",
    "print(de2)\n",
    "print(de)\n",
    "print(dw)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "# Exercícios"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2017-10-06T22:02:17.474843Z",
     "start_time": "2017-10-06T22:02:17.468865Z"
    }
   },
   "source": [
    "1. Atualize um passo de atualização do valor de w, pelo \n",
    "gradiente descendente. Utilize um fator de aprendizado (*learning rate*) de 0.1 \n",
    "e atualize o w e recalcule a função de perda novamente:\n",
    "\n",
    "    - w = w - lr * w.grad.data\n",
    "    - execute a célula 1.3.1 e verifique o quanto que a perda J diminuiu"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.0"
  },
  "toc": {
   "nav_menu": {
    "height": "117px",
    "width": "252px"
   },
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": false,
   "toc_cell": false,
   "toc_position": {},
   "toc_section_display": "block",
   "toc_window_display": false
  },
  "varInspector": {
   "cols": {
    "lenName": 16,
    "lenType": 16,
    "lenVar": 40
   },
   "kernels_config": {
    "python": {
     "delete_cmd_postfix": "",
     "delete_cmd_prefix": "del ",
     "library": "var_list.py",
     "varRefreshCmd": "print(var_dic_list())"
    },
    "r": {
     "delete_cmd_postfix": ") ",
     "delete_cmd_prefix": "rm(",
     "library": "var_list.r",
     "varRefreshCmd": "cat(var_dic_list()) "
    }
   },
   "types_to_exclude": [
    "module",
    "function",
    "builtin_function_or_method",
    "instance",
    "_Feature"
   ],
   "window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
