{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "toc": "true"
   },
   "source": [
    "# Table of Contents\n",
    " <p><div class=\"lev1 toc-item\"><a href=\"#Classificação-de-Textos\" data-toc-modified-id=\"Classificação-de-Textos-1\"><span class=\"toc-item-num\">1&nbsp;&nbsp;</span>Classificação de Textos</a></div><div class=\"lev2 toc-item\"><a href=\"#Preâmbulo\" data-toc-modified-id=\"Preâmbulo-11\"><span class=\"toc-item-num\">1.1&nbsp;&nbsp;</span>Preâmbulo</a></div><div class=\"lev2 toc-item\"><a href=\"#Preparando-o-dataset\" data-toc-modified-id=\"Preparando-o-dataset-12\"><span class=\"toc-item-num\">1.2&nbsp;&nbsp;</span>Preparando o dataset</a></div><div class=\"lev3 toc-item\"><a href=\"#Buscando-o-texto-dos-livros-e-definindo-os-rótulos\" data-toc-modified-id=\"Buscando-o-texto-dos-livros-e-definindo-os-rótulos-121\"><span class=\"toc-item-num\">1.2.1&nbsp;&nbsp;</span>Buscando o texto dos livros e definindo os rótulos</a></div><div class=\"lev3 toc-item\"><a href=\"#Representando-as-palavras-através-de-índices-inteiros\" data-toc-modified-id=\"Representando-as-palavras-através-de-índices-inteiros-122\"><span class=\"toc-item-num\">1.2.2&nbsp;&nbsp;</span>Representando as palavras através de índices inteiros</a></div><div class=\"lev3 toc-item\"><a href=\"#Palavras-características-de-cada-livro\" data-toc-modified-id=\"Palavras-características-de-cada-livro-123\"><span class=\"toc-item-num\">1.2.3&nbsp;&nbsp;</span>Palavras características de cada livro</a></div><div class=\"lev2 toc-item\"><a href=\"#Dividindo-o-dataset-entre-treinamento-e-validação\" data-toc-modified-id=\"Dividindo-o-dataset-entre-treinamento-e-validação-13\"><span class=\"toc-item-num\">1.3&nbsp;&nbsp;</span>Dividindo o dataset entre treinamento e validação</a></div><div class=\"lev3 toc-item\"><a href=\"#Divisão-simples\" data-toc-modified-id=\"Divisão-simples-131\"><span class=\"toc-item-num\">1.3.1&nbsp;&nbsp;</span>Divisão simples</a></div><div class=\"lev3 toc-item\"><a href=\"#Divisão-para-uso-com-geradores-e-aumento-de-dados\" data-toc-modified-id=\"Divisão-para-uso-com-geradores-e-aumento-de-dados-132\"><span class=\"toc-item-num\">1.3.2&nbsp;&nbsp;</span>Divisão para uso com geradores e aumento de dados</a></div><div class=\"lev3 toc-item\"><a href=\"#Criando--geradores-para-treino-e-validação\" data-toc-modified-id=\"Criando--geradores-para-treino-e-validação-133\"><span class=\"toc-item-num\">1.3.3&nbsp;&nbsp;</span>Criando  geradores para treino e validação</a></div>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Classificação de Textos"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Preâmbulo"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n"
     ]
    }
   ],
   "source": [
    "%matplotlib inline\n",
    "import matplotlib.pyplot as plot\n",
    "from IPython import display\n",
    "from __future__ import print_function\n",
    "\n",
    "import os\n",
    "import sys\n",
    "import glob\n",
    "import numpy as np\n",
    "import numpy.random as nr\n",
    "\n",
    "from keras.preprocessing.text import Tokenizer\n",
    "from keras.preprocessing.sequence import pad_sequences\n",
    "from keras.utils import to_categorical\n",
    "from keras.layers import Dense, Input, Flatten, Dropout\n",
    "from keras.layers import Conv1D, MaxPooling1D, Embedding\n",
    "from keras.models import Model\n",
    "from keras.optimizers import (SGD, \n",
    "                              RMSprop, \n",
    "                              Adam, \n",
    "                              Adadelta, \n",
    "                              Adagrad)\n",
    "\n",
    "sys.path.append('../src')\n",
    "from my_keras_utilities import (get_available_gpus, \n",
    "                                load_model_and_history, \n",
    "                                save_model_and_history, \n",
    "                                TrainingPlotter)\n",
    "\n",
    "os.makedirs('../../models',exist_ok=True)\n",
    "np.set_printoptions(precision=3, linewidth=120)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Backend:        tensorflow\n",
      "Data format:    channels_first\n",
      "Available GPUS: []\n"
     ]
    }
   ],
   "source": [
    "import keras.backend as K\n",
    "\n",
    "# K.set_image_data_format('channels_first')\n",
    "K.set_floatx('float32')\n",
    "\n",
    "print('Backend:        {}'.format(K.backend()))\n",
    "print('Data format:    {}'.format(K.image_data_format()))\n",
    "print('Available GPUS:', get_available_gpus())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Preparando o dataset"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Buscando o texto dos livros e definindo os rótulos"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " 427711  Jorge_Amado        Capitães_de_Areia\n",
      "1030735  Jorge_Amado        Dona_flor_seus_dois_maridos\n",
      " 828417  Jorge_Amado        Gabriela\n",
      "1001226  Jorge_Amado        Tereza_Batista_Cansada_de_Guerra\n",
      " 372459  Machado_de_Assis   Dom_Casmurro\n",
      " 411043  Machado_de_Assis   Esaú_e_Jacó\n",
      " 337533  Machado_de_Assis   Helena\n",
      " 336677  Machado_de_Assis   Iaiá_Garcia\n",
      " 280683  Machado_de_Assis   Memorial_de_Aires\n",
      " 352965  Machado_de_Assis   Memórias_Póstumas_de_Brás_Cubas\n",
      " 443778  Machado_de_Assis   Quincas_Borba\n",
      " 294049  Érico_Veríssimo  Clarissa\n",
      " 890215  Érico_Veríssimo  Incidente_em_Antares\n",
      " 699390  Érico_Veríssimo  O_Tempo_e_o_Vento_-_O_Arquipélago\n",
      " 749265  Érico_Veríssimo  O_Tempo_e_o_Vento_-_O_Continente\n",
      "\n",
      "3 Labels:\n",
      "     0: Machado_de_Assis\n",
      "     1: Érico_Veríssimo\n",
      "     2: Jorge_Amado\n"
     ]
    }
   ],
   "source": [
    "data_dir = '../../datasets/'\n",
    "\n",
    "autores = [\n",
    "#     'Fernando_Sabino', \n",
    "    'Jorge_Amado',\n",
    "    'Machado_de_Assis',\n",
    "    'Érico_Veríssimo',\n",
    "]\n",
    "\n",
    "book_text = []\n",
    "book_author = []\n",
    "book_title = []\n",
    "for aut in autores:\n",
    "    for fn in glob.glob(data_dir + 'livros/' + aut + '*.txt'):\n",
    "        author, book = os.path.basename(fn).split('__')\n",
    "        txt = open(fn).read().replace('\\x97', '')\n",
    "        book_text.append(txt)\n",
    "        book_author.append(author)\n",
    "        book_title.append(book[:-4])\n",
    "        print('{:7d}  {:18s} {}'.format(len(txt), author, book[:-4]))\n",
    "\n",
    "author_list = list(set(book_author))\n",
    "n_labels = len(author_list)\n",
    "n_books = len(book_title)\n",
    "book_label = [author_list.index(a) for a in book_author]\n",
    "print('\\n{} Labels:'.format(n_labels))\n",
    "for i, autor in enumerate(author_list):\n",
    "    print('    {:2d}: {}'.format(i, autor))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Representando as palavras através de índices inteiros"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 61707 unique tokens.\n"
     ]
    }
   ],
   "source": [
    "MAX_NB_WORDS = 20000\n",
    "\n",
    "tokenizer = Tokenizer(num_words=MAX_NB_WORDS)\n",
    "tokenizer.fit_on_texts(book_text)\n",
    "sequences = tokenizer.texts_to_sequences(book_text)\n",
    "\n",
    "w2i = tokenizer.word_index\n",
    "i2w = dict([(v, k) for k, v in w2i.items()])\n",
    "\n",
    "i2w_vec = np.array([i2w[i+1] for i in range(len(i2w))])\n",
    "\n",
    "print('Found %s unique tokens.' % len(w2i))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": false,
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Jorge Amado: Capitães de Areia -- 76132 palavras\n",
      "aquele saber aquela vocação para contar histórias fizera o respeitado entre os capitães areia se bem fosse franzino magro e triste o cabelo moreno caindo sobre os olhos apertados de míope apelidaram no de professor porque num livro furtado ele aprendera a fazer mágicas com lenços níqueis e também porque contando aquelas histórias que lia e muitas que inventava fazia a grande e misteriosa mágica de os transportar para mundos diversos fazia com que o s olhos vivos dos capitães da areia como só brilham as estrelas da noite da bahia pedro bala nada resolvia sem o consultar e várias\n",
      "\n",
      "Jorge Amado: Dona flor seus dois maridos -- 166625 palavras\n",
      "muita competência com os olhos acesos completou vejam como vai se rebolando a cara séria mas as ancas olhem aquilo soltas até parece que algu ém está nelas um felizardo esse doutor do braço do marido felizardo sorri mansa dona flor ah essa mania de vadinho ir pela rua a lhe tocar os peitos e os quadris em torno dela como se fosse a brisa da manhã da manhã lavada de domingo onde passeia dona flor feliz de sua vida satisfeita de seus dois amores e aqui se dá por finda a história de dona flor e de seus dois\n",
      "\n",
      "Jorge Amado: Gabriela -- 134498 palavras\n",
      "pânico se perdesse aquela partida não tinha outra coisa a fazer senão arrumar sua bagagem ir se embora de ilhéus a não ser que quisesse viver desmoralizado objeto de dichotes e pilhérias voltar cabisbaixo fracassado para a sombra dos irmãos quase ara de aparecer nos bares nos cabarés onde a maledicência crescia o próprio tonico bastos muito discreto evitando o quanto podia tocar naquele assunto diante dos partidários de mundinho já não se continha gozava o mau humor dos adversários certa vez houve um bate boca entre ele e o capitão teve joão fulgêncio que intervir para evitar um rompimento\n",
      "\n",
      "Jorge Amado: Tereza Batista Cansada de Guerra -- 164906 palavras\n",
      "amor a defender nem amor nem amizade nem prazer na cama andando de um lado para outro doutor oto espinheira cada vez mais nervoso e agoniado — sabe o que ela disse a f ilha da puta quando eu lhe o abandono da vacinação que eu você imagine a voz firme e quase alegre de tereza — pois eu vou — o quê você o quê — vou sair basta que o rapaz me — está a não vou deixar — não lhe perguntei se você vai deixar ou não não está precisando de gente da matriz ás beatas viram\n",
      "\n",
      "Machado de Assis: Dom Casmurro -- 64547 palavras\n",
      "rodela de limão nas fontes fez o que disse e atou o lenço outra vez na testa em seguida acompanhou me ao quintal para se despedir de mim mas ainda aí nos por alguns minutos sentados sobre a borda do poço ventava o céu estava coberto capitu falou novamente da nossa separação como de um fato certo e definitivo por mais que eu receoso disso mesmo buscasse agora razões para animá la capitu quando não falava riscava no chão com um pedaço de taquara e desde que se metera a desenhar era uma das suas diversões tudo lhe servia de\n",
      "\n",
      "Machado de Assis: Esaú e Jacó -- 70153 palavras\n",
      "cláudia deu lhe a um pouco de vinagre lhe os pulsos flora sorriu este sábado perguntou o decreto sim este sábado mas não digas por ora a ninguém são segredos de gabinete é coisa certa enfim alguém nos fez justiça provavelmente o imperador amanhã irás comigo a algumas encomendas faze uma lista do que precisas flora precisava não ir e só pensava nisso uma vez que o decreto estava prestes a ser assinado não havia já a nomeação restava lhe a ela ficar mas como todos os sonhos são próprios ao sono de uma criança não era fácil mas não\n",
      "\n",
      "Machado de Assis: Helena -- 54778 palavras\n",
      "um temporal violento a força do vento e da trovoada mas a chuva continuou a cair com a mesma violência era impossível ir ao rio comprido estácio estimou aquele obstáculo era melhor adorar de longe a imagem da moça do que ir colher algum desgosto junto a ela de pé encostado a uma das vidraças da sala de visitas via cair as grossas toalhas de água ao lado estava sentada helena não alegre mas taciturna e melancólica é tão bom ver chover quando estamos exclamou ele tenho lá na estante um poeta latino que diz alguma coisa neste sentido que\n",
      "\n",
      "Machado de Assis: Iaiá Garcia -- 55342 palavras\n",
      "sorriu da travessura mas repreendeu a deixe ver disse jorge quando ela acabou para que retorquiu iaiá com indiferença e levando o papel à chama queimou o jorge interrogou a com os olhos ela encarou o sem se perturbar depois a gramática lentamente continuemos a lição disse ela i vá onde estávamos aqui era aqui estela assistiu à lição toda com a paciência da curiosidade não olhava nunca para o mestre dividia a atenção entre a discípula e o livro a lição foi longa mais longa do que era necessário porque o próprio mestre não acompanhava o texto e a\n",
      "\n",
      "Machado de Assis: Memorial de Aires -- 50033 palavras\n",
      "chegamos à praia grande quando eu lhe disse que preferia este nome popular ao nome oficial e político de niterói de mim repliquei que a razão do dissentimento vinha de ser eu velho e ele moço criei me com a praia grande quando o senhor nasceu a de niterói pegara não havia nisto alguma ele porém sorriu como achando fina a resposta e disse me não há velhice para um espírito como o seu acha perguntei já meus padrinhos mo haviam dito e eu reconheço que diziam a verdade agradeci de cabeça e estendendo lhe a mão vou ao palácio\n",
      "\n",
      "Machado de Assis: Memórias Póstumas de Brás Cubas -- 58580 palavras\n",
      "meio de demonstrar que dos dois o delicioso o verdadeiro delicioso foi o de e tu madama flor dos se um poeta te pintou como a católica apareceu um incrédulo que te apagou muito essa qualidade e se não a lírio também não ficaste pântano eu deixo me estar entre o poeta e o sábio viva pois a história a história que dá para tudo e tornando à idéia fixa direi que é ela a que faz os varões fortes e os doidos a idéia vaga ou furta cor é a que faz os fórmula era fixa a minha idéia\n",
      "\n",
      "Machado de Assis: Quincas Borba -- 74965 palavras\n",
      "outra sala ouvindo rumor de alguma coisa que se quebrava correu à de visitas e viu a ama sozinha de pé não é nada disse lhe esta pareceu me que ouvi foi aquele boneco que caiu os cacos o chinês exclamou a criada de feito era um mandarim de porcelana pobre diabo que estava muito quieto em cima de uma estante sofia achou se com ele entre os dedos sem saber como nem desde quando ao cuidar na sua voluntária humilhação teve um impulso parece que raiva de si mesma e deu com o boneco em terra pobre mandarim não\n",
      "\n",
      "Érico Veríssimo: Clarissa -- 47827 palavras\n",
      "se volta impaciente credo que clarissa tem os olhos fitos no prato onde se as fatias morenas de pão de no bojudo o açúcar quando olha o clarissa lembra se do barata mel no pote de vidro azulado mais café já disse gosta de deixar o leite bem tostado como a pele da mulata belmira clarissa você inda vai ficar mais gorda que a siá rola do português do armazém você ora dobre a língua sua belmira derrama mais café na xícara de clarissa e ri mostrando os dentes claros mal saiu dos e já pensa que é gente clarissa\n",
      "\n",
      "Érico Veríssimo: Incidente em Antares -- 144785 palavras\n",
      "esquina dá de repente com erotildes ambos bruscamente como se um se tivesse assustado do outro – ué – disse ela – tu por aqui – ando um amigo e tu – fui visitar uma amiga algumas das moscas que e zumbem ao redor do corpo de erotildes passam para o de pudim de cachaça e vice versa depois desse rápido de moscas os dois companheiros se com um “ a mulher dá alguns passos volta a cabeça e grita – não te esqueças do que o dr cícero pediu pudim ao meio dia todos no coreto o cachaceiro volta\n",
      "\n",
      "Érico Veríssimo: O Tempo e o Vento - O Arquipélago -- 115533 palavras\n",
      "enganado conosco pensa que isto é um comício de crianças e não de homens e quer assustar nos com a escuridão — e num tom gaiato exclamou — que siga o fandango no escuro mesmo minha gente risadas e aplausos alguém bradou do meio da turba — a escuridão é um símbolo do borgismo — apoiado muito bem viva o doutor assis brasil abaixo o chimango rodrigo ergueu o braço para o céu procurou a lua mas não a encontrou tinha já um em que chamaria à lua de deus” — a luz das estrelas — gritou — essa nenhum\n",
      "\n",
      "Érico Veríssimo: O Tempo e o Vento - O Continente -- 129346 palavras\n",
      "não era seu marido e de que ela não passava duma de não a abandonou nunca durante toda a lua de mel principalmente quando ela se via frente a frente com o pai mas isso não a tornou menos feliz porque naqueles meses que se seguiram ao casamento bibiana viveu como que no ar erguida na crista duma onda cálida de felicidade que a um pouco dando às pessoas e coisas que a cercavam um aspecto de sonho cuidar da casa fazer comida para rodrigo lavar lhe a roupa branca usar as coisas de seu próprio enxoval tomar conta dos\n",
      "\n"
     ]
    }
   ],
   "source": [
    "for i, seq in enumerate(sequences):\n",
    "    k = nr.randint(len(seq) - 100)\n",
    "    print('{}: {} -- {} palavras'.format(book_author[i], book_title[i], len(seq)).replace('_', ' '))\n",
    "    print(' '.join([i2w[x] for x in seq[k:k+100]]), end='\\n\\n')\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Palavras características de cada livro"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[['trapiche' 'bedel' 'ester' 'barandão' 'almiro' 'dora' '–' 'pirulito']\n",
      " ['marilda' 'dinorá' 'teodoro' 'pelancchi' 'gisa' 'mirandão' 'rozilda' 'vadinho']\n",
      " ['tuísca' 'tonico' 'ribeirinho' 'malvina' 'amâncio' 'fulgêncio' 'gabriela' 'nacib']\n",
      " ['vavá' 'almério' 'januário' '—' 'dóris' 'brígida' 'justiniano' 'tereza']\n",
      " ['manduca' 'protonotário' 'bentinho' 'sancha' 'pádua' 'justina' 'escobar' 'capitu']\n",
      " ['coupé' 'gêmeos' 'excia' 'nóbrega' 'custódio' 'natividade' 'flora' 'cláudia']\n",
      " ['ângela' 'eugênia' 'tomásia' 'melchior' 'helena' 'camargo' 'estácio' 'úrsula']\n",
      " ['procópio' 'valéria' 'jorge' 'garcia' 'madrasta' 'enteada' 'iaiá' 'estela']\n",
      " ['carmo' 'libertos' 'prainha' 'noronha' 'cesária' 'aguiar' 'fidélia' 'tristão']\n",
      " ['damasceno' 'eusébia' 'cubas' 'borba' 'sabina' 'cotrim' 'marcela' 'virgília']\n",
      " ['camacho' 'teófilo' 'tonica' 'borba' 'sofia' 'fernanda' 'benedita' 'rubião']\n",
      " ['gamaliel' 'dudu' 'eufrasina' 'tatá' 'belmira' 'tónico' 'zina' 'clarissa']\n",
      " ['campolargo' 'vacariano' 'vivaldino' 'getúlio' 'quitéria' '–' 'tibério' 'antares']\n",
      " ['dinda' 'alicinha' 'toríbio' 'chiru' 'stein' 'camerino' '—' 'rodrigo']\n",
      " ['maneco' 'amaral' 'lara' 'vosmecê' 'bibiana' '—' 'alonzo' 'rodrigo']]\n"
     ]
    }
   ],
   "source": [
    "tfidf = tokenizer.sequences_to_matrix(sequences, mode='tfidf')\n",
    "ww = np.argsort(tfidf, axis=1)[:, -8:]\n",
    "print(i2w_vec[ww-1])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Dividindo o dataset entre treinamento e validação"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "nr.seed(20170607)\n",
    "\n",
    "batch_size  = 32\n",
    "seq_size    = 500\n",
    "valid_split = 0.2"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Divisão simples"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(2550, 500) (2550,)\n"
     ]
    }
   ],
   "source": [
    "all_data = [[] for i in range(n_labels)]\n",
    "\n",
    "for sequence, label in zip(sequences, book_label):\n",
    "    n_seqs = len(sequence) // seq_size\n",
    "    for i in range(n_seqs):\n",
    "        beg = i * seq_size\n",
    "        all_data[label].append(sequence[beg:beg+seq_size])\n",
    "\n",
    "N = 10 * (min([len(x) for x in all_data]) // 10)\n",
    "all_data = np.array([seq[:N] for seq in all_data], np.int32).reshape(-1, 500)\n",
    "all_labels = np.array([[i] * N for i in range(n_labels)], np.int32).reshape(-1)\n",
    "print(all_data.shape, all_labels.shape)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(2040, 500) (2040,) (510, 500) (510,)\n"
     ]
    }
   ],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "Xtra, Xval, ytra, yval = train_test_split(all_data, all_labels, test_size=valid_split)\n",
    "print(Xtra.shape, ytra.shape, Xval.shape, yval.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "fn = data_dir + 'livros_sequences.npz'\n",
    "np.savez_compressed(fn, Xtra=Xtra, Xval=Xval, ytra=ytra, yval=yval)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Divisão para uso com geradores e aumento de dados"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training sequences:\n",
      "-------------------\n",
      " 1. Jorge_Amado      (2) --  44497 palavras do início do livro Capitães_de_Areia\n",
      " 2. Jorge_Amado      (2) --  92458 palavras do início do livro Dona_flor_seus_dois_maridos\n",
      " 3. Jorge_Amado      (2) --  86994 palavras do início do livro Gabriela\n",
      " 4. Jorge_Amado      (2) --  49425 palavras do início do livro Tereza_Batista_Cansada_de_Guerra\n",
      " 5. Machado_de_Assis (0) --  10722 palavras do início do livro Dom_Casmurro\n",
      " 6. Machado_de_Assis (0) --  48702 palavras do início do livro Esaú_e_Jacó\n",
      " 7. Machado_de_Assis (0) --  20724 palavras do início do livro Helena\n",
      " 8. Machado_de_Assis (0) --  28329 palavras do início do livro Iaiá_Garcia\n",
      " 9. Machado_de_Assis (0) --  33510 palavras do início do livro Memorial_de_Aires\n",
      "10. Machado_de_Assis (0) --  26884 palavras do início do livro Memórias_Póstumas_de_Brás_Cubas\n",
      "11. Machado_de_Assis (0) --  32579 palavras do início do livro Quincas_Borba\n",
      "12. Érico_Veríssimo (1) --  21065 palavras do início do livro Clarissa\n",
      "13. Érico_Veríssimo (1) --  63677 palavras do início do livro Incidente_em_Antares\n",
      "14. Érico_Veríssimo (1) --   7014 palavras do início do livro O_Tempo_e_o_Vento_-_O_Arquipélago\n",
      "15. Érico_Veríssimo (1) --  94828 palavras do início do livro O_Tempo_e_o_Vento_-_O_Continente\n",
      "16. Jorge_Amado      (2) --  16409 palavras do final do livro  Capitães_de_Areia\n",
      "17. Jorge_Amado      (2) --  40842 palavras do final do livro  Dona_flor_seus_dois_maridos\n",
      "18. Jorge_Amado      (2) --  20605 palavras do final do livro  Gabriela\n",
      "19. Jorge_Amado      (2) --  82500 palavras do final do livro  Tereza_Batista_Cansada_de_Guerra\n",
      "20. Machado_de_Assis (0) --  40916 palavras do final do livro  Dom_Casmurro\n",
      "21. Machado_de_Assis (0) --   7421 palavras do final do livro  Esaú_e_Jacó\n",
      "22. Machado_de_Assis (0) --  23099 palavras do final do livro  Helena\n",
      "23. Machado_de_Assis (0) --  15945 palavras do final do livro  Iaiá_Garcia\n",
      "24. Machado_de_Assis (0) --   6517 palavras do final do livro  Memorial_de_Aires\n",
      "25. Machado_de_Assis (0) --  19980 palavras do final do livro  Memórias_Póstumas_de_Brás_Cubas\n",
      "26. Machado_de_Assis (0) --  27393 palavras do final do livro  Quincas_Borba\n",
      "27. Érico_Veríssimo (1) --  17197 palavras do final do livro  Clarissa\n",
      "28. Érico_Veríssimo (1) --  52151 palavras do final do livro  Incidente_em_Antares\n",
      "29. Érico_Veríssimo (1) --  85413 palavras do final do livro  O_Tempo_e_o_Vento_-_O_Arquipélago\n",
      "30. Érico_Veríssimo (1) --   8649 palavras do final do livro  O_Tempo_e_o_Vento_-_O_Continente\n",
      "\n",
      "Validation sequences:\n",
      "---------------------\n",
      " 1. Jorge_Amado      (2) --  15226 palavras do meio do livro Capitães_de_Areia\n",
      " 2. Jorge_Amado      (2) --  33325 palavras do meio do livro Dona_flor_seus_dois_maridos\n",
      " 3. Jorge_Amado      (2) --  26899 palavras do meio do livro Gabriela\n",
      " 4. Jorge_Amado      (2) --  32981 palavras do meio do livro Tereza_Batista_Cansada_de_Guerra\n",
      " 5. Machado_de_Assis (0) --  12909 palavras do meio do livro Dom_Casmurro\n",
      " 6. Machado_de_Assis (0) --  14030 palavras do meio do livro Esaú_e_Jacó\n",
      " 7. Machado_de_Assis (0) --  10955 palavras do meio do livro Helena\n",
      " 8. Machado_de_Assis (0) --  11068 palavras do meio do livro Iaiá_Garcia\n",
      " 9. Machado_de_Assis (0) --  10006 palavras do meio do livro Memorial_de_Aires\n",
      "10. Machado_de_Assis (0) --  11716 palavras do meio do livro Memórias_Póstumas_de_Brás_Cubas\n",
      "11. Machado_de_Assis (0) --  14993 palavras do meio do livro Quincas_Borba\n",
      "12. Érico_Veríssimo (1) --   9565 palavras do meio do livro Clarissa\n",
      "13. Érico_Veríssimo (1) --  28957 palavras do meio do livro Incidente_em_Antares\n",
      "14. Érico_Veríssimo (1) --  23106 palavras do meio do livro O_Tempo_e_o_Vento_-_O_Arquipélago\n",
      "15. Érico_Veríssimo (1) --  25869 palavras do meio do livro O_Tempo_e_o_Vento_-_O_Continente\n",
      "\n",
      "Total number of training words:   1126445\n",
      "Total number of validation words: 281605\n"
     ]
    }
   ],
   "source": [
    "valid_length = [int(0.2 * len(x)) for x in sequences]\n",
    "valid_start = [nr.randint(2000, len(x) - 2000 - n) for x, n in zip(sequences, valid_length)]\n",
    "\n",
    "valid_sequences = [seq[x0:x0+n] for seq, x0, n in zip(sequences, valid_start, valid_length)]\n",
    "\n",
    "train_sequences = [seq[:x0] for seq, x0 in zip(sequences, valid_start)] + \\\n",
    "                  [seq[x0+n:] for seq, x0, n in zip(sequences, valid_start, valid_length)]\n",
    "\n",
    "valid_labels = book_label\n",
    "train_labels = book_label + book_label\n",
    "\n",
    "n_train_words = sum([len(x) for x in train_sequences])\n",
    "n_valid_words = sum([len(x) for x in valid_sequences])\n",
    "\n",
    "print('Training sequences:')\n",
    "print('-------------------')\n",
    "for i, (seq, lab) in enumerate(zip(train_sequences, train_labels)):\n",
    "    if i < n_books:\n",
    "        print('{:2d}. {:16s} ({}) -- {:6d} palavras do início do livro {}'.format(i+1, book_author[i%n_books], lab,\n",
    "                                                                                  len(seq), book_title[i%n_books]))\n",
    "    else:\n",
    "        print('{:2d}. {:16s} ({}) -- {:6d} palavras do final do livro  {}'.format(i+1, book_author[i%n_books], lab,\n",
    "                                                                                  len(seq), book_title[i%n_books]))\n",
    "print()\n",
    "print('Validation sequences:')\n",
    "print('---------------------')\n",
    "for i, (seq, lab) in enumerate(zip(valid_sequences, valid_labels)):\n",
    "    print('{:2d}. {:16s} ({}) -- {:6d} palavras do meio do livro {}'.format(i+1, book_author[i%n_books], lab,\n",
    "                                                                            len(seq), book_title[i%n_books]))\n",
    "print()\n",
    "print('Total number of training words:  ', n_train_words)\n",
    "print('Total number of validation words:', n_valid_words)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "import pickle\n",
    "fn = data_dir + 'livros_sequences_augm.pkl'\n",
    "pickle.dump([train_sequences, valid_sequences, train_labels, valid_labels], open(fn, 'wb'))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Criando  geradores para treino e validação"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "class MyDataGenerator:\n",
    "    def __init__(self, batch_size, seq_size, sequences, labels):\n",
    "        self.batch_size = batch_size\n",
    "        self.length = seq_size\n",
    "        self.sequences = sequences\n",
    "        self.labels = labels\n",
    "        sizes = np.array([len(seq) for seq in sequences])\n",
    "        self.p = 1.0 * sizes / sizes.sum()        # probabilidade de escolha para cada sequencia\n",
    "        self.n = np.arange(len(sequences))        # indices de cada sequencia (para o choice abaixo)\n",
    "        \n",
    "    def __call__(self):\n",
    "        while True:\n",
    "            batch = np.empty((self.batch_size, self.length), np.int32)\n",
    "            label = np.empty((self.batch_size, n_labels), np.int32)\n",
    "            for i in range(self.batch_size):\n",
    "                k = nr.choice(self.n, p=self.p)\n",
    "                p = nr.randint(0, len(self.sequences[k]) - self.length)\n",
    "                batch[i] = self.sequences[k][p:p+self.length]\n",
    "                label[i] = to_categorical(self.labels[k], num_classes=n_labels)\n",
    "            yield batch, label\n",
    "\n",
    "            \n",
    "train_gen = MyDataGenerator(batch_size, seq_size, train_sequences, train_labels)()\n",
    "valid_gen = MyDataGenerator(batch_size, seq_size, valid_sequences, valid_labels)()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.0"
  },
  "latex_envs": {
   "LaTeX_envs_menu_present": true,
   "autocomplete": true,
   "bibliofile": "biblio.bib",
   "cite_by": "apalike",
   "current_citInitial": 1,
   "eqLabelWithNumbers": true,
   "eqNumInitial": 1,
   "hotkeys": {
    "equation": "Ctrl-E",
    "itemize": "Ctrl-I"
   },
   "labels_anchors": false,
   "latex_user_defs": false,
   "report_style_numbering": false,
   "user_envs_cfg": false
  },
  "toc": {
   "colors": {
    "hover_highlight": "#DAA520",
    "navigate_num": "#000000",
    "navigate_text": "#333333",
    "running_highlight": "#FF0000",
    "selected_highlight": "#FFD700",
    "sidebar_border": "#EEEEEE",
    "wrapper_background": "#FFFFFF"
   },
   "moveMenuLeft": true,
   "nav_menu": {
    "height": "264px",
    "width": "252px"
   },
   "navigate_menu": true,
   "number_sections": true,
   "sideBar": true,
   "threshold": 4,
   "toc_cell": true,
   "toc_section_display": "block",
   "toc_window_display": false,
   "widenNotebook": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
