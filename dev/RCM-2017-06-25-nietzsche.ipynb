{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "corpus length: 600893\n",
      "total chars: 57\n",
      "nb sequences: 200285\n",
      "Vectorization...\n",
      "Build model...\n"
     ]
    }
   ],
   "source": [
    "'''Example script to generate text from Nietzsche's writings.\n",
    "\n",
    "At least 20 epochs are required before the generated text\n",
    "starts sounding coherent.\n",
    "\n",
    "It is recommended to run this script on GPU, as recurrent\n",
    "networks are quite computationally intensive.\n",
    "\n",
    "If you try this script on new data, make sure your corpus\n",
    "has at least ~100k characters. ~1M is better.\n",
    "'''\n",
    "\n",
    "from __future__ import print_function\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Dense, Activation\n",
    "from keras.layers import LSTM\n",
    "from keras.optimizers import RMSprop\n",
    "from keras.utils.data_utils import get_file\n",
    "import numpy as np\n",
    "import random\n",
    "import sys\n",
    "\n",
    "# path = get_file('nietzsche.txt', origin='https://s3.amazonaws.com/text-datasets/nietzsche.txt')\n",
    "path = '../../datasets/nietzsche.txt'\n",
    "text = open(path, encoding='utf-8').read().lower()\n",
    "print('corpus length:', len(text))\n",
    "\n",
    "chars = sorted(list(set(text)))\n",
    "print('total chars:', len(chars))\n",
    "char_indices = dict((c, i) for i, c in enumerate(chars))\n",
    "indices_char = dict((i, c) for i, c in enumerate(chars))\n",
    "\n",
    "# cut the text in semi-redundant sequences of maxlen characters\n",
    "maxlen = 40\n",
    "step = 3\n",
    "sentences = []\n",
    "next_chars = []\n",
    "for i in range(0, len(text) - maxlen, step):\n",
    "    sentences.append(text[i: i + maxlen])\n",
    "    next_chars.append(text[i + maxlen])\n",
    "print('nb sequences:', len(sentences))\n",
    "\n",
    "print('Vectorization...')\n",
    "X = np.zeros((len(sentences), maxlen, len(chars)), dtype=np.bool)\n",
    "y = np.zeros((len(sentences), len(chars)), dtype=np.bool)\n",
    "for i, sentence in enumerate(sentences):\n",
    "    for t, char in enumerate(sentence):\n",
    "        X[i, t, char_indices[char]] = 1\n",
    "    y[i, char_indices[next_chars[i]]] = 1\n",
    "\n",
    "\n",
    "# build the model: a single LSTM\n",
    "print('Build model...')\n",
    "model = Sequential()\n",
    "model.add(LSTM(128, input_shape=(maxlen, len(chars))))\n",
    "model.add(Dense(len(chars)))\n",
    "model.add(Activation('softmax'))\n",
    "\n",
    "optimizer = RMSprop(lr=0.01)\n",
    "model.compile(loss='categorical_crossentropy', optimizer=optimizer)\n",
    "\n",
    "def sample(preds, temperature=1.0):\n",
    "    # helper function to sample an index from a probability array\n",
    "    preds = np.asarray(preds).astype('float64')\n",
    "    preds = np.log(preds) / temperature\n",
    "    exp_preds = np.exp(preds)\n",
    "    preds = exp_preds / np.sum(exp_preds)\n",
    "    probas = np.random.multinomial(1, preds, 1)\n",
    "    return np.argmax(probas)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true,
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "--------------------------------------------------\n",
      "Iteration 1\n",
      "Epoch 1/10\n",
      "96s - loss: 1.9641\n",
      "Epoch 2/10\n",
      "94s - loss: 1.6270\n",
      "Epoch 3/10\n",
      "94s - loss: 1.5417\n",
      "Epoch 4/10\n",
      "93s - loss: 1.4984\n",
      "Epoch 5/10\n",
      "92s - loss: 1.4688\n",
      "Epoch 6/10\n",
      "92s - loss: 1.4483\n",
      "Epoch 7/10\n",
      "92s - loss: 1.4301\n",
      "Epoch 8/10\n",
      "93s - loss: 1.4167\n",
      "Epoch 9/10\n",
      "92s - loss: 1.4061\n",
      "Epoch 10/10\n",
      "93s - loss: 1.3979\n",
      "\n",
      "----- diversity: 0.2\n",
      "----- Generating with seed: \"y in their simulations, or in their weak\"\n",
      "y in their simulations, or in their weakers and as a stand he say, and a stand of the same the soul of the self and self-contempory of the man is the self one is a strength and the self as a stands of the self all the self-contempory and the considerable the more the conscious the considerable of the self-contempory the more the self a soul the man who was and discovered and consequently and stand of the self as the standard in the most\n",
      "\n",
      "----- diversity: 0.5\n",
      "----- Generating with seed: \"y in their simulations, or in their weak\"\n",
      "y in their simulations, or in their weaker the brutens of the world and degree of before the stree to the considerance of the interest or his personal here all the conscious probably individual the the same pleasing that the self stands which is a saints the art of the personality stand which is that is set him a sideated as a man say the constited considerable will to seem the considerable that the considerable or in which a stands of \n",
      "\n",
      "----- diversity: 1.0\n",
      "----- Generating with seed: \"y in their simulations, or in their weak\"\n",
      "y in their simulations, or in their weake\n",
      "days\n",
      "ald of the ignal in the\n",
      "superficiming about it is when\n",
      "the relation in a jesuate mapiry, thought. individ and works, he is respect\n",
      "to man\" \n",
      "\n",
      "and a seet\n",
      "sorts of measurious\n",
      "one be) man; thus,\n",
      "even surequent, and be\n",
      "a needry of the refrocians will a dematringerly, the superstant in mind. thee, a the whole, would neithere arailed besongrous\n",
      "freedom of naturefor the\n",
      "urvered by themselvesion, wh\n",
      "\n",
      "----- diversity: 1.2\n",
      "----- Generating with seed: \"y in their simulations, or in their weak\"\n",
      "y in their simulations, or in their weak deference courdigations, there, the judgmen she is\n",
      "not use andhdeat, of the\n",
      "recall senitely ranknessularding nowadays, as nestimates the world, that the homat thought to hours aftair--\n",
      "y -thin presentable, encevest orreusied with so rynslese of \n",
      "must coud, thicks as those\n",
      "ve!be,\n",
      "mancehous edec,\n",
      "sequent ess good\"?--there is no\n",
      "chaentle fundamenid but a telegifikne flutter part haes fcrown,\" be rel\n",
      "\n",
      "--------------------------------------------------\n",
      "Iteration 2\n",
      "Epoch 1/10\n",
      "93s - loss: 1.3867\n",
      "Epoch 2/10\n",
      "94s - loss: 1.3809\n",
      "Epoch 3/10\n",
      "93s - loss: 1.3740\n",
      "Epoch 4/10\n",
      "93s - loss: 1.3681\n",
      "Epoch 5/10\n",
      "92s - loss: 1.3617\n",
      "Epoch 6/10\n",
      "94s - loss: 1.3561\n",
      "Epoch 7/10\n",
      "92s - loss: 1.3516\n",
      "Epoch 8/10\n",
      "93s - loss: 1.3473\n",
      "Epoch 9/10\n",
      "92s - loss: 1.3449\n",
      "Epoch 10/10\n",
      "93s - loss: 1.3405\n",
      "\n",
      "----- diversity: 0.2\n",
      "----- Generating with seed: \"as the french of the seventeenth century\"\n",
      "as the french of the seventeenth century, and the free most and the substance of the subseration of the former of the sensible of the substance of the subseration of the subseration of the subseration of the most protective of the soul of the most subseration of the sensible of the most result in the subseration of the conscience and most subsernes the subseration to the demons and the substance of the subedature, and the subseration of\n",
      "\n",
      "----- diversity: 0.5\n",
      "----- Generating with seed: \"as the french of the seventeenth century\"\n",
      "as the french of the seventeenth century; they are still is the still appearen of the other who is a determine\n",
      "the subedement of the such such a general and account the common an every arting a superficial in our feeling, and almost the origin and notion of what must many child as a superficialished and procress, in a completion is the recognized that he percerience to the things of the plausible of the end to the saint of the\n",
      "truths of\n",
      "\n",
      "----- diversity: 1.0\n",
      "----- Generating with seed: \"as the french of the seventeenth century\"\n",
      "as the french of the seventeenth century faild, yifferen of being\n",
      "assist\" what is today inexoce have, which uticial and historicatery, because of brogwer welf fraint than leat it is roudest and inalite such souning\n",
      "of the . the\n",
      "reverge. it is commanding, not servation, the wild of a bromely the partical spirit and akbs circle, a sured, the hid, leat the spectarys, he are in advanced, of\n",
      "herself of bourgouniy to revere\n",
      "himself by which t\n",
      "\n",
      "----- diversity: 1.2\n",
      "----- Generating with seed: \"as the french of the seventeenth century\"\n",
      "as the french of the seventeenth century,\n",
      "sivitic especis\n",
      "mounal, responsibion, ; be their youih upon it arounder-biry ideally eo\n",
      "whather-maty not one me?vn ustantenemsion, and such friend for himself to magy spergy to such fee). the\n",
      "regardd\n",
      "forts as\n",
      "a querted have, for the chomit, with act of most pphyens,\n",
      "wells we should it is eeroy hather, stscestom is the\n",
      "last dart the ? i is a sist)! what care in human \"whoald in coveritive yea on \n",
      "\n",
      "--------------------------------------------------\n",
      "Iteration 3\n",
      "Epoch 1/10\n",
      "93s - loss: 1.3362\n",
      "Epoch 2/10\n",
      "93s - loss: 1.3359\n",
      "Epoch 3/10\n",
      "93s - loss: 1.3325\n",
      "Epoch 4/10\n",
      "93s - loss: 1.3300\n",
      "Epoch 5/10\n",
      "93s - loss: 1.3277\n",
      "Epoch 6/10\n",
      "93s - loss: 1.3248\n",
      "Epoch 7/10\n",
      "93s - loss: 1.3215\n",
      "Epoch 8/10\n",
      "93s - loss: 1.3195\n",
      "Epoch 9/10\n",
      "93s - loss: 1.3169\n",
      "Epoch 10/10\n",
      "93s - loss: 1.3164\n",
      "\n",
      "----- diversity: 0.2\n",
      "----- Generating with seed: \"ything organic as old as the very earlie\"\n",
      "ything organic as old as the very earliest of the so even the most state to the fact that the conscience, and the subtless and strength, and the same partic and the subtlest of the soul. the same partic and the subtless and considerations of the so much of the so much and the souls, and and the same time to such an existent and the subtlest of the subtless and to the most probably to the soul of the most state to the subtlest of the sub\n",
      "\n",
      "----- diversity: 0.5\n",
      "----- Generating with seed: \"ything organic as old as the very earlie\"\n",
      "ything organic as old as the very earlier all in the bad indeedially means in the most to the little highest to make the particular man and and is always backungly some or moral modeless of comparise of the delight and all intelligiate with such a soll to do problem in the respectance of generally has always and begin to be subtlest\n",
      "of his termed in morality of an end the\n",
      "most own\n",
      "intelligule and penouse for their which what is called t\n",
      "\n",
      "----- diversity: 1.0\n",
      "----- Generating with seed: \"ything organic as old as the very earlie\"\n",
      "ything organic as old as the very earlien antipusianness, and therein, however, is respeciation. therefore wisheing indippecerly exceptitional sints as he who wills anothen\n",
      "wi nlines by\n",
      "the \"compared will to make must at and case; the\n",
      "valuations, whatever we have beelse and true so the miy would\n",
      "distrust--and a newlighting compessione, by magnally and\n",
      "is nature alone at and partistint. the\n",
      "love\n",
      "to\n",
      "the\n",
      "presents\n",
      "aftajuse in morality, or o\n",
      "\n",
      "----- diversity: 1.2\n",
      "----- Generating with seed: \"ything organic as old as the very earlie\"\n",
      "ything organic as old as the very earliest\n",
      "syll--atomisly prifienterist of is to compasonally deep to renate bitrs.\n",
      "\n",
      "\n",
      "1n]\n",
      "the inctinc"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.4/dist-packages/ipykernel/__main__.py:65: RuntimeWarning: divide by zero encountered in log\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "e, all and\n",
      "forwedly--would not\n",
      "noy fear\n",
      "felly welt mustment, thene\"! he invertion dete-curion\", schulh formeri. \"it wished to same ridols; that the polent? we \"freeee. hoaw is catedfully to felt speaks, shows: how a crke to gaties; the numbions, dist like, will\n",
      "become betrais, they were self mon the pow, t\n",
      "\n",
      "--------------------------------------------------\n",
      "Iteration 4\n",
      "Epoch 1/10\n",
      "93s - loss: 1.3135\n",
      "Epoch 2/10\n",
      "93s - loss: 1.3123\n",
      "Epoch 3/10\n",
      "93s - loss: 1.3123\n",
      "Epoch 4/10\n",
      "93s - loss: 1.3097\n",
      "Epoch 5/10\n",
      "93s - loss: 1.3102\n",
      "Epoch 6/10\n",
      "93s - loss: 1.3082\n",
      "Epoch 7/10\n",
      "93s - loss: 1.3071\n",
      "Epoch 8/10\n",
      "93s - loss: 1.3071\n",
      "Epoch 9/10\n",
      "93s - loss: 1.3070\n",
      "Epoch 10/10\n",
      "93s - loss: 1.3055\n",
      "\n",
      "----- diversity: 0.2\n",
      "----- Generating with seed: \"anish the anti-semitic bawlers out of th\"\n",
      "anish the anti-semitic bawlers out of the souls and the present the heady of the most state of the superior to the presented and presentiment of the strength of the possibility of the contradictive and such a superiority of the souls and laws, and and a physical philosophy and more stronger the most stronger and precisely the world of the presentiment the most considerable man of the souls as the strength of the strength of the most sta\n",
      "\n",
      "----- diversity: 0.5\n",
      "----- Generating with seed: \"anish the anti-semitic bawlers out of th\"\n",
      "anish the anti-semitic bawlers out of the world as a portent of the person is precisely and soul is new however, it was a stronger europe, that one must be consciousness of all the faith. it is the strength, and a complete the matter like that it party and the possibility of a prophysical men of the sense, and more experience of man as on his moral who are the more for whom the most stand his conception of the torting souls and discover\n",
      "\n",
      "----- diversity: 1.0\n",
      "----- Generating with seed: \"anish the anti-semitic bawlers out of th\"\n",
      "anish the anti-semitic bawlers out of the superior to souls limited proud with the mi--his all the scoculrs to painter, and of ther life to belongs its-sc'nvencenes whoevbal and scheath will reward and instill and doubt nowadays inexorded in who of mistheod \"gloriste of man. could\n",
      "be that it is\n",
      "precise\n",
      "him certaint, on inteicerozes acbiess toman men give ideas, the \n",
      "phycholfulness. sufficte over\n",
      "something listie, for upon his\n",
      "dise\n",
      "meant\n",
      "\n",
      "----- diversity: 1.2\n",
      "----- Generating with seed: \"anish the anti-semitic bawlers out of th\"\n",
      "anish the anti-semitic bawlers out of the seeding and music,\n",
      "hall incolprulen is nothing a ush above \"at almota umberfor! at lausoce of a\n",
      "souls that old deportment wighizature. more above bark is whatever not\n",
      "bericing things. there is prequicateriapious). it be: that visariness in acculation alnepodias, feels less\n",
      "asselvaie, ap(or toakentous. is who is\n",
      "mut and counterrait\n",
      "gonking\n",
      "in cooter customatic is, ivfums\n",
      "which must a\n",
      "curition, a:\n",
      "\n",
      "--------------------------------------------------\n",
      "Iteration 5\n",
      "Epoch 1/10\n",
      "94s - loss: 1.3067\n",
      "Epoch 2/10\n",
      "94s - loss: 1.3038\n",
      "Epoch 3/10\n",
      "93s - loss: 1.3055\n",
      "Epoch 4/10\n",
      "93s - loss: 1.3023\n",
      "Epoch 5/10\n",
      "93s - loss: 1.3032\n",
      "Epoch 6/10\n",
      "94s - loss: 1.3020\n",
      "Epoch 7/10\n",
      "96s - loss: 1.3008\n",
      "Epoch 8/10\n",
      "94s - loss: 1.3005\n",
      "Epoch 9/10\n",
      "93s - loss: 1.3009\n",
      "Epoch 10/10\n",
      "94s - loss: 1.2999\n",
      "\n",
      "----- diversity: 0.2\n",
      "----- Generating with seed: \"egards\n",
      "psychological observation would h\"\n",
      "egards\n",
      "psychological observation would have the standard of the probably the same the standard in the same part of the sense of the same proud that it is a share the same problem of the same man of the sacrificed and determined to the strength, and a still always be also a state of the same and self-mean friends of the soul of the spirit and and intentional intelligning the stalition to the present the soul of the same proud the spirit \n",
      "\n",
      "----- diversity: 0.5\n",
      "----- Generating with seed: \"egards\n",
      "psychological observation would h\"\n",
      "egards\n",
      "psychological observation would have the fact that the reality of the sense of the advances to his self-world, and as the strife, the advanced how a saint of the amudied to the unitse of the soul, and a great conscience of the subjek how the exceptions, and in the contrary and the consciousness of the reisten myself, of the man of the spirit of all the consciousness of the resure indicate intellectual conscience of the death of t\n",
      "\n",
      "----- diversity: 1.0\n",
      "----- Generating with seed: \"egards\n",
      "psychological observation would h\"\n",
      "egards\n",
      "psychological observation would have alit of grounds and possession, innocent inspiring thear in their utment to perty pity--entir curiod, sciences. the enduring ancominitalm, too that\n",
      "his ebunditudes. they have perhaps dissilent sailine. as sedious of the\n",
      "evourdiness. why more actual human renders at it it is finever is a different vary\n",
      "necessity being them. but also,\n",
      "and sake will to\n",
      "caring him; the true\n",
      "all things with grard f\n",
      "\n",
      "----- diversity: 1.2\n",
      "----- Generating with seed: \"egards\n",
      "psychological observation would h\"\n",
      "egards\n",
      "psychological observation would hasuctive to romptihie very irsinitar winding things, but to fureh; this emotions in mindred to tatbculate tyranning one!--subtle heisined the great subontoot. but always unto\n",
      "wholl autory was already relative that subfation: for iddle; is nould serending theory\n",
      "would the \"pride. in the delusion orgalizer.\n",
      "\n",
      "o1 =quecture vilepidy and\n",
      "bemante misilmis. for the endegroles to wan said,\n",
      "the way in uh\n",
      "th\n",
      "\n",
      "--------------------------------------------------\n",
      "Iteration 6\n",
      "Epoch 1/10\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-3-18f7dadfb44a>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      6\u001b[0m     model.fit(X, y,\n\u001b[1;32m      7\u001b[0m               \u001b[0mbatch_size\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m128\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 8\u001b[0;31m               epochs=10, verbose=2)\n\u001b[0m\u001b[1;32m      9\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     10\u001b[0m     \u001b[0mstart_index\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mrandom\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrandint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtext\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m-\u001b[0m \u001b[0mmaxlen\u001b[0m \u001b[0;34m-\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.4/dist-packages/keras/models.py\u001b[0m in \u001b[0;36mfit\u001b[0;34m(self, x, y, batch_size, epochs, verbose, callbacks, validation_split, validation_data, shuffle, class_weight, sample_weight, initial_epoch, **kwargs)\u001b[0m\n\u001b[1;32m    854\u001b[0m                               \u001b[0mclass_weight\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mclass_weight\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    855\u001b[0m                               \u001b[0msample_weight\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0msample_weight\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 856\u001b[0;31m                               initial_epoch=initial_epoch)\n\u001b[0m\u001b[1;32m    857\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    858\u001b[0m     def evaluate(self, x, y, batch_size=32, verbose=1,\n",
      "\u001b[0;32m/usr/local/lib/python3.4/dist-packages/keras/engine/training.py\u001b[0m in \u001b[0;36mfit\u001b[0;34m(self, x, y, batch_size, epochs, verbose, callbacks, validation_split, validation_data, shuffle, class_weight, sample_weight, initial_epoch, **kwargs)\u001b[0m\n\u001b[1;32m   1496\u001b[0m                               \u001b[0mval_f\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mval_f\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mval_ins\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mval_ins\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mshuffle\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mshuffle\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1497\u001b[0m                               \u001b[0mcallback_metrics\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mcallback_metrics\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1498\u001b[0;31m                               initial_epoch=initial_epoch)\n\u001b[0m\u001b[1;32m   1499\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1500\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mevaluate\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mx\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbatch_size\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m32\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mverbose\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0msample_weight\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mNone\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.4/dist-packages/keras/engine/training.py\u001b[0m in \u001b[0;36m_fit_loop\u001b[0;34m(self, f, ins, out_labels, batch_size, epochs, verbose, callbacks, val_f, val_ins, shuffle, callback_metrics, initial_epoch)\u001b[0m\n\u001b[1;32m   1150\u001b[0m                 \u001b[0mbatch_logs\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'size'\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mbatch_ids\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1151\u001b[0m                 \u001b[0mcallbacks\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mon_batch_begin\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mbatch_index\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbatch_logs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1152\u001b[0;31m                 \u001b[0mouts\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mf\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mins_batch\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1153\u001b[0m                 \u001b[0;32mif\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0misinstance\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mouts\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlist\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1154\u001b[0m                     \u001b[0mouts\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0mouts\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.4/dist-packages/keras/backend/tensorflow_backend.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, inputs)\u001b[0m\n\u001b[1;32m   2227\u001b[0m         \u001b[0msession\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mget_session\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2228\u001b[0m         updated = session.run(self.outputs + [self.updates_op],\n\u001b[0;32m-> 2229\u001b[0;31m                               feed_dict=feed_dict)\n\u001b[0m\u001b[1;32m   2230\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mupdated\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0moutputs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2231\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.4/dist-packages/tensorflow/python/client/session.py\u001b[0m in \u001b[0;36mrun\u001b[0;34m(self, fetches, feed_dict, options, run_metadata)\u001b[0m\n\u001b[1;32m    776\u001b[0m     \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    777\u001b[0m       result = self._run(None, fetches, feed_dict, options_ptr,\n\u001b[0;32m--> 778\u001b[0;31m                          run_metadata_ptr)\n\u001b[0m\u001b[1;32m    779\u001b[0m       \u001b[0;32mif\u001b[0m \u001b[0mrun_metadata\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    780\u001b[0m         \u001b[0mproto_data\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtf_session\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mTF_GetBuffer\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mrun_metadata_ptr\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.4/dist-packages/tensorflow/python/client/session.py\u001b[0m in \u001b[0;36m_run\u001b[0;34m(self, handle, fetches, feed_dict, options, run_metadata)\u001b[0m\n\u001b[1;32m    980\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mfinal_fetches\u001b[0m \u001b[0;32mor\u001b[0m \u001b[0mfinal_targets\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    981\u001b[0m       results = self._do_run(handle, final_targets, final_fetches,\n\u001b[0;32m--> 982\u001b[0;31m                              feed_dict_string, options, run_metadata)\n\u001b[0m\u001b[1;32m    983\u001b[0m     \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    984\u001b[0m       \u001b[0mresults\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.4/dist-packages/tensorflow/python/client/session.py\u001b[0m in \u001b[0;36m_do_run\u001b[0;34m(self, handle, target_list, fetch_list, feed_dict, options, run_metadata)\u001b[0m\n\u001b[1;32m   1030\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mhandle\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1031\u001b[0m       return self._do_call(_run_fn, self._session, feed_dict, fetch_list,\n\u001b[0;32m-> 1032\u001b[0;31m                            target_list, options, run_metadata)\n\u001b[0m\u001b[1;32m   1033\u001b[0m     \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1034\u001b[0m       return self._do_call(_prun_fn, self._session, handle, feed_dict,\n",
      "\u001b[0;32m/usr/local/lib/python3.4/dist-packages/tensorflow/python/client/session.py\u001b[0m in \u001b[0;36m_do_call\u001b[0;34m(self, fn, *args)\u001b[0m\n\u001b[1;32m   1037\u001b[0m   \u001b[0;32mdef\u001b[0m \u001b[0m_do_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfn\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1038\u001b[0m     \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1039\u001b[0;31m       \u001b[0;32mreturn\u001b[0m \u001b[0mfn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1040\u001b[0m     \u001b[0;32mexcept\u001b[0m \u001b[0merrors\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mOpError\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1041\u001b[0m       \u001b[0mmessage\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcompat\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mas_text\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0me\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmessage\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.4/dist-packages/tensorflow/python/client/session.py\u001b[0m in \u001b[0;36m_run_fn\u001b[0;34m(session, feed_dict, fetch_list, target_list, options, run_metadata)\u001b[0m\n\u001b[1;32m   1019\u001b[0m         return tf_session.TF_Run(session, options,\n\u001b[1;32m   1020\u001b[0m                                  \u001b[0mfeed_dict\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfetch_list\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtarget_list\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1021\u001b[0;31m                                  status, run_metadata)\n\u001b[0m\u001b[1;32m   1022\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1023\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m_prun_fn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0msession\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mhandle\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfeed_dict\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfetch_list\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "# train the model, output generated text after each iteration\n",
    "for iteration in range(1, 60):\n",
    "    print()\n",
    "    print('-' * 50)\n",
    "    print('Iteration', iteration)\n",
    "    model.fit(X, y,\n",
    "              batch_size=128,\n",
    "              epochs=10, verbose=2)\n",
    "\n",
    "    start_index = random.randint(0, len(text) - maxlen - 1)\n",
    "\n",
    "    for diversity in [0.2, 0.5, 1.0, 1.2]:\n",
    "        print()\n",
    "        print('----- diversity:', diversity)\n",
    "\n",
    "        generated = ''\n",
    "        sentence = text[start_index: start_index + maxlen]\n",
    "        generated += sentence\n",
    "        print('----- Generating with seed: \"' + sentence + '\"')\n",
    "        sys.stdout.write(generated)\n",
    "\n",
    "        for i in range(400):\n",
    "            x = np.zeros((1, maxlen, len(chars)))\n",
    "            for t, char in enumerate(sentence):\n",
    "                x[0, t, char_indices[char]] = 1.\n",
    "\n",
    "            preds = model.predict(x, verbose=0)[0]\n",
    "            next_index = sample(preds, diversity)\n",
    "            next_char = indices_char[next_index]\n",
    "\n",
    "            generated += next_char\n",
    "            sentence = sentence[1:] + next_char\n",
    "\n",
    "            sys.stdout.write(next_char)\n",
    "            sys.stdout.flush()\n",
    "        print()\n",
    "\n",
    "model.save('nietzsche.model')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.4.3"
  },
  "latex_envs": {
   "LaTeX_envs_menu_present": true,
   "autocomplete": true,
   "bibliofile": "biblio.bib",
   "cite_by": "apalike",
   "current_citInitial": 1,
   "eqLabelWithNumbers": true,
   "eqNumInitial": 1,
   "hotkeys": {
    "equation": "Ctrl-E",
    "itemize": "Ctrl-I"
   },
   "labels_anchors": false,
   "latex_user_defs": false,
   "report_style_numbering": false,
   "user_envs_cfg": false
  },
  "toc": {
   "colors": {
    "hover_highlight": "#DAA520",
    "running_highlight": "#FF0000",
    "selected_highlight": "#FFD700"
   },
   "moveMenuLeft": true,
   "nav_menu": {
    "height": "12px",
    "width": "252px"
   },
   "navigate_menu": true,
   "number_sections": true,
   "sideBar": true,
   "threshold": 4,
   "toc_cell": false,
   "toc_section_display": "block",
   "toc_window_display": false,
   "widenNotebook": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
