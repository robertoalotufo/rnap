{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Explorando convolução no Keras usando o Theano\n",
    "\n",
    "O objetivo deste notebook é de explorar a convolução que é implementada pelo Theano através do Keras.\n",
    "\n",
    "A convolução é a operação essencial das redes convolucionais. É uma operação demorada e a sua implementação na GPU acelera bastante o seu processamento. A implementação é feita no Theano utilizando GPU. Se a GPU não for encontrada, a implementação roda na CPU.\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using Theano backend.\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import keras\n",
    "from keras.models import Sequential\n",
    "from keras.utils.np_utils import convert_kernel\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Uma rede com uma única camada convolucional\n",
    "\n",
    "O objetivo deste experimento é explorar numericamente a convolução implementada na rede\n",
    "convolucional do Keras/Theano. Para isso iremos criar uma rede convolucional com apenas\n",
    "uma camada de convolução. A sua predição será o resultado da rede, que neste caso será apenas uma convolução.\n",
    "\n",
    "Uma convolução pode ser visto como uma média móvel ponderada sobre a imagem. A equação matemática da convolução é dada por:\n",
    "\n",
    "$$ y = x \\ast w $$\n",
    "\n",
    "onde $x$ é a imagem de entrada, $y$ é o resultado da convolução e $w$ é chamado de peso,\n",
    "núcleo, entre outros nomes. No caso das redes convolucionais, o array $w$ contém os\n",
    "parâmetros da rede convolucional que precisam ser treinados.\n",
    "\n",
    "A figura a seguir ilustra uma convolução da imagem verde de entrada, utilizando o núcleo da convolução (kernel) em amarelo, deslizando sobre a imagem verde. O resultado da convolução é a imagem rosa, de tamanho ligeiramente menor, devido ao processamento na borda da imagem.\n",
    "\n",
    "![](http://mourafiq.com/images/posts/convolution_schematic.gif)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# 4-D convolution\n",
    "def conv4d(x,w,border_mode='same'):\n",
    "    assert x.ndim == 4\n",
    "    assert w.ndim == 4\n",
    "    nb_filters,wd,wh,ww = w.shape\n",
    "    samples,channels,xh,xw = x.shape\n",
    "    model = Sequential([\n",
    "    Convolution2D(nb_filters, wh, ww, \n",
    "                  input_shape=(channels, xh, xw),\n",
    "                  weights=[W], \n",
    "                  border_mode=border_mode, bias=False, dim_ordering='th')\n",
    "    ])\n",
    "    y = model.predict(x,batch_size=1)\n",
    "    return y\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "x: (1, 1, 5, 7)\n",
      "[[[[ 0.  0.  0.  0.  0.  0.  0.]\n",
      "   [ 0.  0.  0.  0.  0.  0.  0.]\n",
      "   [ 0.  0.  0.  1.  0.  0.  0.]\n",
      "   [ 0.  0.  0.  0.  0.  0.  0.]\n",
      "   [ 0.  0.  0.  0.  0.  0.  0.]]]]\n",
      "y: (1, 1, 5, 7)\n",
      "[[[[ 0.  0.  0.  0.  0.  0.  0.]\n",
      "   [ 0.  0.  0.  0.  0.  0.  0.]\n",
      "   [ 0.  0.  1.  2.  3.  0.  0.]\n",
      "   [ 0.  0.  4.  5.  6.  0.  0.]\n",
      "   [ 0.  0.  0.  0.  0.  0.  0.]]]]\n",
      "kernel\n",
      "[array([[[[ 1.,  2.,  3.],\n",
      "         [ 4.,  5.,  6.]]]], dtype=float32)]\n"
     ]
    }
   ],
   "source": [
    "np.set_printoptions(suppress=True, precision=3)\n",
    "\n",
    "x = np.zeros((5,7))\n",
    "x[2,3]=1\n",
    "x = x.reshape(1,1,5,7)\n",
    "W = np.array([[1.,2.,3.],\n",
    "              [4.,5.,6.]]).reshape(1,1,2,3)\n",
    "\n",
    "y = conv4d(x,W)\n",
    "\n",
    "print 'x:', x.shape\n",
    "print x\n",
    "print 'y:', y.shape\n",
    "print y\n",
    "print 'kernel'\n",
    "w = model.layers[0].get_weights()\n",
    "print w\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "## Reproduzindo o exemplo da figura animada acima"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "x: (1, 1, 5, 5)\n",
      "[[[[1 1 1 0 0]\n",
      "   [0 1 1 1 0]\n",
      "   [0 0 1 1 1]\n",
      "   [0 0 1 1 0]\n",
      "   [0 1 1 0 0]]]]\n",
      "y: (1, 1, 3, 3)\n",
      "[[[[ 4.  3.  4.]\n",
      "   [ 2.  4.  3.]\n",
      "   [ 2.  3.  4.]]]]\n"
     ]
    }
   ],
   "source": [
    "W = np.array([[1,0,1],\n",
    "              [0,1,0],\n",
    "              [1,0,1]]).reshape(1,1,3,3)\n",
    "x = np.array([[1,1,1,0,0],\n",
    "              [0,1,1,1,0],\n",
    "              [0,0,1,1,1],\n",
    "              [0,0,1,1,0],\n",
    "              [0,1,1,0,0]]).reshape(1,1,5,5)\n",
    "y = conv4d(x,W,'valid')\n",
    "print 'x:', x.shape\n",
    "print x\n",
    "print 'y:', y.shape\n",
    "print y\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 4 amostras de imagem cinza 3x5, 1 filtro com kernel de 3x3 \n",
    "\n",
    "Neste caso, \n",
    "- shape da entrada, x:(4,1,3,5)\n",
    "- shape dos pesos W:(1, 1, 3,3). \n",
    "- shape de saída será y:(4,1,3,5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {
    "collapsed": false,
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "x: (4, 1, 3, 5)\n",
      "[[[[0 0 0 0 0]\n",
      "   [0 0 0 0 0]\n",
      "   [0 0 0 0 0]]]\n",
      "\n",
      "\n",
      " [[[0 0 0 0 0]\n",
      "   [0 0 1 0 0]\n",
      "   [0 0 0 0 0]]]\n",
      "\n",
      "\n",
      " [[[0 0 0 0 0]\n",
      "   [0 0 2 0 0]\n",
      "   [0 0 0 0 0]]]\n",
      "\n",
      "\n",
      " [[[0 0 0 0 0]\n",
      "   [0 0 3 0 0]\n",
      "   [0 0 0 0 0]]]]\n",
      "y: (4, 1, 3, 5)\n",
      "[[[[ 0.  0.  0.  0.  0.]\n",
      "   [ 0.  0.  0.  0.  0.]\n",
      "   [ 0.  0.  0.  0.  0.]]]\n",
      "\n",
      "\n",
      " [[[ 0.  1.  0.  1.  0.]\n",
      "   [ 0.  0.  1.  0.  0.]\n",
      "   [ 0.  1.  0.  1.  0.]]]\n",
      "\n",
      "\n",
      " [[[ 0.  2.  0.  2.  0.]\n",
      "   [ 0.  0.  2.  0.  0.]\n",
      "   [ 0.  2.  0.  2.  0.]]]\n",
      "\n",
      "\n",
      " [[[ 0.  3.  0.  3.  0.]\n",
      "   [ 0.  0.  3.  0.  0.]\n",
      "   [ 0.  3.  0.  3.  0.]]]]\n"
     ]
    }
   ],
   "source": [
    "W = np.array([[1,0,1],\n",
    "              [0,1,0],\n",
    "              [1,0,1]]).reshape(1,1,3,3)\n",
    "# criando 4 amostras de imagens\n",
    "x = np.array([[0,0,0,0,0],\n",
    "              [0,0,1,0,0],\n",
    "              [0,0,0,0,0]]).reshape(1,1,3,5) * np.arange(4).reshape(4,1,1,1)\n",
    "y = conv4d(x,W,'same')\n",
    "print 'x:', x.shape\n",
    "print x\n",
    "print 'y:', y.shape\n",
    "print y\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2 filtros com kernel de 3x3, 1 amostra de imagem cinza 3x5\n",
    "\n",
    "Neste caso, \n",
    "- shape da entrada, x:(1,1,3,5)\n",
    "- shape dos pesos W:(2, 1, 3,3). \n",
    "- shape de saída será y:(1,2,3,5)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "x: (1, 1, 3, 5)\n",
      "[[[[0 0 0 0 0]\n",
      "   [0 0 1 0 0]\n",
      "   [0 0 0 0 0]]]]\n",
      "y: (1, 2, 3, 5)\n",
      "[[[[ 0.  1.  0.  1.  0.]\n",
      "   [ 0.  0.  1.  0.  0.]\n",
      "   [ 0.  1.  0.  1.  0.]]\n",
      "\n",
      "  [[ 0.  0.  1.  0.  0.]\n",
      "   [ 0.  1.  2.  1.  0.]\n",
      "   [ 0.  0.  1.  0.  0.]]]]\n"
     ]
    }
   ],
   "source": [
    "W = np.array([[[1,0,1],\n",
    "               [0,1,0],\n",
    "               [1,0,1]],\n",
    "              [[0,1,0],\n",
    "               [1,2,1],\n",
    "               [0,1,0]]]).reshape(2,1,3,3)\n",
    "x = np.array([[0,0,0,0,0],\n",
    "              [0,0,1,0,0],\n",
    "              [0,0,0,0,0]]).reshape(1,1,3,5)\n",
    "y = conv4d(x,W,'same')\n",
    "print 'x:', x.shape\n",
    "print x\n",
    "print 'y:', y.shape\n",
    "print y\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1 filtro com kernel de 3x3, 1 amostra de imagem 3x5 RGB (3 canais)\n",
    "Neste caso, \n",
    "- shape da entrada, x:(1,3,3,5)\n",
    "- shape dos pesos W:(1, 1, 3,3). \n",
    "- shape de saída será y:(1,2,3,5)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "ename": "Exception",
     "evalue": "Layer weight shape (1, 3, 3, 3) not compatible with provided weight shape (1, 1, 3, 3)",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mException\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-45-5908d2403b35>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m()\u001b[0m\n\u001b[0;32m      5\u001b[0m               \u001b[1;33m[\u001b[0m\u001b[1;36m0\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;36m0\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;36m1\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;36m0\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;36m0\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      6\u001b[0m               [0,0,0,0,0]]).reshape(1,1,3,5) * np.arange(1,4).reshape(1,3,1,1)\n\u001b[1;32m----> 7\u001b[1;33m \u001b[0my\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mconv4d\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mx\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0mW\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;34m'same'\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m      8\u001b[0m \u001b[1;32mprint\u001b[0m \u001b[1;34m'x:'\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mx\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mshape\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      9\u001b[0m \u001b[1;32mprint\u001b[0m \u001b[0mx\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m<ipython-input-32-2ab9d275b086>\u001b[0m in \u001b[0;36mconv4d\u001b[1;34m(x, w, border_mode)\u001b[0m\n\u001b[0;32m      9\u001b[0m                   \u001b[0minput_shape\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mxd\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mxh\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mxw\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     10\u001b[0m                   \u001b[0mweights\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mW\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 11\u001b[1;33m                   border_mode=border_mode, bias=False, dim_ordering='th')\n\u001b[0m\u001b[0;32m     12\u001b[0m     ])\n\u001b[0;32m     13\u001b[0m     \u001b[0my\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mmodel\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mpredict\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mx\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0mbatch_size\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;36m1\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m/opt/conda/lib/python2.7/site-packages/keras/models.pyc\u001b[0m in \u001b[0;36m__init__\u001b[1;34m(self, layers, name)\u001b[0m\n\u001b[0;32m    252\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    253\u001b[0m         \u001b[1;32mfor\u001b[0m \u001b[0mlayer\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mlayers\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 254\u001b[1;33m             \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0madd\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mlayer\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    255\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    256\u001b[0m     \u001b[1;32mdef\u001b[0m \u001b[0madd\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mlayer\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m/opt/conda/lib/python2.7/site-packages/keras/models.pyc\u001b[0m in \u001b[0;36madd\u001b[1;34m(self, layer)\u001b[0m\n\u001b[0;32m    273\u001b[0m                 \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    274\u001b[0m                     \u001b[0minput_dtype\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mNone\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 275\u001b[1;33m                 \u001b[0mlayer\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mcreate_input_layer\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mbatch_input_shape\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0minput_dtype\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    276\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    277\u001b[0m             \u001b[1;32mif\u001b[0m \u001b[0mlen\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mlayer\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0minbound_nodes\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;33m!=\u001b[0m \u001b[1;36m1\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m/opt/conda/lib/python2.7/site-packages/keras/engine/topology.pyc\u001b[0m in \u001b[0;36mcreate_input_layer\u001b[1;34m(self, batch_input_shape, input_dtype, name)\u001b[0m\n\u001b[0;32m    365\u001b[0m         \u001b[1;31m# and create the node connecting the current layer\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    366\u001b[0m         \u001b[1;31m# to the input layer we just created.\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 367\u001b[1;33m         \u001b[0mself\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mx\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    368\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    369\u001b[0m     \u001b[1;32mdef\u001b[0m \u001b[0massert_input_compatibility\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0minput\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m/opt/conda/lib/python2.7/site-packages/keras/engine/topology.pyc\u001b[0m in \u001b[0;36m__call__\u001b[1;34m(self, x, mask)\u001b[0m\n\u001b[0;32m    482\u001b[0m                                     '`layer.build(batch_input_shape)`')\n\u001b[0;32m    483\u001b[0m             \u001b[1;32mif\u001b[0m \u001b[0mlen\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0minput_shapes\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;33m==\u001b[0m \u001b[1;36m1\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 484\u001b[1;33m                 \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mbuild\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0minput_shapes\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;36m0\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    485\u001b[0m             \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    486\u001b[0m                 \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mbuild\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0minput_shapes\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m/opt/conda/lib/python2.7/site-packages/keras/layers/convolutional.pyc\u001b[0m in \u001b[0;36mbuild\u001b[1;34m(self, input_shape)\u001b[0m\n\u001b[0;32m    322\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    323\u001b[0m         \u001b[1;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0minitial_weights\u001b[0m \u001b[1;32mis\u001b[0m \u001b[1;32mnot\u001b[0m \u001b[0mNone\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 324\u001b[1;33m             \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mset_weights\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0minitial_weights\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    325\u001b[0m             \u001b[1;32mdel\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0minitial_weights\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    326\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m/opt/conda/lib/python2.7/site-packages/keras/engine/topology.pyc\u001b[0m in \u001b[0;36mset_weights\u001b[1;34m(self, weights)\u001b[0m\n\u001b[0;32m    884\u001b[0m                                 \u001b[0mstr\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mpv\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mshape\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;33m+\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    885\u001b[0m                                 \u001b[1;34m' not compatible with '\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 886\u001b[1;33m                                 'provided weight shape ' + str(w.shape))\n\u001b[0m\u001b[0;32m    887\u001b[0m             \u001b[0mweight_value_tuples\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mp\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mw\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    888\u001b[0m         \u001b[0mK\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mbatch_set_value\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mweight_value_tuples\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mException\u001b[0m: Layer weight shape (1, 3, 3, 3) not compatible with provided weight shape (1, 1, 3, 3)"
     ]
    }
   ],
   "source": [
    "W = np.array([[1,0,1],\n",
    "              [0,1,0],\n",
    "              [1,0,1]]).reshape(1,1,3,3)\n",
    "x = np.array([[0,0,0,0,0],\n",
    "              [0,0,1,0,0],\n",
    "              [0,0,0,0,0]]).reshape(1,1,3,5) * np.arange(1,4).reshape(1,3,1,1)\n",
    "y = conv4d(x,W,'same')\n",
    "print 'x:', x.shape\n",
    "print x\n",
    "print 'y:', y.shape\n",
    "print y\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Exercícios\n",
    "\n",
    "### Teórico\n",
    "\n",
    "1. Supondo uma imagem de entrada 100 x 100 e um kernel 3 x 3. Utilizando-se o border_mode como válido, a imagem de saída será de 99 x 99. Se fosse utilizar uma rede densa, com entrada de 100 x 100 e saída 99 x 99, quantos parâmetros seriam necessários para ser treinados? E no caso da rede convolucional? Qual é o fator de redução?\n",
    "\n",
    "### Práticos\n",
    "\n",
    "1. Trocar o parâmetro ``border_mode`` para ``same`` e veja a diferença.\n",
    "2. Rodar a convolução para uma imagem de cinza\n",
    "3. Rodar a convolução para uma imagem colorida RGB\n",
    "4. Rodar a convolução para gerar várias bandas de saída como nas redes convolucionais\n",
    "5. Comparar o tempo de execução desta convolução com outras implementações: openCV por exemplo"
   ]
  }
 ],
 "metadata": {
  "anaconda-cloud": {},
  "kernelspec": {
   "display_name": "Python [Root]",
   "language": "python",
   "name": "Python [Root]"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
