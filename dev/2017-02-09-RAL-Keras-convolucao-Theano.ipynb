{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Explorando convolução no Keras usando o Theano\n",
    "\n",
    "O objetivo deste notebook é de explorar a convolução que é implementada pelo Theano através do Keras.\n",
    "\n",
    "A convolução é a operação essencial das redes convolucionais. É uma operação demorada e a sua implementação na GPU acelera bastante o seu processamento. A implementação é feita no Theano utilizando GPU. Se a GPU não for encontrada, a implementação roda na CPU.\n",
    "\n",
    "[A guide to convolution arithmetic for deep\n",
    "learning by Vincent Dumoulin and Francesco Visin, 2016](https://arxiv.org/pdf/1603.07285.pdf)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using Theano backend.\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import keras\n",
    "from keras.models import Sequential\n",
    "from keras.utils.np_utils import convert_kernel\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Uma rede com uma única camada convolucional\n",
    "\n",
    "O objetivo deste experimento é explorar numericamente a convolução implementada na rede\n",
    "convolucional do Keras/Theano. Para isso iremos criar uma rede convolucional com apenas\n",
    "uma camada de convolução. A sua predição será o resultado da rede, que neste caso será apenas uma convolução.\n",
    "\n",
    "Uma convolução pode ser visto como uma média móvel ponderada sobre a imagem. A equação matemática da convolução é dada por:\n",
    "\n",
    "$$ \\boldsymbol{Y} = \\boldsymbol{X} \\ast \\boldsymbol{W} $$\n",
    "\n",
    "onde $x$ é a imagem de entrada, $y$ é o resultado da convolução e $w$ é chamado de peso,\n",
    "núcleo, máscara, entre outros nomes. A convolução é a implementação de filtro linear\n",
    "invariante à translação. Este filtro é totalmente especificado pelo núcleo (array $w$) que\n",
    "contém os parâmetros do filtro linear (da rede convolucional) que precisam ser treinados.\n",
    "\n",
    "A figura a seguir ilustra uma convolução da imagem verde de entrada, utilizando o núcleo da convolução (kernel) em amarelo, deslizando sobre a imagem verde. O resultado da convolução é a imagem rosa, de tamanho ligeiramente menor, devido ao processamento na borda da imagem.\n",
    "\n",
    "![](http://mourafiq.com/images/posts/convolution_schematic.gif)\n",
    "\n",
    "Esta próxima figura ilustra a convolução quando a imagem de saída (em verde) é igual às\n",
    "dimensões da imagem de entrada (em azul). Neste caso, a imagem de entrada é artificialmente\n",
    "aumentada com valores zeros. Este processo de aumentar a imagem de entrada com zeros é \n",
    "denominado *zero padding*.\n",
    "\n",
    "![](https://raw.githubusercontent.com/vdumoulin/conv_arithmetic/master/gif/same_padding_no_strides.gif)\n",
    "\n",
    "## Organização da imagem de entrada\n",
    "\n",
    "As convoluções do Theano foram projetadas principalmente para tratar imagens ou sons. Assim, a organização dos arrays da imagem de entrada, de saída e dos pesos são feitos de forma específica para atender às necessidades das redes convolucionais. Iremos ilustrar as convoluções utilizando imagem de entrada em nível de cinza e coloridas com 3 bandas, usando\n",
    "a convenção do *shape* de imagens do Theano. Diferentemente da organização utilizada nos classificadores usuais (não convolucionais), onde a organização da matriz $\\boldsymbol{X}$ de entrada é bidimensional, com $n$ amostras nas linhas e $k$ *features* nas colunas. O shape de $\\boldsymbol{X}$ é então\n",
    "\n",
    "$$ (n,k)$$.\n",
    " \n",
    "No caso de imagens, como elas têm\n",
    "natureza bidimensional, a relação de vizinhança entre os pixels é fundamental, principalmente\n",
    "para que os pesos dos núcleo abranjam uma região bidimensional da imagem. Assim, as *features* passam agora a terem duas dimensões: são $k$ pixels organizados em `(img_height, img_width)`. Desta forma o array passa a ter uma nova dimensão: ($n$, image_height, image_width). Numa \n",
    "imagem em nível de cinza temos apenas um valor para representar o pixel, que é sua intensidade, variando de escuro a claro. Quando a imagem é colorida, são necessários 3 valores\n",
    "para cada pixel. No Theano, este 3 valores são organizados em uma dimensão adicional, denominada canal (*channel*) ou banda. A imagem colorida é organizada no *shape*:`(bandas, img_height, img_width)`. Desta forma o *shape* da imagem de entrada deve ter 4 dimensões:\n",
    "\n",
    "$\\boldsymbol{X}: $` (samples, channels, img_height, img_width)`\n",
    "\n",
    "## Organização dos pesos (kernel) da convolução\n",
    "\n",
    "Os pesos do kernel da convolução para tratar imagens devem ser 2D, quando a imagem\n",
    "de entrada for em nível de cinza e devem ter 3 bandas 2D para imagens coloridas. Assim, a organização\n",
    "do *shape* do kernel é $(bands, I_{height}, I_{width})$. Entretanto, nas arquiteturas das redes\n",
    "convolucionais, é usual definir vários filtros (vários kernels), para que a rede tenha um\n",
    "maior número de parâmetros a serem ajustados. Assim, o shape dos pesos devem ter 4 dimensões:\n",
    "\n",
    "$\\boldsymbol{W}:$ `(nb_filters, channels, img_height, img_width)`\n",
    "\n",
    "Observe que a primeira dimensão (`nb_filters`) diz respeito ao número de filtros na saída,\n",
    "enquanto que as três demais dimensões `(channels, img_height, img_width)` à janela deslizante\n",
    "(*kernel*) da convolução.\n",
    "\n",
    "## Organização da imagem de saída (filtrada)\n",
    "\n",
    "A organização da imagem de saída é a mesma da imagem de entrada, até porque a camada convolucional pode ser colocada não apenas na entrada, mas como qualquer camada interna da\n",
    "rede. A principal diferença está na nomenclatura da segunda dimensão: enquanto que na\n",
    "imagem da camada de entrada a segunda dimensão é o *channel*, isto é o número de bandas \n",
    "da imagem colorida, na saída e demais camadas, a segunda dimensão passa a ser o número de\n",
    "filtros aplicados naquela camada. Assim, o *shape* da imagem de saída fica como:\n",
    "\n",
    "$\\boldsymbol{Y}: $` (samples, filtros, img_height, img_width)`\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Analisando as convoluções em uma rede convolucional típica\n",
    "\n",
    "Veja a rede a seguir com 4 camadas convolucionais:\n",
    "\n",
    "![](../figures/architecture.png)\n",
    "Fonte: [Figura apresentação do Sander Dieleman](http://benanne.github.io/images/architecture.png)\n",
    "\n",
    "A imagem de entrada é uma imagem colorida\n",
    "quadrada de 45 pixels de lado. Utiliza-se um kernel de 6x6 gerando 32 filtros, então os *shapes* são:\n",
    "* Camada 1:\n",
    "    - entrada: (amostras, 3, 45, 45)\n",
    "    - kernel:  (32, 3, 6, 6)\n",
    "    - saída: (amostras, 32, 40, 40) Obs: a imagem de saída fica menor\n",
    "* Camada 2:\n",
    "    - entrada: (amostras, 32, 40, 40) Obs: é a imagem de saída da camada anterior\n",
    "    - kernel: (64, 32, 5, 5)\n",
    "    - saída: (amostras, 64, 16, 16)\n",
    "* Camada 3:\n",
    "    - entrada: (amostras, 64, 16, 16)\n",
    "    - kernel: (128, 64, 3, 3)\n",
    "    - saída: (amostras, 128, 6, 6)\n",
    "* Camada 4:\n",
    "    - entrada: (amostras 128, 6, 6)\n",
    "    - kernel: (128, 128, 3, 3)\n",
    "    - saída: (amostras, 128, 4, 4)\n",
    "    \n",
    "## Cálculo do número de parâmetros no núcleos das convoluções\n",
    "\n",
    "O número de parâmetros de cada convolução é igual ao número de elementos do kernel,\n",
    "contabilizando todas as suas dimensões. Assim, um kernel de *shape* (10, 3, 5, 5) terá 750 elementos.\n",
    "\n",
    "Como exercício, calcule o número de elementos dos kernels de cada uma das 4 camadas da rede\n",
    "ilustrativa e o total de elementos."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Resposta:\n",
    "- Camada 1:\n",
    "- Camada 2:\n",
    "- Camada 3:\n",
    "- Camada 4:\n",
    "- Total:"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Definição da convolução usando Keras\n",
    "\n",
    "A implementação da convolução utiliza um modelo sequencial do Keras com `Convolution2D`.\n",
    "Obtemos o resultado da rede pela função `predict`:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# 4-D convolution\n",
    "def conv4d(x,w,border_mode='same'):\n",
    "    assert x.ndim == 4\n",
    "    assert w.ndim == 4\n",
    "    nb_filters,wd,wh,ww = w.shape\n",
    "    samples,channels,xh,xw = x.shape\n",
    "    model = Sequential([\n",
    "                Convolution2D(nb_filters, wh, ww, \n",
    "                              input_shape=(channels, xh, xw),\n",
    "                              weights=[W], \n",
    "                              border_mode=border_mode, bias=False, dim_ordering='th')\n",
    "    ])\n",
    "    y = model.predict(x,batch_size=1)\n",
    "    return y\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Primeiro caso, resposta ao impulso\n",
    "\n",
    "Quando a imagem de entrada é apenas um 1 rodeado de vários zeros, o resultado da convolução\n",
    "é o próprio kernel posicionado no local do 1. Esta é uma forma usual para se verificar se\n",
    "a convolução está funcionando. Assim, utilizaremos uma imagem cinza 3x5 com um \"1\" no centro.\n",
    "O kernel é de 2 linhas e 3 colunas. O resultado é uma imagem 3x5 com o kernel posicionado\n",
    "no local do 1 da imagem de entrada."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "np.set_printoptions(suppress=True, precision=3)\n",
    "\n",
    "x = np.array([[0,0,0,0,0,0,0],\n",
    "              [0,0,0,0,0,0,0],\n",
    "              [0,0,0,1,0,0,0],\n",
    "              [0,0,0,0,0,0,0],\n",
    "              [0,0,0,0,0,0,0]]).reshape(1,1,5,7)\n",
    "W = np.array([[1.,2.,3.],\n",
    "              [4.,5.,6.]]).reshape(1,1,2,3)\n",
    "\n",
    "y = conv4d(x,W)\n",
    "\n",
    "print 'x:', x.shape\n",
    "print x\n",
    "print 'y:', y.shape\n",
    "print y\n",
    "print 'kernel'\n",
    "w = model.layers[0].get_weights()\n",
    "print w\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "## Reproduzindo o exemplo da figura animada acima"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "W = np.array([[1,0,1],\n",
    "              [0,1,0],\n",
    "              [1,0,1]]).reshape(1,1,3,3)\n",
    "x = np.array([[1,1,1,0,0],\n",
    "              [0,1,1,1,0],\n",
    "              [0,0,1,1,1],\n",
    "              [0,0,1,1,0],\n",
    "              [0,1,1,0,0]]).reshape(1,1,5,5)\n",
    "y = conv4d(x,W,'valid')\n",
    "print 'x:', x.shape\n",
    "print x\n",
    "print 'y:', y.shape\n",
    "print y\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 4 amostras de imagem cinza 3x5, 1 filtro com kernel de 3x3 \n",
    "\n",
    "Neste caso, \n",
    "- shape da entrada, x:(4,1,3,5)\n",
    "- shape dos pesos W:(1, 1, 3,3). \n",
    "- shape de saída será y:(4,1,3,5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "W = np.array([[1,0,1],\n",
    "              [0,1,0],\n",
    "              [1,0,1]]).reshape(1,1,3,3)\n",
    "# criando 4 amostras de imagens\n",
    "x = np.array([[0,0,0,0,0],\n",
    "              [0,0,1,0,0],\n",
    "              [0,0,0,0,0]]).reshape(1,1,3,5) * np.arange(4).reshape(4,1,1,1)\n",
    "y = conv4d(x,W,'same')\n",
    "print 'x:', x.shape\n",
    "print x\n",
    "print 'y:', y.shape\n",
    "print y\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2 filtros com kernel de 3x3, 1 amostra de imagem cinza 3x5\n",
    "\n",
    "Neste caso, \n",
    "- shape da entrada, x:(1,1,3,5)\n",
    "- shape dos pesos W:(2, 1, 3,3). \n",
    "- shape de saída será y:(1,2,3,5)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "W = np.array([[[1,0,1],\n",
    "               [0,1,0],\n",
    "               [1,0,1]],\n",
    "              [[0,1,0],\n",
    "               [1,2,1],\n",
    "               [0,1,0]]]).reshape(2,1,3,3)\n",
    "x = np.array([[0,0,0,0,0],\n",
    "              [0,0,1,0,0],\n",
    "              [0,0,0,0,0]]).reshape(1,1,3,5)\n",
    "y = conv4d(x,W,'same')\n",
    "print 'x:', x.shape\n",
    "print x\n",
    "print 'y:', y.shape\n",
    "print y\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1 filtro com kernel de 3x3 e 3 canais, 1 amostra de imagem 3x5 RGB (3 canais)\n",
    "Neste caso, como a imagem de entrada possui 3 bandas, para guardar as bandas Red, Green e Blue, o kernel também precisa ter 3 bandas pois são necessários pesos para cada banda de cor.\n",
    "- shape da entrada, x:(1,3,3,5)\n",
    "- shape dos pesos W:(1, 3, 3,3). \n",
    "- shape de saída será y:(1,2,3,5)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "W = np.array([[[1,0,1],\n",
    "               [0,1,0],\n",
    "               [1,0,1]],\n",
    "              [[0,1,0],\n",
    "               [1,1,1],\n",
    "               [0,1,0]],\n",
    "              [[0,1,0],\n",
    "               [0,1,0],\n",
    "               [0,1,0]]]).reshape(1,3,3,3)\n",
    "x = np.array([[[0,0,0,0,0],\n",
    "               [0,1,0,0,0],\n",
    "               [0,0,0,0,0]],\n",
    "              [[0,0,0,0,1],\n",
    "               [0,0,1,0,0],\n",
    "               [0,0,0,0,0]],\n",
    "              [[0,0,0,0,0],\n",
    "               [0,0,0,1,0],\n",
    "               [0,0,0,0,0]]]).reshape(1,3,3,5)\n",
    "y = conv4d(x,W,'same')\n",
    "print 'x:', x.shape\n",
    "print x\n",
    "print 'W:', W.shape\n",
    "print W\n",
    "print 'y:', y.shape\n",
    "print y\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Exercícios\n",
    "\n",
    "### Teórico\n",
    "\n",
    "1. Supondo uma imagem de entrada 100 x 100 e um kernel 3 x 3. Utilizando-se o border_mode como válido, a imagem de saída será de 99 x 99. Se fosse utilizar uma rede densa, com entrada de 100 x 100 e saída 98 x 98, quantos parâmetros seriam necessários para ser treinados? E no caso da rede convolucional? Qual é o fator de redução?\n",
    "\n",
    "### Práticos\n",
    "\n",
    "1. Trocar o parâmetro ``border_mode`` para ``same`` e veja a diferença.\n",
    "2. Rodar a convolução para uma imagem de cinza\n",
    "3. Rodar a convolução para uma imagem colorida RGB\n",
    "4. Comparar o tempo de execução desta convolução com outras implementações: scipy, skimage ou openCV"
   ]
  }
 ],
 "metadata": {
  "anaconda-cloud": {},
  "kernelspec": {
   "display_name": "Python [Root]",
   "language": "python",
   "name": "Python [Root]"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
