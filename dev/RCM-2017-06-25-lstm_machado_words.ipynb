{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "%matplotlib inline\n",
    "import matplotlib.pyplot as plot\n",
    "from IPython import display\n",
    "from __future__ import print_function\n",
    "\n",
    "from keras.preprocessing.text import Tokenizer\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Dense, Activation\n",
    "from keras.layers import LSTM, Embedding\n",
    "from keras.optimizers import RMSprop, Adam\n",
    "from keras.regularizers import l2\n",
    "from keras.utils.data_utils import get_file\n",
    "import numpy as np\n",
    "import numpy.random as nr\n",
    "import random\n",
    "import glob\n",
    "import sys\n",
    "import os\n",
    "import re\n",
    "\n",
    "sys.path.append('../src')\n",
    "from my_keras_utilities import (get_available_gpus, \n",
    "                                load_model_and_history, \n",
    "                                save_model_and_history, \n",
    "                                TrainingPlotter)\n",
    "\n",
    "os.makedirs('../../models',exist_ok=True)\n",
    "np.set_printoptions(precision=3, linewidth=120)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Backend:        tensorflow\n",
      "Data format:    channels_last\n",
      "Available GPUS: ['/gpu:0']\n"
     ]
    }
   ],
   "source": [
    "import keras.backend as K\n",
    "\n",
    "# K.set_image_data_format('channels_first')\n",
    "K.set_floatx('float32')\n",
    "\n",
    "print('Backend:        {}'.format(K.backend()))\n",
    "print('Data format:    {}'.format(K.image_data_format()))\n",
    "print('Available GPUS:', get_available_gpus())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "collapsed": true,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "class MyCb(TrainingPlotter):\n",
    "    \n",
    "    def on_epoch_end(self, epoch, logs={}):\n",
    "        super().on_epoch_end(epoch, logs)\n",
    "\n",
    "\n",
    "def train_network(model, model_name, X_train, y_train, Xval=None, yval=None, loss=\"categorical_crossentropy\",\n",
    "                  metrics=('accuracy',), opt='rmsprop', batch_size=60, nepochs=50000, patience=500, \n",
    "                  nr_seed=20170522, reset=False, ploss=1.0):\n",
    "\n",
    "    do_plot = (ploss > 0.0)\n",
    "    \n",
    "    model_fn = model_name + '.model'\n",
    "    if reset and os.path.isfile(model_fn):\n",
    "        os.unlink(model_name + '.model')\n",
    "        \n",
    "    if not os.path.isfile(model_fn):\n",
    "        # initialize the optimizer and model\n",
    "        print(\"[INFO] compiling model...\")\n",
    "        model.compile(loss=loss, optimizer=opt, metrics=metrics)    \n",
    "\n",
    "        # History, checkpoint, earlystop, plot losses:\n",
    "        cb = MyCb(n=1, filepath=model_name, patience=patience, plot_losses=do_plot)\n",
    "        \n",
    "    else:\n",
    "        print(\"[INFO] loading model...\")\n",
    "        model, cb = load_model_and_history(model_name)\n",
    "        cb.patience = patience\n",
    "\n",
    "    past_epochs = cb.get_nepochs()\n",
    "    tr_epochs = nepochs - past_epochs\n",
    "    \n",
    "    if tr_epochs <= 0:\n",
    "        print('[INFO] Model already trained for {} epochs'.format(nepochs))\n",
    "        return model, cb\n",
    "    \n",
    "    if do_plot:\n",
    "        vv = 0\n",
    "        fig = plot.figure(figsize=(15,6))\n",
    "        plot.ylim(0.0, ploss)\n",
    "        plot.xlim(0, nepochs)\n",
    "        plot.grid(True)\n",
    "    else:\n",
    "        vv = 2\n",
    "        \n",
    "    if Xval is not None:\n",
    "        val_data = (Xval, yval)\n",
    "    else:\n",
    "        val_data = None\n",
    "\n",
    "    print(\"[INFO] training for {} epochs...\".format(tr_epochs))\n",
    "    try:\n",
    "        h = model.fit(X_train, y_train, batch_size=60, epochs=tr_epochs, verbose=0, \n",
    "                      validation_data=val_data, callbacks=[cb])\n",
    "    except KeyboardInterrupt:\n",
    "        pass\n",
    "\n",
    "    return model, cb\n",
    "\n",
    "\n",
    "def test_network(model_name, X_test, y_test):\n",
    "    model, histo = load_model_and_history(model_name)\n",
    "    print('Model from epoch {}'.format(histo.best_epoch))\n",
    "    print(\"[INFO] evaluating in the test data set ...\")\n",
    "    loss, accuracy = model.evaluate(X_test, y_test, batch_size=128, verbose=1)\n",
    "    print(\"\\n[INFO] accuracy on the test data set: {:.2f}% [{:.5f}]\".format(accuracy * 100, loss))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " 347400  Memorias_Postumas_de_Bras_Cubas\n",
      " 280008  Memorial_de_Aires\n",
      " 408432  Esau_e_Jaco\n",
      " 369465  Dom_Casmurro\n",
      " 326196  Iaia_Garcia\n",
      " 440240  Quincas_Borba\n",
      " 327155  Helena\n",
      "2498896\n"
     ]
    }
   ],
   "source": [
    "data_dir = '../../datasets/'\n",
    "\n",
    "def clean_text(text):\n",
    "    txt = re.sub('\\n\\n+', '\\07', text)\n",
    "    txt = re.sub('\\n', ' ', txt)\n",
    "    txt = re.sub('\\07', '\\n', txt)\n",
    "    txt = re.sub('  +', ' ', txt)\n",
    "    txt = re.sub('\\nCAPÍTULO [^\\n]*\\n', '\\n', txt)    \n",
    "    return txt.lower()\n",
    "\n",
    "book_texts = []\n",
    "book_titles = []\n",
    "char_count = 0\n",
    "for fn in glob.glob(data_dir + 'livros/Machado_de_Assis__*.txt'):\n",
    "    _, book = os.path.basename(fn).split('__')\n",
    "    txt = open(fn, encoding='utf-8').read()\n",
    "    txt = clean_text(txt)\n",
    "    book_texts.append(txt)\n",
    "    book_titles.append(book[:-4])\n",
    "    print('{:7d}  {}'.format(len(txt), book[:-4]))\n",
    "    char_count += len(txt)\n",
    "print('{:7d}'.format(char_count))\n",
    "\n",
    "nb_books = len(book_texts)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "total text length:  2498896 chars\n",
      "total unique chars: 82\n",
      "['\\n', ' ', '!', '\"', '$', '&', \"'\", '(', ')', '*', '+', ',', '-', '.', '0', '1', '2', '3', '4', '5', '6', '7', '8', '9', ':', ';', '=', '?', '_', 'a', 'b', 'c', 'd', 'e', 'f', 'g', 'h', 'i', 'j', 'k', 'l', 'm', 'n', 'o', 'p', 'q', 'r', 's', 't', 'u', 'v', 'w', 'x', 'y', 'z', '\\x92', '\\x93', '\\x94', '\\x96', '\\x97', '\\xa0', '¡', 'ª', '°', 'º', 'à', 'á', 'â', 'ã', 'ä', 'ç', 'è', 'é', 'ê', 'ë', 'í', 'ñ', 'ó', 'ô', 'õ', 'ú', 'ü']\n"
     ]
    }
   ],
   "source": [
    "all_text = ''\n",
    "for txt in book_texts:\n",
    "    all_text += txt\n",
    "    \n",
    "chars = sorted(list(set(all_text)))\n",
    "char_indices = dict((c, i) for i, c in enumerate(chars))\n",
    "indices_char = dict((i, c) for i, c in enumerate(chars))\n",
    "\n",
    "nb_chars = len(chars)\n",
    "text_len = len(all_text)\n",
    "\n",
    "print('total text length: ', text_len, 'chars')\n",
    "print('total unique chars:', nb_chars)\n",
    "print(chars)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " se deve inclinar.\n",
      "estácio ouviu atento estas vozes com que a serpente lhe apontava para a árvore da ciência do bem e do mal. menos curioso que eva, entrou a discutir filosoficamente com o réptil.\n",
      "-- entra-se na política, disse ele, por vocação legítima, ambição nobre, interesse, vaidade, e até por simples distração. nenhum desses motivos me impele a dobrar o cabo tormentório...\n",
      "-- da boa esperanç\n"
     ]
    }
   ],
   "source": [
    "idx = nr.randint(text_len - 400)\n",
    "print(all_text[idx:idx+400])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 25471 unique tokens.\n",
      "Using the first 19999 words.\n",
      "[60678, 51320, 72382, 66713, 56527, 77755, 55985]\n"
     ]
    }
   ],
   "source": [
    "num_words = 20000\n",
    "\n",
    "tokenizer = Tokenizer(num_words=num_words)\n",
    "tokenizer.fit_on_texts(book_texts)\n",
    "sequences = tokenizer.texts_to_sequences(book_texts)\n",
    "\n",
    "w2i = tokenizer.word_index\n",
    "i2w = dict([(v, k) for k, v in w2i.items()])\n",
    "\n",
    "i2w_vec = np.array([i2w[i+1] for i in range(len(i2w))])\n",
    "\n",
    "print('Found %d unique tokens.' % len(i2w))\n",
    "print('Using the first %d words.' % max([max(s) for s in sequences]))\n",
    "print([len(s) for s in sequences])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "nb sequences: 147096\n"
     ]
    }
   ],
   "source": [
    "seq_len = 10\n",
    "step = 3\n",
    "sentences = []\n",
    "for k, sequence in enumerate(sequences):\n",
    "    for i in range(0, len(sequence) - (seq_len + 1), step):\n",
    "        sentences.append(sequence[i: i + seq_len + 1])\n",
    "\n",
    "print('nb sequences:', len(sentences))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Vectorization ...\n",
      "X.shape: (147096, 10)\n",
      "y.shape: (147096,)\n"
     ]
    }
   ],
   "source": [
    "print('Vectorization ...')\n",
    "nb_samples = len(sentences)\n",
    "\n",
    "X = np.zeros((nb_samples, seq_len), dtype=np.int)\n",
    "y = np.zeros((nb_samples,), dtype=np.int)\n",
    "for i, sentence in enumerate(sentences):\n",
    "    X[i, :] = sentence[:-1]\n",
    "    y[i] = sentence[-1]\n",
    "    \n",
    "print('X.shape:', X.shape)\n",
    "print('y.shape:', y.shape)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[   6  214 6883  382  344 1919 1966    4  357    6] 2922\n",
      "não te deixes ficar aí inútil obscuro e triste não -> gastei\n",
      "\n",
      "[2268    1  186   83   60    5    2   50  176  217] 238\n",
      "dirigiu a palavra alguma vez o que tudo viu luís -> garcia\n",
      "\n",
      "[   37   420   233    10  1104     5   184    27 11722     4] 2701\n",
      "dos dez minutos da alcova o gesto mais genuíno e -> cordial\n",
      "\n",
      "[   68   271     3  1288 15961    26   931   972     2    16] 401\n",
      "estava longe de trazer arraigada no cérebro confesso que me -> achei\n",
      "\n",
      "[    1   129 14012   150    32   319   390     3   223   136] 878\n",
      "a isto ligasse tal ou qual desejo de saber algum -> segredo\n",
      "\n",
      "[   19  1350  3817   495 11325     1  2057     6    18 14757] 9\n",
      "uma linguagem cortês embora enérgica a violência não era especiaria -> do\n",
      "\n",
      "[ 272    4    2  104 1195   13   80    1  744    2] 6\n",
      "quer e que pode dê lhe bem a entender que -> não\n",
      "\n",
      "[  1 124   2  16 894  12 545  47 115   4] 15\n",
      "a mão que me apertou os dedos só isso e -> é\n",
      "\n",
      "[  267     8  2137    10    41     4 10131    48     9  5125] 36\n",
      "entrou um íntimo da casa e conversou também do fazendeiro -> disse\n",
      "\n",
      "[  10  251 2399  434    9   27   24  394    3  616] 83\n",
      "da viúva cedia além do mais à necessidade de contar -> alguma\n",
      "\n",
      "[ 225   15 1364    2 5659    9  247    4 3129  752] 3\n",
      "ambos é provável que descesse do céu e buscasse maneira -> de\n",
      "\n",
      "[7163  126  118  323    6  133    2 1804    6  229] 25\n",
      "adivinhe quem está cá não tem que adivinhar não veio -> por\n",
      "\n",
      "[1931   80  143 7630 1568   16    2  826   51  131] 14\n",
      "ficam bem onde caem redargüiu me que estão muito melhor -> com\n",
      "\n",
      "[114  12  71 151   5 860 199  31  66   2] 311\n",
      "todos os dias nunca o senti tanto como agora que -> estou\n",
      "\n",
      "[  28  629 1251    1  396  179    2  311 2880   17] 1\n",
      "ele sorrindo perde a graça parece que estou repetindo mas -> a\n",
      "\n",
      "[  14    5 1442   11  759    1 9950    1 9950  270] 71\n",
      "com o dedo  olhe a presilha a presilha josé -> dias\n",
      "\n",
      "[   3    8  358  400   27   74   17   54 3516  407] 2\n",
      "de um capítulo quanto mais dois mas há matérias tais -> que\n",
      "\n",
      "[   1  180   60    2    1  248   16 2153   70  634] 16\n",
      "a primeira vez que a morte me aparecia assim perto -> me\n",
      "\n",
      "[  92 2729   17    3 1222 1992 3839  977    1  430] 44\n",
      "eram fáceis mas de pouca dura faltou explicar a natureza -> das\n",
      "\n",
      "[   7   10  119  809    4 1407   23   91    3  155] 2\n",
      "se da noite anterior e observou ao pai de estela -> que\n",
      "\n"
     ]
    }
   ],
   "source": [
    "for i in nr.randint(nb_samples, size=(20,)):\n",
    "    print(X[i], y[i])\n",
    "    print(' '.join([i2w[x] for x in X[i]]), '->', i2w[y[i]])\n",
    "    print()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "embedding_2 (Embedding)      (None, 10, 50)            1000000   \n",
      "_________________________________________________________________\n",
      "lstm_2 (LSTM)                (None, 64)                29440     \n",
      "_________________________________________________________________\n",
      "dense_2 (Dense)              (None, 20000)             1300000   \n",
      "=================================================================\n",
      "Total params: 2,329,440\n",
      "Trainable params: 2,329,440\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "model = Sequential()\n",
    "model.add(Embedding(num_words, 50, input_length=seq_len, embeddings_regularizer=l2(1e-5)))\n",
    "model.add(LSTM(64))\n",
    "model.add(Dense(num_words, activation='softmax'))\n",
    "model.summary()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(132386, 10) (132386,) (14710, 10) (14710,)\n"
     ]
    }
   ],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "X_tra, X_val, y_tra, y_val = train_test_split(X, y, test_size=0.1)\n",
    "print(X_tra.shape, y_tra.shape, X_val.shape, y_val.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[INFO] loading model...\n",
      "[INFO] Model already trained for 100 epochs\n"
     ]
    }
   ],
   "source": [
    "model_name = '../../models/lstm_machado_words_1'\n",
    "\n",
    "fit_params = {\n",
    "    'opt':        Adam(),\n",
    "    'loss':       'sparse_categorical_crossentropy',\n",
    "    'metrics':    ['accuracy'],\n",
    "    'batch_size': 100, \n",
    "    'nepochs':    100,\n",
    "    'patience':   15,\n",
    "    'ploss':      10.0,\n",
    "    'reset':      False,\n",
    "}\n",
    "\n",
    "N = -1\n",
    "Xtra, ytra = X_tra[:N], y_tra[:N]\n",
    "\n",
    "train_network(model, model_name, Xtra, ytra, **fit_params);\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "model, histo = load_model_and_history(model_name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "janeiro não lhe oferecia a mesma variedade de recursos que\n",
      "-----\n",
      "janeiro não lhe oferecia a mesma variedade de recursos que a\n",
      "------------------------------------------------------------\n",
      "janeiro não lhe oferecia a mesma variedade de recursos que a muro ao vê à propriamente há de árvores  não\n",
      "------------------------------------------------------------\n",
      "janeiro não lhe oferecia a mesma variedade de recursos que a muro ao vê à propriamente há de árvores  não é a fidélia não sei é o apenas dia como\n",
      "------------------------------------------------------------\n",
      "janeiro não lhe oferecia a mesma variedade de recursos que a muro ao vê à propriamente há de árvores  não é a fidélia não sei é o apenas dia como me algum me pressa e princípio calvo portinhola sossegado em\n",
      "------------------------------------------------------------\n"
     ]
    }
   ],
   "source": [
    "def get_string(seq):\n",
    "    return\n",
    "\n",
    "all_words = []\n",
    "for seq in sequences:\n",
    "    all_words += seq\n",
    "corpus_word_count = len(all_words)\n",
    "\n",
    "start_index = random.randint(0, corpus_word_count - seq_len - 1)\n",
    "generated = []\n",
    "sentence = all_words[start_index: start_index + seq_len]\n",
    "generated += sentence\n",
    "print(' '.join([i2w[x] for x in generated]))\n",
    "print('-----')\n",
    "\n",
    "\n",
    "for i in range(40):\n",
    "    x = np.array(sentence).reshape(1, -1)\n",
    "    preds = model.predict(x, verbose=0)[0]\n",
    "    next_word = np.argmax(preds)\n",
    "    \n",
    "    generated += [next_word]\n",
    "    sentence = sentence[1:] + [next_word]\n",
    "\n",
    "    if i%10 == 0:\n",
    "        print(' '.join([i2w[x] for x in generated]))\n",
    "        print('-'*60)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.4.3"
  },
  "latex_envs": {
   "LaTeX_envs_menu_present": true,
   "autocomplete": true,
   "bibliofile": "biblio.bib",
   "cite_by": "apalike",
   "current_citInitial": 1,
   "eqLabelWithNumbers": true,
   "eqNumInitial": 1,
   "hotkeys": {
    "equation": "Ctrl-E",
    "itemize": "Ctrl-I"
   },
   "labels_anchors": false,
   "latex_user_defs": false,
   "report_style_numbering": false,
   "user_envs_cfg": false
  },
  "toc": {
   "colors": {
    "hover_highlight": "#DAA520",
    "running_highlight": "#FF0000",
    "selected_highlight": "#FFD700"
   },
   "moveMenuLeft": true,
   "nav_menu": {
    "height": "12px",
    "width": "252px"
   },
   "navigate_menu": true,
   "number_sections": true,
   "sideBar": true,
   "threshold": 4,
   "toc_cell": false,
   "toc_section_display": "block",
   "toc_window_display": false,
   "widenNotebook": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
