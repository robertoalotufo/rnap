{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Funções necessárias para o pré-processsamento das imagens antes de inseri-lás na CNN U-NET."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using Theano backend.\n",
      "Using gpu device 0: Tesla K40c (CNMeM is disabled, cuDNN Version is too old. Update to v5, was 2000.)\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import cv2\n",
    "import numpy as np\n",
    "import glob\n",
    "import os,time\n",
    "import scipy.misc\n",
    "from sklearn.feature_extraction.image import extract_patches_2d\n",
    "from sklearn.feature_extraction.image import reconstruct_from_patches_2d\n",
    "from natsort import natsorted\n",
    "from keras import backend as K\n",
    "\n",
    "K.set_image_dim_ordering('th')  # Theano dimension ordering in this code\n",
    "\n",
    "n_base = 250 # 250 imagens para o treinamento\n",
    "max_patches = 100 # número máximo de patches em cada imagem utilizada no treino.\n",
    "n_imgs = 4 # número de imagens para o teste.\n",
    "\n",
    "# Configuracoes da u-net\n",
    "img_rows = 64\n",
    "img_cols = 80\n",
    "patch_size = (img_rows,img_cols) # unet input size \n",
    "\n",
    "# Criação dos dados em formato de array .py  a partir dos patches extraídos.\n",
    "def create_data(folder):\n",
    "\n",
    "    images = natsorted(os.listdir(folder))\n",
    "    total = len(images) / 2\n",
    "    imgs = np.ndarray((total, 1, patch_size[0], patch_size[1]), dtype=np.uint8)\n",
    "    imgs_mask = np.ndarray((total, 1, patch_size[0], patch_size[1]), dtype=np.uint8)\n",
    "\n",
    "    i = 0\n",
    "\n",
    "    for image_name in images:\n",
    "        if 'staplepatch' in image_name:\n",
    "            continue\n",
    "        image_mask_name = image_name.split('-')[0] + '-staplepatch.tif'\n",
    "\n",
    "        img = cv2.imread(os.path.join(folder, image_name), cv2.IMREAD_GRAYSCALE)\n",
    "        img_mask = cv2.imread(os.path.join(folder, image_mask_name), cv2.IMREAD_GRAYSCALE)\n",
    "\n",
    "        img = np.array([img])\n",
    "        img_mask = np.array([img_mask])\n",
    "\n",
    "        imgs[i] = img\n",
    "        imgs_mask[i] = img_mask\n",
    "\n",
    "        if i % 100 == 0:\n",
    "            print('Done: {0}/{1} images'.format(i, total))\n",
    "        i += 1\n",
    "\n",
    "    print('Data created.')\n",
    "\n",
    "    return imgs, imgs_mask\n",
    "\n",
    "# salva array contendo os patches no formato .npy\n",
    "def save_data(imgs, imgs_mask, imgs_name, imgs_mask_name, out):\n",
    "\n",
    "    np.save(os.path.join(out,imgs_name), imgs)\n",
    "    np.save(os.path.join(out,imgs_mask_name), imgs_mask)\n",
    "    \n",
    "    print('Saved data to .npy.')\n",
    "\n",
    "# salva imagens no formata .tif\n",
    "def save_2d_samples(dst_path,name,img,mask):\n",
    "\n",
    "    for i in range(img.shape[0]):\n",
    "        cv2.imwrite(os.path.join(dst_path,name + '_' + str(i+1) + '-staplepatch.tif'),\n",
    "                    mask[i].astype(np.uint8)*255)\n",
    "        scipy.misc.imsave(os.path.join(dst_path,name + '_' + str(i+1) +'-sagpatch.tif'),img[i])\n",
    "\n",
    "# Extrai patches a partir de imagens 2D. A extração dos patches é realizada com a função do sklearn 'extract_patches_2d' \n",
    "# (http://scikit-learn.org/stable/modules/generated/sklearn.feature_extraction.image.extract_patches_2d.html)\n",
    "def sample_2d_patches(srcDir, dstDir, opt):\n",
    "    \n",
    "    mid_sag_samples = np.sort(glob.glob(os.path.join(srcDir, '*_staple.tif')))\n",
    "    \n",
    "    if (opt == 'train'):\n",
    "        print ('Sampling Train Images ...')\n",
    "       \n",
    "        for img in mid_sag_samples:\n",
    "            name = img.split('/')[-1].split('_staple.tif')[0]\n",
    "            \n",
    "            sag = cv2.imread(os.path.join(srcDir, name + '.tif'), cv2.IMREAD_GRAYSCALE)\n",
    "            staple = cv2.imread(os.path.join(srcDir, name + '_staple.tif'), cv2.IMREAD_GRAYSCALE)\n",
    "                      \n",
    "            sag_patches = extract_patches_2d(sag, patch_size, max_patches, random_state = 1)\n",
    "            staple_patches = extract_patches_2d(staple, patch_size, max_patches, random_state = 1)\n",
    "            \n",
    "            print ('Saving train image patches:', name)\n",
    "            save_2d_samples(dstDir, name, sag_patches,staple_patches)\n",
    "            \n",
    "    if (opt == 'test'):\n",
    "        print ('Sampling Test Images ...')\n",
    "\n",
    "        for img in mid_sag_samples[:n_imgs]:\n",
    "            name = img.split('/')[-1].split('_staple.tif')[0]\n",
    "            \n",
    "            sag = cv2.imread(os.path.join(srcDir, name + '.tif'), cv2.IMREAD_GRAYSCALE)\n",
    "            staple = cv2.imread(os.path.join(srcDir, name + '_staple.tif'), cv2.IMREAD_GRAYSCALE)\n",
    "                      \n",
    "            sag_patches = extract_patches_2d(sag, patch_size)\n",
    "            staple_patches = extract_patches_2d(staple, patch_size)\n",
    "\n",
    "            print ('Saving test image patches:', name)           \n",
    "            out = os.path.join(dstDir,name)\n",
    "            print (out)\n",
    "            \n",
    "            if not os.path.exists(out):\n",
    "                os.makedirs(out)\n",
    "            \n",
    "            save_2d_samples(out, name, sag_patches,staple_patches)\n",
    "\n",
    "# Faz resize das imagens para o tamanho de entrada da U-NET\n",
    "def preprocess(imgs):\n",
    "    \n",
    "    imgs_p = np.ndarray((imgs.shape[0], imgs.shape[1], img_rows, img_cols), dtype=np.uint8)\n",
    "    for i in range(imgs.shape[0]):\n",
    "        imgs_p[i, 0] = cv2.resize(imgs[i, 0], (img_cols, img_rows), interpolation=cv2.INTER_CUBIC)\n",
    "    return imgs_p\n",
    "\n",
    "# Extrai a média e o desvio padrão dos dados de treino para normalizar o teste\n",
    "def get_mean_std_train(imgs,mask):\n",
    "\n",
    "    imgs_train, imgs_mask_train = load_train_data(imgs,mask)\n",
    "\n",
    "    imgs_train = preprocess(imgs_train)\n",
    "    imgs_mask_train = preprocess(imgs_mask_train)\n",
    "\n",
    "    imgs_train = imgs_train.astype('float32')\n",
    "    mean = np.mean(imgs_train)  # mean for data centering\n",
    "    std = np.std(imgs_train)  # std for data normalization\n",
    "    \n",
    "    return mean,std\n",
    "\n",
    "# Ler os dados de teste e faz o resize mais a normalização\n",
    "def read_prep_test(img,mean,std):\n",
    "        \n",
    "    imgs_test = preprocess(img)\n",
    "    \n",
    "    imgs_test = imgs_test.astype('float32')\n",
    "    imgs_test -= mean\n",
    "    imgs_test /= std\n",
    "\n",
    "    return imgs_test\n",
    "\n",
    "# Carrega os dados de treino em formato .py \n",
    "def load_train_data(imgs,mask):\n",
    "    \n",
    "    imgs_train = np.load(imgs)\n",
    "    imgs_mask_train = np.load(mask)\n",
    "    \n",
    "    return imgs_train, imgs_mask_train\n",
    "\n",
    "# Reconstroi as imagens a partir dos patches preditos da saída da CNN. A função utilizada par aisso é do sklean\n",
    "# 'reconstruct_from_patches_2d' \n",
    "# (http://scikit-learn.org/stable/modules/generated/sklearn.feature_extraction.image.reconstruct_from_patches_2d.html)\n",
    "def reconstruct_2d_sample(dst_path, data_path, root_folder):\n",
    "\n",
    "    pred_imgs_maks_test = np.load(data_path)\n",
    "    n_patches = pred_imgs_maks_test.shape[0]\n",
    "\n",
    "    pred_imgs_maks_test = np.reshape(pred_imgs_maks_test,(n_patches,patch_size[0],patch_size[1]))\n",
    "\n",
    "    pred_imgs_maks_test[pred_imgs_maks_test >= 0.5] = 1\n",
    "    pred_imgs_maks_test[pred_imgs_maks_test < 0.5] = 0\n",
    "\n",
    "    name = data_path.split('/')[-1].split('-')[0]\n",
    "    orig_mask = cv2.imread(os.path.join(root_folder,name + '_staple.tif'), cv2.IMREAD_GRAYSCALE)\n",
    "    orig_size = orig_mask.shape\n",
    "     \n",
    "    del(orig_mask)\n",
    "    rec_image_mask = reconstruct_from_patches_2d(pred_imgs_maks_test,orig_size)\n",
    "    cv2.imwrite(os.path.join(dst_path,name + '-pred.tif'),rec_image_mask.astype(np.uint8)*255)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[NbConvertApp] Converting notebook prep_ss_utils.py to html\r\n",
      "Traceback (most recent call last):\r\n",
      "  File \"/home/adessowiki/Virtualenvs/theano/bin/ipython\", line 11, in <module>\r\n",
      "    sys.exit(start_ipython())\r\n",
      "  File \"/home/adessowiki/Virtualenvs/theano/local/lib/python2.7/site-packages/IPython/__init__.py\", line 118, in start_ipython\r\n",
      "    return launch_new_instance(argv=argv, **kwargs)\r\n",
      "  File \"/home/adessowiki/Virtualenvs/theano/local/lib/python2.7/site-packages/traitlets/config/application.py\", line 592, in launch_instance\r\n",
      "    app.start()\r\n",
      "  File \"/home/adessowiki/Virtualenvs/theano/local/lib/python2.7/site-packages/IPython/terminal/ipapp.py\", line 349, in start\r\n",
      "    return self.subapp.start()\r\n",
      "  File \"/home/adessowiki/Virtualenvs/theano/local/lib/python2.7/site-packages/nbconvert/nbconvertapp.py\", line 289, in start\r\n",
      "    self.convert_notebooks()\r\n",
      "  File \"/home/adessowiki/Virtualenvs/theano/local/lib/python2.7/site-packages/nbconvert/nbconvertapp.py\", line 412, in convert_notebooks\r\n",
      "    self.convert_single_notebook(notebook_filename)\r\n",
      "  File \"/home/adessowiki/Virtualenvs/theano/local/lib/python2.7/site-packages/nbconvert/nbconvertapp.py\", line 383, in convert_single_notebook\r\n",
      "    output, resources = self.export_single_notebook(notebook_filename, resources)\r\n",
      "  File \"/home/adessowiki/Virtualenvs/theano/local/lib/python2.7/site-packages/nbconvert/nbconvertapp.py\", line 335, in export_single_notebook\r\n",
      "    output, resources = self.exporter.from_filename(notebook_filename, resources=resources)\r\n",
      "  File \"/home/adessowiki/Virtualenvs/theano/local/lib/python2.7/site-packages/nbconvert/exporters/exporter.py\", line 165, in from_filename\r\n",
      "    return self.from_notebook_node(nbformat.read(f, as_version=4), resources=resources, **kw)\r\n",
      "  File \"/home/adessowiki/Virtualenvs/theano/local/lib/python2.7/site-packages/nbformat/__init__.py\", line 141, in read\r\n",
      "    return reads(fp.read(), as_version, **kwargs)\r\n",
      "  File \"/home/adessowiki/Virtualenvs/theano/local/lib/python2.7/site-packages/nbformat/__init__.py\", line 74, in reads\r\n",
      "    nb = reader.reads(s, **kwargs)\r\n",
      "  File \"/home/adessowiki/Virtualenvs/theano/local/lib/python2.7/site-packages/nbformat/reader.py\", line 58, in reads\r\n",
      "    nb_dict = parse_json(s, **kwargs)\r\n",
      "  File \"/home/adessowiki/Virtualenvs/theano/local/lib/python2.7/site-packages/nbformat/reader.py\", line 17, in parse_json\r\n",
      "    raise NotJSONError((\"Notebook does not appear to be JSON: %r\" % s)[:77] + \"...\")\r\n",
      "NotJSONError: Notebook does not appear to be JSON: u\"\\n# coding: utf-8\\n\\n# Fun\\xe7\\xf5es n...\r\n",
      "\r\n",
      "If you suspect this is an IPython bug, please report it at:\r\n",
      "    https://github.com/ipython/ipython/issues\r\n",
      "or send an email to the mailing list at ipython-dev@scipy.org\r\n",
      "\r\n",
      "You can print a more detailed traceback right now with \"%tb\", or use \"%debug\"\r\n",
      "to interactively debug it.\r\n",
      "\r\n",
      "Extra-detailed tracebacks for bug-reporting purposes can be enabled via:\r\n",
      "    c.Application.verbose_crash=True\r\n",
      "\r\n"
     ]
    }
   ],
   "source": [
    "!ipython nbconvert prep_ss_utils.py"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
