{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": true,
    "editable": true,
    "toc": "true"
   },
   "source": [
    "# Table of Contents\n",
    " <p><div class=\"lev1 toc-item\"><a href=\"#Classificação-de-Textos\" data-toc-modified-id=\"Classificação-de-Textos-1\"><span class=\"toc-item-num\">1&nbsp;&nbsp;</span>Classificação de Textos</a></div><div class=\"lev2 toc-item\"><a href=\"#Preâmbulo\" data-toc-modified-id=\"Preâmbulo-11\"><span class=\"toc-item-num\">1.1&nbsp;&nbsp;</span>Preâmbulo</a></div><div class=\"lev2 toc-item\"><a href=\"#Preparando-o-dataset\" data-toc-modified-id=\"Preparando-o-dataset-12\"><span class=\"toc-item-num\">1.2&nbsp;&nbsp;</span>Preparando o dataset</a></div><div class=\"lev3 toc-item\"><a href=\"#Buscando-o-texto-dos-livros-e-definindo-os-rótulos\" data-toc-modified-id=\"Buscando-o-texto-dos-livros-e-definindo-os-rótulos-121\"><span class=\"toc-item-num\">1.2.1&nbsp;&nbsp;</span>Buscando o texto dos livros e definindo os rótulos</a></div><div class=\"lev3 toc-item\"><a href=\"#Representando-as-palavras-através-de-índices-inteiros\" data-toc-modified-id=\"Representando-as-palavras-através-de-índices-inteiros-122\"><span class=\"toc-item-num\">1.2.2&nbsp;&nbsp;</span>Representando as palavras através de índices inteiros</a></div><div class=\"lev3 toc-item\"><a href=\"#Palavras-características-de-cada-livro\" data-toc-modified-id=\"Palavras-características-de-cada-livro-123\"><span class=\"toc-item-num\">1.2.3&nbsp;&nbsp;</span>Palavras características de cada livro</a></div><div class=\"lev2 toc-item\"><a href=\"#Dividindo-o-dataset-entre-treinamento-e-validação\" data-toc-modified-id=\"Dividindo-o-dataset-entre-treinamento-e-validação-13\"><span class=\"toc-item-num\">1.3&nbsp;&nbsp;</span>Dividindo o dataset entre treinamento e validação</a></div><div class=\"lev3 toc-item\"><a href=\"#Divisão-simples\" data-toc-modified-id=\"Divisão-simples-131\"><span class=\"toc-item-num\">1.3.1&nbsp;&nbsp;</span>Divisão simples</a></div><div class=\"lev3 toc-item\"><a href=\"#Divisão-para-uso-com-geradores-e-aumento-de-dados\" data-toc-modified-id=\"Divisão-para-uso-com-geradores-e-aumento-de-dados-132\"><span class=\"toc-item-num\">1.3.2&nbsp;&nbsp;</span>Divisão para uso com geradores e aumento de dados</a></div><div class=\"lev4 toc-item\"><a href=\"#Criando--geradores-para-treino-e-validação\" data-toc-modified-id=\"Criando--geradores-para-treino-e-validação-1321\"><span class=\"toc-item-num\">1.3.2.1&nbsp;&nbsp;</span>Criando  geradores para treino e validação</a></div>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": true,
    "editable": true
   },
   "source": [
    "# Classificação de Textos"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": true,
    "editable": true
   },
   "source": [
    "## Preâmbulo"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n"
     ]
    }
   ],
   "source": [
    "%matplotlib inline\n",
    "import matplotlib.pyplot as plot\n",
    "from IPython import display\n",
    "from __future__ import print_function\n",
    "\n",
    "import os\n",
    "import sys\n",
    "import glob\n",
    "import numpy as np\n",
    "import numpy.random as nr\n",
    "\n",
    "from keras.preprocessing.text import Tokenizer\n",
    "from keras.preprocessing.sequence import pad_sequences\n",
    "from keras.utils import to_categorical\n",
    "from keras.layers import Dense, Input, Flatten, Dropout\n",
    "from keras.layers import Conv1D, MaxPooling1D, Embedding\n",
    "from keras.models import Model\n",
    "from keras.optimizers import (SGD, \n",
    "                              RMSprop, \n",
    "                              Adam, \n",
    "                              Adadelta, \n",
    "                              Adagrad)\n",
    "\n",
    "sys.path.append('../src')\n",
    "from my_keras_utilities import (get_available_gpus, \n",
    "                                load_model_and_history, \n",
    "                                save_model_and_history, \n",
    "                                TrainingPlotter)\n",
    "\n",
    "os.makedirs('../../models',exist_ok=True)\n",
    "np.set_printoptions(precision=3, linewidth=120)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Backend:        tensorflow\n",
      "Data format:    channels_last\n",
      "Available GPUS: ['/gpu:0']\n",
      "Encoding:       utf-8\n"
     ]
    }
   ],
   "source": [
    "import keras.backend as K\n",
    "\n",
    "# K.set_image_data_format('channels_first')\n",
    "K.set_floatx('float32')\n",
    "\n",
    "print('Backend:        {}'.format(K.backend()))\n",
    "print('Data format:    {}'.format(K.image_data_format()))\n",
    "print('Available GPUS:', get_available_gpus())\n",
    "print('Encoding:      ', sys.getdefaultencoding())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": true,
    "editable": true
   },
   "source": [
    "## Preparando o dataset"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": true,
    "editable": true
   },
   "source": [
    "### Buscando o texto dos livros e definindo os rótulos"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1001226  Jorge_Amado        Tereza_Batista_Cansada_de_Guerra\n",
      "1030735  Jorge_Amado        Dona_flor_seus_dois_maridos\n",
      " 427711  Jorge_Amado        Capitaes_de_Areia\n",
      " 828417  Jorge_Amado        Gabriela\n",
      " 352965  Machado_de_Assis   Memorias_Postumas_de_Bras_Cubas\n",
      " 280683  Machado_de_Assis   Memorial_de_Aires\n",
      " 411043  Machado_de_Assis   Esau_e_Jaco\n",
      " 372459  Machado_de_Assis   Dom_Casmurro\n",
      " 336677  Machado_de_Assis   Iaia_Garcia\n",
      " 443778  Machado_de_Assis   Quincas_Borba\n",
      " 337533  Machado_de_Assis   Helena\n",
      " 294049  Erico_Verissimo    Clarissa\n",
      " 890215  Erico_Verissimo    Incidente_em_Antares\n",
      " 749265  Erico_Verissimo    O_Tempo_e_o_Vento_-_O_Continente\n",
      " 699390  Erico_Verissimo    O_Tempo_e_o_Vento_-_O_Arquipelago\n",
      "\n",
      "3 Labels:\n",
      "     0: Machado_de_Assis\n",
      "     1: Erico_Verissimo\n",
      "     2: Jorge_Amado\n"
     ]
    }
   ],
   "source": [
    "data_dir = '../../datasets/'\n",
    "\n",
    "autores = [\n",
    "#     'Fernando_Sabino', \n",
    "    'Jorge_Amado',\n",
    "    'Machado_de_Assis',\n",
    "    'Erico_Verissimo',\n",
    "]\n",
    "\n",
    "book_text = []\n",
    "book_author = []\n",
    "book_title = []\n",
    "for aut in autores:\n",
    "    for fn in glob.glob(data_dir + 'livros/' + aut + '*.txt'):\n",
    "        author, book = os.path.basename(fn).split('__')\n",
    "        txt = open(fn, encoding='utf-8').read().replace('\\x97', '')\n",
    "        book_text.append(txt)\n",
    "        book_author.append(author)\n",
    "        book_title.append(book[:-4])\n",
    "        print('{:7d}  {:18s} {}'.format(len(txt), author, book[:-4]))\n",
    "\n",
    "author_list = list(set(book_author))\n",
    "n_labels = len(author_list)\n",
    "n_books = len(book_title)\n",
    "book_label = [author_list.index(a) for a in book_author]\n",
    "print('\\n{} Labels:'.format(n_labels))\n",
    "for i, autor in enumerate(author_list):\n",
    "    print('    {:2d}: {}'.format(i, autor))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": true,
    "editable": true
   },
   "source": [
    "### Representando as palavras através de índices inteiros"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 61707 unique tokens.\n",
      "Using the first 19999 words.\n"
     ]
    }
   ],
   "source": [
    "MAX_NB_WORDS = 20000\n",
    "\n",
    "tokenizer = Tokenizer(num_words=MAX_NB_WORDS)\n",
    "tokenizer.fit_on_texts(book_text)\n",
    "sequences = tokenizer.texts_to_sequences(book_text)\n",
    "\n",
    "w2i = tokenizer.word_index\n",
    "i2w = dict([(v, k) for k, v in w2i.items()])\n",
    "\n",
    "i2w_vec = np.array([i2w[i+1] for i in range(len(i2w))])\n",
    "\n",
    "print('Found %d unique tokens.' % len(i2w))\n",
    "print('Using the first %d words.' % max([max(s) for s in sequences]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true,
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Jorge Amado: Tereza Batista Cansada de Guerra -- 164712 palavras\n",
      "ainda por — não nada não é culpa minha se a metida a honesta largou o curso ao regressar o doutor quis saber dos progressos por tereza na esc de corte e costura ah largara as aulas não levava jeito nem gosto aprendera o suficiente para as necessidades e pronto o doutor tinha o dom de adivinhar quem podia sustentar o confronto daqueles olhos límpidos de verruma — tereza eu nã o gosto de mentiras por que você está mentindo eu já lhe alguma vez conte a verdade o que se passou — ela veio me propor homem jorge amado\n",
      "\n",
      "Jorge Amado: Dona flor seus dois maridos -- 165856 palavras\n",
      "e assinante música flores e luzes e gente mu ita gente na igreja de são bento onde o dom sermão dos mais enquanto na cerimônia civil o juiz doutor pinho pedreira com aquela sua elegância de conceitos em breve e amável oração previu uma vida de paz e entendimento para o casal sob o signo da música voz dos deuses era o descarnado e preclaro juiz colega do noivo na orquestra de amadores reunida sob a batuta do maestro agenor gomes onde o magistrado se distinguia na teve a ssim o segundo casamento de dona flor quanto faltou ao primeiro\n",
      "\n",
      "Jorge Amado: Capitaes de Areia -- 75976 palavras\n",
      "o homem se aproximou mais do muro junto ao qual vinha andando pedro caminhava para ele quando estava defronte parou – pode me dar o fogo senhor – levava na mão um cigarro apagado o homem não disse nada sacou a caixa de fósforos estendeu ao menino pedro riscou um e enquanto acendia o cigarro olhou para o homem depois ao entregara caixa de fósforos perguntou – é o senhor que se chama joel – porquê – quis saber o homem – foi o querido de deus que nos mandou joão grande e o gato se aproximavam o homem mirou\n",
      "\n",
      "Jorge Amado: Gabriela -- 134069 palavras\n",
      "ria quase a mofar se dele e ia embora ajudar o tio cada vez mais fatigado e magro uma tarde tiveram que parar a caminhada o tio de gabriela estava nas últimas vinha cuspindo sangue não mais andar o negro jogou o nas costas como um fardo e o carregou durante um pedaço de caminho o velho ia gabriela a seu lado morreu de tardinha botando sangue pela boca os urubus voavam sobre o cadáver então clemente a viu órfã e só necessitada e triste pela primeira vez pensou compreendê la nada mais era que uma pobre moça quase menina\n",
      "\n",
      "Machado de Assis: Memorias Postumas de Bras Cubas -- 58700 palavras\n",
      "eles a felicidade em verdade vos digo que toda a sabedoria humana não vale um par de botas curtas tu minha eugênia é que não as nunca foste aí pela estrada da vida da perna e do amor triste como os enterros pobres solitária calada laboriosa até que também para esta outra margem o que eu não sei é se a tua existência era muito necessária ao século quem sabe talvez um de menos fizesse a tragédia humana capítulo xxxvii enfim enfim eis aqui virgília antes de ir à casa do conselheiro dutra perguntei a meu pai se havia algum\n",
      "\n",
      "Machado de Assis: Memorial de Aires -- 50099 palavras\n",
      "ficamos com o dobro cada um gostei desta palavra de aguiar e a bem para me não esquecer e escrevê la aqui aquele gerente de banco não perdeu o vício poético é bom homem creio que já o escrevi alguma vez mas lá vai ainda agora não perco nada em repeti lo falávamos a um canto da sala onde campos e tristão foram ter conosco deixando as duas damas entregues uma à outra e eu cá de longe fiquei a mirá las naquela expressão de si mesmas a harmonia dos cabelos brancos de uma e dos cabelos pretos de outra\n",
      "\n",
      "Machado de Assis: Esau e Jaco -- 70259 palavras\n",
      "não pudesse vir logo para casa ficaria adoentada o resto do tempo note se que estando na ilha teria o mar em volta e o mar era um dos seus encantos mas se lhe lembrasse o mar e se com a esperança de o mirar também que a noite escura a consolação que multidão de na vida leitor umas coisas nascem de outras se se confundem se perdem se e o tempo vai andando sem se perder a si mas donde viria o tédio a flora se viesse com pedro no baile não este era como sabes um dos dois\n",
      "\n",
      "Machado de Assis: Dom Casmurro -- 64677 palavras\n",
      "si e antes parenta que estranha alguns minutos na varanda alumiada por um lampião quis saber se eu não esquecera os projetos de minha mãe e dizendo lhe eu que não inquiriu me sobre o gosto que eu tinha à vida de padre respondi vida de padre é muito bonita sim é bonita mas o que pergunto é se você gostaria de ser padre explicou rindo eu gosto do que mamãe quiser prima glória deseja muito que você se ordene mas ainda que não desejasse há cá em casa quem lhe meta isso na cabeça quem é ora quem quem\n",
      "\n",
      "Machado de Assis: Iaia Garcia -- 55430 palavras\n",
      "tempo depois começou a diminuir essa aparência até que cessou de todo e se noutra coisa que visivelmente era repugnância com uma de hostilidade luís garcia viu logo a diferença tanto mais fácil de notar quanto que estela se não era já tão expansiva como nos primeiros dias tratava ainda assim o filho de valéria com uma afabilidade que salvava as aparências a única exceção era a filha não deixou de a advertir ponderou lhe que jorge era filho de uma pessoa a quem eles deviam estima e de quem ela mesma houvera uma recordação póstuma que essa circunstância devia\n",
      "\n",
      "Machado de Assis: Quincas Borba -- 75046 palavras\n",
      "roça para lhe dar lustre de cidade e que esqueceu todos os benefícios para só se lembrar das suas ambições e d fernanda também madrinha dos seus amores que de caso pensado trouxera na véspera a carta de maria benedita com o post confidencial não advertiu que o prazer da amiga bastava a explicar o esquecimento da parte reservada da carta menos ainda indagou se a natureza moral de d fernanda essa suposição vieram assim outras cogitações e imagens e tornaram as primeiras e todas se iam ligando e desligando entre elas apareceu uma lembrança da véspera o marido de\n",
      "\n",
      "Machado de Assis: Helena -- 54864 palavras\n",
      "à bandeira perguntou a moça deixe me ao menos dizer lhe adeus tinha já tirado da algibeira o seu fino lenço de cambraia agitou o na direção da casa quis o acaso que a bandeira até então quieta se ao sopro de uma aragem que passou vê como ela me respondeu não se pode ser mais cortês exclamou helena rindo estácio riu também da lembrança da irmã e ambos desceram a passo lento como haviam subido helena vinha taciturna e pensativa os olhos cravados nas orelhas de moema não pareciam ver sequer o caminho que o animal seguia estácio para\n",
      "\n",
      "Erico Verissimo: Clarissa -- 47908 palavras\n",
      "um gesto nem um olhar não é possível d zina afasta se para um lado em cima da mesa acha se um pequeno aquário bojudo de cristal dentro do qual se agita um peixinho dourado titia o rosto de clarissa é todo um espanto por um instante ela não consegue dizer mais nada comovida olhos presos no aquário oh bem o que eu queria bem o que eu queria o que eu vi o outro dia bate palmas aproxima se da mesa apalpa o aquário mergulha os dedos na água olhe só que bonito dourado alaranjado prateado tem todas as\n",
      "\n",
      "Erico Verissimo: Incidente em Antares -- 145118 palavras\n",
      "dominar a voz ele murmura – devo te confessar que não sei o que dizer estou profundamente magoado e decepcionado contigo – não que eu diga que estou arrependida de ter dito o que disse porque não estou – que pretendes fazer agora – fazer sei lá disse o que há muito te queria dizer agora é a tua vez de falar ele se senta dessa vez a cabeça caída sobre o respaldo da poltrona os olhos fechados – não não estou nesse jogo só quero saber que pretendes fazer agora – nada como sempre a vida vai continuar como\n",
      "\n",
      "Erico Verissimo: O Tempo e o Vento - O Continente -- 129569 palavras\n",
      "olhou os arabescos da bainha de prata e murmurou — nunca vi um punhal assim deve ser estrangeiro juvenal deu de ombros e repetiu indiferente — é mui antigo apanhou a arma e tornou a metê la na bainha rodrigo agora sentia de mistura com a canseira um certo — amigo juvenal nunca hei de esquecer o que vosmecê fez por mim o outro desviou o olhar do rosto do capitão como se aquelas palavras lhe um certo constrangimento — ora — fez ele lançando um olhar para a figueira grande através da janela — se lembra quando vosmecê disse\n",
      "\n",
      "Erico Verissimo: O Tempo e o Vento - O Arquipelago -- 115767 palavras\n",
      "mário de andrade eu insulto o burguês o burguês níquel o burguês burguês a digestão bem feita de são paulo o homem curva o homem nádegas o homem que sendo francês brasileiro italiano é sempre um cauteloso pouco a pouco rodrigo interrompeu o — vocês querem que um leitor de hugo e olavo como eu leve a sério essas maluquices sem dar lhe ouvidos stein continuou ai filha que te darei pelos teus anos — um colar — conto e quinhentos mas nós de fome rodrigo olhou para chiru que valsava com quinota sorriu e deu dois passos na direção\n",
      "\n"
     ]
    }
   ],
   "source": [
    "for i, seq in enumerate(sequences):\n",
    "    k = nr.randint(len(seq) - 100)\n",
    "    print('{}: {} -- {} palavras'.format(book_author[i], book_title[i], len(seq)).replace('_', ' '))\n",
    "    print(' '.join([i2w[x] for x in seq[k:k+100]]), end='\\n\\n')\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": true,
    "editable": true
   },
   "source": [
    "### Palavras características de cada livro"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[['vavá' 'almério' 'januário' '—' 'dóris' 'brígida' 'justiniano' 'tereza']\n",
      " ['marilda' 'dinorá' 'teodoro' 'pelancchi' 'gisa' 'mirandão' 'rozilda' 'vadinho']\n",
      " ['trapiche' 'bedel' 'ester' 'barandão' 'almiro' 'dora' '–' 'pirulito']\n",
      " ['tuísca' 'tonico' 'ribeirinho' 'malvina' 'amâncio' 'fulgêncio' 'gabriela' 'nacib']\n",
      " ['damasceno' 'eusébia' 'cubas' 'borba' 'sabina' 'cotrim' 'marcela' 'virgília']\n",
      " ['carmo' 'libertos' 'prainha' 'noronha' 'cesária' 'aguiar' 'fidélia' 'tristão']\n",
      " ['coupé' 'gêmeos' 'excia' 'custódio' 'nóbrega' 'natividade' 'flora' 'cláudia']\n",
      " ['manduca' 'protonotário' 'bentinho' 'sancha' 'pádua' 'justina' 'escobar' 'capitu']\n",
      " ['procópio' 'valéria' 'jorge' 'garcia' 'madrasta' 'enteada' 'iaiá' 'estela']\n",
      " ['camacho' 'teófilo' 'tonica' 'borba' 'sofia' 'fernanda' 'benedita' 'rubião']\n",
      " ['ângela' 'eugênia' 'tomásia' 'melchior' 'helena' 'camargo' 'estácio' 'úrsula']\n",
      " ['gamaliel' 'dudu' 'eufrasina' 'tatá' 'belmira' 'tónico' 'zina' 'clarissa']\n",
      " ['campolargo' 'vacariano' 'vivaldino' 'getúlio' 'quitéria' '–' 'tibério' 'antares']\n",
      " ['maneco' 'amaral' 'lara' 'vosmecê' 'bibiana' '—' 'alonzo' 'rodrigo']\n",
      " ['dinda' 'alicinha' 'toríbio' 'chiru' 'stein' 'camerino' '—' 'rodrigo']]\n"
     ]
    }
   ],
   "source": [
    "tfidf = tokenizer.sequences_to_matrix(sequences, mode='tfidf')\n",
    "ww = np.argsort(tfidf, axis=1)[:, -8:]\n",
    "print(i2w_vec[ww-1])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": true,
    "editable": true
   },
   "source": [
    "## Dividindo o dataset entre treinamento e validação"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": true,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "nr.seed(20170607)\n",
    "\n",
    "batch_size  = 32\n",
    "seq_size    = 500\n",
    "valid_split = 0.2"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": true,
    "editable": true
   },
   "source": [
    "### Divisão simples"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(2550, 500) (2550,)\n"
     ]
    }
   ],
   "source": [
    "all_data = [[] for i in range(n_labels)]\n",
    "\n",
    "for sequence, label in zip(sequences, book_label):\n",
    "    n_seqs = len(sequence) // seq_size\n",
    "    for i in range(n_seqs):\n",
    "        beg = i * seq_size\n",
    "        all_data[label].append(sequence[beg:beg+seq_size])\n",
    "\n",
    "N = 10 * (min([len(x) for x in all_data]) // 10)\n",
    "all_data = np.array([seq[:N] for seq in all_data], np.int32).reshape(-1, 500)\n",
    "all_labels = np.array([[i] * N for i in range(n_labels)], np.int32).reshape(-1)\n",
    "print(all_data.shape, all_labels.shape)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(2040, 500) (2040,) (510, 500) (510,)\n"
     ]
    }
   ],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "Xtra, Xval, ytra, yval = train_test_split(all_data, all_labels, test_size=valid_split)\n",
    "print(Xtra.shape, ytra.shape, Xval.shape, yval.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "fn = data_dir + 'livros_sequences.npz'\n",
    "np.savez_compressed(fn, Xtra=Xtra, Xval=Xval, ytra=ytra, yval=yval, i2w=i2w_vec[:MAX_NB_WORDS])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": true,
    "editable": true
   },
   "source": [
    "### Divisão para uso com geradores e aumento de dados"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training sequences:\n",
      "-------------------\n",
      " 1. Jorge_Amado      (2) --  44497 palavras do início do livro Tereza_Batista_Cansada_de_Guerra\n",
      " 2. Jorge_Amado      (2) --  92458 palavras do início do livro Dona_flor_seus_dois_maridos\n",
      " 3. Jorge_Amado      (2) --  21458 palavras do início do livro Capitaes_de_Areia\n",
      " 4. Jorge_Amado      (2) --  49425 palavras do início do livro Gabriela\n",
      " 5. Machado_de_Assis (0) --  10722 palavras do início do livro Memorias_Postumas_de_Bras_Cubas\n",
      " 6. Machado_de_Assis (0) --  20724 palavras do início do livro Memorial_de_Aires\n",
      " 7. Machado_de_Assis (0) --  28329 palavras do início do livro Esau_e_Jaco\n",
      " 8. Machado_de_Assis (0) --  33510 palavras do início do livro Dom_Casmurro\n",
      " 9. Machado_de_Assis (0) --  26884 palavras do início do livro Iaia_Garcia\n",
      "10. Machado_de_Assis (0) --  32579 palavras do início do livro Quincas_Borba\n",
      "11. Machado_de_Assis (0) --  21065 palavras do início do livro Helena\n",
      "12. Erico_Verissimo  (1) --   7014 palavras do início do livro Clarissa\n",
      "13. Erico_Verissimo  (1) --  94828 palavras do início do livro Incidente_em_Antares\n",
      "14. Erico_Verissimo  (1) --  44471 palavras do início do livro O_Tempo_e_o_Vento_-_O_Continente\n",
      "15. Erico_Verissimo  (1) --  65361 palavras do início do livro O_Tempo_e_o_Vento_-_O_Arquipelago\n",
      "16. Jorge_Amado      (2) --  87273 palavras do final do livro  Tereza_Batista_Cansada_de_Guerra\n",
      "17. Jorge_Amado      (2) --  40227 palavras do final do livro  Dona_flor_seus_dois_maridos\n",
      "18. Jorge_Amado      (2) --  39323 palavras do final do livro  Capitaes_de_Areia\n",
      "19. Jorge_Amado      (2) --  57831 palavras do final do livro  Gabriela\n",
      "20. Machado_de_Assis (0) --  36238 palavras do final do livro  Memorias_Postumas_de_Bras_Cubas\n",
      "21. Machado_de_Assis (0) --  19356 palavras do final do livro  Memorial_de_Aires\n",
      "22. Machado_de_Assis (0) --  27879 palavras do final do livro  Esau_e_Jaco\n",
      "23. Machado_de_Assis (0) --  18232 palavras do final do livro  Dom_Casmurro\n",
      "24. Machado_de_Assis (0) --  17460 palavras do final do livro  Iaia_Garcia\n",
      "25. Machado_de_Assis (0) --  27458 palavras do final do livro  Quincas_Borba\n",
      "26. Machado_de_Assis (0) --  22827 palavras do final do livro  Helena\n",
      "27. Erico_Verissimo  (1) --  31313 palavras do final do livro  Clarissa\n",
      "28. Erico_Verissimo  (1) --  21267 palavras do final do livro  Incidente_em_Antares\n",
      "29. Erico_Verissimo  (1) --  59185 palavras do final do livro  O_Tempo_e_o_Vento_-_O_Continente\n",
      "30. Erico_Verissimo  (1) --  27253 palavras do final do livro  O_Tempo_e_o_Vento_-_O_Arquipelago\n",
      "\n",
      "Validation sequences:\n",
      "---------------------\n",
      " 1. Jorge_Amado      (2) --  32942 palavras do meio do livro Tereza_Batista_Cansada_de_Guerra\n",
      " 2. Jorge_Amado      (2) --  33171 palavras do meio do livro Dona_flor_seus_dois_maridos\n",
      " 3. Jorge_Amado      (2) --  15195 palavras do meio do livro Capitaes_de_Areia\n",
      " 4. Jorge_Amado      (2) --  26813 palavras do meio do livro Gabriela\n",
      " 5. Machado_de_Assis (0) --  11740 palavras do meio do livro Memorias_Postumas_de_Bras_Cubas\n",
      " 6. Machado_de_Assis (0) --  10019 palavras do meio do livro Memorial_de_Aires\n",
      " 7. Machado_de_Assis (0) --  14051 palavras do meio do livro Esau_e_Jaco\n",
      " 8. Machado_de_Assis (0) --  12935 palavras do meio do livro Dom_Casmurro\n",
      " 9. Machado_de_Assis (0) --  11086 palavras do meio do livro Iaia_Garcia\n",
      "10. Machado_de_Assis (0) --  15009 palavras do meio do livro Quincas_Borba\n",
      "11. Machado_de_Assis (0) --  10972 palavras do meio do livro Helena\n",
      "12. Erico_Verissimo  (1) --   9581 palavras do meio do livro Clarissa\n",
      "13. Erico_Verissimo  (1) --  29023 palavras do meio do livro Incidente_em_Antares\n",
      "14. Erico_Verissimo  (1) --  25913 palavras do meio do livro O_Tempo_e_o_Vento_-_O_Continente\n",
      "15. Erico_Verissimo  (1) --  23153 palavras do meio do livro O_Tempo_e_o_Vento_-_O_Arquipelago\n",
      "\n",
      "Total number of training words:   1126447\n",
      "Total number of validation words: 281603\n"
     ]
    }
   ],
   "source": [
    "valid_length = [int(0.2 * len(x)) for x in sequences]\n",
    "valid_start = [nr.randint(2000, len(x) - 2000 - n) for x, n in zip(sequences, valid_length)]\n",
    "\n",
    "valid_sequences = [seq[x0:x0+n] for seq, x0, n in zip(sequences, valid_start, valid_length)]\n",
    "\n",
    "train_sequences = [seq[:x0] for seq, x0 in zip(sequences, valid_start)] + \\\n",
    "                  [seq[x0+n:] for seq, x0, n in zip(sequences, valid_start, valid_length)]\n",
    "\n",
    "valid_labels = book_label\n",
    "train_labels = book_label + book_label\n",
    "\n",
    "n_train_words = sum([len(x) for x in train_sequences])\n",
    "n_valid_words = sum([len(x) for x in valid_sequences])\n",
    "\n",
    "print('Training sequences:')\n",
    "print('-------------------')\n",
    "for i, (seq, lab) in enumerate(zip(train_sequences, train_labels)):\n",
    "    if i < n_books:\n",
    "        print('{:2d}. {:16s} ({}) -- {:6d} palavras do início do livro {}'.format(i+1, book_author[i%n_books], lab,\n",
    "                                                                                  len(seq), book_title[i%n_books]))\n",
    "    else:\n",
    "        print('{:2d}. {:16s} ({}) -- {:6d} palavras do final do livro  {}'.format(i+1, book_author[i%n_books], lab,\n",
    "                                                                                  len(seq), book_title[i%n_books]))\n",
    "print()\n",
    "print('Validation sequences:')\n",
    "print('---------------------')\n",
    "for i, (seq, lab) in enumerate(zip(valid_sequences, valid_labels)):\n",
    "    print('{:2d}. {:16s} ({}) -- {:6d} palavras do meio do livro {}'.format(i+1, book_author[i%n_books], lab,\n",
    "                                                                            len(seq), book_title[i%n_books]))\n",
    "print()\n",
    "print('Total number of training words:  ', n_train_words)\n",
    "print('Total number of validation words:', n_valid_words)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": true,
    "editable": true
   },
   "source": [
    "#### Criando  geradores para treino e validação"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "collapsed": true,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "class MyDataGenerator:\n",
    "    def __init__(self, batch_size, seq_size, sequences, labels):\n",
    "        self.batch_size = batch_size\n",
    "        self.length = seq_size\n",
    "        self.sequences = sequences\n",
    "        self.labels = labels\n",
    "        sizes = np.array([len(seq) for seq in sequences])\n",
    "        self.p = 1.0 * sizes / sizes.sum()        # probabilidade de escolha para cada sequencia\n",
    "        self.n = np.arange(len(sequences))        # indices de cada sequencia (para o choice abaixo)\n",
    "        \n",
    "    def __call__(self):\n",
    "        while True:\n",
    "            batch = np.empty((self.batch_size, self.length), np.int32)\n",
    "            label = np.empty((self.batch_size, n_labels), np.int32)\n",
    "            for i in range(self.batch_size):\n",
    "                k = nr.choice(self.n, p=self.p)\n",
    "                p = nr.randint(0, len(self.sequences[k]) - self.length)\n",
    "                batch[i] = self.sequences[k][p:p+self.length]\n",
    "                label[i] = to_categorical(self.labels[k], num_classes=n_labels)\n",
    "            yield batch, label\n",
    "\n",
    "            \n",
    "train_gen = MyDataGenerator(batch_size, seq_size, train_sequences, train_labels)\n",
    "valid_gen = MyDataGenerator(batch_size, seq_size, valid_sequences, valid_labels)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "import pickle\n",
    "fn = data_dir + 'livros_generators.pkl'\n",
    "pickle.dump([train_gen, valid_gen, i2w_vec[:MAX_NB_WORDS]], open(fn, 'wb'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.4.3"
  },
  "latex_envs": {
   "LaTeX_envs_menu_present": true,
   "autocomplete": true,
   "bibliofile": "biblio.bib",
   "cite_by": "apalike",
   "current_citInitial": 1,
   "eqLabelWithNumbers": true,
   "eqNumInitial": 1,
   "hotkeys": {
    "equation": "Ctrl-E",
    "itemize": "Ctrl-I"
   },
   "labels_anchors": false,
   "latex_user_defs": false,
   "report_style_numbering": false,
   "user_envs_cfg": false
  },
  "toc": {
   "colors": {
    "hover_highlight": "#DAA520",
    "running_highlight": "#FF0000",
    "selected_highlight": "#FFD700"
   },
   "moveMenuLeft": true,
   "nav_menu": {
    "height": "264px",
    "width": "252px"
   },
   "navigate_menu": true,
   "number_sections": true,
   "sideBar": true,
   "threshold": 4,
   "toc_cell": true,
   "toc_section_display": "block",
   "toc_window_display": false,
   "widenNotebook": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
