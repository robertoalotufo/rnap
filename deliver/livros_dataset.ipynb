{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": true,
    "editable": true,
    "toc": "true"
   },
   "source": [
    "# Table of Contents\n",
    " <p><div class=\"lev1 toc-item\"><a href=\"#Classificação-de-Textos\" data-toc-modified-id=\"Classificação-de-Textos-1\"><span class=\"toc-item-num\">1&nbsp;&nbsp;</span>Classificação de Textos</a></div><div class=\"lev2 toc-item\"><a href=\"#Preâmbulo\" data-toc-modified-id=\"Preâmbulo-11\"><span class=\"toc-item-num\">1.1&nbsp;&nbsp;</span>Preâmbulo</a></div><div class=\"lev2 toc-item\"><a href=\"#Preparando-o-dataset\" data-toc-modified-id=\"Preparando-o-dataset-12\"><span class=\"toc-item-num\">1.2&nbsp;&nbsp;</span>Preparando o dataset</a></div><div class=\"lev3 toc-item\"><a href=\"#Buscando-o-texto-dos-livros-e-definindo-os-rótulos\" data-toc-modified-id=\"Buscando-o-texto-dos-livros-e-definindo-os-rótulos-121\"><span class=\"toc-item-num\">1.2.1&nbsp;&nbsp;</span>Buscando o texto dos livros e definindo os rótulos</a></div><div class=\"lev3 toc-item\"><a href=\"#Representando-as-palavras-através-de-índices-inteiros\" data-toc-modified-id=\"Representando-as-palavras-através-de-índices-inteiros-122\"><span class=\"toc-item-num\">1.2.2&nbsp;&nbsp;</span>Representando as palavras através de índices inteiros</a></div><div class=\"lev3 toc-item\"><a href=\"#Palavras-características-de-cada-livro\" data-toc-modified-id=\"Palavras-características-de-cada-livro-123\"><span class=\"toc-item-num\">1.2.3&nbsp;&nbsp;</span>Palavras características de cada livro</a></div><div class=\"lev2 toc-item\"><a href=\"#Dividindo-o-dataset-entre-treinamento-e-validação\" data-toc-modified-id=\"Dividindo-o-dataset-entre-treinamento-e-validação-13\"><span class=\"toc-item-num\">1.3&nbsp;&nbsp;</span>Dividindo o dataset entre treinamento e validação</a></div><div class=\"lev3 toc-item\"><a href=\"#Divisão-simples\" data-toc-modified-id=\"Divisão-simples-131\"><span class=\"toc-item-num\">1.3.1&nbsp;&nbsp;</span>Divisão simples</a></div><div class=\"lev3 toc-item\"><a href=\"#Divisão-para-uso-com-geradores-e-aumento-de-dados\" data-toc-modified-id=\"Divisão-para-uso-com-geradores-e-aumento-de-dados-132\"><span class=\"toc-item-num\">1.3.2&nbsp;&nbsp;</span>Divisão para uso com geradores e aumento de dados</a></div><div class=\"lev4 toc-item\"><a href=\"#Criando--geradores-para-treino-e-validação\" data-toc-modified-id=\"Criando--geradores-para-treino-e-validação-1321\"><span class=\"toc-item-num\">1.3.2.1&nbsp;&nbsp;</span>Criando  geradores para treino e validação</a></div>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": true,
    "editable": true
   },
   "source": [
    "# Classificação de Textos"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": true,
    "editable": true
   },
   "source": [
    "## Preâmbulo"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n"
     ]
    }
   ],
   "source": [
    "%matplotlib inline\n",
    "import matplotlib.pyplot as plot\n",
    "from IPython import display\n",
    "from __future__ import print_function\n",
    "\n",
    "import os\n",
    "import sys\n",
    "import glob\n",
    "import numpy as np\n",
    "import numpy.random as nr\n",
    "\n",
    "from keras.preprocessing.text import Tokenizer\n",
    "from keras.preprocessing.sequence import pad_sequences\n",
    "from keras.utils import to_categorical\n",
    "from keras.layers import Dense, Input, Flatten, Dropout\n",
    "from keras.layers import Conv1D, MaxPooling1D, Embedding\n",
    "from keras.models import Model\n",
    "from keras.optimizers import (SGD, \n",
    "                              RMSprop, \n",
    "                              Adam, \n",
    "                              Adadelta, \n",
    "                              Adagrad)\n",
    "\n",
    "sys.path.append('../src')\n",
    "from my_keras_utilities import (get_available_gpus, \n",
    "                                load_model_and_history, \n",
    "                                save_model_and_history, \n",
    "                                TrainingPlotter)\n",
    "\n",
    "os.makedirs('../../models',exist_ok=True)\n",
    "np.set_printoptions(precision=3, linewidth=120)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Backend:        tensorflow\n",
      "Data format:    channels_first\n",
      "Available GPUS: []\n",
      "Encoding:       utf-8\n"
     ]
    }
   ],
   "source": [
    "import keras.backend as K\n",
    "\n",
    "# K.set_image_data_format('channels_first')\n",
    "K.set_floatx('float32')\n",
    "\n",
    "print('Backend:        {}'.format(K.backend()))\n",
    "print('Data format:    {}'.format(K.image_data_format()))\n",
    "print('Available GPUS:', get_available_gpus())\n",
    "print('Encoding:      ', sys.getdefaultencoding())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": true,
    "editable": true
   },
   "source": [
    "## Preparando o dataset"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": true,
    "editable": true
   },
   "source": [
    "### Buscando o texto dos livros e definindo os rótulos"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " 427711  Jorge_Amado        Capitaes_de_Areia\n",
      "1030735  Jorge_Amado        Dona_flor_seus_dois_maridos\n",
      " 828417  Jorge_Amado        Gabriela\n",
      "1001226  Jorge_Amado        Tereza_Batista_Cansada_de_Guerra\n",
      " 372459  Machado_de_Assis   Dom_Casmurro\n",
      " 411043  Machado_de_Assis   Esau_e_Jaco\n",
      " 337533  Machado_de_Assis   Helena\n",
      " 336677  Machado_de_Assis   Iaia_Garcia\n",
      " 280683  Machado_de_Assis   Memorial_de_Aires\n",
      " 352965  Machado_de_Assis   Memorias_Postumas_de_Bras_Cubas\n",
      " 443778  Machado_de_Assis   Quincas_Borba\n",
      " 294049  Erico_Verissimo    Clarissa\n",
      " 890215  Erico_Verissimo    Incidente_em_Antares\n",
      " 699390  Erico_Verissimo    O_Tempo_e_o_Vento_-_O_Arquipelago\n",
      " 749265  Erico_Verissimo    O_Tempo_e_o_Vento_-_O_Continente\n",
      "\n",
      "3 Labels:\n",
      "     0: Machado_de_Assis\n",
      "     1: Erico_Verissimo\n",
      "     2: Jorge_Amado\n"
     ]
    }
   ],
   "source": [
    "data_dir = '../../datasets/'\n",
    "\n",
    "autores = [\n",
    "#     'Fernando_Sabino', \n",
    "    'Jorge_Amado',\n",
    "    'Machado_de_Assis',\n",
    "    'Erico_Verissimo',\n",
    "]\n",
    "\n",
    "book_text = []\n",
    "book_author = []\n",
    "book_title = []\n",
    "for aut in autores:\n",
    "    for fn in glob.glob(data_dir + 'livros/' + aut + '*.txt'):\n",
    "        author, book = os.path.basename(fn).split('__')\n",
    "        txt = open(fn, encoding='utf-8').read().replace('\\x97', '')\n",
    "        book_text.append(txt)\n",
    "        book_author.append(author)\n",
    "        book_title.append(book[:-4])\n",
    "        print('{:7d}  {:18s} {}'.format(len(txt), author, book[:-4]))\n",
    "\n",
    "author_list = list(set(book_author))\n",
    "n_labels = len(author_list)\n",
    "n_books = len(book_title)\n",
    "book_label = [author_list.index(a) for a in book_author]\n",
    "print('\\n{} Labels:'.format(n_labels))\n",
    "for i, autor in enumerate(author_list):\n",
    "    print('    {:2d}: {}'.format(i, autor))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": true,
    "editable": true
   },
   "source": [
    "### Representando as palavras através de índices inteiros"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 61707 unique tokens.\n",
      "Using the first 19999 words.\n"
     ]
    }
   ],
   "source": [
    "MAX_NB_WORDS = 20000\n",
    "\n",
    "tokenizer = Tokenizer(num_words=MAX_NB_WORDS)\n",
    "tokenizer.fit_on_texts(book_text)\n",
    "sequences = tokenizer.texts_to_sequences(book_text)\n",
    "\n",
    "w2i = tokenizer.word_index\n",
    "i2w = dict([(v, k) for k, v in w2i.items()])\n",
    "\n",
    "i2w_vec = np.array([i2w[i+1] for i in range(len(i2w))])\n",
    "\n",
    "print('Found %d unique tokens.' % len(i2w))\n",
    "print('Using the first %d words.' % max([max(s) for s in sequences]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true,
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Jorge Amado: Capitaes de Areia -- 76132 palavras\n",
      "partir carregados não mais trabalharam ali os negros musculosos que vieram da escravatura não mais cantou na velha ponte uma canção um iro a areia se estendeu muito alva em frente ao trapiche é nunca mais encheram de fardos de sacos de caixões o imenso casarão ficou abandonado em meio ao areal mancha negra na brancura do cais durante anos foi povoado exclusivamente pelo s ratos que ai atravessavam em corridas que rolam a madeira das portas que o habitavam como senhores exclusivos em certa época um cachorro vagabundo o procurou como refúgio contra o vento e contra a chuva\n",
      "\n",
      "Jorge Amado: Dona flor seus dois maridos -- 166625 palavras\n",
      "no rol do esquecimento aquele assunto do doutor aluísio rábula e sapeca doutor para inglês ver doutor teodoro doutor de verdade de can udo e anel a observava indo e vindo para o armário ela lhe exibiu a camisola tomando a pelos ombros bonita não acha e ele ao ver e achar sentiu um frio no cangote cuidado meu caro não tudo a perder com um gesto brusco uma palavra forte recomendou se o noivo mais uma vez prudência e tato se nesses sete dias de lua de mel no paraíso de são tomé nos longes de paripe em casa\n",
      "\n",
      "Jorge Amado: Gabriela -- 134498 palavras\n",
      "sob aplausos ela retirou se para voltar minutos depois num segundo número mais sensacional ainda coberta de véus multicores que iam caindo um a um como anunciara mundinho e durante um breve minuto quando ca iu o último véu e as luzes novamente se acenderam puderam ver o corpo magro e bem feito quase nu apenas uma mínima e um trapo vermelho sobre os seios pequenos a sala gritava em coro reclamava bis anabela passava correndo entre as mesas o el ribeirinho mandava descer champanha agora valeu a pena até nhô galo estava entusiasmado anabela e o príncipe foram para\n",
      "\n",
      "Jorge Amado: Tereza Batista Cansada de Guerra -- 164906 palavras\n",
      "razão à prima beatriz devassa e maternal o fulgor dos olhos não passara com certeza de raio de sol a iluminar lhe a vista paciência sendo a capacidade de conhecer e as pessoas elemento fundamental para o comando pelo doutor senhor de terras e capitão de indústrias banqueiro sentia se vaidoso de acertar no julgamento à primeira vista e por isso mesmo era lhe difícil esconder o desaponto quando a decepção o fez vol jorge amado tar se para o juiz substituto precisando descarregar em alguém o despeito a lhe amargar a boca dirigiu se à prefeitura onde se o\n",
      "\n",
      "Machado de Assis: Dom Casmurro -- 64547 palavras\n",
      "me que não era mais que uma sensação fulgurante destinada a morrer com a noite e o sono há remorsos que não nascem de outro pecado nem têm maior duração agarrei me a esta hipótese que se com a mão de sancha que eu sentia de memória dentro da minha mão quente e demorada apertada e apertando sinceramente eu achava me mal entre um amigo e a atração a timidez pode ser que fosse outra causa daquela crise não é só o céu que dá as nossas virtudes a timidez também não contando o acaso mas o acaso é um\n",
      "\n",
      "Machado de Assis: Esau e Jaco -- 70153 palavras\n",
      "este nome mas a totalidade das vinha a dar nele de honesto e era uma pérola concluiu santos foi a última palavra da paz aos mortos dali em diante vingou a da criança que não os hábitos nos primeiros tempos e as visitas e os bailes continuaram como dantes até que pouco a pouco natividade se fechou totalmente em casa as amigas iam vê la os amigos iam visitá los ou jogar cartas com o marido natividade queria um filho santos uma filha e cada um a sua escolha com tão boas razões que acabavam trocando de parecer então ela\n",
      "\n",
      "Machado de Assis: Helena -- 54778 palavras\n",
      "opiniões feitas que importa grande número de jovens políticos seguem não uma opinião e escolhida mas a do círculo de suas afeições a que os pais ou amigos e a que as circunstâncias lhe daí vêm algumas legítimas posteriores tarde ou cedo o temperamento domina as circunstâncias da origem e do botão luzia ou saquarema nasce um magnífico lírio saquarema ou luzia demais a política é ciência prática e eu desconto de teorias que só são teorias entre primeiro na câmara a experiência e o estudo dos homens e das coisas lhe a que lado se deve inclinar estácio ouviu\n",
      "\n",
      "Machado de Assis: Iaia Garcia -- 55342 palavras\n",
      "mal e dominou se quando se achou só consigo deu livre campo às angústias encarou a catástrofe e pensou nas conseqüências da morte e no incerto futuro que a aguardava dentro de poucos dias o futuro trouxe a ao presente o presente levou a ao passado a vida só lhe dera alegrias e dores máximas não foi a paixão que a levou ao casamento mas somente a conveniência e o raciocínio no casamento achara os sentimentos de apreço a mútua consideração a brandura das relações domésticas esse fogo porém cuja intensidade não dura mas que é o sol dos primeiros\n",
      "\n",
      "Machado de Assis: Memorial de Aires -- 50033 palavras\n",
      "se mostram tão mana rita a quem esta impressão acha também que é assim acrescenta porém uma reflexão mais fina que essa e não tenho dúvida em a escrever aqui ao pé da minha tanto mais que lhe repliquei com outra não menos fina que a sua vá este elogio a nós ambos sempre há de haver quem nos um pouco e aí fica já a compensação nem custa muito elogiar se a gente a si mesma eis o que me disse a mana esse sentimento há de custar pouco ao tristão estando aqui de passagem ao que eu repliquei\n",
      "\n",
      "Machado de Assis: Memorias Postumas de Bras Cubas -- 58580 palavras\n",
      "fase é a da substância não o seu etc vai aonde te chamam não esqueças porém que és o meu e vede agora a minha modéstia me na ordem terceira de ali alguns cargos foi essa a fase mais brilhante da minha vida não obstante calo me não digo nada não conto os meus serviços o que fiz aos pobres e aos enfermos nem as que recebi nada não digo absolutamente nada talvez a economia social pudesse ganhar alguma coisa se eu mostrasse como todo e qualquer prêmio estranho vale pouco ao lado do prêmio e imediato mas seria romper\n",
      "\n",
      "Machado de Assis: Quincas Borba -- 74965 palavras\n",
      "após alguns minutos respondeu que não era nada perdera o costume de fazer discursos é o que era e afastando com o gesto a pessoa de rubião a fim de poder encará la sem esforço uma brilhante descrição do mundo e suas excelências idéias próprias e alheias imagens de toda sorte a tal ponto que rubião perguntava a si mesmo como é que um homem que ia morrer dali a dias podia tratar tão aqueles negócios ande repousar um pouco quincas borba refletiu não vou dar um passeio agora não você está muito cansado qual passou ergueu se e pôs\n",
      "\n",
      "Erico Verissimo: Clarissa -- 47827 palavras\n",
      "frenesi agita se olhos momentaneamente brilhantes sacode os braços ao ritmo da faz um esforço desesperado para se levantar e por fim impotente põe se a com os punhos fechados a guarda da sua cadeira de rodas numa raiva histérica o som dos clarins e dos tambores perde se ao longe o batalhão passa o menino doente se seu rosto retoma a antiga imobilidade os olhos de novo caem na sombra morrem clarissa tem uma pena infinita do seu pobre vizinho mutilado meu deus reflecte ela como é que o senhor permite essas coisas como é por que é que\n",
      "\n",
      "Erico Verissimo: Incidente em Antares -- 144785 palavras\n",
      "à capital do estado explicar pessoalmente “o isto é os ao governador aos jornais e às estações de rádio e televisão para que ficasse limpo o nome de an tares o mendes que voltara à reunião disse – com a permissão aqui do meu ilustre chefe proponho que se agora os membros da comissão executiva da operação borracha – e de novo sentindo se o mais vil e servil dos mortais acrescentou – proponho que o nosso cel tibério vacariano seja eleito por aclamação seu presidente de aplausos unânimes xcii a verdade porém é que por artes do repórter da\n",
      "\n",
      "Erico Verissimo: O Tempo e o Vento - O Arquipelago -- 115533 palavras\n",
      "o artigo autêntico foi para mim uma decepção torna a sentar se — bom contigo deve ter sido diferente — continua — tens bom físico fêmeas de verdade que te amaram ou pelo menos se entregaram a ti por desejo mas olha para esta cara para este corpo achas que alguma mulher de bom gosto pode ir para a cama comigo por desejo não precisas responder tens receio de ferir as pessoas és uma verdadeira irmã paula mas não aí com essa cara esta me tem trazido também algumas vantagens por exemplo impediu que alguma mulher quisesse casar comigo assim\n",
      "\n",
      "Erico Verissimo: O Tempo e o Vento - O Continente -- 129346 palavras\n",
      "pudesse fazer parar o pensamento l licurgo mas o licurgo não vai casar com a irmã dela a alice claro mas a maria valéria também gosta dele licurgo escolheu a outra coisas da vida sorte é bobagem licurgo sorte é bobagem alice casou maria valéria vai ficar solteirona o resto da vida l licurgo maria valéria chega ao patamar fica um instante ali parada sentindo as faces só o pensar nessas coisas me dá uma vergonha decerto estou vermelha melhor é ir ver os meninos aproxima se da porta do quarto dos sobrinhos abre a devagarinho faz avançar a mão\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# escolhe e imprime uma sequencia aleatoria de cada livro\n",
    "rseq_len = 100\n",
    "for i, seq in enumerate(sequences):\n",
    "    k = nr.randint(len(seq) - rseq_len)\n",
    "    print('{}: {} -- {} palavras'.format(book_author[i], book_title[i], len(seq)).replace('_', ' '))\n",
    "    print(' '.join([i2w[x] for x in seq[k:k+rseq_len]]), end='\\n\\n')\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": true,
    "editable": true
   },
   "source": [
    "### Palavras características de cada livro"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[['trapiche' 'bedel' 'ester' 'barandão' 'almiro' 'dora' '–' 'pirulito']\n",
      " ['marilda' 'dinorá' 'teodoro' 'pelancchi' 'gisa' 'mirandão' 'rozilda' 'vadinho']\n",
      " ['tuísca' 'tonico' 'ribeirinho' 'malvina' 'amâncio' 'fulgêncio' 'gabriela' 'nacib']\n",
      " ['vavá' 'almério' 'januário' '—' 'dóris' 'brígida' 'justiniano' 'tereza']\n",
      " ['manduca' 'protonotário' 'bentinho' 'sancha' 'pádua' 'justina' 'escobar' 'capitu']\n",
      " ['coupé' 'gêmeos' 'excia' 'nóbrega' 'custódio' 'natividade' 'flora' 'cláudia']\n",
      " ['ângela' 'eugênia' 'tomásia' 'melchior' 'helena' 'camargo' 'estácio' 'úrsula']\n",
      " ['procópio' 'valéria' 'jorge' 'garcia' 'madrasta' 'enteada' 'iaiá' 'estela']\n",
      " ['carmo' 'libertos' 'prainha' 'noronha' 'cesária' 'aguiar' 'fidélia' 'tristão']\n",
      " ['damasceno' 'eusébia' 'cubas' 'borba' 'sabina' 'cotrim' 'marcela' 'virgília']\n",
      " ['camacho' 'teófilo' 'tonica' 'borba' 'sofia' 'fernanda' 'benedita' 'rubião']\n",
      " ['gamaliel' 'dudu' 'eufrasina' 'tatá' 'belmira' 'tónico' 'zina' 'clarissa']\n",
      " ['campolargo' 'vacariano' 'vivaldino' 'getúlio' 'quitéria' '–' 'tibério' 'antares']\n",
      " ['dinda' 'alicinha' 'toríbio' 'chiru' 'stein' 'camerino' '—' 'rodrigo']\n",
      " ['maneco' 'amaral' 'lara' 'vosmecê' 'bibiana' '—' 'alonzo' 'rodrigo']]\n"
     ]
    }
   ],
   "source": [
    "tfidf = tokenizer.sequences_to_matrix(sequences, mode='tfidf')\n",
    "ww = np.argsort(tfidf, axis=1)[:, -8:]\n",
    "print(i2w_vec[ww-1])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": true,
    "editable": true
   },
   "source": [
    "## Dividindo o dataset entre treinamento e validação"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": true,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "nr.seed(20170607)\n",
    "\n",
    "batch_size  = 32\n",
    "seq_size    = 500\n",
    "valid_split = 0.2"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": true,
    "editable": true
   },
   "source": [
    "### Divisão simples"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Sequencias obtidas para cada autor: [854, 873, 1082]\n",
      "O dataset conterá 854 sequencias por autor, totalizando 2562 sequencias.\n",
      "\n",
      "Dataset shapes: (2562, 500) (2562,)\n"
     ]
    }
   ],
   "source": [
    "all_data = [[] for i in range(n_labels)]\n",
    "\n",
    "# divide cada livro em sequencias de 'seq_size' words\n",
    "# 'all_data' contem as sequencias agrupadas por autor\n",
    "for sequence, label in zip(sequences, book_label):\n",
    "    n_seqs = len(sequence) // seq_size\n",
    "    for i in range(n_seqs):\n",
    "        beg = i * seq_size\n",
    "        all_data[label].append(sequence[beg:beg+seq_size])\n",
    "\n",
    "print('Sequencias obtidas para cada autor:', [len(x) for x in all_data])\n",
    "\n",
    "# balanceando o dataset:\n",
    "# calcula o numero de sequencias, N, de forma que o dataset \n",
    "# contenha N sequencias para cada autor\n",
    "N = min([len(x) for x in all_data])\n",
    "print('O dataset conterá {} sequencias por autor, totalizando {} sequencias.'.format(N, 3*N))\n",
    "\n",
    "all_data = np.array([seq[:N] for seq in all_data], np.int32).reshape(-1, seq_size)\n",
    "all_labels = np.array([[i] * N for i in range(n_labels)], np.int32).reshape(-1)\n",
    "print('\\nDataset shapes:', all_data.shape, all_labels.shape)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(2049, 500) (2049,) (513, 500) (513,)\n"
     ]
    }
   ],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "Xtra, Xval, ytra, yval = train_test_split(all_data, all_labels, test_size=valid_split)\n",
    "print(Xtra.shape, ytra.shape, Xval.shape, yval.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "fn = data_dir + 'livros_sequences_{}.npz'.format(seq_size)\n",
    "np.savez_compressed(fn, Xtra=Xtra, Xval=Xval, ytra=ytra, yval=yval, i2w=i2w_vec[:MAX_NB_WORDS])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": true,
    "editable": true
   },
   "source": [
    "### Divisão para uso com geradores e aumento de dados"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training sequences:\n",
      "-------------------\n",
      " 1. Jorge_Amado      (2) --  51751 palavras do início do livro Capitaes_de_Areia\n",
      " 2. Jorge_Amado      (2) --  48828 palavras do início do livro Dona_flor_seus_dois_maridos\n",
      " 3. Jorge_Amado      (2) --  99312 palavras do início do livro Gabriela\n",
      " 4. Jorge_Amado      (2) --  98707 palavras do início do livro Tereza_Batista_Cansada_de_Guerra\n",
      " 5. Machado_de_Assis (0) --   4178 palavras do início do livro Dom_Casmurro\n",
      " 6. Machado_de_Assis (0) --  17944 palavras do início do livro Esau_e_Jaco\n",
      " 7. Machado_de_Assis (0) --   7268 palavras do início do livro Helena\n",
      " 8. Machado_de_Assis (0) --  37856 palavras do início do livro Iaia_Garcia\n",
      " 9. Machado_de_Assis (0) --  21315 palavras do início do livro Memorial_de_Aires\n",
      "10. Machado_de_Assis (0) --   4275 palavras do início do livro Memorias_Postumas_de_Bras_Cubas\n",
      "11. Machado_de_Assis (0) --  33413 palavras do início do livro Quincas_Borba\n",
      "12. Erico_Verissimo  (1) --   4857 palavras do início do livro Clarissa\n",
      "13. Erico_Verissimo  (1) --  19928 palavras do início do livro Incidente_em_Antares\n",
      "14. Erico_Verissimo  (1) --  33701 palavras do início do livro O_Tempo_e_o_Vento_-_O_Arquipelago\n",
      "15. Erico_Verissimo  (1) --  81144 palavras do início do livro O_Tempo_e_o_Vento_-_O_Continente\n",
      "16. Jorge_Amado      (2) --   9155 palavras do final do livro  Capitaes_de_Areia\n",
      "17. Jorge_Amado      (2) --  84472 palavras do final do livro  Dona_flor_seus_dois_maridos\n",
      "18. Jorge_Amado      (2) --   8287 palavras do final do livro  Gabriela\n",
      "19. Jorge_Amado      (2) --  33218 palavras do final do livro  Tereza_Batista_Cansada_de_Guerra\n",
      "20. Machado_de_Assis (0) --  47460 palavras do final do livro  Dom_Casmurro\n",
      "21. Machado_de_Assis (0) --  38179 palavras do final do livro  Esau_e_Jaco\n",
      "22. Machado_de_Assis (0) --  36555 palavras do final do livro  Helena\n",
      "23. Machado_de_Assis (0) --   6418 palavras do final do livro  Iaia_Garcia\n",
      "24. Machado_de_Assis (0) --  18712 palavras do final do livro  Memorial_de_Aires\n",
      "25. Machado_de_Assis (0) --  42589 palavras do final do livro  Memorias_Postumas_de_Bras_Cubas\n",
      "26. Machado_de_Assis (0) --  26559 palavras do final do livro  Quincas_Borba\n",
      "27. Erico_Verissimo  (1) --  33405 palavras do final do livro  Clarissa\n",
      "28. Erico_Verissimo  (1) --  95900 palavras do final do livro  Incidente_em_Antares\n",
      "29. Erico_Verissimo  (1) --  58726 palavras do final do livro  O_Tempo_e_o_Vento_-_O_Arquipelago\n",
      "30. Erico_Verissimo  (1) --  22333 palavras do final do livro  O_Tempo_e_o_Vento_-_O_Continente\n",
      "\n",
      "Validation sequences:\n",
      "---------------------\n",
      " 1. Jorge_Amado      (2) --  15226 palavras do meio do livro Capitaes_de_Areia\n",
      " 2. Jorge_Amado      (2) --  33325 palavras do meio do livro Dona_flor_seus_dois_maridos\n",
      " 3. Jorge_Amado      (2) --  26899 palavras do meio do livro Gabriela\n",
      " 4. Jorge_Amado      (2) --  32981 palavras do meio do livro Tereza_Batista_Cansada_de_Guerra\n",
      " 5. Machado_de_Assis (0) --  12909 palavras do meio do livro Dom_Casmurro\n",
      " 6. Machado_de_Assis (0) --  14030 palavras do meio do livro Esau_e_Jaco\n",
      " 7. Machado_de_Assis (0) --  10955 palavras do meio do livro Helena\n",
      " 8. Machado_de_Assis (0) --  11068 palavras do meio do livro Iaia_Garcia\n",
      " 9. Machado_de_Assis (0) --  10006 palavras do meio do livro Memorial_de_Aires\n",
      "10. Machado_de_Assis (0) --  11716 palavras do meio do livro Memorias_Postumas_de_Bras_Cubas\n",
      "11. Machado_de_Assis (0) --  14993 palavras do meio do livro Quincas_Borba\n",
      "12. Erico_Verissimo  (1) --   9565 palavras do meio do livro Clarissa\n",
      "13. Erico_Verissimo  (1) --  28957 palavras do meio do livro Incidente_em_Antares\n",
      "14. Erico_Verissimo  (1) --  23106 palavras do meio do livro O_Tempo_e_o_Vento_-_O_Arquipelago\n",
      "15. Erico_Verissimo  (1) --  25869 palavras do meio do livro O_Tempo_e_o_Vento_-_O_Continente\n",
      "\n",
      "Total number of training words:   1126445\n",
      "Total number of validation words: 281605\n"
     ]
    }
   ],
   "source": [
    "valid_length = [int(0.2 * len(x)) for x in sequences]\n",
    "valid_start = [nr.randint(2000, len(x) - 2000 - n) for x, n in zip(sequences, valid_length)]\n",
    "\n",
    "valid_sequences = [seq[x0:x0+n] for seq, x0, n in zip(sequences, valid_start, valid_length)]\n",
    "\n",
    "train_sequences = [seq[:x0] for seq, x0 in zip(sequences, valid_start)] + \\\n",
    "                  [seq[x0+n:] for seq, x0, n in zip(sequences, valid_start, valid_length)]\n",
    "\n",
    "valid_labels = book_label\n",
    "train_labels = book_label + book_label\n",
    "\n",
    "n_train_words = sum([len(x) for x in train_sequences])\n",
    "n_valid_words = sum([len(x) for x in valid_sequences])\n",
    "\n",
    "print('Training sequences:')\n",
    "print('-------------------')\n",
    "for i, (seq, lab) in enumerate(zip(train_sequences, train_labels)):\n",
    "    if i < n_books:\n",
    "        print('{:2d}. {:16s} ({}) -- {:6d} palavras do início do livro {}'.format(i+1, book_author[i%n_books], lab,\n",
    "                                                                                  len(seq), book_title[i%n_books]))\n",
    "    else:\n",
    "        print('{:2d}. {:16s} ({}) -- {:6d} palavras do final do livro  {}'.format(i+1, book_author[i%n_books], lab,\n",
    "                                                                                  len(seq), book_title[i%n_books]))\n",
    "print()\n",
    "print('Validation sequences:')\n",
    "print('---------------------')\n",
    "for i, (seq, lab) in enumerate(zip(valid_sequences, valid_labels)):\n",
    "    print('{:2d}. {:16s} ({}) -- {:6d} palavras do meio do livro {}'.format(i+1, book_author[i%n_books], lab,\n",
    "                                                                            len(seq), book_title[i%n_books]))\n",
    "print()\n",
    "print('Total number of training words:  ', n_train_words)\n",
    "print('Total number of validation words:', n_valid_words)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": true,
    "editable": true
   },
   "source": [
    "#### Criando  geradores para treino e validação"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "collapsed": true,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "class MyDataGenerator:\n",
    "    def __init__(self, batch_size, seq_size, sequences, labels):\n",
    "        self.batch_size = batch_size\n",
    "        self.length = seq_size\n",
    "        self.sequences = sequences\n",
    "        self.labels = labels\n",
    "        sizes = np.array([len(seq) for seq in sequences])\n",
    "        self.p = 1.0 * sizes / sizes.sum()        # probabilidade de escolha para cada sequencia\n",
    "        self.n = np.arange(len(sequences))        # indices de cada sequencia (para o choice abaixo)\n",
    "        \n",
    "    def __call__(self):\n",
    "        while True:\n",
    "            batch = np.empty((self.batch_size, self.length), np.int32)\n",
    "            label = np.empty((self.batch_size, n_labels), np.int32)\n",
    "            for i in range(self.batch_size):\n",
    "                k = nr.choice(self.n, p=self.p)\n",
    "                p = nr.randint(0, len(self.sequences[k]) - self.length)\n",
    "                batch[i] = self.sequences[k][p:p+self.length]\n",
    "                label[i] = to_categorical(self.labels[k], num_classes=n_labels)\n",
    "            yield batch, label\n",
    "\n",
    "            \n",
    "train_gen = MyDataGenerator(batch_size, seq_size, train_sequences, train_labels)\n",
    "valid_gen = MyDataGenerator(batch_size, seq_size, valid_sequences, valid_labels)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "import pickle\n",
    "fn = data_dir + 'livros_generators_{}.pkl'.format(seq_size)\n",
    "pickle.dump([train_gen, valid_gen, i2w_vec[:MAX_NB_WORDS]], open(fn, 'wb'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.0"
  },
  "latex_envs": {
   "LaTeX_envs_menu_present": true,
   "autocomplete": true,
   "bibliofile": "biblio.bib",
   "cite_by": "apalike",
   "current_citInitial": 1,
   "eqLabelWithNumbers": true,
   "eqNumInitial": 1,
   "hotkeys": {
    "equation": "Ctrl-E",
    "itemize": "Ctrl-I"
   },
   "labels_anchors": false,
   "latex_user_defs": false,
   "report_style_numbering": false,
   "user_envs_cfg": false
  },
  "toc": {
   "colors": {
    "hover_highlight": "#DAA520",
    "navigate_num": "#000000",
    "navigate_text": "#333333",
    "running_highlight": "#FF0000",
    "selected_highlight": "#FFD700",
    "sidebar_border": "#EEEEEE",
    "wrapper_background": "#FFFFFF"
   },
   "moveMenuLeft": true,
   "nav_menu": {
    "height": "264px",
    "width": "252px"
   },
   "navigate_menu": true,
   "number_sections": true,
   "sideBar": true,
   "threshold": 4,
   "toc_cell": true,
   "toc_section_display": "block",
   "toc_window_display": false,
   "widenNotebook": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
