{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": true,
    "editable": true,
    "toc": "true"
   },
   "source": [
    "# Table of Contents\n",
    " <p><div class=\"lev1 toc-item\"><a href=\"#Classificação-de-Textos\" data-toc-modified-id=\"Classificação-de-Textos-1\"><span class=\"toc-item-num\">1&nbsp;&nbsp;</span>Classificação de Textos</a></div><div class=\"lev2 toc-item\"><a href=\"#Preâmbulo\" data-toc-modified-id=\"Preâmbulo-11\"><span class=\"toc-item-num\">1.1&nbsp;&nbsp;</span>Preâmbulo</a></div><div class=\"lev2 toc-item\"><a href=\"#Preparando-o-dataset\" data-toc-modified-id=\"Preparando-o-dataset-12\"><span class=\"toc-item-num\">1.2&nbsp;&nbsp;</span>Preparando o dataset</a></div><div class=\"lev3 toc-item\"><a href=\"#Buscando-o-texto-dos-livros-e-definindo-os-rótulos\" data-toc-modified-id=\"Buscando-o-texto-dos-livros-e-definindo-os-rótulos-121\"><span class=\"toc-item-num\">1.2.1&nbsp;&nbsp;</span>Buscando o texto dos livros e definindo os rótulos</a></div><div class=\"lev3 toc-item\"><a href=\"#Representando-as-palavras-através-de-índices-inteiros\" data-toc-modified-id=\"Representando-as-palavras-através-de-índices-inteiros-122\"><span class=\"toc-item-num\">1.2.2&nbsp;&nbsp;</span>Representando as palavras através de índices inteiros</a></div><div class=\"lev3 toc-item\"><a href=\"#Palavras-características-de-cada-livro\" data-toc-modified-id=\"Palavras-características-de-cada-livro-123\"><span class=\"toc-item-num\">1.2.3&nbsp;&nbsp;</span>Palavras características de cada livro</a></div><div class=\"lev2 toc-item\"><a href=\"#Dividindo-o-dataset-entre-treinamento-e-validação\" data-toc-modified-id=\"Dividindo-o-dataset-entre-treinamento-e-validação-13\"><span class=\"toc-item-num\">1.3&nbsp;&nbsp;</span>Dividindo o dataset entre treinamento e validação</a></div><div class=\"lev3 toc-item\"><a href=\"#Divisão-simples\" data-toc-modified-id=\"Divisão-simples-131\"><span class=\"toc-item-num\">1.3.1&nbsp;&nbsp;</span>Divisão simples</a></div><div class=\"lev3 toc-item\"><a href=\"#Divisão-para-uso-com-geradores-e-aumento-de-dados\" data-toc-modified-id=\"Divisão-para-uso-com-geradores-e-aumento-de-dados-132\"><span class=\"toc-item-num\">1.3.2&nbsp;&nbsp;</span>Divisão para uso com geradores e aumento de dados</a></div><div class=\"lev4 toc-item\"><a href=\"#Criando--geradores-para-treino-e-validação\" data-toc-modified-id=\"Criando--geradores-para-treino-e-validação-1321\"><span class=\"toc-item-num\">1.3.2.1&nbsp;&nbsp;</span>Criando  geradores para treino e validação</a></div>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": true,
    "editable": true
   },
   "source": [
    "# Classificação de Textos"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": true,
    "editable": true
   },
   "source": [
    "## Preâmbulo"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n"
     ]
    }
   ],
   "source": [
    "%matplotlib inline\n",
    "import matplotlib.pyplot as plot\n",
    "from IPython import display\n",
    "from __future__ import print_function\n",
    "\n",
    "import os\n",
    "import sys\n",
    "import glob\n",
    "import numpy as np\n",
    "import numpy.random as nr\n",
    "\n",
    "from keras.preprocessing.text import Tokenizer\n",
    "from keras.preprocessing.sequence import pad_sequences\n",
    "from keras.utils import to_categorical\n",
    "from keras.layers import Dense, Input, Flatten, Dropout\n",
    "from keras.layers import Conv1D, MaxPooling1D, Embedding\n",
    "from keras.models import Model\n",
    "from keras.optimizers import (SGD, \n",
    "                              RMSprop, \n",
    "                              Adam, \n",
    "                              Adadelta, \n",
    "                              Adagrad)\n",
    "\n",
    "sys.path.append('../src')\n",
    "from my_keras_utilities import (get_available_gpus, \n",
    "                                load_model_and_history, \n",
    "                                save_model_and_history, \n",
    "                                TrainingPlotter)\n",
    "\n",
    "os.makedirs('../../models',exist_ok=True)\n",
    "np.set_printoptions(precision=3, linewidth=120)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Backend:        tensorflow\n",
      "Data format:    channels_last\n",
      "Available GPUS: ['/gpu:0']\n",
      "Encoding:       utf-8\n"
     ]
    }
   ],
   "source": [
    "import keras.backend as K\n",
    "\n",
    "# K.set_image_data_format('channels_first')\n",
    "K.set_floatx('float32')\n",
    "\n",
    "print('Backend:        {}'.format(K.backend()))\n",
    "print('Data format:    {}'.format(K.image_data_format()))\n",
    "print('Available GPUS:', get_available_gpus())\n",
    "print('Encoding:      ', sys.getdefaultencoding())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": true,
    "editable": true
   },
   "source": [
    "## Preparando o dataset"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": true,
    "editable": true
   },
   "source": [
    "### Buscando o texto dos livros e definindo os rótulos"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1001226  Jorge_Amado        Tereza_Batista_Cansada_de_Guerra\n",
      "1030735  Jorge_Amado        Dona_flor_seus_dois_maridos\n",
      " 427711  Jorge_Amado        Capitaes_de_Areia\n",
      " 828417  Jorge_Amado        Gabriela\n",
      " 352965  Machado_de_Assis   Memorias_Postumas_de_Bras_Cubas\n",
      " 280683  Machado_de_Assis   Memorial_de_Aires\n",
      " 411043  Machado_de_Assis   Esau_e_Jaco\n",
      " 372459  Machado_de_Assis   Dom_Casmurro\n",
      " 336677  Machado_de_Assis   Iaia_Garcia\n",
      " 443778  Machado_de_Assis   Quincas_Borba\n",
      " 337533  Machado_de_Assis   Helena\n",
      " 294049  Erico_Verissimo    Clarissa\n",
      " 890215  Erico_Verissimo    Incidente_em_Antares\n",
      " 749265  Erico_Verissimo    O_Tempo_e_o_Vento_-_O_Continente\n",
      " 699390  Erico_Verissimo    O_Tempo_e_o_Vento_-_O_Arquipelago\n",
      "\n",
      "3 Labels:\n",
      "     0: Machado_de_Assis\n",
      "     1: Jorge_Amado\n",
      "     2: Erico_Verissimo\n"
     ]
    }
   ],
   "source": [
    "data_dir = '../../datasets/'\n",
    "\n",
    "autores = [\n",
    "#     'Fernando_Sabino', \n",
    "    'Jorge_Amado',\n",
    "    'Machado_de_Assis',\n",
    "    'Erico_Verissimo',\n",
    "]\n",
    "\n",
    "book_text = []\n",
    "book_author = []\n",
    "book_title = []\n",
    "for aut in autores:\n",
    "    for fn in glob.glob(data_dir + 'livros/' + aut + '*.txt'):\n",
    "        author, book = os.path.basename(fn).split('__')\n",
    "        txt = open(fn, encoding='utf-8').read().replace('\\x97', '')\n",
    "        book_text.append(txt)\n",
    "        book_author.append(author)\n",
    "        book_title.append(book[:-4])\n",
    "        print('{:7d}  {:18s} {}'.format(len(txt), author, book[:-4]))\n",
    "\n",
    "author_list = list(set(book_author))\n",
    "n_labels = len(author_list)\n",
    "n_books = len(book_title)\n",
    "book_label = [author_list.index(a) for a in book_author]\n",
    "print('\\n{} Labels:'.format(n_labels))\n",
    "for i, autor in enumerate(author_list):\n",
    "    print('    {:2d}: {}'.format(i, autor))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": true,
    "editable": true
   },
   "source": [
    "### Representando as palavras através de índices inteiros"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 61707 unique tokens.\n",
      "Using the first 19999 words.\n"
     ]
    }
   ],
   "source": [
    "MAX_NB_WORDS = 20000\n",
    "\n",
    "tokenizer = Tokenizer(num_words=MAX_NB_WORDS)\n",
    "tokenizer.fit_on_texts(book_text)\n",
    "sequences = tokenizer.texts_to_sequences(book_text)\n",
    "\n",
    "w2i = tokenizer.word_index\n",
    "i2w = dict([(v, k) for k, v in w2i.items()])\n",
    "\n",
    "i2w_vec = np.array([i2w[i+1] for i in range(len(i2w))])\n",
    "\n",
    "print('Found %d unique tokens.' % len(i2w))\n",
    "print('Using the first %d words.' % max([max(s) for s in sequences]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true,
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Jorge Amado: Tereza Batista Cansada de Guerra -- 164693 palavras\n",
      "e louca correria sem bagagem e sem despedida vou a aracaju em busca de socorro o doutorzinho embarcou no trem errado se de rumo e de ah quanto mais longe melhor a bexiga chegou com raiva tinha gana antiga contra a população e o lugar viera a propósito determinada a matar fazendo o com maestria frieza e morte feia e ruim bexiga mais virulenta antes e d da peste seis meses antes ou três anos depois diz ainda tereza batista cansada de guerra c hoje o povo situando a divisão do tempo em calendário próprio tomando como marco das eras\n",
      "\n",
      "Jorge Amado: Dona flor seus dois maridos -- 165910 palavras\n",
      "ter tanta despesa fizera b em pois na véspera a própria dona flor assustada ordenara todas aquelas providências obrigada minha comadre por tanto trabalho que eu lhe dou agora no entanto já nada importa bem ou mal tudo se resolveu o finado deixou de ar dona flor sorriu com embaraço e disse ou eu deixei de me assombrar já não preciso de mais nada e agora suspender o trabalho era impossível durante a noite e pela madrugada tinham feito o sacrifício dos animais e ao primeiro do sol puseram diante de cada orixá a com sua comida ritual por todo\n",
      "\n",
      "Jorge Amado: Capitaes de Areia -- 75965 palavras\n",
      "reformatório cumpra a sua santa missão de educar os seus filhos elas os criam na rua na e como eles aqui são a uma vida exemplar elas são as primeiras a reclamar quando deviam beijar as mãos daqueles que estão fazendo dos seus filhos homens de bem primeiro vêm pedir lugar para os filhos depois sentem falta deles do produto dos furtos que eles levam para casa e então saem a reclamar contra o reformatório mas como já disse senhor diretor esta carta não me preocupou não é uma mulherzinha do povo quem há de compreender a obra que estou\n",
      "\n",
      "Jorge Amado: Gabriela -- 134042 palavras\n",
      "lindeza de neta é capaz jerusa retirava as xícaras dava um recado avô tio tonico chegou pergunta se pode vir aqui ramiro olhou para altino que d coronel conversa particular pra seu tonico não é seu filho diga a ele que venha tonico surgia de colete e polainas altino levantou se foi envolvido num abraço cordial um vira bosta pensou o fazendeiro pois coronel é co m muita satisfação que vejo o senhor nessa casa quase nunca aparece sou homem do mato só saio do rio do braço quando não tenho outro jeito é de lá pras águas claras que\n",
      "\n",
      "Machado de Assis: Memorias Postumas de Bras Cubas -- 58712 palavras\n",
      "bacharel único filho de seu casamento que na idade de cinco anos fora cúmplice inconsciente de nossos amores vieram juntos dois dias depois e confesso que ao vê los ali na minha alcova fui tomado de um acanhamento que nem me permitiu corresponder logo às palavras do rapaz virgília adivinhou me e disse ao filho nhonhô não nesse grande que aí está não quer falar para fazer crer que está à morte sorriu o filho eu creio que também sorri e tudo acabou em pura galhofa virgília estava serena e risonha tinha o aspecto das vidas nenhum olhar suspeito nenhum\n",
      "\n",
      "Machado de Assis: Memorial de Aires -- 50091 palavras\n",
      "também assim penso da cegueira que me daria a paixão vejo claro que a escolha é perfeita já tivemos ocasião de falar nela e no parecer digo lhe até que foi esse o motivo que me levou a confessar me hoje lembra se que há algum tempo em sua casa almoçando em achar lhe todas as prendas morais e físicas compreendi que me e resolvi falar lhe acerca deste sentimento e seus efeitos a resposta estava dada como diz não há consulta nova há ainda lhe não disse tudo pois diga o resto disponho me a ouvi lo como se\n",
      "\n",
      "Machado de Assis: Esau e Jaco -- 70277 palavras\n",
      "las bater e recuar gostava delas assim achava lhes uma espécie de alma forte que as movia para meter medo à terra a água se em si mesma dava lhe uma sensação mais que de vida de pessoa também a que não faltavam nervos nem músculos nem a voz que bradava as suas cóleras enfim cansou e desceu foi se ao lago ao arvoredo e passeou à toa revivendo homens e coisas até que se sentou em um banco notou que a pouca gente que havia ali não estava sentada como de costume olhando à toa lendo gazetas ou cochilando\n",
      "\n",
      "Machado de Assis: Dom Casmurro -- 64659 palavras\n",
      "e os clarins soltam as notas que dormiam no metal e tudo marcha com uma alma imprevista é que tudo se acha fora de um livro falho leitor amigo assim as lacunas alheias assim podes também as minhas capítulo lx querido opúsculo assim fiz eu ao panegírico de santa mônica e fiz mais pus lhe não só o que faltava da santa mas ainda coisas que não eram dela viste o soneto as meias as ligas o seminarista escobar e vários outros vais agora ver o mais que naquele dia me foi saindo das páginas amarelas do opúsculo querido opúsculo\n",
      "\n",
      "Machado de Assis: Iaia Garcia -- 55418 palavras\n",
      "de refletir na possibilidade de um estranho inclinou se também e perguntou lhe afetuosamente o que tinha iaiá ergueu a cabeça e enxugou os olhos mas não respondeu nada a senhora não tem confiança em mim disse jorge há coisas que se não fazem outras que se não dizem algumas ficarão entre mim e deus retorquiu ela como se fizesse uma reflexão para si depois fitou o e pediu lhe a promessa de que não diria nada do que acabava de ver e ouvir essa promessa não se faz está feita por si quanto ao seu segredo não quero lo\n",
      "\n",
      "Machado de Assis: Quincas Borba -- 75071 palavras\n",
      "nenhum carioca pode crer que exista em outra parte do mundo a figura de sofia passou ao longe na encosta do morro e se no luar a última sessão da câmara tumultuosa ressoou aos ouvidos de rubião camacho foi até à janela e voltou logo mas quantos dias perguntou ele isso é que não sei mas poucos em todo o caso amanhã conversaremos camacho despediu se palha ficou ainda alguns instantes para dizer lhe que seria esquisito voltar a minas sem que eles as contas rubião interrompeu o contas quem lhe pedia contas bem se vê que o senhor não\n",
      "\n",
      "Machado de Assis: Helena -- 54866 palavras\n",
      "interrompeu melchior com brandura nós somente saber o essencial tudo é essencial na minha narração disse salvador aquela entrevista mostrou me a toda a luz o caráter de ângela que outra mulher se em tais circunstâncias a afrontar a cólera do homem desprezado ângela era um complexo de qualidades singulares capaz de suportar as maiores angústias forte e risonha no meio das máximas privações esqueceu num instante as virtudes que tinha para correr atrás de uma fantasia de amor não foi a riqueza que a ela iria ainda que tivesse de trocar a riqueza pela miséria ângela nasceu metade freira\n",
      "\n",
      "Erico Verissimo: Clarissa -- 47893 palavras\n",
      "já morreu se é por falta de carinho viuvinha cá estou eu no meio da roda ana maria ar cândido olhos baixos dedo polegar apertado entre os lábios bolinha gira também pela mão de clarissa e de luzia mal se pode suster nas que se está sério fecha a boca em botão num esforço comovente para acompanhar o canto e faz do meio do coro de quando em quando se sem música a voz metálica do capitão mata sete a tarde é tépida o ar macio a sombra da casa quase que já cobriu todo o jardim amaro sonha era\n",
      "\n",
      "Erico Verissimo: Incidente em Antares -- 145112 palavras\n",
      "de cada dia de trabalho toda a equipe se reunia numa sala que havia alugado para ser seu quartel general num edifício de à rua do comércio e então cada pesquisador contava das vicissitudes do dia da desconfiada resistência de alguns antarenses ante o questionário o que finalmente os convencia a fazer o que os membros da equipe lhe pediam era o fato de eles não serem obrigados a assinar seus nomes depois de o nessas reuniões diárias um que outro pesquisador mostrava uma carta anônima recebida naquele dia – ameaças ou claras denúncias insinuações insultos a carta era lida\n",
      "\n",
      "Erico Verissimo: O Tempo e o Vento - O Continente -- 129577 palavras\n",
      "primeira vez percebera que pedrinho era já um homem feito de voz grossa e buço cerrado ficara espantada ao notar que o filho estava mais alto do que ela mas espanto maior ainda lhe causara a descoberta que aos poucos fizera de que embora fosse a imagem viva do pai o rapaz tinha herdado o gênio do avô era calado e teimoso engraçado maneco terra e o homem que ele mandara matar agora se encontravam no corpo de pedrinho ana procurava sempre esquecer os dias de medo e aflição principalmente aquele — o pior de todos — em que chegando\n",
      "\n",
      "Erico Verissimo: O Tempo e o Vento - O Arquipelago -- 115764 palavras\n",
      "o doutor carbone disse que dentro duma semana ele pode já começar a caminhar direito — e vai continuar morando aqui o resto da vida — está claro que não papai há muito que ele quer voltar para um hotel eu é que não deixo o madruga é vingativo a vida do ruas ainda está em perigo mais tarde quando tomavam café na sala de visitas licurgo dirigiu se aos filhos — vou fazer um pedido aos dois não é uma ordem afinal de contas quem sou eu nesta casa pra dar ordens os filhos esperavam — quero que os\n",
      "\n"
     ]
    }
   ],
   "source": [
    "for i, seq in enumerate(sequences):\n",
    "    k = nr.randint(len(seq) - 100)\n",
    "    print('{}: {} -- {} palavras'.format(book_author[i], book_title[i], len(seq)).replace('_', ' '))\n",
    "    print(' '.join([i2w[x] for x in seq[k:k+100]]), end='\\n\\n')\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": true,
    "editable": true
   },
   "source": [
    "### Palavras características de cada livro"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[['vavá' 'januário' 'almério' '—' 'dóris' 'brígida' 'justiniano' 'tereza']\n",
      " ['marilda' 'dinorá' 'teodoro' 'pelancchi' 'gisa' 'mirandão' 'rozilda' 'vadinho']\n",
      " ['trapiche' 'bedel' 'ester' 'barandão' 'almiro' 'dora' '–' 'pirulito']\n",
      " ['tuísca' 'tonico' 'ribeirinho' 'malvina' 'amâncio' 'fulgêncio' 'gabriela' 'nacib']\n",
      " ['damasceno' 'eusébia' 'cubas' 'borba' 'sabina' 'cotrim' 'marcela' 'virgília']\n",
      " ['carmo' 'libertos' 'prainha' 'noronha' 'cesária' 'aguiar' 'fidélia' 'tristão']\n",
      " ['coupé' 'gêmeos' 'excia' 'nóbrega' 'custódio' 'natividade' 'flora' 'cláudia']\n",
      " ['manduca' 'protonotário' 'bentinho' 'sancha' 'pádua' 'justina' 'escobar' 'capitu']\n",
      " ['procópio' 'valéria' 'jorge' 'garcia' 'madrasta' 'enteada' 'iaiá' 'estela']\n",
      " ['camacho' 'teófilo' 'tonica' 'borba' 'sofia' 'fernanda' 'benedita' 'rubião']\n",
      " ['ângela' 'eugênia' 'tomásia' 'melchior' 'helena' 'camargo' 'estácio' 'úrsula']\n",
      " ['gamaliel' 'dudu' 'eufrasina' 'tatá' 'belmira' 'tónico' 'zina' 'clarissa']\n",
      " ['campolargo' 'vacariano' 'vivaldino' 'getúlio' 'quitéria' '–' 'tibério' 'antares']\n",
      " ['maneco' 'amaral' 'lara' 'vosmecê' 'bibiana' '—' 'alonzo' 'rodrigo']\n",
      " ['dinda' 'alicinha' 'toríbio' 'chiru' 'stein' 'camerino' '—' 'rodrigo']]\n"
     ]
    }
   ],
   "source": [
    "tfidf = tokenizer.sequences_to_matrix(sequences, mode='tfidf')\n",
    "ww = np.argsort(tfidf, axis=1)[:, -8:]\n",
    "print(i2w_vec[ww-1])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": true,
    "editable": true
   },
   "source": [
    "## Dividindo o dataset entre treinamento e validação"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": true,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "nr.seed(20170607)\n",
    "\n",
    "batch_size  = 32\n",
    "seq_size    = 500\n",
    "valid_split = 0.2"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": true,
    "editable": true
   },
   "source": [
    "### Divisão simples"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(2565, 500) (2565,)\n"
     ]
    }
   ],
   "source": [
    "all_data = [[] for i in range(n_labels)]\n",
    "\n",
    "for sequence, label in zip(sequences, book_label):\n",
    "    n_seqs = len(sequence) // seq_size\n",
    "    for i in range(n_seqs):\n",
    "        beg = i * seq_size\n",
    "        all_data[label].append(sequence[beg:beg+seq_size])\n",
    "\n",
    "N = 5 * (min([len(x) for x in all_data]) // 5)\n",
    "all_data = np.array([seq[:N] for seq in all_data], np.int32).reshape(-1, 500)\n",
    "all_labels = np.array([[i] * N for i in range(n_labels)], np.int32).reshape(-1)\n",
    "print(all_data.shape, all_labels.shape)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(2052, 500) (2052,) (513, 500) (513,)\n"
     ]
    }
   ],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "Xtra, Xval, ytra, yval = train_test_split(all_data, all_labels, test_size=valid_split)\n",
    "print(Xtra.shape, ytra.shape, Xval.shape, yval.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "fn = data_dir + 'livros_sequences.npz'\n",
    "np.savez_compressed(fn, Xtra=Xtra, Xval=Xval, ytra=ytra, yval=yval, i2w=i2w_vec[:MAX_NB_WORDS])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": true,
    "editable": true
   },
   "source": [
    "### Divisão para uso com geradores e aumento de dados"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training sequences:\n",
      "-------------------\n",
      " 1. Jorge_Amado      (1) --  19928 palavras do início do livro Tereza_Batista_Cansada_de_Guerra\n",
      " 2. Jorge_Amado      (1) --  33701 palavras do início do livro Dona_flor_seus_dois_maridos\n",
      " 3. Jorge_Amado      (1) --  49623 palavras do início do livro Capitaes_de_Areia\n",
      " 4. Jorge_Amado      (1) -- 103308 palavras do início do livro Gabriela\n",
      " 5. Machado_de_Assis (0) --  15608 palavras do início do livro Memorias_Postumas_de_Bras_Cubas\n",
      " 6. Machado_de_Assis (0) --  37345 palavras do início do livro Memorial_de_Aires\n",
      " 7. Machado_de_Assis (0) --  25366 palavras do início do livro Esau_e_Jaco\n",
      " 8. Machado_de_Assis (0) --  35157 palavras do início do livro Dom_Casmurro\n",
      " 9. Machado_de_Assis (0) --  23806 palavras do início do livro Iaia_Garcia\n",
      "10. Machado_de_Assis (0) --  11847 palavras do início do livro Quincas_Borba\n",
      "11. Machado_de_Assis (0) --  17285 palavras do início do livro Helena\n",
      "12. Erico_Verissimo  (2) --  33501 palavras do início do livro Clarissa\n",
      "13. Erico_Verissimo  (2) -- 108519 palavras do início do livro Incidente_em_Antares\n",
      "14. Erico_Verissimo  (2) --  73954 palavras do início do livro O_Tempo_e_o_Vento_-_O_Continente\n",
      "15. Erico_Verissimo  (2) --  13218 palavras do início do livro O_Tempo_e_o_Vento_-_O_Arquipelago\n",
      "16. Jorge_Amado      (1) -- 111827 palavras do final do livro  Tereza_Batista_Cansada_de_Guerra\n",
      "17. Jorge_Amado      (1) --  99027 palavras do final do livro  Dona_flor_seus_dois_maridos\n",
      "18. Jorge_Amado      (1) --  11149 palavras do final do livro  Capitaes_de_Areia\n",
      "19. Jorge_Amado      (1) --   3926 palavras do final do livro  Gabriela\n",
      "20. Machado_de_Assis (0) --  31362 palavras do final do livro  Memorias_Postumas_de_Bras_Cubas\n",
      "21. Machado_de_Assis (0) --   2728 palavras do final do livro  Memorial_de_Aires\n",
      "22. Machado_de_Assis (0) --  30856 palavras do final do livro  Esau_e_Jaco\n",
      "23. Machado_de_Assis (0) --  16571 palavras do final do livro  Dom_Casmurro\n",
      "24. Machado_de_Assis (0) --  20529 palavras do final do livro  Iaia_Garcia\n",
      "25. Machado_de_Assis (0) --  48210 palavras do final do livro  Quincas_Borba\n",
      "26. Machado_de_Assis (0) --  26608 palavras do final do livro  Helena\n",
      "27. Erico_Verissimo  (2) --   4814 palavras do final do livro  Clarissa\n",
      "28. Erico_Verissimo  (2) --   7571 palavras do final do livro  Incidente_em_Antares\n",
      "29. Erico_Verissimo  (2) --  29708 palavras do final do livro  O_Tempo_e_o_Vento_-_O_Continente\n",
      "30. Erico_Verissimo  (2) --  79394 palavras do final do livro  O_Tempo_e_o_Vento_-_O_Arquipelago\n",
      "\n",
      "Validation sequences:\n",
      "---------------------\n",
      " 1. Jorge_Amado      (1) --  32938 palavras do meio do livro Tereza_Batista_Cansada_de_Guerra\n",
      " 2. Jorge_Amado      (1) --  33182 palavras do meio do livro Dona_flor_seus_dois_maridos\n",
      " 3. Jorge_Amado      (1) --  15193 palavras do meio do livro Capitaes_de_Areia\n",
      " 4. Jorge_Amado      (1) --  26808 palavras do meio do livro Gabriela\n",
      " 5. Machado_de_Assis (0) --  11742 palavras do meio do livro Memorias_Postumas_de_Bras_Cubas\n",
      " 6. Machado_de_Assis (0) --  10018 palavras do meio do livro Memorial_de_Aires\n",
      " 7. Machado_de_Assis (0) --  14055 palavras do meio do livro Esau_e_Jaco\n",
      " 8. Machado_de_Assis (0) --  12931 palavras do meio do livro Dom_Casmurro\n",
      " 9. Machado_de_Assis (0) --  11083 palavras do meio do livro Iaia_Garcia\n",
      "10. Machado_de_Assis (0) --  15014 palavras do meio do livro Quincas_Borba\n",
      "11. Machado_de_Assis (0) --  10973 palavras do meio do livro Helena\n",
      "12. Erico_Verissimo  (2) --   9578 palavras do meio do livro Clarissa\n",
      "13. Erico_Verissimo  (2) --  29022 palavras do meio do livro Incidente_em_Antares\n",
      "14. Erico_Verissimo  (2) --  25915 palavras do meio do livro O_Tempo_e_o_Vento_-_O_Continente\n",
      "15. Erico_Verissimo  (2) --  23152 palavras do meio do livro O_Tempo_e_o_Vento_-_O_Arquipelago\n",
      "\n",
      "Total number of training words:   1126446\n",
      "Total number of validation words: 281604\n"
     ]
    }
   ],
   "source": [
    "valid_length = [int(0.2 * len(x)) for x in sequences]\n",
    "valid_start = [nr.randint(2000, len(x) - 2000 - n) for x, n in zip(sequences, valid_length)]\n",
    "\n",
    "valid_sequences = [seq[x0:x0+n] for seq, x0, n in zip(sequences, valid_start, valid_length)]\n",
    "\n",
    "train_sequences = [seq[:x0] for seq, x0 in zip(sequences, valid_start)] + \\\n",
    "                  [seq[x0+n:] for seq, x0, n in zip(sequences, valid_start, valid_length)]\n",
    "\n",
    "valid_labels = book_label\n",
    "train_labels = book_label + book_label\n",
    "\n",
    "n_train_words = sum([len(x) for x in train_sequences])\n",
    "n_valid_words = sum([len(x) for x in valid_sequences])\n",
    "\n",
    "print('Training sequences:')\n",
    "print('-------------------')\n",
    "for i, (seq, lab) in enumerate(zip(train_sequences, train_labels)):\n",
    "    if i < n_books:\n",
    "        print('{:2d}. {:16s} ({}) -- {:6d} palavras do início do livro {}'.format(i+1, book_author[i%n_books], lab,\n",
    "                                                                                  len(seq), book_title[i%n_books]))\n",
    "    else:\n",
    "        print('{:2d}. {:16s} ({}) -- {:6d} palavras do final do livro  {}'.format(i+1, book_author[i%n_books], lab,\n",
    "                                                                                  len(seq), book_title[i%n_books]))\n",
    "print()\n",
    "print('Validation sequences:')\n",
    "print('---------------------')\n",
    "for i, (seq, lab) in enumerate(zip(valid_sequences, valid_labels)):\n",
    "    print('{:2d}. {:16s} ({}) -- {:6d} palavras do meio do livro {}'.format(i+1, book_author[i%n_books], lab,\n",
    "                                                                            len(seq), book_title[i%n_books]))\n",
    "print()\n",
    "print('Total number of training words:  ', n_train_words)\n",
    "print('Total number of validation words:', n_valid_words)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": true,
    "editable": true
   },
   "source": [
    "#### Criando  geradores para treino e validação"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "collapsed": true,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "class MyDataGenerator:\n",
    "    def __init__(self, batch_size, seq_size, sequences, labels):\n",
    "        self.batch_size = batch_size\n",
    "        self.length = seq_size\n",
    "        self.sequences = sequences\n",
    "        self.labels = labels\n",
    "        sizes = np.array([len(seq) for seq in sequences])\n",
    "        self.p = 1.0 * sizes / sizes.sum()        # probabilidade de escolha para cada sequencia\n",
    "        self.n = np.arange(len(sequences))        # indices de cada sequencia (para o choice abaixo)\n",
    "        \n",
    "    def __call__(self):\n",
    "        while True:\n",
    "            batch = np.empty((self.batch_size, self.length), np.int32)\n",
    "            label = np.empty((self.batch_size, n_labels), np.int32)\n",
    "            for i in range(self.batch_size):\n",
    "                k = nr.choice(self.n, p=self.p)\n",
    "                p = nr.randint(0, len(self.sequences[k]) - self.length)\n",
    "                batch[i] = self.sequences[k][p:p+self.length]\n",
    "                label[i] = to_categorical(self.labels[k], num_classes=n_labels)\n",
    "            yield batch, label\n",
    "\n",
    "            \n",
    "train_gen = MyDataGenerator(batch_size, seq_size, train_sequences, train_labels)\n",
    "valid_gen = MyDataGenerator(batch_size, seq_size, valid_sequences, valid_labels)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "import pickle\n",
    "fn = data_dir + 'livros_generators.pkl'\n",
    "pickle.dump([train_gen, valid_gen, i2w_vec[:MAX_NB_WORDS]], open(fn, 'wb'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.4.3"
  },
  "latex_envs": {
   "LaTeX_envs_menu_present": true,
   "autocomplete": true,
   "bibliofile": "biblio.bib",
   "cite_by": "apalike",
   "current_citInitial": 1,
   "eqLabelWithNumbers": true,
   "eqNumInitial": 1,
   "hotkeys": {
    "equation": "Ctrl-E",
    "itemize": "Ctrl-I"
   },
   "labels_anchors": false,
   "latex_user_defs": false,
   "report_style_numbering": false,
   "user_envs_cfg": false
  },
  "toc": {
   "colors": {
    "hover_highlight": "#DAA520",
    "running_highlight": "#FF0000",
    "selected_highlight": "#FFD700"
   },
   "moveMenuLeft": true,
   "nav_menu": {
    "height": "264px",
    "width": "252px"
   },
   "navigate_menu": true,
   "number_sections": true,
   "sideBar": true,
   "threshold": 4,
   "toc_cell": true,
   "toc_section_display": "block",
   "toc_window_display": false,
   "widenNotebook": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
