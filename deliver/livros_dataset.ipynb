{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": true,
    "editable": true,
    "toc": "true"
   },
   "source": [
    "# Table of Contents\n",
    " <p><div class=\"lev1 toc-item\"><a href=\"#Classificação-de-Textos\" data-toc-modified-id=\"Classificação-de-Textos-1\"><span class=\"toc-item-num\">1&nbsp;&nbsp;</span>Classificação de Textos</a></div><div class=\"lev2 toc-item\"><a href=\"#Preâmbulo\" data-toc-modified-id=\"Preâmbulo-11\"><span class=\"toc-item-num\">1.1&nbsp;&nbsp;</span>Preâmbulo</a></div><div class=\"lev2 toc-item\"><a href=\"#Preparando-o-dataset\" data-toc-modified-id=\"Preparando-o-dataset-12\"><span class=\"toc-item-num\">1.2&nbsp;&nbsp;</span>Preparando o dataset</a></div><div class=\"lev3 toc-item\"><a href=\"#Buscando-o-texto-dos-livros-e-definindo-os-rótulos\" data-toc-modified-id=\"Buscando-o-texto-dos-livros-e-definindo-os-rótulos-121\"><span class=\"toc-item-num\">1.2.1&nbsp;&nbsp;</span>Buscando o texto dos livros e definindo os rótulos</a></div><div class=\"lev3 toc-item\"><a href=\"#Representando-as-palavras-através-de-índices-inteiros\" data-toc-modified-id=\"Representando-as-palavras-através-de-índices-inteiros-122\"><span class=\"toc-item-num\">1.2.2&nbsp;&nbsp;</span>Representando as palavras através de índices inteiros</a></div><div class=\"lev3 toc-item\"><a href=\"#Palavras-características-de-cada-livro\" data-toc-modified-id=\"Palavras-características-de-cada-livro-123\"><span class=\"toc-item-num\">1.2.3&nbsp;&nbsp;</span>Palavras características de cada livro</a></div><div class=\"lev2 toc-item\"><a href=\"#Dividindo-o-dataset-entre-treinamento-e-validação\" data-toc-modified-id=\"Dividindo-o-dataset-entre-treinamento-e-validação-13\"><span class=\"toc-item-num\">1.3&nbsp;&nbsp;</span>Dividindo o dataset entre treinamento e validação</a></div><div class=\"lev3 toc-item\"><a href=\"#Divisão-simples\" data-toc-modified-id=\"Divisão-simples-131\"><span class=\"toc-item-num\">1.3.1&nbsp;&nbsp;</span>Divisão simples</a></div><div class=\"lev3 toc-item\"><a href=\"#Divisão-para-uso-com-geradores-e-aumento-de-dados\" data-toc-modified-id=\"Divisão-para-uso-com-geradores-e-aumento-de-dados-132\"><span class=\"toc-item-num\">1.3.2&nbsp;&nbsp;</span>Divisão para uso com geradores e aumento de dados</a></div><div class=\"lev4 toc-item\"><a href=\"#Criando--geradores-para-treino-e-validação\" data-toc-modified-id=\"Criando--geradores-para-treino-e-validação-1321\"><span class=\"toc-item-num\">1.3.2.1&nbsp;&nbsp;</span>Criando  geradores para treino e validação</a></div>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": true,
    "editable": true
   },
   "source": [
    "# Classificação de Textos"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": true,
    "editable": true
   },
   "source": [
    "## Preâmbulo"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "%matplotlib inline\n",
    "import matplotlib.pyplot as plot\n",
    "from IPython import display\n",
    "from __future__ import print_function\n",
    "\n",
    "import os\n",
    "import sys\n",
    "import glob\n",
    "import numpy as np\n",
    "import numpy.random as nr\n",
    "\n",
    "from keras.preprocessing.text import Tokenizer\n",
    "from keras.preprocessing.sequence import pad_sequences\n",
    "from keras.utils import to_categorical\n",
    "from keras.layers import Dense, Input, Flatten, Dropout\n",
    "from keras.layers import Conv1D, MaxPooling1D, Embedding\n",
    "from keras.models import Model\n",
    "from keras.optimizers import (SGD, \n",
    "                              RMSprop, \n",
    "                              Adam, \n",
    "                              Adadelta, \n",
    "                              Adagrad)\n",
    "\n",
    "sys.path.append('../src')\n",
    "from my_keras_utilities import (get_available_gpus, \n",
    "                                load_model_and_history, \n",
    "                                save_model_and_history, \n",
    "                                TrainingPlotter)\n",
    "\n",
    "os.makedirs('../../models',exist_ok=True)\n",
    "np.set_printoptions(precision=3, linewidth=120)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Backend:        tensorflow\n",
      "Data format:    channels_last\n",
      "Available GPUS: ['/gpu:0']\n",
      "Encoding:       utf-8\n"
     ]
    }
   ],
   "source": [
    "import keras.backend as K\n",
    "\n",
    "# K.set_image_data_format('channels_first')\n",
    "K.set_floatx('float32')\n",
    "\n",
    "print('Backend:        {}'.format(K.backend()))\n",
    "print('Data format:    {}'.format(K.image_data_format()))\n",
    "print('Available GPUS:', get_available_gpus())\n",
    "print('Encoding:      ', sys.getdefaultencoding())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": true,
    "editable": true
   },
   "source": [
    "## Preparando o dataset"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": true,
    "editable": true
   },
   "source": [
    "### Buscando o texto dos livros e definindo os rótulos"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1001226  Jorge_Amado        Tereza_Batista_Cansada_de_Guerra\n",
      "1030735  Jorge_Amado        Dona_flor_seus_dois_maridos\n",
      " 427711  Jorge_Amado        Capitaes_de_Areia\n",
      " 828417  Jorge_Amado        Gabriela\n",
      " 352965  Machado_de_Assis   Memorias_Postumas_de_Bras_Cubas\n",
      " 280683  Machado_de_Assis   Memorial_de_Aires\n",
      " 411043  Machado_de_Assis   Esau_e_Jaco\n",
      " 372459  Machado_de_Assis   Dom_Casmurro\n",
      " 336677  Machado_de_Assis   Iaia_Garcia\n",
      " 443778  Machado_de_Assis   Quincas_Borba\n",
      " 337533  Machado_de_Assis   Helena\n",
      " 294049  Erico_Verissimo    Clarissa\n",
      " 890215  Erico_Verissimo    Incidente_em_Antares\n",
      " 749265  Erico_Verissimo    O_Tempo_e_o_Vento_-_O_Continente\n",
      " 699390  Erico_Verissimo    O_Tempo_e_o_Vento_-_O_Arquipelago\n",
      "\n",
      "3 Labels:\n",
      "     0: Machado_de_Assis\n",
      "     1: Erico_Verissimo\n",
      "     2: Jorge_Amado\n"
     ]
    }
   ],
   "source": [
    "data_dir = '../../datasets/'\n",
    "\n",
    "autores = [\n",
    "#     'Fernando_Sabino', \n",
    "    'Jorge_Amado',\n",
    "    'Machado_de_Assis',\n",
    "    'Erico_Verissimo',\n",
    "]\n",
    "\n",
    "book_text = []\n",
    "book_author = []\n",
    "book_title = []\n",
    "for aut in autores:\n",
    "    for fn in glob.glob(data_dir + 'livros/' + aut + '*.txt'):\n",
    "        author, book = os.path.basename(fn).split('__')\n",
    "        txt = open(fn, encoding='utf-8').read().replace('\\x97', '')\n",
    "        book_text.append(txt)\n",
    "        book_author.append(author)\n",
    "        book_title.append(book[:-4])\n",
    "        print('{:7d}  {:18s} {}'.format(len(txt), author, book[:-4]))\n",
    "\n",
    "author_list = list(set(book_author))\n",
    "n_labels = len(author_list)\n",
    "n_books = len(book_title)\n",
    "book_label = [author_list.index(a) for a in book_author]\n",
    "print('\\n{} Labels:'.format(n_labels))\n",
    "for i, autor in enumerate(author_list):\n",
    "    print('    {:2d}: {}'.format(i, autor))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": true,
    "editable": true
   },
   "source": [
    "### Representando as palavras através de índices inteiros"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 61707 unique tokens.\n",
      "Using the first 19999 words.\n"
     ]
    }
   ],
   "source": [
    "MAX_NB_WORDS = 20000\n",
    "\n",
    "tokenizer = Tokenizer(num_words=MAX_NB_WORDS)\n",
    "tokenizer.fit_on_texts(book_text)\n",
    "sequences = tokenizer.texts_to_sequences(book_text)\n",
    "\n",
    "w2i = tokenizer.word_index\n",
    "i2w = dict([(v, k) for k, v in w2i.items()])\n",
    "\n",
    "i2w_vec = np.array([i2w[i+1] for i in range(len(i2w))])\n",
    "\n",
    "print('Found %d unique tokens.' % len(i2w))\n",
    "print('Using the first %d words.' % max([max(s) for s in sequences]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true,
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Jorge Amado: Tereza Batista Cansada de Guerra -- 164695 palavras\n",
      "ouro no rio piauitinga sozinho ou em companhia de joão nascimento filho lá se ia para o rio de manhã cedinho — esse banho é saúde mestre joão ao regressar da primeira viagem após o aborto o doutor trouxe mil lembranças para tereza entre elas um maiô de banho — para irmos ao banho de rio — irmos os dois juntos — quis saber tereza pensativa — sim favo de mel os dois juntos tereza com o maiô por baixo do vestido o doutor com uma minúscula sob as calças atravessavam estância em direção ao rio apesar da hora matinal\n",
      "\n",
      "Jorge Amado: Dona flor seus dois maridos -- 165877 palavras\n",
      "espreguiçadeira pois bem dona flor descobri a malícia nas páginas mais ingênuas e força de sexo naquele barato e baixo dando outra dimensão aos o enredo a transformar dramalhão e personagens a virgem das campinas em marafona os m quase cresciam em brutais em vez de coleção menina e para adolescentes romances leitura para alcova o mesmo se passava com a excitante crônica da cidade no comentário das comadres nas páginas das gazetas em cadeiras na calçada compunha se a roda noturna das amigas no relato e no debate do último crime apaixonante a mucama pelo patrão ela com quinze\n",
      "\n",
      "Jorge Amado: Capitaes de Areia -- 75958 palavras\n",
      "os outros o olharam ainda com receio quando naquela noite ele entrou no trapiche mas professor andou logo para ele – ficou bom mulato boa vida sorriu vinham apertar a mão dele pedro bala lhe deu um abraço – mulato bom mulato batuta até sem pernas veio joão grande ficou junto de boa vida 0 mulato olhou os amigos pediu um cigarro sua mão estava o rosto ficou calado olhando com amor o velho trapiche os meninos o cachorro que estava deitado no colo do sem pernas então joão grande perguntou – como era o lazareto boa vida se voltou\n",
      "\n",
      "Jorge Amado: Gabriela -- 134109 palavras\n",
      "pe fora mandado estudar na faculdade de direito do rio de janeiro mas o velho assunção morrera sem ter ainda completamente perdoado à filha a daquele casamento nobre e o fidalgo tendo adquirido hábitos populares como o jogo de gamão e a bri ga de galos comera a pouco e pouco o a metro e metro de fazenda a e dúzia de grampos a peça e peça de fita colorida assim terminara a abastança dos após a grandeza dos ávilas deixando pelópidas no rio sem recursos para continuar os estudos quando andava pelo terceiro ano pág da faculdade já então\n",
      "\n",
      "Machado de Assis: Memorias Postumas de Bras Cubas -- 58706 palavras\n",
      "vencera meu pai dispus me a aceitar o diploma e o casamento virgília e a câmara dos deputados as duas disse ele num de ternura política aceitei os meu pai deu me dois fortes abraços era o seu próprio sangue que ele enfim reconhecia comigo desço amanhã vou fazer primeiramente uma visita a d eusébia meu pai torceu o nariz mas não disse nada despediu se e desceu eu na tarde desse mesmo dia fui visitar d eusébia achei a a um preto jardineiro mas deixou tudo para vir falar me com um alvoroço um prazer tão sincero que me\n",
      "\n",
      "Machado de Assis: Memorial de Aires -- 50081 palavras\n",
      "o banco a velha vai dizer que não pode ser por ora nem por ora nem jamais concluiu dobrando a carta estou cansada e fraca conselheiro e meio doente não dou para de viagens viagens dão saúde e força pode ser mas em outra idade na minha é já impossível seguiu se uma pausa durante a qual aguiar olhou de soslaio para a mulher ela para si e eu para ambos alternadamente entrou um vizinho e falamos de outras coisas quinta feira tristão e fidélia desceram hoje e aguiar os foi buscar à prainha dali vieram almoçar ao flamengo onde\n",
      "\n",
      "Machado de Assis: Esau e Jaco -- 70260 palavras\n",
      "teria tido tempo contava apenas vinte e sete anos cumprimentou as senhoras quando o carro passou depois ficou a olhar para a nota tão fresca tão nota que as almas nunca viram sair das mãos dele foi subindo a rua de são josé já não tinha ânimo de pedir a nota fazia se ouro e a idéia de ser falsa voltou lhe ao cérebro e agora mais freqüente até que se lhe pegou por alguns instantes se fosse falsa a missa das almas ' gemeu à porta de uma quitanda e deram lhe um vintém um vintém sujo e triste\n",
      "\n",
      "Machado de Assis: Dom Casmurro -- 64674 palavras\n",
      "trêmulo os seis degraus da escada e daí a pouco debruçado sobre a cama ouvia as palavras de minha mãe que me apertava muito as mãos chamando me seu filho estava queimando os olhos ardiam nos meus toda ela parecia consumida por um interno me ao pé do leito mas como este era alto fiquei longe das suas carícias não meu filho levanta levanta capitu que estava na alcova gostou de ver a minha entrada os meus gestos palavras e lágrimas segundo me disse depois mas não suspeitou naturalmente todas as causas da minha aflição entrando no meu quarto pensei\n",
      "\n",
      "Machado de Assis: Iaia Garcia -- 55427 palavras\n",
      "com tranqüilidade já tive ocasião de lhe dizer que foi um dos heróis interveio luís garcia olhando para a mulher mas o dr jorge teima em os seus próprios serviços iaiá não é a mesma coisa sim perguntou jorge é verdade durante toda a campanha matou pelo menos metade do exército iaiá lançou ao pai um olhar de graciosa censura não precisa corar disse jorge era uma maneira de ser patriota mas creia que havia menos perigo em matar o inimigo cá de longe o senhor matou algum perguntou iaiá no fim de um instante provavelmente na guerra é preciso\n",
      "\n",
      "Machado de Assis: Quincas Borba -- 75088 palavras\n",
      "o apuro conseguira que todas entrassem naquela obra de caridade desde alguns dias não pensara em outra coisa às vezes à noite antes do chá parecia dormir na cadeira de balanço não dormia fechava os olhos para considerar se a si mesma no meio das companheiras pessoas de qualidade compreende se que este fosse o assunto principal da conversação mas sofia tornava de quando em quando ao presente amigo por que é que ele fazia tão longas oito dez quinze dias e mais rubião respondeu que por nada mas tão comovido que uma das costureiras bateu no pé da outra\n",
      "\n",
      "Machado de Assis: Helena -- 54877 palavras\n",
      "lhe o sono a confissão súbita lacônica e eloqüente da irmã ficara lhe no espírito como se fora o eco perpétuo de uma voz extinta nem no dia seguinte nem nos alcançou o que esperava helena ou evitava ficar a sós com ele ou se a maior explicação nos passeios que eram freqüentes procurou estácio mais de uma vez tratar do assunto que o preocupava helena ouvia com um sorriso e respondia com um gracejo depois dava de rédea à conversação e na direção oposta como a fantasia era campo vasto nunca mais o moço trazê la ao ponto de\n",
      "\n",
      "Erico Verissimo: Clarissa -- 47888 palavras\n",
      "que estão fazendo naturalmente conversando e que dirão boa tarde comadre boa tarde tem trabalhado muito tenho veja só o que eu vou carregando nas costas oh a senhora é muito forte como vai a família quanta coisa se podem dizer as formigas clarissa lembra se da história da cigarra e da formiga que está na em prosa e verso por sinal o trecho já lhe caiu uma vez em exame pois agora » clarissa ergue os olhos como está bonito o pessegueiro todo de flores cor de rosa contra o céu azul através dos ramos ela olha as nuvens\n",
      "\n",
      "Erico Verissimo: Incidente em Antares -- 145093 palavras\n",
      "porém um vacariano entre os membros da legião bento gonçalves que depois da vitória da revolução seus cavalos no da av rio branco como observou alguém não bastara aos gaúchos derrubar o governo federal era preciso também numa afirmação de guasca aquele símbolo da cidade são sebastião do rio de janeiro xxvii zózimo campolargo seguira também rumo de com o corpo provisório de antares por tibério vacariano não levava a sério o seu uniforme caqui nem as suas divisas de major não se considerava diminuído e muito menos por servir sob as ordens dum vacariano tudo aquilo lhe era indiferente\n",
      "\n",
      "Erico Verissimo: O Tempo e o Vento - O Continente -- 129544 palavras\n",
      "vez diga que sim rodrigo piscou duas vezes o rosto do vigário era uma careta de aflição — pense no que há depois desta vida capitão não perca a sua alma para toda a eternidade vosmecê morre e sua alma vai para o inferno se vosmecê se confessar e receber a extrema unção sua alma se estou aqui não só como sacerdote mas também como seu amigo tudo o que está se passando agora entre nós será conservado em segredo neste momento só deus está nos vendo e ouvindo rodrigo continuava imóvel não sorria mais e suas pálpebras estavam caídas\n",
      "\n",
      "Erico Verissimo: O Tempo e o Vento - O Arquipelago -- 115773 palavras\n",
      "e isso o deixa de tal modo constrangido que ele não tem coragem de encará la como se a rapariga tivesse realmente acabado de cometer um incesto bibi desce apressada e ao passar entre o irmão e o marido murmura buscar um prato fundo para a a palavra sangria floriano em pleno peito mas ele sobe a escada às pressas fugindo na direção da coisa que o lá em cima no corredor sombrio encontra sílvia por alguns segundos ficam parados um à frente do outro em silêncio floriano sente se tomado de um trêmulo terno desejo de a cunhada contra\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# escolhe e imprime uma sequencia aleatoria de cada livro\n",
    "rseq_len = 100\n",
    "for i, seq in enumerate(sequences):\n",
    "    k = nr.randint(len(seq) - rseq_len)\n",
    "    print('{}: {} -- {} palavras'.format(book_author[i], book_title[i], len(seq)).replace('_', ' '))\n",
    "    print(' '.join([i2w[x] for x in seq[k:k+rseq_len]]), end='\\n\\n')\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": true,
    "editable": true
   },
   "source": [
    "### Palavras características de cada livro"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[['vavá' 'almério' 'januário' '—' 'dóris' 'brígida' 'justiniano' 'tereza']\n",
      " ['marilda' 'dinorá' 'teodoro' 'pelancchi' 'gisa' 'mirandão' 'rozilda' 'vadinho']\n",
      " ['trapiche' 'bedel' 'ester' 'barandão' 'almiro' 'dora' '–' 'pirulito']\n",
      " ['tuísca' 'tonico' 'ribeirinho' 'malvina' 'amâncio' 'fulgêncio' 'gabriela' 'nacib']\n",
      " ['loló' 'eusébia' 'cubas' 'borba' 'sabina' 'cotrim' 'marcela' 'virgília']\n",
      " ['carmo' 'libertos' 'prainha' 'noronha' 'cesária' 'aguiar' 'fidélia' 'tristão']\n",
      " ['coupé' 'gêmeos' 'excia' 'custódio' 'nóbrega' 'natividade' 'flora' 'cláudia']\n",
      " ['manduca' 'protonotário' 'bentinho' 'sancha' 'pádua' 'justina' 'escobar' 'capitu']\n",
      " ['procópio' 'valéria' 'jorge' 'garcia' 'madrasta' 'enteada' 'iaiá' 'estela']\n",
      " ['camacho' 'teófilo' 'tonica' 'borba' 'sofia' 'fernanda' 'benedita' 'rubião']\n",
      " ['ângela' 'eugênia' 'tomásia' 'melchior' 'helena' 'camargo' 'estácio' 'úrsula']\n",
      " ['gamaliel' 'dudu' 'eufrasina' 'tatá' 'belmira' 'tónico' 'zina' 'clarissa']\n",
      " ['campolargo' 'vacariano' 'vivaldino' 'getúlio' 'quitéria' '–' 'tibério' 'antares']\n",
      " ['maneco' 'amaral' 'lara' 'vosmecê' 'bibiana' '—' 'alonzo' 'rodrigo']\n",
      " ['dinda' 'alicinha' 'toríbio' 'chiru' 'stein' 'camerino' '—' 'rodrigo']]\n"
     ]
    }
   ],
   "source": [
    "tfidf = tokenizer.sequences_to_matrix(sequences, mode='tfidf')\n",
    "ww = np.argsort(tfidf, axis=1)[:, -8:]\n",
    "print(i2w_vec[ww-1])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": true,
    "editable": true
   },
   "source": [
    "## Dividindo o dataset entre treinamento e validação"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "collapsed": true,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "nr.seed(20170607)\n",
    "\n",
    "batch_size  = 32\n",
    "seq_size    = 200\n",
    "valid_split = 0.2"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": true,
    "editable": true
   },
   "source": [
    "### Divisão simples"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Sequencias obtidas para cada autor: [2143, 2189, 2701]\n",
      "O dataset conterá 2143 sequencias por autor, totalizando 6429 sequencias.\n",
      "\n",
      "Dataset shapes: (6429, 200) (6429,)\n"
     ]
    }
   ],
   "source": [
    "all_data = [[] for i in range(n_labels)]\n",
    "\n",
    "# divide cada livro em sequencias de 'seq_size' words\n",
    "# 'all_data' contem as sequencias agrupadas por autor\n",
    "for sequence, label in zip(sequences, book_label):\n",
    "    n_seqs = len(sequence) // seq_size\n",
    "    for i in range(n_seqs):\n",
    "        beg = i * seq_size\n",
    "        all_data[label].append(sequence[beg:beg+seq_size])\n",
    "\n",
    "print('Sequencias obtidas para cada autor:', [len(x) for x in all_data])\n",
    "\n",
    "# balanceando o dataset:\n",
    "# calcula o numero de sequencias, N, de forma que o dataset \n",
    "# contenha N sequencias para cada autor\n",
    "N = min([len(x) for x in all_data])\n",
    "print('O dataset conterá {} sequencias por autor, totalizando {} sequencias.'.format(N, 3*N))\n",
    "\n",
    "all_data = np.array([seq[:N] for seq in all_data], np.int32).reshape(-1, seq_size)\n",
    "all_labels = np.array([[i] * N for i in range(n_labels)], np.int32).reshape(-1)\n",
    "print('\\nDataset shapes:', all_data.shape, all_labels.shape)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(5143, 200) (5143,) (1286, 200) (1286,)\n"
     ]
    }
   ],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "Xtra, Xval, ytra, yval = train_test_split(all_data, all_labels, test_size=valid_split)\n",
    "print(Xtra.shape, ytra.shape, Xval.shape, yval.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "fn = data_dir + 'livros_sequences_{}.npz'.format(seq_size)\n",
    "np.savez_compressed(fn, Xtra=Xtra, Xval=Xval, ytra=ytra, yval=yval, i2w=i2w_vec[:MAX_NB_WORDS])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": true,
    "editable": true
   },
   "source": [
    "### Divisão para uso com geradores e aumento de dados"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training sequences:\n",
      "-------------------\n",
      " 1. Jorge_Amado      (2) --  11876 palavras do início do livro Tereza_Batista_Cansada_de_Guerra\n",
      " 2. Jorge_Amado      (2) -- 120243 palavras do início do livro Dona_flor_seus_dois_maridos\n",
      " 3. Jorge_Amado      (2) --  57529 palavras do início do livro Capitaes_de_Areia\n",
      " 4. Jorge_Amado      (2) --  71632 palavras do início do livro Gabriela\n",
      " 5. Machado_de_Assis (0) --  20278 palavras do início do livro Memorias_Postumas_de_Bras_Cubas\n",
      " 6. Machado_de_Assis (0) --  13961 palavras do início do livro Memorial_de_Aires\n",
      " 7. Machado_de_Assis (0) --  24553 palavras do início do livro Esau_e_Jaco\n",
      " 8. Machado_de_Assis (0) --  27571 palavras do início do livro Dom_Casmurro\n",
      " 9. Machado_de_Assis (0) --  15991 palavras do início do livro Iaia_Garcia\n",
      "10. Machado_de_Assis (0) --  51304 palavras do início do livro Quincas_Borba\n",
      "11. Machado_de_Assis (0) --  31535 palavras do início do livro Helena\n",
      "12. Erico_Verissimo  (1) --   9346 palavras do início do livro Clarissa\n",
      "13. Erico_Verissimo  (1) --  12637 palavras do início do livro Incidente_em_Antares\n",
      "14. Erico_Verissimo  (1) --  80454 palavras do início do livro O_Tempo_e_o_Vento_-_O_Continente\n",
      "15. Erico_Verissimo  (1) --   3607 palavras do início do livro O_Tempo_e_o_Vento_-_O_Arquipelago\n",
      "16. Jorge_Amado      (2) -- 119880 palavras do final do livro  Tereza_Batista_Cansada_de_Guerra\n",
      "17. Jorge_Amado      (2) --  12459 palavras do final do livro  Dona_flor_seus_dois_maridos\n",
      "18. Jorge_Amado      (2) --   3238 palavras do final do livro  Capitaes_de_Areia\n",
      "19. Jorge_Amado      (2) --  35656 palavras do final do livro  Gabriela\n",
      "20. Machado_de_Assis (0) --  26687 palavras do final do livro  Memorias_Postumas_de_Bras_Cubas\n",
      "21. Machado_de_Assis (0) --  26104 palavras do final do livro  Memorial_de_Aires\n",
      "22. Machado_de_Assis (0) --  31655 palavras do final do livro  Esau_e_Jaco\n",
      "23. Machado_de_Assis (0) --  24169 palavras do final do livro  Dom_Casmurro\n",
      "24. Machado_de_Assis (0) --  28351 palavras do final do livro  Iaia_Garcia\n",
      "25. Machado_de_Assis (0) --   8767 palavras do final do livro  Quincas_Borba\n",
      "26. Machado_de_Assis (0) --  12367 palavras do final do livro  Helena\n",
      "27. Erico_Verissimo  (1) --  28965 palavras do final do livro  Clarissa\n",
      "28. Erico_Verissimo  (1) -- 103438 palavras do final do livro  Incidente_em_Antares\n",
      "29. Erico_Verissimo  (1) --  23182 palavras do final do livro  O_Tempo_e_o_Vento_-_O_Continente\n",
      "30. Erico_Verissimo  (1) --  89012 palavras do final do livro  O_Tempo_e_o_Vento_-_O_Arquipelago\n",
      "\n",
      "Validation sequences:\n",
      "---------------------\n",
      " 1. Jorge_Amado      (2) --  32939 palavras do meio do livro Tereza_Batista_Cansada_de_Guerra\n",
      " 2. Jorge_Amado      (2) --  33175 palavras do meio do livro Dona_flor_seus_dois_maridos\n",
      " 3. Jorge_Amado      (2) --  15191 palavras do meio do livro Capitaes_de_Areia\n",
      " 4. Jorge_Amado      (2) --  26821 palavras do meio do livro Gabriela\n",
      " 5. Machado_de_Assis (0) --  11741 palavras do meio do livro Memorias_Postumas_de_Bras_Cubas\n",
      " 6. Machado_de_Assis (0) --  10016 palavras do meio do livro Memorial_de_Aires\n",
      " 7. Machado_de_Assis (0) --  14052 palavras do meio do livro Esau_e_Jaco\n",
      " 8. Machado_de_Assis (0) --  12934 palavras do meio do livro Dom_Casmurro\n",
      " 9. Machado_de_Assis (0) --  11085 palavras do meio do livro Iaia_Garcia\n",
      "10. Machado_de_Assis (0) --  15017 palavras do meio do livro Quincas_Borba\n",
      "11. Machado_de_Assis (0) --  10975 palavras do meio do livro Helena\n",
      "12. Erico_Verissimo  (1) --   9577 palavras do meio do livro Clarissa\n",
      "13. Erico_Verissimo  (1) --  29018 palavras do meio do livro Incidente_em_Antares\n",
      "14. Erico_Verissimo  (1) --  25908 palavras do meio do livro O_Tempo_e_o_Vento_-_O_Continente\n",
      "15. Erico_Verissimo  (1) --  23154 palavras do meio do livro O_Tempo_e_o_Vento_-_O_Arquipelago\n",
      "\n",
      "Total number of training words:   1126447\n",
      "Total number of validation words: 281603\n"
     ]
    }
   ],
   "source": [
    "valid_length = [int(0.2 * len(x)) for x in sequences]\n",
    "valid_start = [nr.randint(2000, len(x) - 2000 - n) for x, n in zip(sequences, valid_length)]\n",
    "\n",
    "valid_sequences = [seq[x0:x0+n] for seq, x0, n in zip(sequences, valid_start, valid_length)]\n",
    "\n",
    "train_sequences = [seq[:x0] for seq, x0 in zip(sequences, valid_start)] + \\\n",
    "                  [seq[x0+n:] for seq, x0, n in zip(sequences, valid_start, valid_length)]\n",
    "\n",
    "valid_labels = book_label\n",
    "train_labels = book_label + book_label\n",
    "\n",
    "n_train_words = sum([len(x) for x in train_sequences])\n",
    "n_valid_words = sum([len(x) for x in valid_sequences])\n",
    "\n",
    "print('Training sequences:')\n",
    "print('-------------------')\n",
    "for i, (seq, lab) in enumerate(zip(train_sequences, train_labels)):\n",
    "    if i < n_books:\n",
    "        print('{:2d}. {:16s} ({}) -- {:6d} palavras do início do livro {}'.format(i+1, book_author[i%n_books], lab,\n",
    "                                                                                  len(seq), book_title[i%n_books]))\n",
    "    else:\n",
    "        print('{:2d}. {:16s} ({}) -- {:6d} palavras do final do livro  {}'.format(i+1, book_author[i%n_books], lab,\n",
    "                                                                                  len(seq), book_title[i%n_books]))\n",
    "print()\n",
    "print('Validation sequences:')\n",
    "print('---------------------')\n",
    "for i, (seq, lab) in enumerate(zip(valid_sequences, valid_labels)):\n",
    "    print('{:2d}. {:16s} ({}) -- {:6d} palavras do meio do livro {}'.format(i+1, book_author[i%n_books], lab,\n",
    "                                                                            len(seq), book_title[i%n_books]))\n",
    "print()\n",
    "print('Total number of training words:  ', n_train_words)\n",
    "print('Total number of validation words:', n_valid_words)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": true,
    "editable": true
   },
   "source": [
    "#### Criando  geradores para treino e validação"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {
    "collapsed": true,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "class MyDataGenerator:\n",
    "    def __init__(self, batch_size, seq_size, sequences, labels):\n",
    "        self.batch_size = batch_size\n",
    "        self.length = seq_size\n",
    "        self.sequences = sequences\n",
    "        self.labels = labels\n",
    "        sizes = np.array([len(seq) for seq in sequences])\n",
    "        self.p = 1.0 * sizes / sizes.sum()        # probabilidade de escolha para cada sequencia\n",
    "        self.n = np.arange(len(sequences))        # indices de cada sequencia (para o choice abaixo)\n",
    "        \n",
    "    def __call__(self):\n",
    "        while True:\n",
    "            batch = np.empty((self.batch_size, self.length), np.int32)\n",
    "            label = np.empty((self.batch_size, n_labels), np.int32)\n",
    "            for i in range(self.batch_size):\n",
    "                k = nr.choice(self.n, p=self.p)\n",
    "                p = nr.randint(0, len(self.sequences[k]) - self.length)\n",
    "                batch[i] = self.sequences[k][p:p+self.length]\n",
    "                label[i] = to_categorical(self.labels[k], num_classes=n_labels)\n",
    "            yield batch, label\n",
    "\n",
    "            \n",
    "train_gen = MyDataGenerator(batch_size, seq_size, train_sequences, train_labels)\n",
    "valid_gen = MyDataGenerator(batch_size, seq_size, valid_sequences, valid_labels)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "import pickle\n",
    "fn = data_dir + 'livros_generators_{}.pkl'.format(seq_size)\n",
    "pickle.dump([train_gen, valid_gen, i2w_vec[:MAX_NB_WORDS]], open(fn, 'wb'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.4.3"
  },
  "latex_envs": {
   "LaTeX_envs_menu_present": true,
   "autocomplete": true,
   "bibliofile": "biblio.bib",
   "cite_by": "apalike",
   "current_citInitial": 1,
   "eqLabelWithNumbers": true,
   "eqNumInitial": 1,
   "hotkeys": {
    "equation": "Ctrl-E",
    "itemize": "Ctrl-I"
   },
   "labels_anchors": false,
   "latex_user_defs": false,
   "report_style_numbering": false,
   "user_envs_cfg": false
  },
  "toc": {
   "colors": {
    "hover_highlight": "#DAA520",
    "running_highlight": "#FF0000",
    "selected_highlight": "#FFD700"
   },
   "moveMenuLeft": true,
   "nav_menu": {
    "height": "264px",
    "width": "252px"
   },
   "navigate_menu": true,
   "number_sections": true,
   "sideBar": true,
   "threshold": 4,
   "toc_cell": true,
   "toc_section_display": "block",
   "toc_window_display": false,
   "widenNotebook": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
