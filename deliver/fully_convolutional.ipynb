{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": true,
    "editable": true
   },
   "source": [
    "# Redes totalmente convolucionais\n",
    "\n",
    "Este notebook aborda os seguintes aspectos relacionados às redes totalmente convolucionais:\n",
    "- como transformar uma camada densa em convolucional, aproveitando seus pesos;\n",
    "- como criar, a partir de uma rede pré-treinada para classificar imagens, uma rede totalmente convolucional;\n",
    "- demonstrar que uma rede totalmente convolucional, quando aplicada em imagens maiores que aquelas usadas em seu treinamento, implementa uma varredura implícita com ganhos de eficiência.\n",
    "- apresentar um método para aumentar a resolução (*shift-and-stitch*)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2017-05-28T16:00:13.893701",
     "start_time": "2017-05-28T16:00:08.543645"
    },
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Backend:     tensorflow\n",
      "Data format: channels_first\n",
      "Keras  2.0.3\n",
      "Numpy  1.11.3\n"
     ]
    }
   ],
   "source": [
    "%matplotlib inline\n",
    "import matplotlib.pyplot as plot\n",
    "from IPython import display\n",
    "\n",
    "import sys\n",
    "import time\n",
    "import numpy as np\n",
    "import argparse\n",
    "\n",
    "import keras\n",
    "from keras.models import Sequential\n",
    "from keras.layers.convolutional import Conv2D\n",
    "from keras.layers.convolutional import MaxPooling2D\n",
    "from keras.layers.core import Activation\n",
    "from keras.layers.core import Flatten\n",
    "from keras.layers.core import Dense\n",
    "from keras.layers.core import Dropout\n",
    "\n",
    "from keras.optimizers import SGD, RMSprop\n",
    "from keras.callbacks import Callback\n",
    "from keras.callbacks import History\n",
    "from keras.callbacks import ModelCheckpoint\n",
    "from keras.callbacks import EarlyStopping\n",
    "from keras.callbacks import LearningRateScheduler\n",
    "from keras.utils import np_utils\n",
    "from sklearn import datasets\n",
    "\n",
    "import keras.backend as K\n",
    "K.set_image_data_format('channels_first')\n",
    "K.set_floatx('float32')\n",
    "\n",
    "print('Backend:     {}'.format(K.backend()))\n",
    "print('Data format: {}'.format(K.image_data_format()))\n",
    "\n",
    "print('Keras ', keras.__version__)\n",
    "print('Numpy ', np.__version__)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2017-05-28T16:00:13.940506",
     "start_time": "2017-05-28T16:00:13.896142"
    },
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "# Para demonstrar a técnica shift e stitch\n",
    "def show_scan(M, H, W):\n",
    "    from IPython import display\n",
    "    def printt(arr):\n",
    "        for line in output.tolist():\n",
    "            print(' '.join([' abcdefghijklmnop'[x] for x in line]))\n",
    "\n",
    "    M = 36\n",
    "    image = np.zeros((1, 1, M, M))\n",
    "\n",
    "    lab = 1\n",
    "    output = np.zeros((M-H+1, M-W+1), np.uint8)\n",
    "    for i in range(4):\n",
    "        for j in range(4):\n",
    "            oo = output[i::4, j::4]\n",
    "            output[i::4, j::4] = lab * np.ones_like(oo)\n",
    "            print('origin: ({}, {}), shape: {}, label: {}'.format(i, j, oo.shape, ' abcdefghijklmnop'[lab]))\n",
    "            print()\n",
    "            printt(output)\n",
    "            lab += 1\n",
    "            time.sleep(2)\n",
    "            display.clear_output(wait=True)\n",
    "\n",
    "# Função para criar uma imagem de teste, maior que 28x28 colocando várias amostras\n",
    "def make_image(X_test, y_test, M=200, H=28, W=28):\n",
    "    M = 200\n",
    "    char_index = np.random.choice(X_test.shape[0], 10, replace=False)\n",
    "    char_img = [img.reshape(H,W) for img in (255*X_test).astype(np.uint8)[char_index]]\n",
    "    char_lab = [y for y in y_test[char_index]]\n",
    "\n",
    "    image = np.zeros((M, M), np.uint8)\n",
    "    coords = [(0, 0), (50, 150), (100, 100), (171, 171), (120,30)] # posição das imagens na imagem maior\n",
    "    xlabel = []\n",
    "    for k, (i, j) in enumerate(coords):\n",
    "        image[i:i+H, j:j+W] = char_img[k]\n",
    "        xlabel.append(char_lab[k])\n",
    "    return image, coords, xlabel"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": true,
    "editable": true
   },
   "source": [
    "### MNIST dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2017-05-28T16:00:15.196941",
     "start_time": "2017-05-28T16:00:13.942793"
    },
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(60000, 1, 28, 28) (10000, 1, 28, 28)\n",
      "(60000, 10) (10000, 10)\n"
     ]
    }
   ],
   "source": [
    "sys.path.append('../src')\n",
    "from keras.datasets import mnist\n",
    "from my_keras_utilities import (load_model_and_history, \n",
    "                                save_model_and_history, \n",
    "                                TrainingPlotter)\n",
    "H = W = 28\n",
    "n_classes = 10\n",
    "(X_train, y_train), (X_test, y_test) = mnist.load_data()\n",
    "\n",
    "X_train = X_train.reshape(-1, 1, H, W) / 255.0\n",
    "X_test = X_test.reshape(-1, 1, H, W) / 255.0\n",
    "\n",
    "y_train_oh = np_utils.to_categorical(y_train, 10)\n",
    "y_test_oh = np_utils.to_categorical(y_test, 10)\n",
    "\n",
    "print(X_train.shape, X_test.shape)\n",
    "print(y_train_oh.shape, y_test_oh.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Pequena amostra apenas para testar o código"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2017-05-28T16:02:04.767493",
     "start_time": "2017-05-28T16:02:04.759292"
    },
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "n_samples_train = 1000\n",
    "n_samples_test  = 500\n",
    "\n",
    "X_train = X_train[:n_samples_train]\n",
    "y_train_oh = y_train_oh[:n_samples_train]\n",
    "X_test = X_test[:n_samples_test]\n",
    "y_test = y_test[:n_samples_test]\n",
    "y_test_oh = y_test_oh[:n_samples_test]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": true,
    "editable": true
   },
   "source": [
    "## Carregando nosso modelo pre-treinado"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2017-05-28T16:00:37.663708",
     "start_time": "2017-05-28T16:00:36.299247"
    },
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[INFO] loading model...\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "conv2d_1 (Conv2D)            (None, 20, 28, 28)        520       \n",
      "_________________________________________________________________\n",
      "activation_1 (Activation)    (None, 20, 28, 28)        0         \n",
      "_________________________________________________________________\n",
      "max_pooling2d_1 (MaxPooling2 (None, 20, 14, 14)        0         \n",
      "_________________________________________________________________\n",
      "conv2d_2 (Conv2D)            (None, 50, 14, 14)        25050     \n",
      "_________________________________________________________________\n",
      "activation_2 (Activation)    (None, 50, 14, 14)        0         \n",
      "_________________________________________________________________\n",
      "max_pooling2d_2 (MaxPooling2 (None, 50, 7, 7)          0         \n",
      "_________________________________________________________________\n",
      "dropout_1 (Dropout)          (None, 50, 7, 7)          0         \n",
      "_________________________________________________________________\n",
      "flatten_1 (Flatten)          (None, 2450)              0         \n",
      "_________________________________________________________________\n",
      "dense_1 (Dense)              (None, 500)               1225500   \n",
      "_________________________________________________________________\n",
      "activation_3 (Activation)    (None, 500)               0         \n",
      "_________________________________________________________________\n",
      "dense_2 (Dense)              (None, 10)                5010      \n",
      "_________________________________________________________________\n",
      "activation_4 (Activation)    (None, 10)                0         \n",
      "=================================================================\n",
      "Total params: 1,256,080\n",
      "Trainable params: 1,256,080\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "None\n"
     ]
    }
   ],
   "source": [
    "print(\"[INFO] loading model...\")\n",
    "model_name = '../../models/keras_lenet_1'\n",
    "model_A, histo_A = load_model_and_history(model_name)  # Modelo A é a rede do exercício anterior, com camadas densas no final\n",
    "\n",
    "print(model_A.summary())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2017-05-28T16:00:38.838805",
     "start_time": "2017-05-28T16:00:38.832511"
    },
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(500, 1, 28, 28) (500, 10)\n"
     ]
    }
   ],
   "source": [
    "print(X_test.shape, y_test_oh.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2017-05-28T16:00:41.627403",
     "start_time": "2017-05-28T16:00:40.190345"
    },
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[INFO] evaluating...\n",
      "[INFO] accuracy: 91.40%\n"
     ]
    }
   ],
   "source": [
    "print(\"[INFO] evaluating...\")\n",
    "loss, accuracy = model_A.evaluate(X_test, y_test_oh, batch_size=128, verbose=0)\n",
    "print(\"[INFO] accuracy: {:.2f}%\".format(accuracy * 100))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Modelo totalmente convolucional equivalente"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": true,
    "editable": true
   },
   "source": [
    "O modelo seguinte é todo ele convolucional.\n",
    "\n",
    "A primeira camada densa do modelo tem como entrada um tensor de dimensão 2450, resultante do redimensionamento (via *Flatten*) da saída do *Dropout*, 50x7x7. Esta camada gera uma saída com dimensão 500. Seus pesos têm portanto dimensão 2450x500.\n",
    "\n",
    "Uma camada convolucional que substitua estas camadas *Flatten* e *Dense* terá como entrada um tensor 50x7x7. Para gerar uma saída 500x1x1, a convolução deve criar 500 mapas com um kernel 7x7 e com borda do tipo 'valid'.\n",
    "\n",
    "Para substituir a última camada densa, usamos uma convolução com 10 mapas e kernel 1x1.\n",
    "\n",
    "\n",
    "<table align='left'>\n",
    "<tr><td colspan=2> <img src=\"../figures/fully_conv_5.png\" alt=\"Drawing\" style=\"width: 700px;\"/> </td></tr>\n",
    "</table>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Observando o shape dos pesos da rede original"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "O Keras adota a seguinte convenção para o *shape* dos kernels das camadas convolucionais:\n",
    " - (wh,ww,channels,nb_filters):"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2017-05-28T16:00:48.704066",
     "start_time": "2017-05-28T16:00:48.693525"
    },
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[(5, 5, 1, 20), (20,), (5, 5, 20, 50), (50,), (2450, 500), (500,), (500, 10), (10,)]\n"
     ]
    }
   ],
   "source": [
    "W_all_A = model_A.get_weights()\n",
    "print([w.shape for w in W_all_A])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2017-05-28T16:00:50.978426",
     "start_time": "2017-05-28T16:00:50.716226"
    },
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "conv2d_1 (Conv2D)            (None, 20, None, None)    520       \n",
      "_________________________________________________________________\n",
      "activation_1 (Activation)    (None, 20, None, None)    0         \n",
      "_________________________________________________________________\n",
      "max_pooling2d_1 (MaxPooling2 (None, 20, None, None)    0         \n",
      "_________________________________________________________________\n",
      "conv2d_2 (Conv2D)            (None, 50, None, None)    25050     \n",
      "_________________________________________________________________\n",
      "activation_2 (Activation)    (None, 50, None, None)    0         \n",
      "_________________________________________________________________\n",
      "max_pooling2d_2 (MaxPooling2 (None, 50, None, None)    0         \n",
      "_________________________________________________________________\n",
      "conv2d_3 (Conv2D)            (None, 500, None, None)   1225500   \n",
      "_________________________________________________________________\n",
      "activation_3 (Activation)    (None, 500, None, None)   0         \n",
      "_________________________________________________________________\n",
      "conv2d_4 (Conv2D)            (None, 10, None, None)    5010      \n",
      "=================================================================\n",
      "Total params: 1,256,080\n",
      "Trainable params: 1,256,080\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "model_name = '../../models/keras_lenet_fullconv'\n",
    "\n",
    "class BaseNet:\n",
    "    @staticmethod\n",
    "    def build(width, height, depth, classes):\n",
    "        model = Sequential()\n",
    "        model.add(Conv2D(20, (5, 5), \n",
    "                         padding=\"same\", \n",
    "                         input_shape=(depth, height, width)))\n",
    "        model.add(Activation(\"relu\"))\n",
    "        model.add(MaxPooling2D(pool_size=(2, 2), strides=(2, 2)))\n",
    "        model.add(Conv2D(50, (5, 5), padding=\"same\"))\n",
    "        model.add(Activation(\"relu\"))\n",
    "        model.add(MaxPooling2D(pool_size=(2, 2), strides=(2, 2)))\n",
    "        model.add(Dropout(0.5))\n",
    "        model.add(Flatten())\n",
    "        model.add(Dense(500))\n",
    "        model.add(Activation(\"relu\"))\n",
    "        model.add(Dense(classes))\n",
    "        model.add(Activation(\"softmax\"))\n",
    "        return model\n",
    "\n",
    "class FullConvNet:\n",
    "    @staticmethod\n",
    "    def build():\n",
    "        model = Sequential()\n",
    "        \n",
    "        model.add(Conv2D( 20, (5, 5), padding=\"same\", \n",
    "                             batch_input_shape=(None, 1, None, None)))\n",
    "        model.add(Activation(\"relu\"))\n",
    "        model.add(MaxPooling2D(pool_size=(2, 2), strides=(2, 2)))\n",
    "        \n",
    "        model.add(Conv2D( 50, (5, 5), padding=\"same\"))\n",
    "        model.add(Activation(\"relu\"))\n",
    "        model.add(MaxPooling2D(pool_size=(2, 2), strides=(2, 2)))\n",
    "        \n",
    "        model.add(Conv2D(500, (7, 7), padding=\"valid\"))        \n",
    "        model.add(Activation(\"relu\"))\n",
    "\n",
    "        model.add(Conv2D( 10, (1, 1), padding=\"valid\"))        \n",
    "\n",
    "        return model\n",
    "\n",
    "model_B = FullConvNet.build()  # Modelo B é o totalmente convolucional\n",
    "model_B.summary()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": true,
    "editable": true
   },
   "source": [
    "## Ajustando os pesos do modelo todo convolucional\n",
    "\n",
    "<table align='left'>\n",
    "<tr><td colspan=2> <img src=\"../figures/fully_conv_6.png\" alt=\"Drawing\" style=\"width: 700px;\"/> </td></tr>\n",
    "</table>\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2017-05-28T16:00:54.057481",
     "start_time": "2017-05-28T16:00:53.916439"
    },
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[(5, 5, 1, 20), (20,), (5, 5, 20, 50), (50,), (2450, 500), (500,), (500, 10), (10,)]\n",
      "[(5, 5, 1, 20), (20,), (5, 5, 20, 50), (50,), (7, 7, 50, 500), (500,), (1, 1, 500, 10), (10,)]\n"
     ]
    }
   ],
   "source": [
    "W_all_B = model_B.get_weights()\n",
    "\n",
    "print([w.shape for w in W_all_A])\n",
    "print([w.shape for w in W_all_B])\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2017-05-28T17:46:24.995588",
     "start_time": "2017-05-28T17:46:24.973380"
    },
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[(5, 5, 1, 20), (20,), (5, 5, 20, 50), (50,), (2450, 500), (500,), (500, 10), (10,)]\n",
      "[(5, 5, 1, 20), (20,), (5, 5, 20, 50), (50,), (7, 7, 50, 500), (500,), (1, 1, 500, 10), (10,)]\n"
     ]
    }
   ],
   "source": [
    "W_all_B = [\n",
    "    W_all_A[0], # pesos da primeira convolução 5x5\n",
    "    W_all_A[1], # bias da primeira convolução 5x5\n",
    "    W_all_A[2], # pesos da segunda convolução 5x5\n",
    "    W_all_A[3], # bias da segunda convolução\n",
    "    W_all_A[4].reshape(7, 7, 50, 500).transpose((0,1,2,3))[::-1, ::-1, :, :], # transposta, reshape para kernel e espelhamento (só para Theano)\n",
    "    W_all_A[5], # bias desta camada\n",
    "    W_all_A[6].reshape(1,1, 500, 10).transpose((0,1,2,3))[::-1, ::-1, :, :], # igual, convertendo a densa em convolucional\n",
    "    W_all_A[7], # bias desta camada\n",
    "]\n",
    "model_B.set_weights(W_all_B)\n",
    "print([w.shape for w in W_all_A])\n",
    "print([w.shape for w in W_all_B])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2017-05-28T17:46:26.546137",
     "start_time": "2017-05-28T17:46:26.464704"
    },
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "model_B.compile(optimizer='sgd', loss=\"categorical_crossentropy\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": true,
    "editable": true
   },
   "source": [
    "## Verificando a performance"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2017-05-28T17:46:29.966788",
     "start_time": "2017-05-28T17:46:28.503761"
    },
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "def softmax(Z, axis=-1):\n",
    "    EZ = np.exp(Z)\n",
    "    S = EZ / EZ.sum(axis=axis,keepdims=True)\n",
    "    return S\n",
    "\n",
    "y_hat_score = model_B.predict(X_test)\n",
    "y_hat_oh = softmax(y_hat_score.reshape(n_samples_test,n_classes))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2017-05-28T17:46:30.752030",
     "start_time": "2017-05-28T17:46:30.743909"
    },
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[2 2 2 2 2 2 2 2 2 2]\n",
      "[7 2 1 0 4 1 4 9 5 9]\n"
     ]
    }
   ],
   "source": [
    "y_hat = np.argmax(y_hat_oh, axis=1).reshape(-1)\n",
    "print(y_hat[:10])\n",
    "print(y_test[:10])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2017-05-28T17:46:33.643232",
     "start_time": "2017-05-28T17:46:33.636348"
    },
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "8.2\n"
     ]
    }
   ],
   "source": [
    "print(100.0 * (y_hat == y_test).astype(np.int).sum() / y_test.shape[0])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": true,
    "editable": true
   },
   "source": [
    "## Janela deslizante\n",
    "\n",
    "Agora que temos uma rede toda convolucional, vejamos o que acontece se a imagem de entrada é maior que as imagens utilizadas para treinamento (28x28).\n",
    "\n",
    "A figura abaixo, ilustra o processo mostrando as dimensões dos *features* através de uma linha da imagem de entrada com dimensões 36x36. Acompanhemos cada passo:\n",
    "\n",
    "- imagem de entrada (representada na figura em uma dimensão apenas): 1x36x36;\n",
    "- convolução 20 filtros 5x5, borda *'same'*: 20x36x36\n",
    "- maxpool 2x2, stride 2x2: 20x18x18\n",
    "- convolução 50 filtros 5x5, borda *'same'*: 50x18x18\n",
    "- maxpool 2x2, stride 2x2: 50x9x9\n",
    "- convolução 500 filtros 7x7, borda *'valid'*: 500x3x3\n",
    "- convolução 10 filtros 1x1: 10x3x3\n",
    "\n",
    "<table align='left'>\n",
    "<!-- <tr><td> <img src=\"../figures/fully_conv_4.png\" alt=\"Drawing\" style=\"width: 200px;\"/> </td> <td/></tr> -->\n",
    "<tr><td colspan=2> <img src=\"../figures/fully_conv_3.png\" alt=\"Drawing\" style=\"width: 600px;\"/> </td></tr>\n",
    "</table>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "M = 200\n",
    "image, coords, xlabel = make_image(X_test, y_test_oh, M, H, W) # Construindo uma imagem para testes M x M com 4 dígitos"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true,
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "fig = plot.figure(figsize=(15,6)) \n",
    "\n",
    "fig.add_subplot(1,2,1)\n",
    "plot.imshow(image, cmap=plot.cm.gray)\n",
    "\n",
    "in_image = image.astype(np.float32).reshape(1, 1, M, M) / 255.0  # Preparando a imagem para entrar na rede\n",
    "\n",
    "pp = model_B.predict(in_image)[0]  # Rede totalmente convolucional em execução\n",
    "pp = softmax(pp, 0)\n",
    "\n",
    "pmax = pp.max(0)\n",
    "#pmax = np.where(pmax < 0.2, 0, pmax) # zerando quando probabilidade < 0.2\n",
    "\n",
    "hm = np.zeros((50,50), pmax.dtype)\n",
    "hm[3:-3, 3:-3] = pmax\n",
    "\n",
    "fig.add_subplot(1,2,2)\n",
    "plot.imshow(255 * hm, cmap=plot.cm.hot);\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": true,
    "editable": true
   },
   "source": [
    "**Atenção:** Observe que as duas imagens acima possuem resolução (*shape*) diferentes. A resolução da imagem de entrada, mostrada à esquerda, é de (200,200) e a resolução da imagem de saída (à direita) é de (50,50)."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": true,
    "editable": true
   },
   "source": [
    "## Aumentando a resolução\n",
    "\n",
    "Demonstrando a técnica de *shift* e *stitch*"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "show_scan(M, H, W) # Demonstração da varredura e preenchimento (shift, stitch)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "fig = plot.figure(figsize=(15,6)) \n",
    "\n",
    "fig.add_subplot(1,2,1)\n",
    "plot.imshow(255 - image, cmap=plot.cm.gray)\n",
    "plot.grid(True)\n",
    "\n",
    "# Aplicando a técnica shift e stitch na imagem\n",
    "# A rede convolucional é aplicada na imagem, 16 vezes para\n",
    "# preencher os dados\n",
    "output = np.zeros((10, M-H+1, M-W+1), np.float32)\n",
    "for i in range(4):\n",
    "    for j in range(4):\n",
    "        output[:, i::4, j::4] = oo = model_B.predict(in_image[:, :, i:, j:])[0] # Execução da rede\n",
    "        print i, j, oo.shape\n",
    "\n",
    "output = softmax(output, 0)\n",
    "pmax = output.max(0)\n",
    "imax = output.argmax(0)\n",
    "pmax = np.where(pmax < 0.3, 0, pmax)\n",
    "print pmax.min(), pmax.max()\n",
    "print output.shape, pmax.shape, pmax[0,0], imax[0,0], pmax[-1,-1], imax[-1,-1]\n",
    "\n",
    "phm = np.zeros((M,M), pmax.dtype)\n",
    "phm[(H+1)/2-1:-H/2, (W+1)/2-1:-W/2] = pmax\n",
    "\n",
    "ihm = np.zeros((M,M), imax.dtype)\n",
    "ihm[(H+1)/2-1:-H/2, (W+1)/2-1:-W/2] = imax\n",
    "\n",
    "fig.add_subplot(1,2,2)\n",
    "plot.imshow(255 * (1.0 - phm), cmap=plot.cm.hot)\n",
    "# plot.imsave('heatmap.png', 255 * pmax)\n",
    "plot.grid(True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true,
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "for k, (i, j) in zip(xlabel, coords):\n",
    "    for m in (-1, 0, 1):\n",
    "        for n in (-1, 0, 1):\n",
    "            print('p = {:.5f}, char: \\'{}\\' [correct: \\'{}\\']'.format(phm[i+m+13, j+n+13], \n",
    "                                                                      ihm[i+m+13, j+n+13], k), end=' ')\n",
    "            if m == n == 0:\n",
    "                print('**')\n",
    "            else:\n",
    "                print()\n",
    "    print()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": true,
    "editable": true
   },
   "source": [
    "## Observações\n",
    "\n",
    "- A rede base utilizada não foi treinada para a não-ocorrência de um dos dez caracteres, nem de recortes parciais dos caracteres originais.\n",
    "- Um exercício interessante seria treinar o modelo com os caracteres sobrepostos a imagens de fundo, além de recortes do fundo sem caracter (11 classes).\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true,
    "deletable": true,
    "editable": true
   },
   "source": [
    "## Aprendizados com este notebook\n"
   ]
  }
 ],
 "metadata": {
  "anaconda-cloud": {},
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.0"
  },
  "toc": {
   "colors": {
    "hover_highlight": "#DAA520",
    "running_highlight": "#FF0000",
    "selected_highlight": "#FFD700"
   },
   "moveMenuLeft": true,
   "nav_menu": {
    "height": "210px",
    "width": "252px"
   },
   "navigate_menu": true,
   "number_sections": true,
   "sideBar": true,
   "threshold": 4,
   "toc_cell": false,
   "toc_section_display": "block",
   "toc_window_display": false,
   "widenNotebook": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
