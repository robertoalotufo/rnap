{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Explorando convolução no Keras usando o TensorFlow\n",
    "\n",
    "O objetivo deste notebook é de explorar a convolução que é implementada pelo TensorFlow através do Keras.\n",
    "\n",
    "A convolução é a operação essencial das redes convolucionais. É uma operação demorada e a sua implementação na GPU acelera bastante o seu processamento. A implementação é feita no TensorFlow utilizando GPU. Se a GPU não for encontrada, a implementação roda na CPU.\n",
    "\n",
    "[A guide to convolution arithmetic for deep\n",
    "learning by Vincent Dumoulin and Francesco Visin, 2016](https://arxiv.org/pdf/1603.07285.pdf)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "import os\n",
    "os.environ['KERAS_BACKEND'] = 'tensorflow'\n",
    "#os.environ['THEANO_FLAGS'] = 'mode=FAST_RUN,device=gpu0,floatX=float32'\n",
    "#os.environ['THEANO_FLAGS'] = 'mode=FAST_RUN,device=cpu,floatX=float32'\n",
    "\n",
    "import keras\n",
    "from keras.models import Sequential\n",
    "from keras.layers.convolutional import Conv2D"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Uma rede com uma única camada convolucional\n",
    "\n",
    "O objetivo deste experimento é explorar numericamente a convolução implementada na rede\n",
    "convolucional do Keras/TensorFlow. Para isso iremos criar uma rede convolucional com apenas\n",
    "uma camada de convolução. A sua predição será o resultado da rede, que neste caso será apenas uma convolução.\n",
    "\n",
    "Uma convolução pode ser visto como uma média móvel ponderada sobre a imagem. A equação matemática da convolução é dada por:\n",
    "\n",
    "$$ \\boldsymbol{Y} = \\boldsymbol{X} \\ast \\boldsymbol{W} $$\n",
    "\n",
    "onde $\\boldsymbol{X}$ é a imagem de entrada, $\\boldsymbol{Y}$ é o resultado da convolução e $\\boldsymbol{W}$ é chamado de peso,\n",
    "núcleo, máscara, entre outros nomes. A convolução é a implementação de filtro linear\n",
    "invariante à translação. Este filtro é totalmente especificado pelo núcleo (array $\\boldsymbol{W}$) que\n",
    "contém os parâmetros do filtro linear (da rede convolucional) que precisam ser treinados.\n",
    "\n",
    "A figura a seguir ilustra uma convolução da imagem verde de entrada, utilizando o núcleo da convolução (kernel) em amarelo, deslizando sobre a imagem verde. O resultado da convolução é a imagem rosa, de tamanho ligeiramente menor, devido ao processamento na borda da imagem.\n",
    "\n",
    "![](http://mourafiq.com/images/posts/convolution_schematic.gif)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Organização dos dados de entrada\n",
    "\n",
    "As convoluções do TensorFlow foram projetadas principalmente para tratar imagens ou sons. Assim, a organização dos arrays da imagem de entrada, de saída e dos pesos são feitos de forma específica para atender às necessidades das redes convolucionais. Iremos ilustrar as convoluções utilizando imagem de entrada em nível de cinza e coloridas com 3 bandas, usando a convenção do *shape* de imagens do TensorFlow. \n",
    "\n",
    "As representação usuais (não convolucionais), onde a organização da matriz $\\boldsymbol{X}$ de entrada é bidimensional, com $n$ amostras nas linhas e $i$ *features* nas colunas, têm shape de $\\boldsymbol{X}$ igual a:\n",
    "\n",
    "$ \\boldsymbol{X}:$ `(n, i)`\n",
    " \n",
    "No caso de imagens, como elas têm natureza bidimensional, a relação de vizinhança entre os pixels é fundamental, principalmente\n",
    "para que os pesos dos núcleo abranjam uma região bidimensional da imagem. Assim, as *features* passam agora a terem duas dimensões. São $i$ pixels organizados em `(img_height, img_width)`. Desta forma o array passa a ter uma nova dimensão: \n",
    "\n",
    "$ \\boldsymbol{X}:$ `(n, img_height, img_width)`\n",
    "\n",
    "Numa imagem em nível de cinza temos apenas um valor para representar o pixel, que é sua intensidade, variando de escuro a claro. Quando a imagem é colorida, são necessários 3 valores\n",
    "para cada pixel. No TensorFlow, este 3 valores são organizados em uma dimensão adicional, denominada canal *channel* ou banda. A imagem colorida é então representada com *shape*:`(bandas, img_height, img_width)`. Portanto, o *shape* de entrada deve ter 4 dimensões:\n",
    "\n",
    "$ \\boldsymbol{X}:$ `(samples, channels, img_height, img_width)`\n",
    "\n",
    "![](../figures/image_representation.png)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Organização dos pesos (kernel) da convolução\n",
    "\n",
    "Os pesos do kernel da convolução para tratar imagens devem ser 2D, quando a imagem\n",
    "de entrada for em nível de cinza e devem ter 3 bandas 2D para imagens coloridas. Assim, a organização\n",
    "do *shape* do kernel é $(bands, k_{height}, k_{width})$. Entretanto, nas arquiteturas das redes\n",
    "convolucionais, é usual definir vários filtros (vários kernels), para que a rede tenha um\n",
    "maior número de parâmetros a serem ajustados. Assim, o shape dos pesos devem ter 4 dimensões:\n",
    "\n",
    "$\\boldsymbol{W}:$ `(nb_filters, channels, k_height, k_width)`\n",
    "\n",
    "Observe que a primeira dimensão (`nb_filters`) diz respeito ao número de filtros na saída,\n",
    "enquanto que as três demais dimensões `(channels, k_height, k_width)` à janela deslizante\n",
    "(*kernel*) da convolução.\n",
    "\n",
    "Esta representação também pode ser vista da seguinte forma:\n",
    "\n",
    "$\\boldsymbol{W}:$ `(nb_outputs, nb_inputs, k_height, k_width)`\n",
    "\n",
    "onde\n",
    "\n",
    "- `nb_outputs` = número de imagens que serão geradas por amostra (sample) na saída\n",
    "\n",
    "- `nb_inputs` = número de imagens que são fornecidas por amostra (sample) na entrada\n",
    "\n",
    "- `(k_height, k_width)` = dimensões do kernel\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Organização da imagem de saída (filtrada)\n",
    "\n",
    "A organização da imagem de saída é a mesma da imagem de entrada, até porque a camada convolucional pode ser colocada não apenas na entrada, mas como qualquer camada interna da\n",
    "rede. A principal diferença está na nomenclatura da segunda dimensão: enquanto que na\n",
    "imagem da camada de entrada a segunda dimensão é o *channel*, isto é o número de bandas \n",
    "da imagem colorida, na saída e demais camadas, a segunda dimensão passa a ser o número de\n",
    "filtros aplicados naquela camada. Assim, o *shape* da imagem de saída fica como:\n",
    "\n",
    "$\\boldsymbol{Y}: $` (samples, filtros, img_height, img_width)`"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Exercícios rápidos - análise da convolução\n",
    "\n",
    "### Análise do comprimento e largura das imagens na convolução\n",
    "\n",
    "1. Se $X$ tem dimensão (1, 1, 4, 4) e o Kernel (1, 1, 3, 3) qual é a dimensão da saída $Y$?\n",
    "\n",
    "2. E se $X$ tem dimensão (1, 1, 10, 6) e o Kernel (1, 1, 5, 3) qual é a dimensão da saída $Y$?\n",
    "\n",
    "3. Qual é a relação de `img_height` e `img_width` da saída com o comprimento e largura de $X$ e do Kernel? "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Respostas:\n",
    "1. $\\boldsymbol{Y}:$ (?,?,?,?)\n",
    "2. $\\boldsymbol{Y}:$ (?,?,?,?)\n",
    "3.  - `y_img_height` = x_img_height ? k_height\n",
    "    - `y_img_width` = x_img_width ? k_width"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Análise das dimensões de saída para mais de uma banda (channel)\n",
    "\n",
    "1. Se $X$ tem dimensão (1024, 3, 4, 4) e o Kernel (10, 3, 3, 3) qual deve ser a dimensão da saída $Y$?\n",
    "\n",
    "2. Se $X$ tem dimensão (20, 3, 5, 5) qual deve ser a dimensão do Kernel para que a saída $Y$ tenha dimensão (20, 5, 2, 2)?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Respostas:\n",
    "1. $\\boldsymbol{Y}:$ (?,?,?,?)\n",
    "2. $\\boldsymbol{W}:$ (?,?,?,?)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Ilustração da convolução do primeiro exercício.\n",
    "![](../figures/no_padding_no_strides.gif)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "## Zero padding\n",
    "\n",
    "Esta próxima figura ilustra a convolução quando a imagem de saída (em verde) é igual às\n",
    "dimensões da imagem de entrada (em azul). Neste caso, a imagem de entrada é artificialmente\n",
    "aumentada com valores zeros. Este processo de aumentar a imagem de entrada com zeros é \n",
    "denominado *zero padding*.\n",
    "\n",
    "![](https://raw.githubusercontent.com/vdumoulin/conv_arithmetic/master/gif/same_padding_no_strides.gif)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Analisando as convoluções em uma rede convolucional típica\n",
    "\n",
    "Veja a rede a seguir com 4 camadas convolucionais:\n",
    "\n",
    "![](../figures/architecture.png)\n",
    "Fonte: [Figura apresentação do Sander Dieleman](http://benanne.github.io/images/architecture.png)\n",
    "\n",
    "A imagem de entrada é uma imagem colorida\n",
    "quadrada de 45 pixels de lado. Utiliza-se um kernel de 6x6 gerando 32 filtros, então os *shapes* são:\n",
    "* Camada 1:\n",
    "    - entrada: (amostras, 3, 45, 45)\n",
    "    - kernel:  (32, 3, 6, 6)\n",
    "    - saída: (amostras, 32, 40, 40) Obs: a imagem de saída fica menor\n",
    "* Camada 2:\n",
    "    - entrada: (amostras, 32, 40, 40) Obs: é a imagem de saída da camada anterior\n",
    "    - kernel: (64, 32, 5, 5)\n",
    "    - saída: (amostras, 64, 16, 16)\n",
    "* Camada 3:\n",
    "    - entrada: (amostras, 64, 16, 16)\n",
    "    - kernel: (128, 64, 3, 3)\n",
    "    - saída: (amostras, 128, 6, 6)\n",
    "* Camada 4:\n",
    "    - entrada: (amostras 128, 6, 6)\n",
    "    - kernel: (128, 128, 3, 3)\n",
    "    - saída: (amostras, 128, 4, 4)\n",
    "    \n",
    "## Cálculo do número de parâmetros no núcleos das convoluções\n",
    "\n",
    "O número de parâmetros de cada convolução é igual ao número de elementos do kernel,\n",
    "contabilizando todas as suas dimensões. Assim, um kernel de *shape* (10, 3, 5, 5) terá 750 elementos.\n",
    "\n",
    "Como exercício, calcule o número de elementos dos kernels de cada uma das 4 camadas da rede\n",
    "ilustrativa e o total de elementos."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Resposta:\n",
    "- Camada 1:\n",
    "- Camada 2:\n",
    "- Camada 3:\n",
    "- Camada 4:\n",
    "- Total:"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Ilustrações da convolução\n",
    "\n",
    "### Convolução com mais de uma banda\n",
    "\n",
    "O Kernel precisa ter o mesmo número de bandas da imagem, cada banda da imagem é convoluida com a sua correspondente no Kernel. As convoluções são então somadas posição a posição para formar a saída.\n",
    "\n",
    "![](../figures/Convolution_channels.png)\n",
    "\n",
    "\n",
    "### Convolução com mais de um filtro\n",
    "\n",
    "No caso em qua há mais de um filtro, a operação com a imagem acima é realizada para cada filtro.\n",
    "\n",
    "![](../figures/Convolution_many_filters.png)\n",
    "\n",
    "\n",
    "\n",
    "### Próximas camadas\n",
    "\n",
    "Nas próximas camadas da rede o conjunto de entrada é a saída da convolução anterior. A operação realizada é a mesma acima.\n",
    "\n",
    "!Nova figura de continuação, com entrada de n channels\n",
    "\n",
    "\n",
    "Lembrando que essas operações são realizadas para cada imagem (sample) da entrada."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Definição da convolução usando Keras\n",
    "\n",
    "A implementação da convolução utiliza um modelo sequencial do Keras com `Conv2D`.\n",
    "Obtemos o resultado da rede pela função `predict`:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# 4-D convolution\n",
    "def conv4d(X,W,padding='same'):\n",
    "    \"\"\"\n",
    "    Faz a convolução de um conjunto de imagens com um Kernel com pesos expecificados.\n",
    "\n",
    "    Parâmetros\n",
    "    ----------\n",
    "    X : numpy array (4 dimensões)\n",
    "        Conjunto de imagens de entrada, deve ter as dimensões da seguinte forma \n",
    "        (samples, channels, img_height, img_width).\n",
    "    W : numpy array (4 dimensões)\n",
    "        Kernel que será utilizado para realizar a convolução, deve ter as dimensões \n",
    "        da seguinte forma (filtros, channels, kernel_height, kernel_width).\n",
    "    padding : string\n",
    "        O tipo de convolução que será realizado.\n",
    "        \"valid\": modo que não utilizada padding.\n",
    "        \"same\": utiliza zero padding de forma que a imagens de saída tem o mesmo tamanho\n",
    "        da imagens de entrada.\n",
    "        \n",
    "    Retorno\n",
    "    -------\n",
    "    Y : numpy array (4 dimensões)\n",
    "        Conjunto das imagens resultantes da convolução, as dimensões são da seguinte forma \n",
    "        (samples, channels, img_height, img_width).\n",
    "    \"\"\"\n",
    "    \n",
    "    assert X.ndim == 4\n",
    "    assert W.ndim == 4\n",
    "    samples,channels,xh,xw = X.shape\n",
    "    nb_filters,_,wh,ww = W.shape\n",
    "    \n",
    "    # na verdade Conv2D recebe as dimensões do kernel como (wh,ww,channels,nb_filters) as dimensões são ajustadas aqui\n",
    "    # Formato inicial (nb_filters, channels, wh, ww)\n",
    "    W = np.rollaxis(W, 1, 4)\n",
    "    # W aqui é (nb_filters, wh, ww, channels)\n",
    "    W = np.rollaxis(W, 0, 4)\n",
    "    # W aqui é (wh,ww,channels,nb_filters)\n",
    "    \n",
    "    model = Sequential([\n",
    "                Conv2D(filters=nb_filters, \n",
    "                       kernel_size=(wh, ww), \n",
    "                       input_shape=(channels, xh, xw), \n",
    "                       weights=[W], \n",
    "                       padding=padding, \n",
    "                       use_bias=False, \n",
    "                       data_format=\"channels_first\") \n",
    "                ])\n",
    "\n",
    "    return model.predict(X,batch_size=1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Primeiro caso, resposta ao impulso\n",
    "\n",
    "Esta é uma forma usual para se verificar se a convolução está funcionando. Quando a imagem de entrada é apenas um 1 rodeado de vários zeros, o resultado da convolução é o próprio kernel posicionado no local do 1? \n",
    "\n",
    "Teoricamente é o que deveria acontecer, porém o que chamamos de convolução neste notebook é na verdade é uma relação cruzada (cross-correlation). Durante o treinamento da rede convulucional o resultado é o mesmo nas duas notações. E na maior parte da literatura sobre Deep Learning o termo *convolução* se refere ao que utilizamos aqui. \n",
    "\n",
    "Assim, utilizaremos uma imagem cinza 3x5 com um \"1\" no centro. O kernel é de 2 linhas e 3 colunas. O resultado é uma imagem 3x5 com o kernel posicionado no local do 1 da imagem de entrada, porém invertido horizontalmente e verticalmente."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "x.shape: (1, 1, 5, 7)\n",
      "[[[[0 0 0 0 0 0 0]\n",
      "   [0 0 0 0 0 0 0]\n",
      "   [0 0 0 1 0 0 0]\n",
      "   [0 0 0 0 0 0 0]\n",
      "   [0 0 0 0 0 0 0]]]]\n",
      "W.shape: (1, 1, 2, 3)\n",
      "[[[[ 1.  2.  3.]\n",
      "   [ 4.  5.  6.]]]]\n",
      "y.shape: (1, 1, 4, 5)\n",
      "[[[[ 0.  0.  0.  0.  0.]\n",
      "   [ 0.  6.  5.  4.  0.]\n",
      "   [ 0.  3.  2.  1.  0.]\n",
      "   [ 0.  0.  0.  0.  0.]]]]\n"
     ]
    }
   ],
   "source": [
    "#np.set_printoptions(suppress=True, precision=3)\n",
    "\n",
    "x = np.array([[0,0,0,0,0,0,0],\n",
    "              [0,0,0,0,0,0,0],\n",
    "              [0,0,0,1,0,0,0],\n",
    "              [0,0,0,0,0,0,0],\n",
    "              [0,0,0,0,0,0,0]]).reshape(1,1,5,7)\n",
    "W = np.array([[1.,2.,3.],\n",
    "              [4.,5.,6.]]).reshape(1,1,2,3)\n",
    "\n",
    "y = conv4d(x,W, 'valid')\n",
    "\n",
    "print('x.shape:', x.shape)\n",
    "print(x)\n",
    "print('W.shape:', W.shape)\n",
    "print(W)\n",
    "print('y.shape:', y.shape)\n",
    "print(y)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "## Reproduzindo o exemplo da figura animada acima"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "x.shape: (1, 1, 5, 5)\n",
      "[[[[1 1 1 0 0]\n",
      "   [0 1 1 1 0]\n",
      "   [0 0 1 1 1]\n",
      "   [0 0 1 1 0]\n",
      "   [0 1 1 0 0]]]]\n",
      "W.shape: (1, 1, 3, 3)\n",
      "[[[[1 0 1]\n",
      "   [0 1 0]\n",
      "   [1 0 1]]]]\n",
      "y.shape: (1, 1, 3, 3)\n",
      "[[[[ 4.  3.  4.]\n",
      "   [ 2.  4.  3.]\n",
      "   [ 2.  3.  4.]]]]\n"
     ]
    }
   ],
   "source": [
    "x = np.array([[1,1,1,0,0],\n",
    "              [0,1,1,1,0],\n",
    "              [0,0,1,1,1],\n",
    "              [0,0,1,1,0],\n",
    "              [0,1,1,0,0]]).reshape(1,1,5,5)\n",
    "W = np.array([[1,0,1],\n",
    "              [0,1,0],\n",
    "              [1,0,1]]).reshape(1,1,3,3)\n",
    "\n",
    "y = conv4d(x,W,'valid')\n",
    "\n",
    "print('x.shape:', x.shape)\n",
    "print(x)\n",
    "print('W.shape:', W.shape)\n",
    "print(W)\n",
    "print('y.shape:', y.shape)\n",
    "print(y)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 4 amostras de imagem cinza 3x5, 1 filtro com kernel de 3x3 \n",
    "\n",
    "Neste caso, \n",
    "- shape da entrada, x:(4,1,3,5)\n",
    "- shape dos pesos W:(1, 1, 3,3). \n",
    "- shape de saída será y:(4,1,3,5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "x.shape: (4, 1, 3, 5)\n",
      "[[[[0 0 0 0 0]\n",
      "   [0 0 0 0 0]\n",
      "   [0 0 0 0 0]]]\n",
      "\n",
      "\n",
      " [[[0 0 0 0 0]\n",
      "   [0 0 1 0 0]\n",
      "   [0 0 0 0 0]]]\n",
      "\n",
      "\n",
      " [[[0 0 0 0 0]\n",
      "   [0 0 2 0 0]\n",
      "   [0 0 0 0 0]]]\n",
      "\n",
      "\n",
      " [[[0 0 0 0 0]\n",
      "   [0 0 3 0 0]\n",
      "   [0 0 0 0 0]]]]\n",
      "W.shape: (1, 1, 3, 3)\n",
      "[[[[1 0 1]\n",
      "   [0 1 0]\n",
      "   [1 0 1]]]]\n",
      "y.shape: (4, 1, 3, 5)\n",
      "[[[[ 0.  0.  0.  0.  0.]\n",
      "   [ 0.  0.  0.  0.  0.]\n",
      "   [ 0.  0.  0.  0.  0.]]]\n",
      "\n",
      "\n",
      " [[[ 0.  1.  0.  1.  0.]\n",
      "   [ 0.  0.  1.  0.  0.]\n",
      "   [ 0.  1.  0.  1.  0.]]]\n",
      "\n",
      "\n",
      " [[[ 0.  2.  0.  2.  0.]\n",
      "   [ 0.  0.  2.  0.  0.]\n",
      "   [ 0.  2.  0.  2.  0.]]]\n",
      "\n",
      "\n",
      " [[[ 0.  3.  0.  3.  0.]\n",
      "   [ 0.  0.  3.  0.  0.]\n",
      "   [ 0.  3.  0.  3.  0.]]]]\n"
     ]
    }
   ],
   "source": [
    "W = np.array([[1,0,1],\n",
    "              [0,1,0],\n",
    "              [1,0,1]]).reshape(1,1,3,3)\n",
    "# criando 4 amostras de imagens\n",
    "x = np.array([[0,0,0,0,0],\n",
    "              [0,0,1,0,0],\n",
    "              [0,0,0,0,0]]).reshape(1,1,3,5) * np.arange(4).reshape(4,1,1,1)\n",
    "y = conv4d(x,W,'same')\n",
    "print('x.shape:', x.shape)\n",
    "print(x)\n",
    "print('W.shape:', W.shape)\n",
    "print(W)\n",
    "print('y.shape:', y.shape)\n",
    "print(y)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2 filtros com kernel de 3x3, 1 amostra de imagem cinza 3x5\n",
    "\n",
    "Neste caso, \n",
    "- shape da entrada, x:(1,1,3,5)\n",
    "- shape dos pesos W:(2, 1, 3,3). \n",
    "- shape de saída será y:(1,2,3,5)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "x.shape: (1, 1, 3, 5)\n",
      "[[[[0 0 0 0 0]\n",
      "   [0 0 1 0 0]\n",
      "   [0 0 0 0 0]]]]\n",
      "W.shape: (2, 1, 3, 3)\n",
      "[[[[1 0 1]\n",
      "   [0 1 0]\n",
      "   [1 0 1]]]\n",
      "\n",
      "\n",
      " [[[0 1 0]\n",
      "   [1 2 1]\n",
      "   [0 1 0]]]]\n",
      "y.shape: (1, 2, 3, 5)\n",
      "[[[[ 0.  1.  0.  1.  0.]\n",
      "   [ 0.  0.  1.  0.  0.]\n",
      "   [ 0.  1.  0.  1.  0.]]\n",
      "\n",
      "  [[ 0.  0.  1.  0.  0.]\n",
      "   [ 0.  1.  2.  1.  0.]\n",
      "   [ 0.  0.  1.  0.  0.]]]]\n"
     ]
    }
   ],
   "source": [
    "W = np.array([[[1,0,1],\n",
    "               [0,1,0],\n",
    "               [1,0,1]],\n",
    "              [[0,1,0],\n",
    "               [1,2,1],\n",
    "               [0,1,0]]]).reshape(2,1,3,3)\n",
    "x = np.array([[0,0,0,0,0],\n",
    "              [0,0,1,0,0],\n",
    "              [0,0,0,0,0]]).reshape(1,1,3,5)\n",
    "y = conv4d(x,W,'same')\n",
    "print('x.shape:', x.shape)\n",
    "print(x)\n",
    "print('W.shape:', W.shape)\n",
    "print(W)\n",
    "print('y.shape:', y.shape)\n",
    "print(y)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1 filtro com kernel de 3x3 e 3 canais, 1 amostra de imagem 3x5 RGB (3 canais)\n",
    "Neste caso, como a imagem de entrada possui 3 bandas, para guardar as bandas Red, Green e Blue, o kernel também precisa ter 3 bandas pois são necessários pesos para cada banda de cor.\n",
    "- shape da entrada, x:(1,3,3,5)\n",
    "- shape dos pesos W:(1, 3, 3,3). \n",
    "- shape de saída será y:(1,2,3,5)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "x.shape: (1, 3, 3, 5)\n",
      "[[[[0 0 0 0 0]\n",
      "   [0 1 0 0 0]\n",
      "   [0 0 0 0 0]]\n",
      "\n",
      "  [[0 0 0 0 1]\n",
      "   [0 0 1 0 0]\n",
      "   [0 0 0 0 0]]\n",
      "\n",
      "  [[0 0 0 0 0]\n",
      "   [0 0 0 1 0]\n",
      "   [0 0 0 0 0]]]]\n",
      "W.shape: (1, 3, 3, 3)\n",
      "[[[[1 0 1]\n",
      "   [0 1 0]\n",
      "   [1 0 1]]\n",
      "\n",
      "  [[0 1 0]\n",
      "   [1 1 1]\n",
      "   [0 1 0]]\n",
      "\n",
      "  [[0 1 0]\n",
      "   [0 1 0]\n",
      "   [0 1 0]]]]\n",
      "y.shape: (1, 1, 3, 5)\n",
      "[[[[ 1.  0.  2.  2.  1.]\n",
      "   [ 0.  2.  1.  2.  1.]\n",
      "   [ 1.  0.  2.  1.  0.]]]]\n"
     ]
    }
   ],
   "source": [
    "W = np.array([[[1,0,1],\n",
    "               [0,1,0],\n",
    "               [1,0,1]],\n",
    "              [[0,1,0],\n",
    "               [1,1,1],\n",
    "               [0,1,0]],\n",
    "              [[0,1,0],\n",
    "               [0,1,0],\n",
    "               [0,1,0]]]).reshape(1,3,3,3)\n",
    "x = np.array([[[0,0,0,0,0],\n",
    "               [0,1,0,0,0],\n",
    "               [0,0,0,0,0]],\n",
    "              [[0,0,0,0,1],\n",
    "               [0,0,1,0,0],\n",
    "               [0,0,0,0,0]],\n",
    "              [[0,0,0,0,0],\n",
    "               [0,0,0,1,0],\n",
    "               [0,0,0,0,0]]]).reshape(1,3,3,5)\n",
    "y = conv4d(x,W,'same')\n",
    "print('x.shape:', x.shape)\n",
    "print(x)\n",
    "print('W.shape:', W.shape)\n",
    "print(W)\n",
    "print('y.shape:', y.shape)\n",
    "print(y)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Exercícios\n",
    "\n",
    "### Teórico\n",
    "\n",
    "1. Supondo uma imagem de entrada 100 x 100 e um kernel 3 x 3. Utilizando-se o border_mode como válido, a imagem de saída será de 98 x 98. Se fosse utilizar uma rede densa, com entrada de 100 x 100 e saída 98 x 98, quantos parâmetros seriam necessários para ser treinados? E no caso da rede convolucional? Qual é o fator de redução?\n",
    "\n",
    "### Práticos\n",
    "\n",
    "1. Trocar o parâmetro ``border_mode`` para ``same`` e veja a diferença.\n",
    "2. Rodar a convolução para uma imagem de cinza\n",
    "3. Rodar a convolução para uma imagem colorida RGB\n",
    "4. Comparar o tempo de execução desta convolução com outras implementações: scipy, skimage ou openCV"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Aprendizados com este notebook\n",
    "\n",
    "1. A rede convolucional é uma forma eficiente de se ter uma rede densa restrita, onde os parâmetros são localizados (em imagens). Os parâmetros do filtro da convolução agem como pesos compartilhados na rede densa. As vantagens são que o número de parâmetros é extremamente reduzido se comparado com a rede densa, permitindo assim criar redes com muitas camadas (maior flexibilidade) facilitando o treinamento.\n",
    "2. Este notebook ilustra como usar a convolução no Keras.\n"
   ]
  }
 ],
 "metadata": {
  "anaconda-cloud": {},
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.1"
  },
  "toc": {
   "colors": {
    "hover_highlight": "#DAA520",
    "running_highlight": "#FF0000",
    "selected_highlight": "#FFD700"
   },
   "moveMenuLeft": true,
   "nav_menu": {
    "height": "334px",
    "width": "252px"
   },
   "navigate_menu": true,
   "number_sections": true,
   "sideBar": true,
   "threshold": 4,
   "toc_cell": false,
   "toc_section_display": "block",
   "toc_window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
