{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "heading_collapsed": true
   },
   "source": [
    "# Segundo dia de treinamento"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "hidden": true
   },
   "source": [
    "Neste segundo dia estaremos cobrindo \n",
    "* os conceitos básicos de redes neurais e \n",
    "* iniciando os conceitos básicos de redes convolucionais.\n",
    "\n",
    "Resolução e Comentários sobre os Exercícios:\n",
    "\n",
    "- [Gradiente Estocástico - mini_batch](Regressao-Linear-solucaoExercicio.ipynb)\n",
    "- [Jview Jview3D - Visualização 2D do Gradiente Descendente no espaço de parâmetros](Regressao-Linear-solucaoExercicio.ipynb)\n",
    "- [FSview - Visualização do Espaço de Atributos - Classificador](Regressao-Logistica-Softmax-Iris-2D-matricial-SolucaoExercicio.ipynb)\n",
    "- [Regressao-Logistica-Softmax-MNIST-matricial.ipynb](Regressao-Logistica-Softmax-MNIST-matricial.ipynb)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "heading_collapsed": true
   },
   "source": [
    "# Treinamento Redes Neurais e Aprendizado Profundo de Máquina"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "hidden": true
   },
   "source": [
    "<img src=\"../figures/capacursomovile.png\",width=600pt>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "heading_collapsed": true
   },
   "source": [
    "# I - Introdução ao curso"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "hidden": true
   },
   "source": [
    "1. Conteúdo e formato do curso \n",
    "2. Introdução a Aprendizagem de Máquina, Redes Neurais Profundas e Redes Convolucionais\n",
    "3. Ferramentas e Ambiente de trabalho durante o curso\n",
    "    - Jupyter, Git, Python, NumPy\n",
    "    * NB:[Git e Github](Git-basico-Git-Classroom.ipynb)\n",
    "    * NB:[Python](tutorial-python.ipynb)\n",
    "    * NB:[NumPy](tutorial-numpy.ipynb)\n",
    "    * NB:[NumPy - reshape, redução de eixo e broadcast](numpy-reshape-broadcast-reducao.ipynb)\n",
    "    * Toolbox ia898: [Tutoriais Jupyter/Python/NumPy/Proc. Imagens](../../ia898/master/0_index.ipynb)\n",
    "    \n",
    "4. [Glossário](Glossario.ipynb)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "heading_collapsed": true
   },
   "source": [
    "# II - Introdução a redes neurais"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "heading_collapsed": true,
    "hidden": true
   },
   "source": [
    "## Regressão Linear"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "hidden": true
   },
   "source": [
    "### Regressão Linear - codificação matricial NumPy - codificação Keras"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "hidden": true
   },
   "source": [
    "- Conceitos novos:\n",
    "- Teoria: Otimização Mínimos Quadrados usando gradiente descendente, notação matemática\n",
    "- Prática: Programação matricial $y = Xw$; Laço de gradiente descendente; Plotando gráficos; visualizando animação da otimização na função custo e no ajuste reta\n",
    "    * NB: [Regressão Linear](Regressao-Linear.ipynb) "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "hidden": true
   },
   "source": [
    "### Regressão Linear no TensorFlow"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "hidden": true
   },
   "source": [
    "- Conceitos novos:\n",
    "- Teoria: Estilo de programação linguagem de fluxo\n",
    "- Prática: Implementação da Regressão Linear no TensorFlow\n",
    "    * NB: [Regressão Linear Tensorflow](Regressao-Linear-tensorflow.ipynb) \n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "heading_collapsed": true,
    "hidden": true
   },
   "source": [
    "## Regressão Logística - Classificação"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "hidden": true
   },
   "source": [
    "### Softmax"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "hidden": true
   },
   "source": [
    "- Conceitos novos:\n",
    "- Teoria: Softmax para classificação multiclasse\n",
    "- Prática: Explorando comportamento do Softmax, com parâmetros interativos\n",
    " * NB: [Softmax](softmax.ipynb)\n",
    " "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "hidden": true
   },
   "source": [
    "### Regressão Logística multiclasse - Iris - implementação matricial"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "hidden": true
   },
   "source": [
    "- Conceitos novos: \n",
    "- Teoria: Classificação multiclasse com Softmax; Custo entropia cruzada; one-hot-encoding; mesmo modelo anterior de otimização\n",
    "    * NB: [Regressão Logística Multiclasse Softmax - Iris 2D - Programação matricial](Regressao-Logistica-Softmax-Iris-2D-matricial.ipynb)\n",
    "    * NB: [Regressão Logística Multiclasse Softmax - Iris 2D - programação matricial - fronteira dinâmica](Regressao-Logistica-Softmax-Iris-2D-matricial-Fronteira-Dinamica.ipynb)\n",
    "\n",
    "### Regressão Logística multiclasse - Iris - implementação no Keras"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "hidden": true
   },
   "source": [
    "- Conceitos novos:\n",
    "- Prática: Introdução inicial do Keras, mostrando que executa o mesmo exemplo anterior; criando a rede, definindo otimizador\n",
    " * NB: [Regressão Logística Multiclasse Softmax - Iris 2D - usando o Keras](Regressao-Logistica-Softmax-Iris-2D-Keras.ipynb)\n",
    " * NB: [Regressão Logística Multiclasse Softmax - Iris 2D - usando o Keras - Fronteira dinâmica](Regressao-Logistica-Softmax-Iris-2D-Keras-Fronteira-Dinamica.ipynb)\n",
    "\n",
    "### Regressão Logística multiclasse - dataset NMIST - implementação matricial"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "hidden": true
   },
   "source": [
    "- Conceitos novos:\n",
    "- Prática: dataset NMIST, Visualização dos pesos na forma de template; não é possível mais visualizar espaço de atributos nem espaço de parâmetros. Visualiza-se a queda da função de perda\n",
    " * NB: [Regressão Logística Multiclasse Softmax - MNIST - Programação Matricial](Regressao-Logistica-Softmax-MNIST-matricial.ipynb)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "hidden": true
   },
   "source": [
    "### Regressão Logística multiclasse - dataset NMIST - implementação no Keras"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "hidden": true
   },
   "source": [
    "- Conceitos novos:\n",
    "- Prática: extraindo os pesos aprendidos da rede no Keras\n",
    " * NB: [Regressão Logística Multiclasse Softmax - MNIST - usando o Keras](Regressao-Logistica-Softmax-MNIST-Keras.ipynb)\n",
    " "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "heading_collapsed": true,
    "hidden": true
   },
   "source": [
    "## Overfitting e Underfitting - Regularização"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "hidden": true
   },
   "source": [
    "### Ilustrando overfitting e underfitting, regularização com exemplo de  ajuste de polinômio"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "hidden": true
   },
   "source": [
    "- Conceitos novos:\n",
    "- Teoria: Conceito de overfitting e underfitting, conceito de regularização, função de custo\n",
    "- Prática: Explorando parâmetros de ajustes e parâmetros de regularização\n",
    " * NB: [Ajuste curvas: Overfitting - Underfitting - Regularização](overfitting_regularization.ipynb)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "heading_collapsed": true,
    "hidden": true
   },
   "source": [
    "## Ativações"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "hidden": true
   },
   "source": [
    "- Conceitos novos: \n",
    "- Teoria: introdução aos novos tipos de ativações não lineares\n",
    "- Prática: programa que implementa a equação de diversas ativações\n",
    " * NB: [Ativações](Activations.ipynb)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "heading_collapsed": true,
    "hidden": true
   },
   "source": [
    "## Rede Neural"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "hidden": true
   },
   "source": [
    "### Dataset - Boston Houses"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "hidden": true
   },
   "source": [
    "- Conceitos novos:\n",
    "- Prática: Explorando um dataset, verificando consistência de dados\n",
    " * NB: [Conjunto de Dados Preços das casas de Boston](boston_housing.ipynb)\n",
    " "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "hidden": true
   },
   "source": [
    "### Rede Neural - Retropropagação - implementação matricial"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "hidden": true
   },
   "source": [
    "- Conceitos novos:\n",
    "- Teoria: concatenação de camadas, gradiente via backpropagation, verificação de gradiente\n",
    "- Prática: implementação matricial rede neural\n",
    " * NB: [Rede neural implementação matricial - backpropagation](neural_networks.ipynb)\n",
    " * NB: [Rede neural implementação matricial - backpropagation com Bias](neural_networks_bias.ipynb)\n",
    " "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "hidden": true
   },
   "source": [
    "### Rede Neural - Iris dataset - implementação no Keras"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "hidden": true
   },
   "source": [
    "- Conceitos novos:\n",
    "- Teoria: concatenação de camadas com elemento não linear reLU; retropropagação;\n",
    "- Prática: Dificuldade de otimização, falta de atributos\n",
    " * NB: [Rede Neural 2 camadas com reLU - Iris - usando Keras](Densas-2.ipynb)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "hidden": true
   },
   "source": [
    "### Rede Neural - implementação matricial com regularização L2"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "hidden": true
   },
   "source": [
    "- Conceitos novos:\n",
    "- Teoria: regularização L2\n",
    "- Prática: implementação matricial rede neural com regularização L2\n",
    " * NB: [Rede neural implementação matricial - regularização L2](neural_networks_l2.ipynb)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "hidden": true
   },
   "source": [
    "### Rede Neural - Regularização no Keras"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "hidden": true
   },
   "source": [
    "- Conceitos novos:\n",
    "- Teoria: regularização L1, L2, dropout, early-stop\n",
    "- Prática: uso da regularização no Keras\n",
    " * NB: [Rede neural - regularização no Keras](Regularization.ipynb)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "hidden": true
   },
   "source": [
    "### Rede Neural - implementação no TensorFlow"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "hidden": true
   },
   "source": [
    "- Conceitos novos:\n",
    "- Prática: implementação da rede neural utilizando o TensorFlow\n",
    " * NB: [Rede neural implementação no tensorflow](neural_networks_tf.ipynb)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "heading_collapsed": true,
    "hidden": true
   },
   "source": [
    "## Seleção de modelo - escolha de hyperparâmetros"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2017-04-21T00:46:59.730628",
     "start_time": "2017-04-21T00:46:59.710761"
    },
    "hidden": true
   },
   "source": [
    "- Conceitos novos:\n",
    "- Teoria: Processo de seleção de modelo, busca de hyperparâmetros\n",
    "- Prática: Divisão do conjunto de dados: treino, validação e testes.\n",
    "- seleção de modelo, busca por ajuste de hyperparâmetros\n",
    " * NB: [Seleção de modelo](model_selection.ipynb)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "heading_collapsed": true
   },
   "source": [
    "# III - Redes neurais profundas - redes convolucionais"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "heading_collapsed": true,
    "hidden": true
   },
   "source": [
    "## Introdução"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "hidden": true
   },
   "source": [
    "### Convolução Keras/TensorFlow"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "hidden": true
   },
   "source": [
    "- Conceitos novos:\n",
    "- Teoria: Convolução, processamento borda, zero-padding, dimensionalidade dos arrays\n",
    "- Prática: rede convolucional no Keras, variação de número de imagens, kernels e filtros de saída\n",
    " * NB: [Convolução](Explorando-Convolucao-no-Keras-usando-TensorFlow.ipynb)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "hidden": true
   },
   "source": [
    "### Introdução ao Keras"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "hidden": true
   },
   "source": [
    "- Conceitos novos:\n",
    "- Prática: Keras, criando o modelo, colocando pesos, retirando pesos e retirando camadas\n",
    " * NB: [Introdução ao Keras](Introducao-CNN-Keras.ipynb)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "hidden": true
   },
   "source": [
    "## Rede Convolucional - Exemplos simples"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "hidden": true
   },
   "source": [
    "### Rede Convolucional - Visualização camadas internas - CIFAR-10"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "hidden": true
   },
   "source": [
    "- Conceitos novos:\n",
    "- Teoria: visualização das camadas internas\n",
    "- Prática: Keras - criando a rede, treinando e avaliando\n",
    " * NB: [CIFAR-10 e rede convolucional no Keras](cifar10-CNN-features.ipynb)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "hidden": true
   },
   "source": [
    "### Rede Convolucional - MNIST reduzido"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "hidden": true
   },
   "source": [
    "- Conceitos novos:\n",
    "- Teoria: Rede convolucional LeNet\n",
    " * NB: [KerasLenetMNIST](keras-lenet-mnist.ipynb)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "heading_collapsed": true
   },
   "source": [
    "# Documentação"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "hidden": true
   },
   "source": [
    "- [Jupyter Notebook](http://jupyter-notebook.readthedocs.io/en/latest/notebook.html)\n",
    "- [NumPy](https://docs.scipy.org/doc/)\n",
    "- [Matplotlib](https://matplotlib.org/contents.html)\n",
    "- [Keras](https://keras.io/)"
   ]
  }
 ],
 "metadata": {
  "anaconda-cloud": {},
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.0"
  },
  "toc": {
   "colors": {
    "hover_highlight": "#DAA520",
    "running_highlight": "#FF0000",
    "selected_highlight": "#FFD700"
   },
   "moveMenuLeft": true,
   "nav_menu": {
    "height": "512px",
    "width": "252px"
   },
   "navigate_menu": true,
   "number_sections": true,
   "sideBar": true,
   "threshold": 4,
   "toc_cell": false,
   "toc_section_display": "block",
   "toc_window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
