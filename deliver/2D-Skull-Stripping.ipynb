{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# CNN U-NET: Skull-Stripping em Imagens 2D\n",
    "\n",
    "From: https://github.com/jocicmarko/ultrasound-nerve-segmentation\n",
    "\n",
    "Exemplo de Skull-Stripping (Segmentação do cérebro) em imagens 2D de ressonância magnética utilizando a implementação da CNN U-NET do link acima. Os resultados iniciais desta implementação foram submetidos ao evento BRAINN 2017.\n",
    "\n",
    "Neste exemplo utilizou-se as imagens do dataset CC-349, em que 250 imagens foram utilizadas para treino e como efeito ilustrativo, o teste foi realizado em 4 imagens as quais são apresentadas no fim do notebook.\n",
    "         \n",
    "CC-349 dataset: http://miclab.fee.unicamp.br/calgary-campinas-359 \n",
    "\n",
    "Artigo U-NET: https://arxiv.org/pdf/1505.04597.pdf\n",
    "\n",
    "Arquitetura da U-NET:\n",
    "![](http://lmb.informatik.uni-freiburg.de/people/ronneber/u-net/u-net-architecture.png)\n",
    "\n",
    "**Informações das pastas**:\n",
    "\n",
    "```\n",
    "src/\n",
    "    train_mid_samples/ (imagens do treino em 2D da fatia central sagital) - Já criada. \n",
    "    train_patches/ (patches para o treino) - Código irá criar!\n",
    "    test_mid_samples/ (imagens do test em 2D da fatia central sagital) - Já criada.\n",
    "    test_patches/ (patches para o teste) Código irá criar!\n",
    "    test_prep_data/ (dados de teste pré-processados para predição) - Código irá criar! \n",
    "    pred_data/ (resultados das predições da CNN) - Código irá criar!\n",
    "    pred_image/ (imagens reconstruídas a partir das predições da CNN) - Código irá criar!\n",
    "\n",
    "```\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Módulos a serem utilizados"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "%matplotlib inline\n",
    "import numpy as np\n",
    "import os\n",
    "os.environ['THEANO_FLAGS'] = \"device=gpu0,floatX=float32\"    \n",
    "import theano"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# Keras\n",
    "from keras.models import Model\n",
    "from keras.layers import Input, merge, Convolution2D, MaxPooling2D, UpSampling2D\n",
    "from keras.optimizers import Adam\n",
    "from keras.callbacks import ModelCheckpoint, LearningRateScheduler\n",
    "from keras import backend as K\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Biblioteca necessária para leitura de dados em ordem lexográfica."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: natsort in /opt/conda/lib/python2.7/site-packages\r\n"
     ]
    }
   ],
   "source": [
    "!pip install natsort"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "import glob\n",
    "import time\n",
    "import cv2\n",
    "import matplotlib.pylab as plt\n",
    "import sys\n",
    "sys.path.append('../src')\n",
    "from prep_ss_utils import create_data, save_2d_samples\n",
    "from prep_ss_utils import sample_2d_patches, preprocess, get_mean_std_train, read_prep_test\n",
    "from prep_ss_utils import load_train_data, reconstruct_2d_sample, save_data\n",
    "from my_keras_utilities import TrainingPlotter, load_model_and_history"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# Diretório do notebook\n",
    "out = '/root'\n",
    "\n",
    "# Configurações da u-net\n",
    "img_rows = 64\n",
    "img_cols = 80\n",
    "smooth = 1.\n",
    "model_name = '/opt/projects/models/epoch_30_unet' #'30_epoch_unet.hdf5'\n",
    "\n",
    "# Pastas que estão ou serão criadas no diretório do notebook\n",
    "train_mid_samples = 'train_mid_samples'\n",
    "train_patches = 'train_patches'\n",
    "test_mid_samples = 'test_mid_samples'\n",
    "test_patches = 'test_patches'\n",
    "test_prep_data = 'test_prep_data'\n",
    "pred_image = 'pred_image'\n",
    "pred_data = 'pred_data'\n",
    "\n",
    "# Função para criar novo diretório\n",
    "def create_new_dir(dstDir):\n",
    "    \n",
    "    if not os.path.exists(dstDir):\n",
    "        os.makedirs(dstDir)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Pré-processamento"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Dados de Treino"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "------------------------------\n",
      "Creating Train 2D Patches...\n",
      "------------------------------\n",
      "Sampling Train Images ...\n",
      "('Saving train image patches:', 'CAMP_SLE_CONTROL0002')\n",
      "('Saving train image patches:', 'CAMP_SLE_CONTROL0004')\n",
      "('Saving train image patches:', 'CAMP_SLE_CONTROL0006')\n",
      "('Saving train image patches:', 'CAMP_SLE_CONTROL0007')\n",
      "('Saving train image patches:', 'CAMP_SLE_CONTROL0008')\n",
      "('Saving train image patches:', 'CAMP_SLE_CONTROL0009')\n",
      "('Saving train image patches:', 'CAMP_SLE_CONTROL0015')\n",
      "('Saving train image patches:', 'CAMP_SLE_CONTROL0021')\n",
      "('Saving train image patches:', 'CAMP_SLE_CONTROL0022')\n",
      "('Saving train image patches:', 'CAMP_SLE_CONTROL0024')\n",
      "('Saving train image patches:', 'CAMP_SLE_CONTROL0027')\n",
      "('Saving train image patches:', 'CAMP_SLE_CONTROL0028')\n",
      "('Saving train image patches:', 'CAMP_SLE_CONTROL0029')\n",
      "('Saving train image patches:', 'CAMP_SLE_CONTROL0030')\n",
      "('Saving train image patches:', 'CAMP_SLE_CONTROL0031')\n",
      "('Saving train image patches:', 'CAMP_SLE_CONTROL0034')\n",
      "('Saving train image patches:', 'CAMP_SLE_CONTROL0036')\n",
      "('Saving train image patches:', 'CAMP_SLE_CONTROL0037')\n",
      "('Saving train image patches:', 'CAMP_SLE_CONTROL0038')\n",
      "('Saving train image patches:', 'CAMP_SLE_CONTROL0039')\n",
      "('Saving train image patches:', 'CAMP_SLE_CONTROL0041')\n",
      "('Saving train image patches:', 'CAMP_SLE_CONTROL0049')\n",
      "('Saving train image patches:', 'CAMP_SLE_CONTROL0050')\n",
      "('Saving train image patches:', 'CAMP_SLE_CONTROL0051')\n",
      "('Saving train image patches:', 'CAMP_SLE_CONTROL0057')\n",
      "('Saving train image patches:', 'CAMP_SLE_CONTROL0058')\n",
      "('Saving train image patches:', 'CAMP_SLE_CONTROL0059')\n",
      "('Saving train image patches:', 'CAMP_SLE_CONTROL0060')\n",
      "('Saving train image patches:', 'CAMP_SLE_CONTROL0062')\n",
      "('Saving train image patches:', 'CAMP_SLE_CONTROL0064')\n",
      "('Saving train image patches:', 'CAMP_SLE_CONTROL0066')\n",
      "('Saving train image patches:', 'CAMP_SLE_CONTROL0069')\n",
      "('Saving train image patches:', 'CAMP_SLE_CONTROL0071')\n",
      "('Saving train image patches:', 'CAMP_SLE_CONTROL0073')\n",
      "('Saving train image patches:', 'CAMP_SLE_CONTROL0076')\n",
      "('Saving train image patches:', 'CAMP_SLE_CONTROL0080')\n",
      "('Saving train image patches:', 'CAMP_SLE_CONTROL0081')\n",
      "('Saving train image patches:', 'CAMP_SLE_CONTROL0082')\n",
      "('Saving train image patches:', 'CAMP_SLE_CONTROL0083')\n",
      "('Saving train image patches:', 'CAMP_SLE_CONTROL0086')\n",
      "('Saving train image patches:', 'CAMP_SLE_CONTROL0087')\n",
      "('Saving train image patches:', 'CAMP_SLE_CONTROL0088')\n",
      "('Saving train image patches:', 'CAMP_SLE_CONTROL0089')\n",
      "('Saving train image patches:', 'CAMP_SLE_CONTROL0091')\n",
      "('Saving train image patches:', 'CAMP_SLE_CONTROL0093')\n",
      "('Saving train image patches:', 'CAMP_SLE_CONTROL0095')\n",
      "('Saving train image patches:', 'CAMP_SLE_CONTROL0097')\n",
      "('Saving train image patches:', 'CAMP_SLE_CONTROL0100')\n",
      "('Saving train image patches:', 'CAMP_SLE_CONTROL0101')\n",
      "('Saving train image patches:', 'CAMP_SLE_CONTROL0102')\n",
      "('Saving train image patches:', 'CAMP_SLE_CONTROL0104')\n",
      "('Saving train image patches:', 'CAMP_SLE_CONTROL0105')\n",
      "('Saving train image patches:', 'CAMP_SLE_CONTROL0106')\n",
      "('Saving train image patches:', 'CAMP_SLE_CONTROL0107')\n",
      "('Saving train image patches:', 'CAMP_SLE_CONTROL0108')\n",
      "('Saving train image patches:', 'CAMP_SLE_CONTROL0109')\n",
      "('Saving train image patches:', 'CAMP_SLE_CONTROL0110')\n",
      "('Saving train image patches:', 'CAMP_SLE_CONTROL0111')\n",
      "('Saving train image patches:', 'CAMP_SLE_CONTROL0112')\n",
      "('Saving train image patches:', 'CAMP_SLE_CONTROL0113')\n",
      "('Saving train image patches:', 'CVCD01120001')\n",
      "('Saving train image patches:', 'CVCD01120003')\n",
      "('Saving train image patches:', 'CVCD01120013')\n",
      "('Saving train image patches:', 'CVCD01120016')\n",
      "('Saving train image patches:', 'CVCD01120018')\n",
      "('Saving train image patches:', 'CVCD01120021')\n",
      "('Saving train image patches:', 'CVCD01120030')\n",
      "('Saving train image patches:', 'CVCD01120034')\n",
      "('Saving train image patches:', 'CVCD01120038')\n",
      "('Saving train image patches:', 'CVCD01120041')\n",
      "('Saving train image patches:', 'CVCD01120043')\n",
      "('Saving train image patches:', 'CVCD01120044')\n",
      "('Saving train image patches:', 'CVCD01120047')\n",
      "('Saving train image patches:', 'CVCD01120054')\n",
      "('Saving train image patches:', 'CVCD01120055')\n",
      "('Saving train image patches:', 'CVCD01120065')\n",
      "('Saving train image patches:', 'CVCD01120067')\n",
      "('Saving train image patches:', 'CVCD01120069')\n",
      "('Saving train image patches:', 'CVCD01120070')\n",
      "('Saving train image patches:', 'CVCD01120074')\n",
      "('Saving train image patches:', 'CVCD01120077')\n",
      "('Saving train image patches:', 'CVCD01120078')\n",
      "('Saving train image patches:', 'CVCD01120079')\n",
      "('Saving train image patches:', 'CVCD01120080')\n",
      "('Saving train image patches:', 'CVCD01120082')\n",
      "('Saving train image patches:', 'CVCD01120099')\n",
      "('Saving train image patches:', 'CVCD01120101')\n",
      "('Saving train image patches:', 'CVCD01120102')\n",
      "('Saving train image patches:', 'CVCD01120105')\n",
      "('Saving train image patches:', 'CVCD01120108')\n",
      "('Saving train image patches:', 'CVCD01120123')\n",
      "('Saving train image patches:', 'CVCD01120124')\n",
      "('Saving train image patches:', 'CVCD01120129')\n",
      "('Saving train image patches:', 'CVCD01120133')\n",
      "('Saving train image patches:', 'CVCD01120136')\n",
      "('Saving train image patches:', 'CVCD01120139')\n",
      "('Saving train image patches:', 'CVCD01120141')\n",
      "('Saving train image patches:', 'CVCD01120166')\n",
      "('Saving train image patches:', 'CVCD01120167')\n",
      "('Saving train image patches:', 'CVCD03060007')\n",
      "('Saving train image patches:', 'CVCD03060009')\n",
      "('Saving train image patches:', 'CVCD03060010')\n",
      "('Saving train image patches:', 'CVCD03060013')\n",
      "('Saving train image patches:', 'CVCD03060015')\n",
      "('Saving train image patches:', 'CVCD03060019')\n",
      "('Saving train image patches:', 'CVCD03060026')\n",
      "('Saving train image patches:', 'CVCD03060028')\n",
      "('Saving train image patches:', 'CVCD03060030')\n",
      "('Saving train image patches:', 'CVCD03060032')\n",
      "('Saving train image patches:', 'CVCD03060036')\n",
      "('Saving train image patches:', 'CVCD03060037')\n",
      "('Saving train image patches:', 'CVCD03060041')\n",
      "('Saving train image patches:', 'CVCD03060042')\n",
      "('Saving train image patches:', 'CVCD03060047')\n",
      "('Saving train image patches:', 'CVCD03060049')\n",
      "('Saving train image patches:', 'CVCD03060051')\n",
      "('Saving train image patches:', 'CVCD03060052')\n",
      "('Saving train image patches:', 'CVCD03060053')\n",
      "('Saving train image patches:', 'CVCD03060058')\n",
      "('Saving train image patches:', 'CVCD03060060')\n",
      "('Saving train image patches:', 'CVCD03060062')\n",
      "('Saving train image patches:', 'CVCD03060066')\n",
      "('Saving train image patches:', 'CVCD03060069')\n",
      "('Saving train image patches:', 'CVCD03060079')\n",
      "('Saving train image patches:', 'CVCD03060087')\n",
      "('Saving train image patches:', 'CVCD03060091')\n",
      "('Saving train image patches:', 'CVCD03060092')\n",
      "('Saving train image patches:', 'CVCD03060095')\n",
      "('Saving train image patches:', 'CVCD03060099')\n",
      "('Saving train image patches:', 'CVCD03060105')\n",
      "('Saving train image patches:', 'CVCD03060108')\n",
      "('Saving train image patches:', 'CVCD03060109')\n",
      "('Saving train image patches:', 'CVCD03060110')\n",
      "('Saving train image patches:', 'CVCD03060111')\n",
      "('Saving train image patches:', 'CVCD03060115')\n",
      "('Saving train image patches:', 'CVCD03060120')\n",
      "('Saving train image patches:', 'CVCD03060124')\n",
      "('Saving train image patches:', 'CVCD03060126')\n",
      "('Saving train image patches:', 'CVCD03060129')\n",
      "('Saving train image patches:', 'CVCD03060131')\n",
      "('Saving train image patches:', 'CVCD03060134')\n",
      "('Saving train image patches:', 'CVCD03060137')\n",
      "('Saving train image patches:', 'CVCD03060139')\n",
      "('Saving train image patches:', 'CVCD03060141')\n",
      "('Saving train image patches:', 'CVCD03060144')\n",
      "('Saving train image patches:', 'CVCD04020001')\n",
      "('Saving train image patches:', 'CVCD04020002')\n",
      "('Saving train image patches:', 'CVCD04020003')\n",
      "('Saving train image patches:', 'CVCD04020004')\n",
      "('Saving train image patches:', 'CVCD04020005')\n",
      "('Saving train image patches:', 'CVCD04020006')\n",
      "('Saving train image patches:', 'CVCD04020007')\n",
      "('Saving train image patches:', 'CVCD04020008')\n",
      "('Saving train image patches:', 'CVCD04020009')\n",
      "('Saving train image patches:', 'CVCD04020010')\n",
      "('Saving train image patches:', 'CVCD04020011')\n",
      "('Saving train image patches:', 'CVCD04020012')\n",
      "('Saving train image patches:', 'CVCD04020013')\n",
      "('Saving train image patches:', 'CVCD04020014')\n",
      "('Saving train image patches:', 'CVCD04020015')\n",
      "('Saving train image patches:', 'CVCD04020017')\n",
      "('Saving train image patches:', 'CVCD04020018')\n",
      "('Saving train image patches:', 'CVCD04020019')\n",
      "('Saving train image patches:', 'CVCD04020020')\n",
      "('Saving train image patches:', 'CVCD04020021')\n",
      "('Saving train image patches:', 'CVCD04020023')\n",
      "('Saving train image patches:', 'CVCD04020024')\n",
      "('Saving train image patches:', 'CVCD04020025')\n",
      "('Saving train image patches:', 'CVCD04020026')\n",
      "('Saving train image patches:', 'CVCD04020027')\n",
      "('Saving train image patches:', 'CVCD04020028')\n",
      "('Saving train image patches:', 'CVCD04020029')\n",
      "('Saving train image patches:', 'CVCD04020030')\n",
      "('Saving train image patches:', 'CVCD04020031')\n",
      "('Saving train image patches:', 'CVCD04020032')\n",
      "('Saving train image patches:', 'CVCD04020034')\n",
      "('Saving train image patches:', 'CVCD04020038')\n",
      "('Saving train image patches:', 'CVCD07030001')\n",
      "('Saving train image patches:', 'CVCD07030004')\n",
      "('Saving train image patches:', 'CVCD07030007')\n",
      "('Saving train image patches:', 'CVCD07030009')\n",
      "('Saving train image patches:', 'CVCD07030014')\n",
      "('Saving train image patches:', 'CVCD07030018')\n",
      "('Saving train image patches:', 'CVCD07030020')\n",
      "('Saving train image patches:', 'CVCD07030026')\n",
      "('Saving train image patches:', 'CVCD07030027')\n",
      "('Saving train image patches:', 'CVCD07030036')\n",
      "('Saving train image patches:', 'CVCD07030039')\n",
      "('Saving train image patches:', 'CVCD07030042')\n",
      "('Saving train image patches:', 'CVCD07030058')\n",
      "('Saving train image patches:', 'CVCD07030061')\n",
      "('Saving train image patches:', 'CVCD07030063')\n",
      "('Saving train image patches:', 'CVCD07030069')\n",
      "('Saving train image patches:', 'CVCD07030072')\n",
      "('Saving train image patches:', 'CVCD07030075')\n",
      "('Saving train image patches:', 'CVCD07030110')\n",
      "('Saving train image patches:', 'CVCD07030171')\n",
      "('Saving train image patches:', 'CVCD07079999')\n",
      "('Saving train image patches:', 'CVCD09130001')\n",
      "('Saving train image patches:', 'CVCD21990004')\n",
      "('Saving train image patches:', 'CVCD21990005')\n",
      "('Saving train image patches:', 'CVCD21990006')\n",
      "('Saving train image patches:', 'CVCD21990015')\n",
      "('Saving train image patches:', 'CVCD21990016')\n",
      "('Saving train image patches:', 'CVCD22990002')\n",
      "('Saving train image patches:', 'CVCD22990006')\n",
      "('Saving train image patches:', 'CVCD22990008')\n",
      "('Saving train image patches:', 'CVCD22990009')\n",
      "('Saving train image patches:', 'CVCD22990010')\n",
      "('Saving train image patches:', 'CVCD22990017')\n",
      "('Saving train image patches:', 'CVCD25060012')\n",
      "('Saving train image patches:', 'CVCD25060015')\n",
      "('Saving train image patches:', 'CVCD25060016')\n",
      "('Saving train image patches:', 'CVCD25060017')\n",
      "('Saving train image patches:', 'CVCD25060018')\n",
      "('Saving train image patches:', 'CVCD25060026')\n",
      "('Saving train image patches:', 'CVCD25060027')\n",
      "('Saving train image patches:', 'CVCD25060029')\n",
      "('Saving train image patches:', 'CVCD25060030')\n",
      "('Saving train image patches:', 'CVCD25060033')\n",
      "('Saving train image patches:', 'CVCD25060035')\n",
      "('Saving train image patches:', 'CVCD25060039')\n",
      "('Saving train image patches:', 'CVCD25060040')\n",
      "('Saving train image patches:', 'CVCD28020001')\n",
      "('Saving train image patches:', 'CVCD28020003')\n",
      "('Saving train image patches:', 'CVCD28020004')\n",
      "('Saving train image patches:', 'CVCD28020005')\n",
      "('Saving train image patches:', 'CVCD28020006')\n",
      "('Saving train image patches:', 'CVCD28020007')\n",
      "('Saving train image patches:', 'CVCD28020008')\n",
      "('Saving train image patches:', 'CVCD28020009')\n",
      "('Saving train image patches:', 'CVCD28020010')\n",
      "('Saving train image patches:', 'CVCD28020011')\n",
      "('Saving train image patches:', 'CVCD28020013')\n",
      "('Saving train image patches:', 'CVCD28020014')\n",
      "('Saving train image patches:', 'CVCD28020015')\n",
      "('Saving train image patches:', 'CVCD28020016')\n",
      "('Saving train image patches:', 'CVCD28020017')\n",
      "('Saving train image patches:', 'CVCD28020018')\n",
      "('Saving train image patches:', 'CVCD28020019')\n",
      "('Saving train image patches:', 'CVCD28020020')\n",
      "('Saving train image patches:', 'CVCD28020021')\n",
      "('Saving train image patches:', 'CVCD28020022')\n",
      "('Saving train image patches:', 'CVCD28020023')\n",
      "('Saving train image patches:', 'CVCD28020025')\n",
      "('Saving train image patches:', 'CVCD28020026')\n",
      "('Saving train image patches:', 'CVCD28020027')\n",
      "('Saving train image patches:', 'CVCD28020028')\n",
      "('Saving train image patches:', 'CVCD28020029')\n",
      "('Saving train image patches:', 'CVCD28020030')\n",
      "------------------------------\n",
      "Creating Train Data...\n",
      "------------------------------\n",
      "Done: 0/25000 images\n",
      "Done: 100/25000 images\n",
      "Done: 200/25000 images\n",
      "Done: 300/25000 images\n",
      "Done: 400/25000 images\n",
      "Done: 500/25000 images\n",
      "Done: 600/25000 images\n",
      "Done: 700/25000 images\n",
      "Done: 800/25000 images\n",
      "Done: 900/25000 images\n",
      "Done: 1000/25000 images\n",
      "Done: 1100/25000 images\n",
      "Done: 1200/25000 images\n",
      "Done: 1300/25000 images\n",
      "Done: 1400/25000 images\n",
      "Done: 1500/25000 images\n",
      "Done: 1600/25000 images\n",
      "Done: 1700/25000 images\n",
      "Done: 1800/25000 images\n",
      "Done: 1900/25000 images\n",
      "Done: 2000/25000 images\n",
      "Done: 2100/25000 images\n",
      "Done: 2200/25000 images\n",
      "Done: 2300/25000 images\n",
      "Done: 2400/25000 images\n",
      "Done: 2500/25000 images\n",
      "Done: 2600/25000 images\n",
      "Done: 2700/25000 images\n",
      "Done: 2800/25000 images\n",
      "Done: 2900/25000 images\n",
      "Done: 3000/25000 images\n",
      "Done: 3100/25000 images\n",
      "Done: 3200/25000 images\n",
      "Done: 3300/25000 images\n",
      "Done: 3400/25000 images\n",
      "Done: 3500/25000 images\n",
      "Done: 3600/25000 images\n",
      "Done: 3700/25000 images\n",
      "Done: 3800/25000 images\n",
      "Done: 3900/25000 images\n",
      "Done: 4000/25000 images\n",
      "Done: 4100/25000 images\n",
      "Done: 4200/25000 images\n",
      "Done: 4300/25000 images\n",
      "Done: 4400/25000 images\n",
      "Done: 4500/25000 images\n",
      "Done: 4600/25000 images\n",
      "Done: 4700/25000 images\n",
      "Done: 4800/25000 images\n",
      "Done: 4900/25000 images\n",
      "Done: 5000/25000 images\n",
      "Done: 5100/25000 images\n",
      "Done: 5200/25000 images\n",
      "Done: 5300/25000 images\n",
      "Done: 5400/25000 images\n",
      "Done: 5500/25000 images\n",
      "Done: 5600/25000 images\n",
      "Done: 5700/25000 images\n",
      "Done: 5800/25000 images\n",
      "Done: 5900/25000 images\n",
      "Done: 6000/25000 images\n",
      "Done: 6100/25000 images\n",
      "Done: 6200/25000 images\n",
      "Done: 6300/25000 images\n",
      "Done: 6400/25000 images\n",
      "Done: 6500/25000 images\n",
      "Done: 6600/25000 images\n",
      "Done: 6700/25000 images\n",
      "Done: 6800/25000 images\n",
      "Done: 6900/25000 images\n",
      "Done: 7000/25000 images\n",
      "Done: 7100/25000 images\n",
      "Done: 7200/25000 images\n",
      "Done: 7300/25000 images\n",
      "Done: 7400/25000 images\n",
      "Done: 7500/25000 images\n",
      "Done: 7600/25000 images\n",
      "Done: 7700/25000 images\n",
      "Done: 7800/25000 images\n",
      "Done: 7900/25000 images\n",
      "Done: 8000/25000 images\n",
      "Done: 8100/25000 images\n",
      "Done: 8200/25000 images\n",
      "Done: 8300/25000 images\n",
      "Done: 8400/25000 images\n",
      "Done: 8500/25000 images\n",
      "Done: 8600/25000 images\n",
      "Done: 8700/25000 images\n",
      "Done: 8800/25000 images\n",
      "Done: 8900/25000 images\n",
      "Done: 9000/25000 images\n",
      "Done: 9100/25000 images\n",
      "Done: 9200/25000 images\n",
      "Done: 9300/25000 images\n",
      "Done: 9400/25000 images\n",
      "Done: 9500/25000 images\n",
      "Done: 9600/25000 images\n",
      "Done: 9700/25000 images\n",
      "Done: 9800/25000 images\n",
      "Done: 9900/25000 images\n",
      "Done: 10000/25000 images\n",
      "Done: 10100/25000 images\n",
      "Done: 10200/25000 images\n",
      "Done: 10300/25000 images\n",
      "Done: 10400/25000 images\n",
      "Done: 10500/25000 images\n",
      "Done: 10600/25000 images\n",
      "Done: 10700/25000 images\n",
      "Done: 10800/25000 images\n",
      "Done: 10900/25000 images\n",
      "Done: 11000/25000 images\n",
      "Done: 11100/25000 images\n",
      "Done: 11200/25000 images\n",
      "Done: 11300/25000 images\n",
      "Done: 11400/25000 images\n",
      "Done: 11500/25000 images\n",
      "Done: 11600/25000 images\n",
      "Done: 11700/25000 images\n",
      "Done: 11800/25000 images\n",
      "Done: 11900/25000 images\n",
      "Done: 12000/25000 images\n",
      "Done: 12100/25000 images\n",
      "Done: 12200/25000 images\n",
      "Done: 12300/25000 images\n",
      "Done: 12400/25000 images\n",
      "Done: 12500/25000 images\n",
      "Done: 12600/25000 images\n",
      "Done: 12700/25000 images\n",
      "Done: 12800/25000 images\n",
      "Done: 12900/25000 images\n",
      "Done: 13000/25000 images\n",
      "Done: 13100/25000 images\n",
      "Done: 13200/25000 images\n",
      "Done: 13300/25000 images\n",
      "Done: 13400/25000 images\n",
      "Done: 13500/25000 images\n",
      "Done: 13600/25000 images\n",
      "Done: 13700/25000 images\n",
      "Done: 13800/25000 images\n",
      "Done: 13900/25000 images\n",
      "Done: 14000/25000 images\n",
      "Done: 14100/25000 images\n",
      "Done: 14200/25000 images\n",
      "Done: 14300/25000 images\n",
      "Done: 14400/25000 images\n",
      "Done: 14500/25000 images\n",
      "Done: 14600/25000 images\n",
      "Done: 14700/25000 images\n",
      "Done: 14800/25000 images\n",
      "Done: 14900/25000 images\n",
      "Done: 15000/25000 images\n",
      "Done: 15100/25000 images\n",
      "Done: 15200/25000 images\n",
      "Done: 15300/25000 images\n",
      "Done: 15400/25000 images\n",
      "Done: 15500/25000 images\n",
      "Done: 15600/25000 images\n",
      "Done: 15700/25000 images\n",
      "Done: 15800/25000 images\n",
      "Done: 15900/25000 images\n",
      "Done: 16000/25000 images\n",
      "Done: 16100/25000 images\n",
      "Done: 16200/25000 images\n",
      "Done: 16300/25000 images\n",
      "Done: 16400/25000 images\n",
      "Done: 16500/25000 images\n",
      "Done: 16600/25000 images\n",
      "Done: 16700/25000 images\n",
      "Done: 16800/25000 images\n",
      "Done: 16900/25000 images\n",
      "Done: 17000/25000 images\n",
      "Done: 17100/25000 images\n",
      "Done: 17200/25000 images\n",
      "Done: 17300/25000 images\n",
      "Done: 17400/25000 images\n",
      "Done: 17500/25000 images\n",
      "Done: 17600/25000 images\n",
      "Done: 17700/25000 images\n",
      "Done: 17800/25000 images\n",
      "Done: 17900/25000 images\n",
      "Done: 18000/25000 images\n",
      "Done: 18100/25000 images\n",
      "Done: 18200/25000 images\n",
      "Done: 18300/25000 images\n",
      "Done: 18400/25000 images\n",
      "Done: 18500/25000 images\n",
      "Done: 18600/25000 images\n",
      "Done: 18700/25000 images\n",
      "Done: 18800/25000 images\n",
      "Done: 18900/25000 images\n",
      "Done: 19000/25000 images\n",
      "Done: 19100/25000 images\n",
      "Done: 19200/25000 images\n",
      "Done: 19300/25000 images\n",
      "Done: 19400/25000 images\n",
      "Done: 19500/25000 images\n",
      "Done: 19600/25000 images\n",
      "Done: 19700/25000 images\n",
      "Done: 19800/25000 images\n",
      "Done: 19900/25000 images\n",
      "Done: 20000/25000 images\n",
      "Done: 20100/25000 images\n",
      "Done: 20200/25000 images\n",
      "Done: 20300/25000 images\n",
      "Done: 20400/25000 images\n",
      "Done: 20500/25000 images\n",
      "Done: 20600/25000 images\n",
      "Done: 20700/25000 images\n",
      "Done: 20800/25000 images\n",
      "Done: 20900/25000 images\n",
      "Done: 21000/25000 images\n",
      "Done: 21100/25000 images\n",
      "Done: 21200/25000 images\n",
      "Done: 21300/25000 images\n",
      "Done: 21400/25000 images\n",
      "Done: 21500/25000 images\n",
      "Done: 21600/25000 images\n",
      "Done: 21700/25000 images\n",
      "Done: 21800/25000 images\n",
      "Done: 21900/25000 images\n",
      "Done: 22000/25000 images\n",
      "Done: 22100/25000 images\n",
      "Done: 22200/25000 images\n",
      "Done: 22300/25000 images\n",
      "Done: 22400/25000 images\n",
      "Done: 22500/25000 images\n",
      "Done: 22600/25000 images\n",
      "Done: 22700/25000 images\n",
      "Done: 22800/25000 images\n",
      "Done: 22900/25000 images\n",
      "Done: 23000/25000 images\n",
      "Done: 23100/25000 images\n",
      "Done: 23200/25000 images\n",
      "Done: 23300/25000 images\n",
      "Done: 23400/25000 images\n",
      "Done: 23500/25000 images\n",
      "Done: 23600/25000 images\n",
      "Done: 23700/25000 images\n",
      "Done: 23800/25000 images\n",
      "Done: 23900/25000 images\n",
      "Done: 24000/25000 images\n",
      "Done: 24100/25000 images\n",
      "Done: 24200/25000 images\n",
      "Done: 24300/25000 images\n",
      "Done: 24400/25000 images\n",
      "Done: 24500/25000 images\n",
      "Done: 24600/25000 images\n",
      "Done: 24700/25000 images\n",
      "Done: 24800/25000 images\n",
      "Done: 24900/25000 images\n",
      "Data created.\n",
      "Saved data to .npy.\n",
      "--- 23.8729460239 seconds ---\n"
     ]
    }
   ],
   "source": [
    "if __name__ == '__main__':\n",
    "\n",
    "    start_time = time.time()\n",
    "    \n",
    "    # Treino   \n",
    "    print('-'*30)\n",
    "    print('Creating Train 2D Patches...')\n",
    "    print('-'*30)\n",
    "    srcDir = os.path.join(out,train_mid_samples)\n",
    "    dstDir = os.path.join(out,train_patches) \n",
    "    create_new_dir(dstDir)\n",
    "\n",
    "    sample_2d_patches(srcDir, dstDir, 'train')\n",
    "        \n",
    "    print('-'*30)\n",
    "    print('Creating Train Data...')\n",
    "    print('-'*30)\n",
    "    \n",
    "    imgs, imgs_mask = create_data(dstDir)\n",
    "    save_data(imgs, imgs_mask, os.path.join(out,'imgs_train.npy')\n",
    "              , os.path.join(out,'imgs_mask_train.npy'),out)\n",
    "    \n",
    "    print(\"--- %s seconds ---\" % (time.time() - start_time))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Dados de Teste"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "------------------------------\n",
      "Creating Test 2D Patches...\n",
      "------------------------------\n",
      "Sampling Test Images ...\n",
      "('Saving test image patches:', 'CVCD10010001')\n",
      "/root/test_patches/CVCD10010001\n",
      "('Saving test image patches:', 'CVCD10010002')\n",
      "/root/test_patches/CVCD10010002\n",
      "('Saving test image patches:', 'CVCD10010003')\n",
      "/root/test_patches/CVCD10010003\n",
      "('Saving test image patches:', 'CVCD10010004')\n",
      "/root/test_patches/CVCD10010004\n",
      "------------------------------\n",
      "Creating Preprocessed Test Data...\n",
      "------------------------------\n",
      "('Image:', 'CVCD10010001')\n",
      "\n",
      "\n",
      "Done: 0/34161 images\n",
      "Done: 100/34161 images\n",
      "Done: 200/34161 images\n",
      "Done: 300/34161 images\n",
      "Done: 400/34161 images\n",
      "Done: 500/34161 images\n",
      "Done: 600/34161 images\n",
      "Done: 700/34161 images\n",
      "Done: 800/34161 images\n",
      "Done: 900/34161 images\n",
      "Done: 1000/34161 images\n",
      "Done: 1100/34161 images\n",
      "Done: 1200/34161 images\n",
      "Done: 1300/34161 images\n",
      "Done: 1400/34161 images\n",
      "Done: 1500/34161 images\n",
      "Done: 1600/34161 images\n",
      "Done: 1700/34161 images\n",
      "Done: 1800/34161 images\n",
      "Done: 1900/34161 images\n",
      "Done: 2000/34161 images\n",
      "Done: 2100/34161 images\n",
      "Done: 2200/34161 images\n",
      "Done: 2300/34161 images\n",
      "Done: 2400/34161 images\n",
      "Done: 2500/34161 images\n",
      "Done: 2600/34161 images\n",
      "Done: 2700/34161 images\n",
      "Done: 2800/34161 images\n",
      "Done: 2900/34161 images\n",
      "Done: 3000/34161 images\n",
      "Done: 3100/34161 images\n",
      "Done: 3200/34161 images\n",
      "Done: 3300/34161 images\n",
      "Done: 3400/34161 images\n",
      "Done: 3500/34161 images\n",
      "Done: 3600/34161 images\n",
      "Done: 3700/34161 images\n",
      "Done: 3800/34161 images\n",
      "Done: 3900/34161 images\n",
      "Done: 4000/34161 images\n",
      "Done: 4100/34161 images\n",
      "Done: 4200/34161 images\n",
      "Done: 4300/34161 images\n",
      "Done: 4400/34161 images\n",
      "Done: 4500/34161 images\n",
      "Done: 4600/34161 images\n",
      "Done: 4700/34161 images\n",
      "Done: 4800/34161 images\n",
      "Done: 4900/34161 images\n",
      "Done: 5000/34161 images\n",
      "Done: 5100/34161 images\n",
      "Done: 5200/34161 images\n",
      "Done: 5300/34161 images\n",
      "Done: 5400/34161 images\n",
      "Done: 5500/34161 images\n",
      "Done: 5600/34161 images\n",
      "Done: 5700/34161 images\n",
      "Done: 5800/34161 images\n",
      "Done: 5900/34161 images\n",
      "Done: 6000/34161 images\n",
      "Done: 6100/34161 images\n",
      "Done: 6200/34161 images\n",
      "Done: 6300/34161 images\n",
      "Done: 6400/34161 images\n",
      "Done: 6500/34161 images\n",
      "Done: 6600/34161 images\n",
      "Done: 6700/34161 images\n",
      "Done: 6800/34161 images\n",
      "Done: 6900/34161 images\n",
      "Done: 7000/34161 images\n",
      "Done: 7100/34161 images\n",
      "Done: 7200/34161 images\n",
      "Done: 7300/34161 images\n",
      "Done: 7400/34161 images\n",
      "Done: 7500/34161 images\n",
      "Done: 7600/34161 images\n",
      "Done: 7700/34161 images\n",
      "Done: 7800/34161 images\n",
      "Done: 7900/34161 images\n",
      "Done: 8000/34161 images\n",
      "Done: 8100/34161 images\n",
      "Done: 8200/34161 images\n",
      "Done: 8300/34161 images\n",
      "Done: 8400/34161 images\n",
      "Done: 8500/34161 images\n",
      "Done: 8600/34161 images\n",
      "Done: 8700/34161 images\n",
      "Done: 8800/34161 images\n",
      "Done: 8900/34161 images\n",
      "Done: 9000/34161 images\n",
      "Done: 9100/34161 images\n",
      "Done: 9200/34161 images\n",
      "Done: 9300/34161 images\n",
      "Done: 9400/34161 images\n",
      "Done: 9500/34161 images\n",
      "Done: 9600/34161 images\n",
      "Done: 9700/34161 images\n",
      "Done: 9800/34161 images\n",
      "Done: 9900/34161 images\n",
      "Done: 10000/34161 images\n",
      "Done: 10100/34161 images\n",
      "Done: 10200/34161 images\n",
      "Done: 10300/34161 images\n",
      "Done: 10400/34161 images\n",
      "Done: 10500/34161 images\n",
      "Done: 10600/34161 images\n",
      "Done: 10700/34161 images\n",
      "Done: 10800/34161 images\n",
      "Done: 10900/34161 images\n",
      "Done: 11000/34161 images\n",
      "Done: 11100/34161 images\n",
      "Done: 11200/34161 images\n",
      "Done: 11300/34161 images\n",
      "Done: 11400/34161 images\n",
      "Done: 11500/34161 images\n",
      "Done: 11600/34161 images\n",
      "Done: 11700/34161 images\n",
      "Done: 11800/34161 images\n",
      "Done: 11900/34161 images\n",
      "Done: 12000/34161 images\n",
      "Done: 12100/34161 images\n",
      "Done: 12200/34161 images\n",
      "Done: 12300/34161 images\n",
      "Done: 12400/34161 images\n",
      "Done: 12500/34161 images\n",
      "Done: 12600/34161 images\n",
      "Done: 12700/34161 images\n",
      "Done: 12800/34161 images\n",
      "Done: 12900/34161 images\n",
      "Done: 13000/34161 images\n",
      "Done: 13100/34161 images\n",
      "Done: 13200/34161 images\n",
      "Done: 13300/34161 images\n",
      "Done: 13400/34161 images\n",
      "Done: 13500/34161 images\n",
      "Done: 13600/34161 images\n",
      "Done: 13700/34161 images\n",
      "Done: 13800/34161 images\n",
      "Done: 13900/34161 images\n",
      "Done: 14000/34161 images\n",
      "Done: 14100/34161 images\n",
      "Done: 14200/34161 images\n",
      "Done: 14300/34161 images\n",
      "Done: 14400/34161 images\n",
      "Done: 14500/34161 images\n",
      "Done: 14600/34161 images\n",
      "Done: 14700/34161 images\n",
      "Done: 14800/34161 images\n",
      "Done: 14900/34161 images\n",
      "Done: 15000/34161 images\n",
      "Done: 15100/34161 images\n",
      "Done: 15200/34161 images\n",
      "Done: 15300/34161 images\n",
      "Done: 15400/34161 images\n",
      "Done: 15500/34161 images\n",
      "Done: 15600/34161 images\n",
      "Done: 15700/34161 images\n",
      "Done: 15800/34161 images\n",
      "Done: 15900/34161 images\n",
      "Done: 16000/34161 images\n",
      "Done: 16100/34161 images\n",
      "Done: 16200/34161 images\n",
      "Done: 16300/34161 images\n",
      "Done: 16400/34161 images\n",
      "Done: 16500/34161 images\n",
      "Done: 16600/34161 images\n",
      "Done: 16700/34161 images\n",
      "Done: 16800/34161 images\n",
      "Done: 16900/34161 images\n",
      "Done: 17000/34161 images\n",
      "Done: 17100/34161 images\n",
      "Done: 17200/34161 images\n",
      "Done: 17300/34161 images\n",
      "Done: 17400/34161 images\n",
      "Done: 17500/34161 images\n",
      "Done: 17600/34161 images\n",
      "Done: 17700/34161 images\n",
      "Done: 17800/34161 images\n",
      "Done: 17900/34161 images\n",
      "Done: 18000/34161 images\n",
      "Done: 18100/34161 images\n",
      "Done: 18200/34161 images\n",
      "Done: 18300/34161 images\n",
      "Done: 18400/34161 images\n",
      "Done: 18500/34161 images\n",
      "Done: 18600/34161 images\n",
      "Done: 18700/34161 images\n",
      "Done: 18800/34161 images\n",
      "Done: 18900/34161 images\n",
      "Done: 19000/34161 images\n",
      "Done: 19100/34161 images\n",
      "Done: 19200/34161 images\n",
      "Done: 19300/34161 images\n",
      "Done: 19400/34161 images\n",
      "Done: 19500/34161 images\n",
      "Done: 19600/34161 images\n",
      "Done: 19700/34161 images\n",
      "Done: 19800/34161 images\n",
      "Done: 19900/34161 images\n",
      "Done: 20000/34161 images\n",
      "Done: 20100/34161 images\n",
      "Done: 20200/34161 images\n",
      "Done: 20300/34161 images\n",
      "Done: 20400/34161 images\n",
      "Done: 20500/34161 images\n",
      "Done: 20600/34161 images\n",
      "Done: 20700/34161 images\n",
      "Done: 20800/34161 images\n",
      "Done: 20900/34161 images\n",
      "Done: 21000/34161 images\n",
      "Done: 21100/34161 images\n",
      "Done: 21200/34161 images\n",
      "Done: 21300/34161 images\n",
      "Done: 21400/34161 images\n",
      "Done: 21500/34161 images\n",
      "Done: 21600/34161 images\n",
      "Done: 21700/34161 images\n",
      "Done: 21800/34161 images\n",
      "Done: 21900/34161 images\n",
      "Done: 22000/34161 images\n",
      "Done: 22100/34161 images\n",
      "Done: 22200/34161 images\n",
      "Done: 22300/34161 images\n",
      "Done: 22400/34161 images\n",
      "Done: 22500/34161 images\n",
      "Done: 22600/34161 images\n",
      "Done: 22700/34161 images\n",
      "Done: 22800/34161 images\n",
      "Done: 22900/34161 images\n",
      "Done: 23000/34161 images\n",
      "Done: 23100/34161 images\n",
      "Done: 23200/34161 images\n",
      "Done: 23300/34161 images\n",
      "Done: 23400/34161 images\n",
      "Done: 23500/34161 images\n",
      "Done: 23600/34161 images\n",
      "Done: 23700/34161 images\n",
      "Done: 23800/34161 images\n",
      "Done: 23900/34161 images\n",
      "Done: 24000/34161 images\n",
      "Done: 24100/34161 images\n",
      "Done: 24200/34161 images\n",
      "Done: 24300/34161 images\n",
      "Done: 24400/34161 images\n",
      "Done: 24500/34161 images\n",
      "Done: 24600/34161 images\n",
      "Done: 24700/34161 images\n",
      "Done: 24800/34161 images\n",
      "Done: 24900/34161 images\n",
      "Done: 25000/34161 images\n",
      "Done: 25100/34161 images\n",
      "Done: 25200/34161 images\n",
      "Done: 25300/34161 images\n",
      "Done: 25400/34161 images\n",
      "Done: 25500/34161 images\n",
      "Done: 25600/34161 images\n",
      "Done: 25700/34161 images\n",
      "Done: 25800/34161 images\n",
      "Done: 25900/34161 images\n",
      "Done: 26000/34161 images\n",
      "Done: 26100/34161 images\n",
      "Done: 26200/34161 images\n",
      "Done: 26300/34161 images\n",
      "Done: 26400/34161 images\n",
      "Done: 26500/34161 images\n",
      "Done: 26600/34161 images\n",
      "Done: 26700/34161 images\n",
      "Done: 26800/34161 images\n",
      "Done: 26900/34161 images\n",
      "Done: 27000/34161 images\n",
      "Done: 27100/34161 images\n",
      "Done: 27200/34161 images\n",
      "Done: 27300/34161 images\n",
      "Done: 27400/34161 images\n",
      "Done: 27500/34161 images\n",
      "Done: 27600/34161 images\n",
      "Done: 27700/34161 images\n",
      "Done: 27800/34161 images\n",
      "Done: 27900/34161 images\n",
      "Done: 28000/34161 images\n",
      "Done: 28100/34161 images\n",
      "Done: 28200/34161 images\n",
      "Done: 28300/34161 images\n",
      "Done: 28400/34161 images\n",
      "Done: 28500/34161 images\n",
      "Done: 28600/34161 images\n",
      "Done: 28700/34161 images\n",
      "Done: 28800/34161 images\n",
      "Done: 28900/34161 images\n",
      "Done: 29000/34161 images\n",
      "Done: 29100/34161 images\n",
      "Done: 29200/34161 images\n",
      "Done: 29300/34161 images\n",
      "Done: 29400/34161 images\n",
      "Done: 29500/34161 images\n",
      "Done: 29600/34161 images\n",
      "Done: 29700/34161 images\n",
      "Done: 29800/34161 images\n",
      "Done: 29900/34161 images\n",
      "Done: 30000/34161 images\n",
      "Done: 30100/34161 images\n",
      "Done: 30200/34161 images\n",
      "Done: 30300/34161 images\n",
      "Done: 30400/34161 images\n",
      "Done: 30500/34161 images\n",
      "Done: 30600/34161 images\n",
      "Done: 30700/34161 images\n",
      "Done: 30800/34161 images\n",
      "Done: 30900/34161 images\n",
      "Done: 31000/34161 images\n",
      "Done: 31100/34161 images\n",
      "Done: 31200/34161 images\n",
      "Done: 31300/34161 images\n",
      "Done: 31400/34161 images\n",
      "Done: 31500/34161 images\n",
      "Done: 31600/34161 images\n",
      "Done: 31700/34161 images\n",
      "Done: 31800/34161 images\n",
      "Done: 31900/34161 images\n",
      "Done: 32000/34161 images\n",
      "Done: 32100/34161 images\n",
      "Done: 32200/34161 images\n",
      "Done: 32300/34161 images\n",
      "Done: 32400/34161 images\n",
      "Done: 32500/34161 images\n",
      "Done: 32600/34161 images\n",
      "Done: 32700/34161 images\n",
      "Done: 32800/34161 images\n",
      "Done: 32900/34161 images\n",
      "Done: 33000/34161 images\n",
      "Done: 33100/34161 images\n",
      "Done: 33200/34161 images\n",
      "Done: 33300/34161 images\n",
      "Done: 33400/34161 images\n",
      "Done: 33500/34161 images\n",
      "Done: 33600/34161 images\n",
      "Done: 33700/34161 images\n",
      "Done: 33800/34161 images\n",
      "Done: 33900/34161 images\n",
      "Done: 34000/34161 images\n",
      "Done: 34100/34161 images\n",
      "Data created.\n",
      "('Image:', 'CVCD10010002')\n",
      "\n",
      "\n",
      "Done: 0/34161 images\n",
      "Done: 100/34161 images\n",
      "Done: 200/34161 images\n",
      "Done: 300/34161 images\n",
      "Done: 400/34161 images\n",
      "Done: 500/34161 images\n",
      "Done: 600/34161 images\n",
      "Done: 700/34161 images\n",
      "Done: 800/34161 images\n",
      "Done: 900/34161 images\n",
      "Done: 1000/34161 images\n",
      "Done: 1100/34161 images\n",
      "Done: 1200/34161 images\n",
      "Done: 1300/34161 images\n",
      "Done: 1400/34161 images\n",
      "Done: 1500/34161 images\n",
      "Done: 1600/34161 images\n",
      "Done: 1700/34161 images\n",
      "Done: 1800/34161 images\n",
      "Done: 1900/34161 images\n",
      "Done: 2000/34161 images\n",
      "Done: 2100/34161 images\n",
      "Done: 2200/34161 images\n",
      "Done: 2300/34161 images\n",
      "Done: 2400/34161 images\n",
      "Done: 2500/34161 images\n",
      "Done: 2600/34161 images\n",
      "Done: 2700/34161 images\n",
      "Done: 2800/34161 images\n",
      "Done: 2900/34161 images\n",
      "Done: 3000/34161 images\n",
      "Done: 3100/34161 images\n",
      "Done: 3200/34161 images\n",
      "Done: 3300/34161 images\n",
      "Done: 3400/34161 images\n",
      "Done: 3500/34161 images\n",
      "Done: 3600/34161 images\n",
      "Done: 3700/34161 images\n",
      "Done: 3800/34161 images\n",
      "Done: 3900/34161 images\n",
      "Done: 4000/34161 images\n",
      "Done: 4100/34161 images\n",
      "Done: 4200/34161 images\n",
      "Done: 4300/34161 images\n",
      "Done: 4400/34161 images\n",
      "Done: 4500/34161 images\n",
      "Done: 4600/34161 images\n",
      "Done: 4700/34161 images\n",
      "Done: 4800/34161 images\n",
      "Done: 4900/34161 images\n",
      "Done: 5000/34161 images\n",
      "Done: 5100/34161 images\n",
      "Done: 5200/34161 images\n",
      "Done: 5300/34161 images\n",
      "Done: 5400/34161 images\n",
      "Done: 5500/34161 images\n",
      "Done: 5600/34161 images\n",
      "Done: 5700/34161 images\n",
      "Done: 5800/34161 images\n",
      "Done: 5900/34161 images\n",
      "Done: 6000/34161 images\n",
      "Done: 6100/34161 images\n",
      "Done: 6200/34161 images\n",
      "Done: 6300/34161 images\n",
      "Done: 6400/34161 images\n",
      "Done: 6500/34161 images\n",
      "Done: 6600/34161 images\n",
      "Done: 6700/34161 images\n",
      "Done: 6800/34161 images\n",
      "Done: 6900/34161 images\n",
      "Done: 7000/34161 images\n",
      "Done: 7100/34161 images\n",
      "Done: 7200/34161 images\n",
      "Done: 7300/34161 images\n",
      "Done: 7400/34161 images\n",
      "Done: 7500/34161 images\n",
      "Done: 7600/34161 images\n",
      "Done: 7700/34161 images\n",
      "Done: 7800/34161 images\n",
      "Done: 7900/34161 images\n",
      "Done: 8000/34161 images\n",
      "Done: 8100/34161 images\n",
      "Done: 8200/34161 images\n",
      "Done: 8300/34161 images\n",
      "Done: 8400/34161 images\n",
      "Done: 8500/34161 images\n",
      "Done: 8600/34161 images\n",
      "Done: 8700/34161 images\n",
      "Done: 8800/34161 images\n",
      "Done: 8900/34161 images\n",
      "Done: 9000/34161 images\n",
      "Done: 9100/34161 images\n",
      "Done: 9200/34161 images\n",
      "Done: 9300/34161 images\n",
      "Done: 9400/34161 images\n",
      "Done: 9500/34161 images\n",
      "Done: 9600/34161 images\n",
      "Done: 9700/34161 images\n",
      "Done: 9800/34161 images\n",
      "Done: 9900/34161 images\n",
      "Done: 10000/34161 images\n",
      "Done: 10100/34161 images\n",
      "Done: 10200/34161 images\n",
      "Done: 10300/34161 images\n",
      "Done: 10400/34161 images\n",
      "Done: 10500/34161 images\n",
      "Done: 10600/34161 images\n",
      "Done: 10700/34161 images\n",
      "Done: 10800/34161 images\n",
      "Done: 10900/34161 images\n",
      "Done: 11000/34161 images\n",
      "Done: 11100/34161 images\n",
      "Done: 11200/34161 images\n",
      "Done: 11300/34161 images\n",
      "Done: 11400/34161 images\n",
      "Done: 11500/34161 images\n",
      "Done: 11600/34161 images\n",
      "Done: 11700/34161 images\n",
      "Done: 11800/34161 images\n",
      "Done: 11900/34161 images\n",
      "Done: 12000/34161 images\n",
      "Done: 12100/34161 images\n",
      "Done: 12200/34161 images\n",
      "Done: 12300/34161 images\n",
      "Done: 12400/34161 images\n",
      "Done: 12500/34161 images\n",
      "Done: 12600/34161 images\n",
      "Done: 12700/34161 images\n",
      "Done: 12800/34161 images\n",
      "Done: 12900/34161 images\n",
      "Done: 13000/34161 images\n",
      "Done: 13100/34161 images\n",
      "Done: 13200/34161 images\n",
      "Done: 13300/34161 images\n",
      "Done: 13400/34161 images\n",
      "Done: 13500/34161 images\n",
      "Done: 13600/34161 images\n",
      "Done: 13700/34161 images\n",
      "Done: 13800/34161 images\n",
      "Done: 13900/34161 images\n",
      "Done: 14000/34161 images\n",
      "Done: 14100/34161 images\n",
      "Done: 14200/34161 images\n",
      "Done: 14300/34161 images\n",
      "Done: 14400/34161 images\n",
      "Done: 14500/34161 images\n",
      "Done: 14600/34161 images\n",
      "Done: 14700/34161 images\n",
      "Done: 14800/34161 images\n",
      "Done: 14900/34161 images\n",
      "Done: 15000/34161 images\n",
      "Done: 15100/34161 images\n",
      "Done: 15200/34161 images\n",
      "Done: 15300/34161 images\n",
      "Done: 15400/34161 images\n",
      "Done: 15500/34161 images\n",
      "Done: 15600/34161 images\n",
      "Done: 15700/34161 images\n",
      "Done: 15800/34161 images\n",
      "Done: 15900/34161 images\n",
      "Done: 16000/34161 images\n",
      "Done: 16100/34161 images\n",
      "Done: 16200/34161 images\n",
      "Done: 16300/34161 images\n",
      "Done: 16400/34161 images\n",
      "Done: 16500/34161 images\n",
      "Done: 16600/34161 images\n",
      "Done: 16700/34161 images\n",
      "Done: 16800/34161 images\n",
      "Done: 16900/34161 images\n",
      "Done: 17000/34161 images\n",
      "Done: 17100/34161 images\n",
      "Done: 17200/34161 images\n",
      "Done: 17300/34161 images\n",
      "Done: 17400/34161 images\n",
      "Done: 17500/34161 images\n",
      "Done: 17600/34161 images\n",
      "Done: 17700/34161 images\n",
      "Done: 17800/34161 images\n",
      "Done: 17900/34161 images\n",
      "Done: 18000/34161 images\n",
      "Done: 18100/34161 images\n",
      "Done: 18200/34161 images\n",
      "Done: 18300/34161 images\n",
      "Done: 18400/34161 images\n",
      "Done: 18500/34161 images\n",
      "Done: 18600/34161 images\n",
      "Done: 18700/34161 images\n",
      "Done: 18800/34161 images\n",
      "Done: 18900/34161 images\n",
      "Done: 19000/34161 images\n",
      "Done: 19100/34161 images\n",
      "Done: 19200/34161 images\n",
      "Done: 19300/34161 images\n",
      "Done: 19400/34161 images\n",
      "Done: 19500/34161 images\n",
      "Done: 19600/34161 images\n",
      "Done: 19700/34161 images\n",
      "Done: 19800/34161 images\n",
      "Done: 19900/34161 images\n",
      "Done: 20000/34161 images\n",
      "Done: 20100/34161 images\n",
      "Done: 20200/34161 images\n",
      "Done: 20300/34161 images\n",
      "Done: 20400/34161 images\n",
      "Done: 20500/34161 images\n",
      "Done: 20600/34161 images\n",
      "Done: 20700/34161 images\n",
      "Done: 20800/34161 images\n",
      "Done: 20900/34161 images\n",
      "Done: 21000/34161 images\n",
      "Done: 21100/34161 images\n",
      "Done: 21200/34161 images\n",
      "Done: 21300/34161 images\n",
      "Done: 21400/34161 images\n",
      "Done: 21500/34161 images\n",
      "Done: 21600/34161 images\n",
      "Done: 21700/34161 images\n",
      "Done: 21800/34161 images\n",
      "Done: 21900/34161 images\n",
      "Done: 22000/34161 images\n",
      "Done: 22100/34161 images\n",
      "Done: 22200/34161 images\n",
      "Done: 22300/34161 images\n",
      "Done: 22400/34161 images\n",
      "Done: 22500/34161 images\n",
      "Done: 22600/34161 images\n",
      "Done: 22700/34161 images\n",
      "Done: 22800/34161 images\n",
      "Done: 22900/34161 images\n",
      "Done: 23000/34161 images\n",
      "Done: 23100/34161 images\n",
      "Done: 23200/34161 images\n",
      "Done: 23300/34161 images\n",
      "Done: 23400/34161 images\n",
      "Done: 23500/34161 images\n",
      "Done: 23600/34161 images\n",
      "Done: 23700/34161 images\n",
      "Done: 23800/34161 images\n",
      "Done: 23900/34161 images\n",
      "Done: 24000/34161 images\n",
      "Done: 24100/34161 images\n",
      "Done: 24200/34161 images\n",
      "Done: 24300/34161 images\n",
      "Done: 24400/34161 images\n",
      "Done: 24500/34161 images\n",
      "Done: 24600/34161 images\n",
      "Done: 24700/34161 images\n",
      "Done: 24800/34161 images\n",
      "Done: 24900/34161 images\n",
      "Done: 25000/34161 images\n",
      "Done: 25100/34161 images\n",
      "Done: 25200/34161 images\n",
      "Done: 25300/34161 images\n",
      "Done: 25400/34161 images\n",
      "Done: 25500/34161 images\n",
      "Done: 25600/34161 images\n",
      "Done: 25700/34161 images\n",
      "Done: 25800/34161 images\n",
      "Done: 25900/34161 images\n",
      "Done: 26000/34161 images\n",
      "Done: 26100/34161 images\n",
      "Done: 26200/34161 images\n",
      "Done: 26300/34161 images\n",
      "Done: 26400/34161 images\n",
      "Done: 26500/34161 images\n",
      "Done: 26600/34161 images\n",
      "Done: 26700/34161 images\n",
      "Done: 26800/34161 images\n",
      "Done: 26900/34161 images\n",
      "Done: 27000/34161 images\n",
      "Done: 27100/34161 images\n",
      "Done: 27200/34161 images\n",
      "Done: 27300/34161 images\n",
      "Done: 27400/34161 images\n",
      "Done: 27500/34161 images\n",
      "Done: 27600/34161 images\n",
      "Done: 27700/34161 images\n",
      "Done: 27800/34161 images\n",
      "Done: 27900/34161 images\n",
      "Done: 28000/34161 images\n",
      "Done: 28100/34161 images\n",
      "Done: 28200/34161 images\n",
      "Done: 28300/34161 images\n",
      "Done: 28400/34161 images\n",
      "Done: 28500/34161 images\n",
      "Done: 28600/34161 images\n",
      "Done: 28700/34161 images\n",
      "Done: 28800/34161 images\n",
      "Done: 28900/34161 images\n",
      "Done: 29000/34161 images\n",
      "Done: 29100/34161 images\n",
      "Done: 29200/34161 images\n",
      "Done: 29300/34161 images\n",
      "Done: 29400/34161 images\n",
      "Done: 29500/34161 images\n",
      "Done: 29600/34161 images\n",
      "Done: 29700/34161 images\n",
      "Done: 29800/34161 images\n",
      "Done: 29900/34161 images\n",
      "Done: 30000/34161 images\n",
      "Done: 30100/34161 images\n",
      "Done: 30200/34161 images\n",
      "Done: 30300/34161 images\n",
      "Done: 30400/34161 images\n",
      "Done: 30500/34161 images\n",
      "Done: 30600/34161 images\n",
      "Done: 30700/34161 images\n",
      "Done: 30800/34161 images\n",
      "Done: 30900/34161 images\n",
      "Done: 31000/34161 images\n",
      "Done: 31100/34161 images\n",
      "Done: 31200/34161 images\n",
      "Done: 31300/34161 images\n",
      "Done: 31400/34161 images\n",
      "Done: 31500/34161 images\n",
      "Done: 31600/34161 images\n",
      "Done: 31700/34161 images\n",
      "Done: 31800/34161 images\n",
      "Done: 31900/34161 images\n",
      "Done: 32000/34161 images\n",
      "Done: 32100/34161 images\n",
      "Done: 32200/34161 images\n",
      "Done: 32300/34161 images\n",
      "Done: 32400/34161 images\n",
      "Done: 32500/34161 images\n",
      "Done: 32600/34161 images\n",
      "Done: 32700/34161 images\n",
      "Done: 32800/34161 images\n",
      "Done: 32900/34161 images\n",
      "Done: 33000/34161 images\n",
      "Done: 33100/34161 images\n",
      "Done: 33200/34161 images\n",
      "Done: 33300/34161 images\n",
      "Done: 33400/34161 images\n",
      "Done: 33500/34161 images\n",
      "Done: 33600/34161 images\n",
      "Done: 33700/34161 images\n",
      "Done: 33800/34161 images\n",
      "Done: 33900/34161 images\n",
      "Done: 34000/34161 images\n",
      "Done: 34100/34161 images\n",
      "Data created.\n",
      "('Image:', 'CVCD10010003')\n",
      "\n",
      "\n",
      "Done: 0/34161 images\n",
      "Done: 100/34161 images\n",
      "Done: 200/34161 images\n",
      "Done: 300/34161 images\n",
      "Done: 400/34161 images\n",
      "Done: 500/34161 images\n",
      "Done: 600/34161 images\n",
      "Done: 700/34161 images\n",
      "Done: 800/34161 images\n",
      "Done: 900/34161 images\n",
      "Done: 1000/34161 images\n",
      "Done: 1100/34161 images\n",
      "Done: 1200/34161 images\n",
      "Done: 1300/34161 images\n",
      "Done: 1400/34161 images\n",
      "Done: 1500/34161 images\n",
      "Done: 1600/34161 images\n",
      "Done: 1700/34161 images\n",
      "Done: 1800/34161 images\n",
      "Done: 1900/34161 images\n",
      "Done: 2000/34161 images\n",
      "Done: 2100/34161 images\n",
      "Done: 2200/34161 images\n",
      "Done: 2300/34161 images\n",
      "Done: 2400/34161 images\n",
      "Done: 2500/34161 images\n",
      "Done: 2600/34161 images\n",
      "Done: 2700/34161 images\n",
      "Done: 2800/34161 images\n",
      "Done: 2900/34161 images\n",
      "Done: 3000/34161 images\n",
      "Done: 3100/34161 images\n",
      "Done: 3200/34161 images\n",
      "Done: 3300/34161 images\n",
      "Done: 3400/34161 images\n",
      "Done: 3500/34161 images\n",
      "Done: 3600/34161 images\n",
      "Done: 3700/34161 images\n",
      "Done: 3800/34161 images\n",
      "Done: 3900/34161 images\n",
      "Done: 4000/34161 images\n",
      "Done: 4100/34161 images\n",
      "Done: 4200/34161 images\n",
      "Done: 4300/34161 images\n",
      "Done: 4400/34161 images\n",
      "Done: 4500/34161 images\n",
      "Done: 4600/34161 images\n",
      "Done: 4700/34161 images\n",
      "Done: 4800/34161 images\n",
      "Done: 4900/34161 images\n",
      "Done: 5000/34161 images\n",
      "Done: 5100/34161 images\n",
      "Done: 5200/34161 images\n",
      "Done: 5300/34161 images\n",
      "Done: 5400/34161 images\n",
      "Done: 5500/34161 images\n",
      "Done: 5600/34161 images\n",
      "Done: 5700/34161 images\n",
      "Done: 5800/34161 images\n",
      "Done: 5900/34161 images\n",
      "Done: 6000/34161 images\n",
      "Done: 6100/34161 images\n",
      "Done: 6200/34161 images\n",
      "Done: 6300/34161 images\n",
      "Done: 6400/34161 images\n",
      "Done: 6500/34161 images\n",
      "Done: 6600/34161 images\n",
      "Done: 6700/34161 images\n",
      "Done: 6800/34161 images\n",
      "Done: 6900/34161 images\n",
      "Done: 7000/34161 images\n",
      "Done: 7100/34161 images\n",
      "Done: 7200/34161 images\n",
      "Done: 7300/34161 images\n",
      "Done: 7400/34161 images\n",
      "Done: 7500/34161 images\n",
      "Done: 7600/34161 images\n",
      "Done: 7700/34161 images\n",
      "Done: 7800/34161 images\n",
      "Done: 7900/34161 images\n",
      "Done: 8000/34161 images\n",
      "Done: 8100/34161 images\n",
      "Done: 8200/34161 images\n",
      "Done: 8300/34161 images\n",
      "Done: 8400/34161 images\n",
      "Done: 8500/34161 images\n",
      "Done: 8600/34161 images\n",
      "Done: 8700/34161 images\n",
      "Done: 8800/34161 images\n",
      "Done: 8900/34161 images\n",
      "Done: 9000/34161 images\n",
      "Done: 9100/34161 images\n",
      "Done: 9200/34161 images\n",
      "Done: 9300/34161 images\n",
      "Done: 9400/34161 images\n",
      "Done: 9500/34161 images\n",
      "Done: 9600/34161 images\n",
      "Done: 9700/34161 images\n",
      "Done: 9800/34161 images\n",
      "Done: 9900/34161 images\n",
      "Done: 10000/34161 images\n",
      "Done: 10100/34161 images\n",
      "Done: 10200/34161 images\n",
      "Done: 10300/34161 images\n",
      "Done: 10400/34161 images\n",
      "Done: 10500/34161 images\n",
      "Done: 10600/34161 images\n",
      "Done: 10700/34161 images\n",
      "Done: 10800/34161 images\n",
      "Done: 10900/34161 images\n",
      "Done: 11000/34161 images\n",
      "Done: 11100/34161 images\n",
      "Done: 11200/34161 images\n",
      "Done: 11300/34161 images\n",
      "Done: 11400/34161 images\n",
      "Done: 11500/34161 images\n",
      "Done: 11600/34161 images\n",
      "Done: 11700/34161 images\n",
      "Done: 11800/34161 images\n",
      "Done: 11900/34161 images\n",
      "Done: 12000/34161 images\n",
      "Done: 12100/34161 images\n",
      "Done: 12200/34161 images\n",
      "Done: 12300/34161 images\n",
      "Done: 12400/34161 images\n",
      "Done: 12500/34161 images\n",
      "Done: 12600/34161 images\n",
      "Done: 12700/34161 images\n",
      "Done: 12800/34161 images\n",
      "Done: 12900/34161 images\n",
      "Done: 13000/34161 images\n",
      "Done: 13100/34161 images\n",
      "Done: 13200/34161 images\n",
      "Done: 13300/34161 images\n",
      "Done: 13400/34161 images\n",
      "Done: 13500/34161 images\n",
      "Done: 13600/34161 images\n",
      "Done: 13700/34161 images\n",
      "Done: 13800/34161 images\n",
      "Done: 13900/34161 images\n",
      "Done: 14000/34161 images\n",
      "Done: 14100/34161 images\n",
      "Done: 14200/34161 images\n",
      "Done: 14300/34161 images\n",
      "Done: 14400/34161 images\n",
      "Done: 14500/34161 images\n",
      "Done: 14600/34161 images\n",
      "Done: 14700/34161 images\n",
      "Done: 14800/34161 images\n",
      "Done: 14900/34161 images\n",
      "Done: 15000/34161 images\n",
      "Done: 15100/34161 images\n",
      "Done: 15200/34161 images\n",
      "Done: 15300/34161 images\n",
      "Done: 15400/34161 images\n",
      "Done: 15500/34161 images\n",
      "Done: 15600/34161 images\n",
      "Done: 15700/34161 images\n",
      "Done: 15800/34161 images\n",
      "Done: 15900/34161 images\n",
      "Done: 16000/34161 images\n",
      "Done: 16100/34161 images\n",
      "Done: 16200/34161 images\n",
      "Done: 16300/34161 images\n",
      "Done: 16400/34161 images\n",
      "Done: 16500/34161 images\n",
      "Done: 16600/34161 images\n",
      "Done: 16700/34161 images\n",
      "Done: 16800/34161 images\n",
      "Done: 16900/34161 images\n",
      "Done: 17000/34161 images\n",
      "Done: 17100/34161 images\n",
      "Done: 17200/34161 images\n",
      "Done: 17300/34161 images\n",
      "Done: 17400/34161 images\n",
      "Done: 17500/34161 images\n",
      "Done: 17600/34161 images\n",
      "Done: 17700/34161 images\n",
      "Done: 17800/34161 images\n",
      "Done: 17900/34161 images\n",
      "Done: 18000/34161 images\n",
      "Done: 18100/34161 images\n",
      "Done: 18200/34161 images\n",
      "Done: 18300/34161 images\n",
      "Done: 18400/34161 images\n",
      "Done: 18500/34161 images\n",
      "Done: 18600/34161 images\n",
      "Done: 18700/34161 images\n",
      "Done: 18800/34161 images\n",
      "Done: 18900/34161 images\n",
      "Done: 19000/34161 images\n",
      "Done: 19100/34161 images\n",
      "Done: 19200/34161 images\n",
      "Done: 19300/34161 images\n",
      "Done: 19400/34161 images\n",
      "Done: 19500/34161 images\n",
      "Done: 19600/34161 images\n",
      "Done: 19700/34161 images\n",
      "Done: 19800/34161 images\n",
      "Done: 19900/34161 images\n",
      "Done: 20000/34161 images\n",
      "Done: 20100/34161 images\n",
      "Done: 20200/34161 images\n",
      "Done: 20300/34161 images\n",
      "Done: 20400/34161 images\n",
      "Done: 20500/34161 images\n",
      "Done: 20600/34161 images\n",
      "Done: 20700/34161 images\n",
      "Done: 20800/34161 images\n",
      "Done: 20900/34161 images\n",
      "Done: 21000/34161 images\n",
      "Done: 21100/34161 images\n",
      "Done: 21200/34161 images\n",
      "Done: 21300/34161 images\n",
      "Done: 21400/34161 images\n",
      "Done: 21500/34161 images\n",
      "Done: 21600/34161 images\n",
      "Done: 21700/34161 images\n",
      "Done: 21800/34161 images\n",
      "Done: 21900/34161 images\n",
      "Done: 22000/34161 images\n",
      "Done: 22100/34161 images\n",
      "Done: 22200/34161 images\n",
      "Done: 22300/34161 images\n",
      "Done: 22400/34161 images\n",
      "Done: 22500/34161 images\n",
      "Done: 22600/34161 images\n",
      "Done: 22700/34161 images\n",
      "Done: 22800/34161 images\n",
      "Done: 22900/34161 images\n",
      "Done: 23000/34161 images\n",
      "Done: 23100/34161 images\n",
      "Done: 23200/34161 images\n",
      "Done: 23300/34161 images\n",
      "Done: 23400/34161 images\n",
      "Done: 23500/34161 images\n",
      "Done: 23600/34161 images\n",
      "Done: 23700/34161 images\n",
      "Done: 23800/34161 images\n",
      "Done: 23900/34161 images\n",
      "Done: 24000/34161 images\n",
      "Done: 24100/34161 images\n",
      "Done: 24200/34161 images\n",
      "Done: 24300/34161 images\n",
      "Done: 24400/34161 images\n",
      "Done: 24500/34161 images\n",
      "Done: 24600/34161 images\n",
      "Done: 24700/34161 images\n",
      "Done: 24800/34161 images\n",
      "Done: 24900/34161 images\n",
      "Done: 25000/34161 images\n",
      "Done: 25100/34161 images\n",
      "Done: 25200/34161 images\n",
      "Done: 25300/34161 images\n",
      "Done: 25400/34161 images\n",
      "Done: 25500/34161 images\n",
      "Done: 25600/34161 images\n",
      "Done: 25700/34161 images\n",
      "Done: 25800/34161 images\n",
      "Done: 25900/34161 images\n",
      "Done: 26000/34161 images\n",
      "Done: 26100/34161 images\n",
      "Done: 26200/34161 images\n",
      "Done: 26300/34161 images\n",
      "Done: 26400/34161 images\n",
      "Done: 26500/34161 images\n",
      "Done: 26600/34161 images\n",
      "Done: 26700/34161 images\n",
      "Done: 26800/34161 images\n",
      "Done: 26900/34161 images\n",
      "Done: 27000/34161 images\n",
      "Done: 27100/34161 images\n",
      "Done: 27200/34161 images\n",
      "Done: 27300/34161 images\n",
      "Done: 27400/34161 images\n",
      "Done: 27500/34161 images\n",
      "Done: 27600/34161 images\n",
      "Done: 27700/34161 images\n",
      "Done: 27800/34161 images\n",
      "Done: 27900/34161 images\n",
      "Done: 28000/34161 images\n",
      "Done: 28100/34161 images\n",
      "Done: 28200/34161 images\n",
      "Done: 28300/34161 images\n",
      "Done: 28400/34161 images\n",
      "Done: 28500/34161 images\n",
      "Done: 28600/34161 images\n",
      "Done: 28700/34161 images\n",
      "Done: 28800/34161 images\n",
      "Done: 28900/34161 images\n",
      "Done: 29000/34161 images\n",
      "Done: 29100/34161 images\n",
      "Done: 29200/34161 images\n",
      "Done: 29300/34161 images\n",
      "Done: 29400/34161 images\n",
      "Done: 29500/34161 images\n",
      "Done: 29600/34161 images\n",
      "Done: 29700/34161 images\n",
      "Done: 29800/34161 images\n",
      "Done: 29900/34161 images\n",
      "Done: 30000/34161 images\n",
      "Done: 30100/34161 images\n",
      "Done: 30200/34161 images\n",
      "Done: 30300/34161 images\n",
      "Done: 30400/34161 images\n",
      "Done: 30500/34161 images\n",
      "Done: 30600/34161 images\n",
      "Done: 30700/34161 images\n",
      "Done: 30800/34161 images\n",
      "Done: 30900/34161 images\n",
      "Done: 31000/34161 images\n",
      "Done: 31100/34161 images\n",
      "Done: 31200/34161 images\n",
      "Done: 31300/34161 images\n",
      "Done: 31400/34161 images\n",
      "Done: 31500/34161 images\n",
      "Done: 31600/34161 images\n",
      "Done: 31700/34161 images\n",
      "Done: 31800/34161 images\n",
      "Done: 31900/34161 images\n",
      "Done: 32000/34161 images\n",
      "Done: 32100/34161 images\n",
      "Done: 32200/34161 images\n",
      "Done: 32300/34161 images\n",
      "Done: 32400/34161 images\n",
      "Done: 32500/34161 images\n",
      "Done: 32600/34161 images\n",
      "Done: 32700/34161 images\n",
      "Done: 32800/34161 images\n",
      "Done: 32900/34161 images\n",
      "Done: 33000/34161 images\n",
      "Done: 33100/34161 images\n",
      "Done: 33200/34161 images\n",
      "Done: 33300/34161 images\n",
      "Done: 33400/34161 images\n",
      "Done: 33500/34161 images\n",
      "Done: 33600/34161 images\n",
      "Done: 33700/34161 images\n",
      "Done: 33800/34161 images\n",
      "Done: 33900/34161 images\n",
      "Done: 34000/34161 images\n",
      "Done: 34100/34161 images\n",
      "Data created.\n",
      "('Image:', 'CVCD10010004')\n",
      "\n",
      "\n",
      "Done: 0/34161 images\n",
      "Done: 100/34161 images\n",
      "Done: 200/34161 images\n",
      "Done: 300/34161 images\n",
      "Done: 400/34161 images\n",
      "Done: 500/34161 images\n",
      "Done: 600/34161 images\n",
      "Done: 700/34161 images\n",
      "Done: 800/34161 images\n",
      "Done: 900/34161 images\n",
      "Done: 1000/34161 images\n",
      "Done: 1100/34161 images\n",
      "Done: 1200/34161 images\n",
      "Done: 1300/34161 images\n",
      "Done: 1400/34161 images\n",
      "Done: 1500/34161 images\n",
      "Done: 1600/34161 images\n",
      "Done: 1700/34161 images\n",
      "Done: 1800/34161 images\n",
      "Done: 1900/34161 images\n",
      "Done: 2000/34161 images\n",
      "Done: 2100/34161 images\n",
      "Done: 2200/34161 images\n",
      "Done: 2300/34161 images\n",
      "Done: 2400/34161 images\n",
      "Done: 2500/34161 images\n",
      "Done: 2600/34161 images\n",
      "Done: 2700/34161 images\n",
      "Done: 2800/34161 images\n",
      "Done: 2900/34161 images\n",
      "Done: 3000/34161 images\n",
      "Done: 3100/34161 images\n",
      "Done: 3200/34161 images\n",
      "Done: 3300/34161 images\n",
      "Done: 3400/34161 images\n",
      "Done: 3500/34161 images\n",
      "Done: 3600/34161 images\n",
      "Done: 3700/34161 images\n",
      "Done: 3800/34161 images\n",
      "Done: 3900/34161 images\n",
      "Done: 4000/34161 images\n",
      "Done: 4100/34161 images\n",
      "Done: 4200/34161 images\n",
      "Done: 4300/34161 images\n",
      "Done: 4400/34161 images\n",
      "Done: 4500/34161 images\n",
      "Done: 4600/34161 images\n",
      "Done: 4700/34161 images\n",
      "Done: 4800/34161 images\n",
      "Done: 4900/34161 images\n",
      "Done: 5000/34161 images\n",
      "Done: 5100/34161 images\n",
      "Done: 5200/34161 images\n",
      "Done: 5300/34161 images\n",
      "Done: 5400/34161 images\n",
      "Done: 5500/34161 images\n",
      "Done: 5600/34161 images\n",
      "Done: 5700/34161 images\n",
      "Done: 5800/34161 images\n",
      "Done: 5900/34161 images\n",
      "Done: 6000/34161 images\n",
      "Done: 6100/34161 images\n",
      "Done: 6200/34161 images\n",
      "Done: 6300/34161 images\n",
      "Done: 6400/34161 images\n",
      "Done: 6500/34161 images\n",
      "Done: 6600/34161 images\n",
      "Done: 6700/34161 images\n",
      "Done: 6800/34161 images\n",
      "Done: 6900/34161 images\n",
      "Done: 7000/34161 images\n",
      "Done: 7100/34161 images\n",
      "Done: 7200/34161 images\n",
      "Done: 7300/34161 images\n",
      "Done: 7400/34161 images\n",
      "Done: 7500/34161 images\n",
      "Done: 7600/34161 images\n",
      "Done: 7700/34161 images\n",
      "Done: 7800/34161 images\n",
      "Done: 7900/34161 images\n",
      "Done: 8000/34161 images\n",
      "Done: 8100/34161 images\n",
      "Done: 8200/34161 images\n",
      "Done: 8300/34161 images\n",
      "Done: 8400/34161 images\n",
      "Done: 8500/34161 images\n",
      "Done: 8600/34161 images\n",
      "Done: 8700/34161 images\n",
      "Done: 8800/34161 images\n",
      "Done: 8900/34161 images\n",
      "Done: 9000/34161 images\n",
      "Done: 9100/34161 images\n",
      "Done: 9200/34161 images\n",
      "Done: 9300/34161 images\n",
      "Done: 9400/34161 images\n",
      "Done: 9500/34161 images\n",
      "Done: 9600/34161 images\n",
      "Done: 9700/34161 images\n",
      "Done: 9800/34161 images\n",
      "Done: 9900/34161 images\n",
      "Done: 10000/34161 images\n",
      "Done: 10100/34161 images\n",
      "Done: 10200/34161 images\n",
      "Done: 10300/34161 images\n",
      "Done: 10400/34161 images\n",
      "Done: 10500/34161 images\n",
      "Done: 10600/34161 images\n",
      "Done: 10700/34161 images\n",
      "Done: 10800/34161 images\n",
      "Done: 10900/34161 images\n",
      "Done: 11000/34161 images\n",
      "Done: 11100/34161 images\n",
      "Done: 11200/34161 images\n",
      "Done: 11300/34161 images\n",
      "Done: 11400/34161 images\n",
      "Done: 11500/34161 images\n",
      "Done: 11600/34161 images\n",
      "Done: 11700/34161 images\n",
      "Done: 11800/34161 images\n",
      "Done: 11900/34161 images\n",
      "Done: 12000/34161 images\n",
      "Done: 12100/34161 images\n",
      "Done: 12200/34161 images\n",
      "Done: 12300/34161 images\n",
      "Done: 12400/34161 images\n",
      "Done: 12500/34161 images\n",
      "Done: 12600/34161 images\n",
      "Done: 12700/34161 images\n",
      "Done: 12800/34161 images\n",
      "Done: 12900/34161 images\n",
      "Done: 13000/34161 images\n",
      "Done: 13100/34161 images\n",
      "Done: 13200/34161 images\n",
      "Done: 13300/34161 images\n",
      "Done: 13400/34161 images\n",
      "Done: 13500/34161 images\n",
      "Done: 13600/34161 images\n",
      "Done: 13700/34161 images\n",
      "Done: 13800/34161 images\n",
      "Done: 13900/34161 images\n",
      "Done: 14000/34161 images\n",
      "Done: 14100/34161 images\n",
      "Done: 14200/34161 images\n",
      "Done: 14300/34161 images\n",
      "Done: 14400/34161 images\n",
      "Done: 14500/34161 images\n",
      "Done: 14600/34161 images\n",
      "Done: 14700/34161 images\n",
      "Done: 14800/34161 images\n",
      "Done: 14900/34161 images\n",
      "Done: 15000/34161 images\n",
      "Done: 15100/34161 images\n",
      "Done: 15200/34161 images\n",
      "Done: 15300/34161 images\n",
      "Done: 15400/34161 images\n",
      "Done: 15500/34161 images\n",
      "Done: 15600/34161 images\n",
      "Done: 15700/34161 images\n",
      "Done: 15800/34161 images\n",
      "Done: 15900/34161 images\n",
      "Done: 16000/34161 images\n",
      "Done: 16100/34161 images\n",
      "Done: 16200/34161 images\n",
      "Done: 16300/34161 images\n",
      "Done: 16400/34161 images\n",
      "Done: 16500/34161 images\n",
      "Done: 16600/34161 images\n",
      "Done: 16700/34161 images\n",
      "Done: 16800/34161 images\n",
      "Done: 16900/34161 images\n",
      "Done: 17000/34161 images\n",
      "Done: 17100/34161 images\n",
      "Done: 17200/34161 images\n",
      "Done: 17300/34161 images\n",
      "Done: 17400/34161 images\n",
      "Done: 17500/34161 images\n",
      "Done: 17600/34161 images\n",
      "Done: 17700/34161 images\n",
      "Done: 17800/34161 images\n",
      "Done: 17900/34161 images\n",
      "Done: 18000/34161 images\n",
      "Done: 18100/34161 images\n",
      "Done: 18200/34161 images\n",
      "Done: 18300/34161 images\n",
      "Done: 18400/34161 images\n",
      "Done: 18500/34161 images\n",
      "Done: 18600/34161 images\n",
      "Done: 18700/34161 images\n",
      "Done: 18800/34161 images\n",
      "Done: 18900/34161 images\n",
      "Done: 19000/34161 images\n",
      "Done: 19100/34161 images\n",
      "Done: 19200/34161 images\n",
      "Done: 19300/34161 images\n",
      "Done: 19400/34161 images\n",
      "Done: 19500/34161 images\n",
      "Done: 19600/34161 images\n",
      "Done: 19700/34161 images\n",
      "Done: 19800/34161 images\n",
      "Done: 19900/34161 images\n",
      "Done: 20000/34161 images\n",
      "Done: 20100/34161 images\n",
      "Done: 20200/34161 images\n",
      "Done: 20300/34161 images\n",
      "Done: 20400/34161 images\n",
      "Done: 20500/34161 images\n",
      "Done: 20600/34161 images\n",
      "Done: 20700/34161 images\n",
      "Done: 20800/34161 images\n",
      "Done: 20900/34161 images\n",
      "Done: 21000/34161 images\n",
      "Done: 21100/34161 images\n",
      "Done: 21200/34161 images\n",
      "Done: 21300/34161 images\n",
      "Done: 21400/34161 images\n",
      "Done: 21500/34161 images\n",
      "Done: 21600/34161 images\n",
      "Done: 21700/34161 images\n",
      "Done: 21800/34161 images\n",
      "Done: 21900/34161 images\n",
      "Done: 22000/34161 images\n",
      "Done: 22100/34161 images\n",
      "Done: 22200/34161 images\n",
      "Done: 22300/34161 images\n",
      "Done: 22400/34161 images\n",
      "Done: 22500/34161 images\n",
      "Done: 22600/34161 images\n",
      "Done: 22700/34161 images\n",
      "Done: 22800/34161 images\n",
      "Done: 22900/34161 images\n",
      "Done: 23000/34161 images\n",
      "Done: 23100/34161 images\n",
      "Done: 23200/34161 images\n",
      "Done: 23300/34161 images\n",
      "Done: 23400/34161 images\n",
      "Done: 23500/34161 images\n",
      "Done: 23600/34161 images\n",
      "Done: 23700/34161 images\n",
      "Done: 23800/34161 images\n",
      "Done: 23900/34161 images\n",
      "Done: 24000/34161 images\n",
      "Done: 24100/34161 images\n",
      "Done: 24200/34161 images\n",
      "Done: 24300/34161 images\n",
      "Done: 24400/34161 images\n",
      "Done: 24500/34161 images\n",
      "Done: 24600/34161 images\n",
      "Done: 24700/34161 images\n",
      "Done: 24800/34161 images\n",
      "Done: 24900/34161 images\n",
      "Done: 25000/34161 images\n",
      "Done: 25100/34161 images\n",
      "Done: 25200/34161 images\n",
      "Done: 25300/34161 images\n",
      "Done: 25400/34161 images\n",
      "Done: 25500/34161 images\n",
      "Done: 25600/34161 images\n",
      "Done: 25700/34161 images\n",
      "Done: 25800/34161 images\n",
      "Done: 25900/34161 images\n",
      "Done: 26000/34161 images\n",
      "Done: 26100/34161 images\n",
      "Done: 26200/34161 images\n",
      "Done: 26300/34161 images\n",
      "Done: 26400/34161 images\n",
      "Done: 26500/34161 images\n",
      "Done: 26600/34161 images\n",
      "Done: 26700/34161 images\n",
      "Done: 26800/34161 images\n",
      "Done: 26900/34161 images\n",
      "Done: 27000/34161 images\n",
      "Done: 27100/34161 images\n",
      "Done: 27200/34161 images\n",
      "Done: 27300/34161 images\n",
      "Done: 27400/34161 images\n",
      "Done: 27500/34161 images\n",
      "Done: 27600/34161 images\n",
      "Done: 27700/34161 images\n",
      "Done: 27800/34161 images\n",
      "Done: 27900/34161 images\n",
      "Done: 28000/34161 images\n",
      "Done: 28100/34161 images\n",
      "Done: 28200/34161 images\n",
      "Done: 28300/34161 images\n",
      "Done: 28400/34161 images\n",
      "Done: 28500/34161 images\n",
      "Done: 28600/34161 images\n",
      "Done: 28700/34161 images\n",
      "Done: 28800/34161 images\n",
      "Done: 28900/34161 images\n",
      "Done: 29000/34161 images\n",
      "Done: 29100/34161 images\n",
      "Done: 29200/34161 images\n",
      "Done: 29300/34161 images\n",
      "Done: 29400/34161 images\n",
      "Done: 29500/34161 images\n",
      "Done: 29600/34161 images\n",
      "Done: 29700/34161 images\n",
      "Done: 29800/34161 images\n",
      "Done: 29900/34161 images\n",
      "Done: 30000/34161 images\n",
      "Done: 30100/34161 images\n",
      "Done: 30200/34161 images\n",
      "Done: 30300/34161 images\n",
      "Done: 30400/34161 images\n",
      "Done: 30500/34161 images\n",
      "Done: 30600/34161 images\n",
      "Done: 30700/34161 images\n",
      "Done: 30800/34161 images\n",
      "Done: 30900/34161 images\n",
      "Done: 31000/34161 images\n",
      "Done: 31100/34161 images\n",
      "Done: 31200/34161 images\n",
      "Done: 31300/34161 images\n",
      "Done: 31400/34161 images\n",
      "Done: 31500/34161 images\n",
      "Done: 31600/34161 images\n",
      "Done: 31700/34161 images\n",
      "Done: 31800/34161 images\n",
      "Done: 31900/34161 images\n",
      "Done: 32000/34161 images\n",
      "Done: 32100/34161 images\n",
      "Done: 32200/34161 images\n",
      "Done: 32300/34161 images\n",
      "Done: 32400/34161 images\n",
      "Done: 32500/34161 images\n",
      "Done: 32600/34161 images\n",
      "Done: 32700/34161 images\n",
      "Done: 32800/34161 images\n",
      "Done: 32900/34161 images\n",
      "Done: 33000/34161 images\n",
      "Done: 33100/34161 images\n",
      "Done: 33200/34161 images\n",
      "Done: 33300/34161 images\n",
      "Done: 33400/34161 images\n",
      "Done: 33500/34161 images\n",
      "Done: 33600/34161 images\n",
      "Done: 33700/34161 images\n",
      "Done: 33800/34161 images\n",
      "Done: 33900/34161 images\n",
      "Done: 34000/34161 images\n",
      "Done: 34100/34161 images\n",
      "Data created.\n",
      "--- 195.655113935 seconds ---\n"
     ]
    }
   ],
   "source": [
    "if __name__ == '__main__':\n",
    "\n",
    "    start_time = time.time()\n",
    "\n",
    "    # Teste \n",
    "    print('-'*30)\n",
    "    print('Creating Test 2D Patches...')\n",
    "    print('-'*30)\n",
    "    srcDir = os.path.join(out,test_mid_samples)\n",
    "    dstDir = os.path.join(out,test_patches) \n",
    "    create_new_dir(dstDir)\n",
    "\n",
    "    sample_2d_patches(srcDir, dstDir, 'test') # Criando patches para 4 imagens de teste\n",
    "\n",
    "    print('-'*30)\n",
    "    print('Creating Preprocessed Test Data...')\n",
    "    print('-'*30)\n",
    "    dstDir = os.path.join(out,'test_prep_data') \n",
    "    create_new_dir(dstDir)\n",
    "    test_patches_folds = np.sort(glob.glob(os.path.join(out,test_patches +'/*')))\n",
    "    mean, std = get_mean_std_train(os.path.join(out,'imgs_train.npy')\n",
    "                                   , os.path.join(out,'imgs_mask_train.npy'))\n",
    "       \n",
    "    for fold in test_patches_folds:\n",
    "        name = fold.split('/')[-1]\n",
    "        print (\"Image:\", name)\n",
    "        print ('\\n')\n",
    "        imgs, imgs_mask = create_data(fold)\n",
    "        imgs_test = read_prep_test(imgs,mean,std)\n",
    "        np.savez_compressed(os.path.join(dstDir,name +'-prep.npz'),\n",
    "                            imgs_test = imgs_test)\n",
    "        \n",
    "    print(\"--- %s seconds ---\" % (time.time() - start_time))\n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Callback modificado"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import os, time\n",
    "import numpy as np\n",
    "import cPickle as pickle\n",
    "from IPython import display\n",
    "import matplotlib.pyplot as plot\n",
    "from keras.models import load_model\n",
    "from keras.callbacks import Callback\n",
    "\n",
    "def load_model_and_history(name):\n",
    "    model_fn = name + '.model'\n",
    "    history_fn = name + '.history'\n",
    "    model, callback = None, None\n",
    "    if os.path.isfile(model_fn):\n",
    "        model = load_model(model_fn)\n",
    "        if os.path.isfile(history_fn):\n",
    "            callback = pickle.load(open(history_fn, 'rb'))\n",
    "    return model, callback\n",
    "\n",
    "def save_model_and_history(name, model, histo):\n",
    "    model.save(name + '.model', overwrite=True)\n",
    "    pickle.dump(histo, open(name + '.history', 'wb'))\n",
    "    \n",
    "class TrainingPlotter_2(Callback):\n",
    "    \"\"\"\n",
    "    History + ModelCheckpoint + EarlyStopping + PlotLosses\n",
    "    \"\"\"\n",
    "    def __init__(self, n=1, filepath=None, patience=10, axis=None):\n",
    "        self.history = []\n",
    "        self.best_loss = np.inf\n",
    "        self.best_epoch = 0\n",
    "        self.filepath = filepath\n",
    "        self.patience = patience\n",
    "        \n",
    "        self.n = n\n",
    "        self.line1 = None\n",
    "        self.line2 = None\n",
    "        self.axis = axis\n",
    "                \n",
    "    def __getstate__(self):\n",
    "        # we do not want to pickle the matplotlib line1/line2/axis\n",
    "        return dict(n=self.n, history=self.history, best_loss=self.best_loss, \n",
    "                    best_epoch=self.best_epoch, filepath=self.filepath, \n",
    "                    patience=self.patience, line1=None, line2=None, axis=None)\n",
    "\n",
    "    def get_nepochs(self):\n",
    "        return len(self.history)\n",
    "    \n",
    "    def on_epoch_begin(self, epoch, logs={}):\n",
    "        self.epoch_t0 = time.time()\n",
    "\n",
    "    def on_epoch_end(self, epoch, logs={}):\n",
    "        # {'acc': 0.97, 'loss': 0.08, 'val_acc': 0.98, 'val_loss': 0.06}\n",
    "        epoch += self.nepochs\n",
    "        epoch_time = time.time() - self.epoch_t0\n",
    "        self.history.append(logs)\n",
    "        \n",
    "        if 'val_loss' in logs.keys():\n",
    "            early_stop_msg = ''\n",
    "            if logs['val_loss'] < self.best_loss:\n",
    "                self.best_loss = logs['val_loss']\n",
    "                self.best_epoch = epoch\n",
    "                self.waiting = 0\n",
    "                if self.filepath is not None:\n",
    "                    save_model_and_history(self.filepath, self.model, self)\n",
    "            else:\n",
    "                self.waiting += 1\n",
    "                if self.waiting > self.patience:\n",
    "                    self.model.stop_training = True\n",
    "                    early_stop_msg = 'Early Stopped.'\n",
    "            val = True\n",
    "        else:\n",
    "            val = False\n",
    "            \n",
    "        if self.axis is None:\n",
    "            self.axis = plot\n",
    "\n",
    "        try:\n",
    "            if (len(self.history) % self.n) == 0:\n",
    "                htrain = np.array([v['val_loss'] for v in self.history], np.float32)\n",
    "                if val:\n",
    "                    hvalid = np.array([v['val_loss'] for v in self.history], np.float32)\n",
    "\n",
    "                if self.line2 is None:\n",
    "                    self.line2 = self.axis.plot(htrain, linewidth=2, label='training dice_coef_loss')[0]\n",
    "                    if val:\n",
    "                        self.line1 = self.axis.plot(hvalid, linewidth=2, label='validation dice_coef_loss')[0]\n",
    "                        self.axis.vlines(self.best_epoch, 0, 1, colors='#EBDDE2', linestyles='dashed', \n",
    "                                         label='validation min')\n",
    "                else:\n",
    "                    self.line2.set_xdata(np.arange(htrain.shape[0]))\n",
    "                    self.line2.set_ydata(htrain)\n",
    "                    if val:\n",
    "                        self.line1.set_xdata(np.arange(hvalid.shape[0]))\n",
    "                        self.line1.set_ydata(hvalid)\n",
    "                        self.axis.vlines(self.best_epoch, 0, 1, colors='#EBDDE2', linestyles='dashed')\n",
    "                    \n",
    "                self.axis.legend()\n",
    "                if 'dice_coef' in logs.keys():\n",
    "                    acc = ' Accuracy = {:.2f}%'.format(100.0 * self.history[self.best_epoch]['dice_coef'])\n",
    "                else:\n",
    "                    acc = ''\n",
    "                if val:\n",
    "                    self.axis.title('{} Best loss is {:.5f} on epoch {:d}.{}'\n",
    "                                    .format(early_stop_msg, self.best_loss, self.best_epoch, acc), \n",
    "                                    weight='bold')\n",
    "                    self.axis.ylabel('Losses [{:.5f} / {:.5f}]'.format(htrain[-1], hvalid[-1]))\n",
    "                else:\n",
    "                    self.axis.ylabel('Training Loss: {:.5f}'.format(htrain[-1]))\n",
    "                self.axis.xlabel('Epoch [{}: {:.2f}s]'.format(epoch, epoch_time))\n",
    "                \n",
    "                display.display(plot.gcf())\n",
    "                display.clear_output(wait=True)\n",
    "\n",
    "        except Exception as e:\n",
    "            print '=*' * 40\n",
    "            print 'Error while trying to plot losses...'\n",
    "            print e\n",
    "            print '*=' * 40\n",
    "            raise\n",
    "            \n",
    "    def on_batch_begin(self, batch, logs={}):\n",
    "        pass\n",
    "\n",
    "    def on_batch_end(self, batch, logs={}):\n",
    "        pass\n",
    "\n",
    "    def on_train_begin(self, logs={}):\n",
    "        self.nepochs = len(self.history)\n",
    "        self.waiting = 0\n",
    "\n",
    "    def on_train_end(self, logs={}):\n",
    "        pass\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Treinamento da CNN"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def dice_coef(y_true, y_pred):\n",
    "    \n",
    "    y_true_f = K.flatten(y_true)\n",
    "    y_pred_f = K.flatten(y_pred)\n",
    "    intersection = K.sum(y_true_f * y_pred_f)\n",
    "    return (2. * intersection + smooth) / (K.sum(y_true_f) + K.sum(y_pred_f) + smooth)\n",
    "\n",
    "\n",
    "def dice_coef_loss(y_true, y_pred):\n",
    "    \n",
    "    return -dice_coef(y_true, y_pred)\n",
    "\n",
    "\n",
    "def get_unet():\n",
    "    \n",
    "    inputs = Input((1, img_rows, img_cols))\n",
    "    conv1 = Convolution2D(32, 3, 3, activation='relu', border_mode='same')(inputs)\n",
    "    conv1 = Convolution2D(32, 3, 3, activation='relu', border_mode='same')(conv1)\n",
    "    pool1 = MaxPooling2D(pool_size=(2, 2))(conv1)\n",
    "\n",
    "    conv2 = Convolution2D(64, 3, 3, activation='relu', border_mode='same')(pool1)\n",
    "    conv2 = Convolution2D(64, 3, 3, activation='relu', border_mode='same')(conv2)\n",
    "    pool2 = MaxPooling2D(pool_size=(2, 2))(conv2)\n",
    "\n",
    "    conv3 = Convolution2D(128, 3, 3, activation='relu', border_mode='same')(pool2)\n",
    "    conv3 = Convolution2D(128, 3, 3, activation='relu', border_mode='same')(conv3)\n",
    "    pool3 = MaxPooling2D(pool_size=(2, 2))(conv3)\n",
    "\n",
    "    conv4 = Convolution2D(256, 3, 3, activation='relu', border_mode='same')(pool3)\n",
    "    conv4 = Convolution2D(256, 3, 3, activation='relu', border_mode='same')(conv4)\n",
    "    pool4 = MaxPooling2D(pool_size=(2, 2))(conv4)\n",
    "\n",
    "    conv5 = Convolution2D(512, 3, 3, activation='relu', border_mode='same')(pool4)\n",
    "    conv5 = Convolution2D(512, 3, 3, activation='relu', border_mode='same')(conv5)\n",
    "\n",
    "    up6 = merge([UpSampling2D(size=(2, 2))(conv5), conv4], mode='concat', concat_axis=1)\n",
    "    conv6 = Convolution2D(256, 3, 3, activation='relu', border_mode='same')(up6)\n",
    "    conv6 = Convolution2D(256, 3, 3, activation='relu', border_mode='same')(conv6)\n",
    "\n",
    "    up7 = merge([UpSampling2D(size=(2, 2))(conv6), conv3], mode='concat', concat_axis=1)\n",
    "    conv7 = Convolution2D(128, 3, 3, activation='relu', border_mode='same')(up7)\n",
    "    conv7 = Convolution2D(128, 3, 3, activation='relu', border_mode='same')(conv7)\n",
    "\n",
    "    up8 = merge([UpSampling2D(size=(2, 2))(conv7), conv2], mode='concat', concat_axis=1)\n",
    "    conv8 = Convolution2D(64, 3, 3, activation='relu', border_mode='same')(up8)\n",
    "    conv8 = Convolution2D(64, 3, 3, activation='relu', border_mode='same')(conv8)\n",
    "\n",
    "    up9 = merge([UpSampling2D(size=(2, 2))(conv8), conv1], mode='concat', concat_axis=1)\n",
    "    conv9 = Convolution2D(32, 3, 3, activation='relu', border_mode='same')(up9)\n",
    "    conv9 = Convolution2D(32, 3, 3, activation='relu', border_mode='same')(conv9)\n",
    "\n",
    "    conv10 = Convolution2D(1, 1, 1, activation='sigmoid')(conv9)\n",
    "\n",
    "    model = Model(input=inputs, output=conv10)\n",
    "    model.compile(optimizer=Adam(lr=1e-5), loss=dice_coef_loss, metrics=[dice_coef])\n",
    "\n",
    "    return model\n",
    "\n",
    "def run_train():\n",
    "    \n",
    "    imgs_train, imgs_mask_train = load_train_data(os.path.join(out,'imgs_train.npy')\n",
    "                                                  , os.path.join(out,'imgs_mask_train.npy'))\n",
    "\n",
    "    imgs_train = preprocess(imgs_train)\n",
    "    imgs_mask_train = preprocess(imgs_mask_train)\n",
    "\n",
    "    imgs_train = imgs_train.astype('float32')\n",
    "    mean = np.mean(imgs_train)  # média e desvio padrão para normalização dos dados\n",
    "    std = np.std(imgs_train)\n",
    "\n",
    "    imgs_train -= mean\n",
    "    imgs_train /= std\n",
    "\n",
    "    imgs_mask_train = imgs_mask_train.astype('float32')\n",
    "    imgs_mask_train[imgs_mask_train>0]=1\n",
    "    \n",
    "    # Visualização dinÂmica do treinamento\n",
    "    nepochs = 30\n",
    "    ploss = -1.0\n",
    "    \n",
    "    if not os.path.isfile(model_name + '.model'):\n",
    "        print(\"[INFO] creating model...\")\n",
    "        model = get_unet()\n",
    "        # History, checkpoint, earlystop, plot losses:\n",
    "        my_big_callback = TrainingPlotter_2(n=1, filepath=model_name, patience=15)\n",
    "   \n",
    "\n",
    "    else:\n",
    "        print(\"[INFO] loading model...\")\n",
    "        model, my_big_callback = load_model_and_history(model_name)\n",
    "\n",
    "    past_epochs = my_big_callback.get_nepochs()\n",
    "\n",
    "    fig = plt.figure(figsize=(15,6))\n",
    "    plt.ylim(ploss, 0.0)\n",
    "    plt.xlim(0, nepochs)\n",
    "    plt.grid(True)\n",
    "\n",
    "    print(\"[INFO] training...\")\n",
    "\n",
    "    if nepochs > 0:\n",
    "        try:\n",
    "            model.fit(imgs_train[:100], \n",
    "                      imgs_mask_train[:100],\n",
    "                      batch_size=50,\n",
    "                      nb_epoch=nepochs - past_epochs,\n",
    "                      verbose=0,\n",
    "                      shuffle=True,\n",
    "                      callbacks=[my_big_callback])\n",
    "\n",
    "        except KeyboardInterrupt:\n",
    "            pass"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[INFO] creating model...\n",
      "[INFO] training...\n",
      "=*=*=*=*=*=*=*=*=*=*=*=*=*=*=*=*=*=*=*=*=*=*=*=*=*=*=*=*=*=*=*=*=*=*=*=*=*=*=*=*\n",
      "Error while trying to plot losses...\n",
      "'val_loss'\n",
      "*=*=*=*=*=*=*=*=*=*=*=*=*=*=*=*=*=*=*=*=*=*=*=*=*=*=*=*=*=*=*=*=*=*=*=*=*=*=*=*=\n"
     ]
    },
    {
     "ename": "KeyError",
     "evalue": "'val_loss'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyError\u001b[0m                                  Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-36-f22db234f740>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0;32mif\u001b[0m \u001b[0m__name__\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;34m'__main__'\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 2\u001b[0;31m     \u001b[0mrun_train\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      3\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m<ipython-input-35-1926ac59cd2c>\u001b[0m in \u001b[0;36mrun_train\u001b[0;34m()\u001b[0m\n\u001b[1;32m    107\u001b[0m                       \u001b[0mverbose\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    108\u001b[0m                       \u001b[0mshuffle\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mTrue\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 109\u001b[0;31m                       callbacks=[my_big_callback])\n\u001b[0m\u001b[1;32m    110\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    111\u001b[0m         \u001b[0;32mexcept\u001b[0m \u001b[0mKeyboardInterrupt\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/conda/lib/python2.7/site-packages/keras/engine/training.pyc\u001b[0m in \u001b[0;36mfit\u001b[0;34m(self, x, y, batch_size, nb_epoch, verbose, callbacks, validation_split, validation_data, shuffle, class_weight, sample_weight, initial_epoch)\u001b[0m\n\u001b[1;32m   1141\u001b[0m                               \u001b[0mval_f\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mval_f\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mval_ins\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mval_ins\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mshuffle\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mshuffle\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1142\u001b[0m                               \u001b[0mcallback_metrics\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mcallback_metrics\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1143\u001b[0;31m                               initial_epoch=initial_epoch)\n\u001b[0m\u001b[1;32m   1144\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1145\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mevaluate\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mx\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbatch_size\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m32\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mverbose\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0msample_weight\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mNone\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/conda/lib/python2.7/site-packages/keras/engine/training.pyc\u001b[0m in \u001b[0;36m_fit_loop\u001b[0;34m(self, f, ins, out_labels, batch_size, nb_epoch, verbose, callbacks, val_f, val_ins, shuffle, callback_metrics, initial_epoch)\u001b[0m\n\u001b[1;32m    861\u001b[0m                         \u001b[0;32mfor\u001b[0m \u001b[0ml\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mo\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mzip\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mout_labels\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mval_outs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    862\u001b[0m                             \u001b[0mepoch_logs\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'val_'\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0ml\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mo\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 863\u001b[0;31m             \u001b[0mcallbacks\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mon_epoch_end\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mepoch\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mepoch_logs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    864\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mcallback_model\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstop_training\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    865\u001b[0m                 \u001b[0;32mbreak\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/conda/lib/python2.7/site-packages/keras/callbacks.pyc\u001b[0m in \u001b[0;36mon_epoch_end\u001b[0;34m(self, epoch, logs)\u001b[0m\n\u001b[1;32m     41\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mon_epoch_end\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mepoch\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlogs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m{\u001b[0m\u001b[0;34m}\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     42\u001b[0m         \u001b[0;32mfor\u001b[0m \u001b[0mcallback\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcallbacks\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 43\u001b[0;31m             \u001b[0mcallback\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mon_epoch_end\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mepoch\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlogs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     44\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     45\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mon_batch_begin\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbatch\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlogs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m{\u001b[0m\u001b[0;34m}\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m<ipython-input-34-edab2900dbb2>\u001b[0m in \u001b[0;36mon_epoch_end\u001b[0;34m(self, epoch, logs)\u001b[0m\n\u001b[1;32m     77\u001b[0m         \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     78\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mhistory\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m%\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mn\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;36m0\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 79\u001b[0;31m                 \u001b[0mhtrain\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0marray\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mv\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'val_loss'\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mv\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mhistory\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfloat32\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     80\u001b[0m                 \u001b[0;32mif\u001b[0m \u001b[0mval\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     81\u001b[0m                     \u001b[0mhvalid\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0marray\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mv\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'val_loss'\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mv\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mhistory\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfloat32\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mKeyError\u001b[0m: 'val_loss'"
     ]
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAA3kAAAFpCAYAAAAhueFnAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\ng4g8AACAQf4/zM6ljddFc5wAAAAASUVORK5CYII=\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x7fd797022b90>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "if __name__ == '__main__':\n",
    "    run_train()\n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Teste nas Images"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def run_predict(path, name, dstDir):\n",
    "\n",
    "    print('  Loading saved weights...')\n",
    "\n",
    "    model = get_unet()\n",
    "    model.load_weights(model_name)\n",
    "\n",
    "    print('  Load. and prepro. test data...')\n",
    "       \n",
    "    print('  Predicting masks on test data...')\n",
    "    \n",
    "    with np.load(path) as data:\n",
    "        imgs_test = data['imgs_test']\n",
    "    \n",
    "    np.save(os.path.join(dstDir, name +'-pred.npy'), model.predict(imgs_test, verbose=1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "------------------------------\n",
      "Test predictions...\n",
      "------------------------------\n",
      "('Image:', 'CVCD10010001')\n",
      "  Loading saved weights...\n"
     ]
    },
    {
     "ename": "IOError",
     "evalue": "Unable to open file (Unable to open file: name = '/opt/projects/models/epoch_30_unet', errno = 2, error message = 'no such file or directory', flags = 0, o_flags = 0)",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mIOError\u001b[0m                                   Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-22-ef264843cab0>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     13\u001b[0m         \u001b[0mname\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mimg\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msplit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'/'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m-\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msplit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'-'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     14\u001b[0m         \u001b[0;32mprint\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0;34m\"Image:\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mname\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 15\u001b[0;31m         \u001b[0mrun_predict\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mimg\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mname\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mdstDir\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     16\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     17\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m<ipython-input-21-11f5c9165369>\u001b[0m in \u001b[0;36mrun_predict\u001b[0;34m(path, name, dstDir)\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m     \u001b[0mmodel\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mget_unet\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 6\u001b[0;31m     \u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mload_weights\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmodel_name\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      7\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      8\u001b[0m     \u001b[0;32mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'  Load. and prepro. test data...'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/conda/lib/python2.7/site-packages/keras/engine/topology.pyc\u001b[0m in \u001b[0;36mload_weights\u001b[0;34m(self, filepath, by_name)\u001b[0m\n\u001b[1;32m   2693\u001b[0m         '''\n\u001b[1;32m   2694\u001b[0m         \u001b[0;32mimport\u001b[0m \u001b[0mh5py\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 2695\u001b[0;31m         \u001b[0mf\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mh5py\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mFile\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfilepath\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmode\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m'r'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   2696\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0;34m'layer_names'\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mattrs\u001b[0m \u001b[0;32mand\u001b[0m \u001b[0;34m'model_weights'\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mf\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2697\u001b[0m             \u001b[0mf\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mf\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'model_weights'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/conda/lib/python2.7/site-packages/h5py/_hl/files.pyc\u001b[0m in \u001b[0;36m__init__\u001b[0;34m(self, name, mode, driver, libver, userblock_size, swmr, **kwds)\u001b[0m\n\u001b[1;32m    270\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    271\u001b[0m                 \u001b[0mfapl\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmake_fapl\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdriver\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlibver\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwds\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 272\u001b[0;31m                 \u001b[0mfid\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmake_fid\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mname\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmode\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0muserblock_size\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfapl\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mswmr\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mswmr\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    273\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    274\u001b[0m                 \u001b[0;32mif\u001b[0m \u001b[0mswmr_support\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/conda/lib/python2.7/site-packages/h5py/_hl/files.pyc\u001b[0m in \u001b[0;36mmake_fid\u001b[0;34m(name, mode, userblock_size, fapl, fcpl, swmr)\u001b[0m\n\u001b[1;32m     90\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mswmr\u001b[0m \u001b[0;32mand\u001b[0m \u001b[0mswmr_support\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     91\u001b[0m             \u001b[0mflags\u001b[0m \u001b[0;34m|=\u001b[0m \u001b[0mh5f\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mACC_SWMR_READ\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 92\u001b[0;31m         \u001b[0mfid\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mh5f\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mopen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mname\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mflags\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfapl\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mfapl\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     93\u001b[0m     \u001b[0;32melif\u001b[0m \u001b[0mmode\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;34m'r+'\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     94\u001b[0m         \u001b[0mfid\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mh5f\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mopen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mname\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mh5f\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mACC_RDWR\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfapl\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mfapl\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32mh5py/_objects.pyx\u001b[0m in \u001b[0;36mh5py._objects.with_phil.wrapper (/home/ilan/minonda/conda-bld/work/h5py/_objects.c:2696)\u001b[0;34m()\u001b[0m\n",
      "\u001b[0;32mh5py/_objects.pyx\u001b[0m in \u001b[0;36mh5py._objects.with_phil.wrapper (/home/ilan/minonda/conda-bld/work/h5py/_objects.c:2654)\u001b[0;34m()\u001b[0m\n",
      "\u001b[0;32mh5py/h5f.pyx\u001b[0m in \u001b[0;36mh5py.h5f.open (/home/ilan/minonda/conda-bld/work/h5py/h5f.c:1942)\u001b[0;34m()\u001b[0m\n",
      "\u001b[0;31mIOError\u001b[0m: Unable to open file (Unable to open file: name = '/opt/projects/models/epoch_30_unet', errno = 2, error message = 'no such file or directory', flags = 0, o_flags = 0)"
     ]
    }
   ],
   "source": [
    "if __name__ == '__main__':\n",
    "    \n",
    "    start_time = time.time()\n",
    "    \n",
    "    print('-'*30)\n",
    "    print('Test predictions...')\n",
    "    print('-'*30)\n",
    "    test_imgs_names = np.sort(glob.glob(os.path.join(out,test_prep_data+'/*')))\n",
    "    dstDir = os.path.join(out,pred_data)\n",
    "    create_new_dir(dstDir)\n",
    "\n",
    "    for img in test_imgs_names:\n",
    "        name = img.split('/')[-1].split('-')[0]\n",
    "        print (\"Image:\", name)\n",
    "        run_predict(img,name,dstDir)\n",
    "\n",
    "\n",
    "    print('-'*30)\n",
    "    print('Reconstructing test predictions...')\n",
    "    print('-'*30)\n",
    "    pred_data =  np.asarray(glob.glob(os.path.join(out,pred_data+'/*')))\n",
    "    dstDir = os.path.join(out,pred_image)\n",
    "    create_new_dir(dstDir)\n",
    "    \n",
    "    for data in pred_data:\n",
    "        reconstruct_2d_sample(dstDir, data, os.path.join(out,test_mid_samples))\n",
    "    \n",
    "    print(\"--- %s seconds ---\" % (time.time() - start_time))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "!pwd"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Resultados"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "def plot_examples(test_image, mask_image, pred_image, name):\n",
    "    \n",
    "    plt.figure(figsize=(10, 15))\n",
    "    plt.subplot(131)\n",
    "    plt.imshow(test_image,cmap='gray')\n",
    "    plt.title('Sujeito: ' + name)\n",
    "    plt.axis('off')\n",
    "\n",
    "    plt.subplot(132)\n",
    "    plt.imshow(mask_image,cmap='gray')\n",
    "    plt.title('STAPLE')\n",
    "    plt.axis('off')\n",
    "\n",
    "    plt.subplot(133)\n",
    "    plt.imshow(pred_image,cmap='gray')\n",
    "    plt.title('U-NET')\n",
    "    plt.axis('off')\n",
    "    plt.show\n",
    "\n",
    "if __name__ == '__main__':\n",
    "    \n",
    "    pred_imgs_names = np.sort(glob.glob(os.path.join(out,pred_image+'/*')))\n",
    "\n",
    "    for img_name in pred_imgs_names:\n",
    "        \n",
    "        name = img_name.split('/')[-1].split('-')[0]\n",
    "        test_image = cv2.imread(os.path.join(out,test_mid_samples+'/' + name +'.tif')\n",
    "                                , cv2.IMREAD_GRAYSCALE)\n",
    "        mask_image = cv2.imread(os.path.join(out,test_mid_samples+'/' + name +'_staple.tif')\n",
    "                                , cv2.IMREAD_GRAYSCALE)\n",
    "        pred_image = cv2.imread(img_name, cv2.IMREAD_GRAYSCALE)\n",
    "        plot_examples(test_image.T[::-1], mask_image.T[::-1], pred_image.T[::-1], name)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python [Root]",
   "language": "python",
   "name": "Python [Root]"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
