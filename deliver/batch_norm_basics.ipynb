{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "toc": "true"
   },
   "source": [
    "# Table of Contents\n",
    " <p><div class=\"lev1 toc-item\"><a href=\"#Batch-Normalization\" data-toc-modified-id=\"Batch-Normalization-1\"><span class=\"toc-item-num\">1&nbsp;&nbsp;</span>Batch Normalization</a></div><div class=\"lev2 toc-item\"><a href=\"#Importações-e-ajustes\" data-toc-modified-id=\"Importações-e-ajustes-11\"><span class=\"toc-item-num\">1.1&nbsp;&nbsp;</span>Importações e ajustes</a></div><div class=\"lev2 toc-item\"><a href=\"#O-Algoritmo\" data-toc-modified-id=\"O-Algoritmo-12\"><span class=\"toc-item-num\">1.2&nbsp;&nbsp;</span>O Algoritmo</a></div><div class=\"lev3 toc-item\"><a href=\"#Equações\" data-toc-modified-id=\"Equações-121\"><span class=\"toc-item-num\">1.2.1&nbsp;&nbsp;</span>Equações</a></div><div class=\"lev3 toc-item\"><a href=\"#Grafo-de-operações\" data-toc-modified-id=\"Grafo-de-operações-122\"><span class=\"toc-item-num\">1.2.2&nbsp;&nbsp;</span>Grafo de operações</a></div><div class=\"lev2 toc-item\"><a href=\"#Keras:-parâmetros\" data-toc-modified-id=\"Keras:-parâmetros-13\"><span class=\"toc-item-num\">1.3&nbsp;&nbsp;</span>Keras: parâmetros</a></div><div class=\"lev3 toc-item\"><a href=\"#Entrada-com-dimensão-2\" data-toc-modified-id=\"Entrada-com-dimensão-2-131\"><span class=\"toc-item-num\">1.3.1&nbsp;&nbsp;</span>Entrada com dimensão 2</a></div><div class=\"lev3 toc-item\"><a href=\"#Entrada-com-dimensão-4\" data-toc-modified-id=\"Entrada-com-dimensão-4-132\"><span class=\"toc-item-num\">1.3.2&nbsp;&nbsp;</span>Entrada com dimensão 4</a></div><div class=\"lev2 toc-item\"><a href=\"#Keras:-Execução-na-fase-de-treinamento\" data-toc-modified-id=\"Keras:-Execução-na-fase-de-treinamento-14\"><span class=\"toc-item-num\">1.4&nbsp;&nbsp;</span>Keras: Execução na fase de treinamento</a></div><div class=\"lev2 toc-item\"><a href=\"#Keras:-Execução-na-fase-de-testes\" data-toc-modified-id=\"Keras:-Execução-na-fase-de-testes-15\"><span class=\"toc-item-num\">1.5&nbsp;&nbsp;</span>Keras: Execução na fase de testes</a></div><div class=\"lev2 toc-item\"><a href=\"#Keras:-Verificando-o-cálculo-das-médias-móveis\" data-toc-modified-id=\"Keras:-Verificando-o-cálculo-das-médias-móveis-16\"><span class=\"toc-item-num\">1.6&nbsp;&nbsp;</span>Keras: Verificando o cálculo das médias móveis</a></div>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Batch Normalization"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Importações e ajustes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Keras  2.0.4\n"
     ]
    }
   ],
   "source": [
    "%matplotlib inline\n",
    "import matplotlib.pyplot as plot\n",
    "from IPython import display\n",
    "\n",
    "import sys\n",
    "import numpy as np\n",
    "import numpy.random as nr\n",
    "\n",
    "import keras\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Dense, BatchNormalization\n",
    "from keras.initializers import Constant\n",
    "from keras.optimizers import SGD\n",
    "\n",
    "from keras import backend as K\n",
    "\n",
    "print('Keras ', keras.__version__)\n",
    "\n",
    "np.set_printoptions(precision=2, suppress=True)\n",
    "nr.seed(23456)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## O Algoritmo\n",
    "\n",
    "Para descrição do algoritmo, veja o artigo original:\n",
    "[Batch Normalization: Accelerating Deep Network Training by Reducing Internal Covariate Shift](https://arxiv.org/pdf/1502.03167.pdf) \n",
    "\n",
    "### Equações\n",
    "\\begin{align*} \n",
    "\\boldsymbol{\\mu} &= \\frac{1}{m} \\sum_{i = 1}^{m} \\boldsymbol{x_i} &&\n",
    "\\boldsymbol{\\sigma^{2}} = \\frac{1}{m} \\sum_{i = 1}^{m} (\\boldsymbol{x_i} - \\boldsymbol{\\mu})^{2}\n",
    "\\\\[3mm]\n",
    "\\hat{\\boldsymbol{x}}_i &= \\frac{\\boldsymbol{x}_i - \\boldsymbol{\\mu}}{\\sqrt{\\boldsymbol{\\sigma^{2}} + \\epsilon}} &&\n",
    "\\boldsymbol{y_i} = \\gamma \\hat{\\boldsymbol{x}}_i + \\beta\n",
    "\\\\[3mm]\n",
    "\\boldsymbol{m}_{(t)} &= (1 - \\lambda) \\boldsymbol{\\mu} + \\lambda \\boldsymbol{m}_{(t-1)} &&\n",
    "\\boldsymbol{v}_{(t)} =  (1 - \\lambda) \\boldsymbol{\\sigma^{2}} + \\lambda \\boldsymbol{v}_{(t-1)}\n",
    "\\end{align*}\n",
    "\n",
    "### Grafo de operações\n",
    "Figura obtida nesta página: [Understanding the backward pass through Batch Normalization Layer](https://kratzert.github.io/2016/02/12/understanding-the-gradient-flow-through-the-batch-normalization-layer.html)\n",
    "\n",
    "<table align='left'>\n",
    "<tr><td> <img src=\"https://drive.google.com/uc?id=0By1KMDFVxsI2ZGN6eWhCeTJSMDg\"> </td></tr>\n",
    "</table>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Keras: parâmetros"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Entrada com dimensão 2\n",
    "\n",
    "Usualmente, quando a entrada da camada tem duas dimensões (amostras e atributos) a normalização é feita na dimensão dos atributos, *axis=1*. Ou seja, calcula-se a estatística (média e variância) para cada coluna da matriz de dados, em cada *mini-batch*."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "batch_normalization_1 (Batch (None, 5)                 20        \n",
      "=================================================================\n",
      "Total params: 20\n",
      "Trainable params: 10\n",
      "Non-trainable params: 10\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "model = Sequential()\n",
    "model.add(BatchNormalization(axis=1, input_shape=(5,), momentum=0.9, epsilon=0.0001, \n",
    "                             gamma_initializer=Constant(10), \n",
    "                             beta_initializer=Constant(11), \n",
    "                             moving_mean_initializer=Constant(12), \n",
    "                             moving_variance_initializer=Constant(13)))\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Configuration:\n",
      "--------------\n",
      "  name                          : batch_normalization_1\n",
      "  trainable                     : True\n",
      "  batch_input_shape             : (None, 5)\n",
      "  dtype                         : float32\n",
      "  axis                          : 1\n",
      "  momentum                      : 0.9\n",
      "  epsilon                       : 0.0001\n",
      "  center                        : True\n",
      "  scale                         : True\n",
      "  beta_initializer              : {'class_name': 'Constant', 'config': {'value': 11}}\n",
      "  gamma_initializer             : {'class_name': 'Constant', 'config': {'value': 10}}\n",
      "  moving_mean_initializer       : {'class_name': 'Constant', 'config': {'value': 12}}\n",
      "  moving_variance_initializer   : {'class_name': 'Constant', 'config': {'value': 13}}\n",
      "  beta_regularizer              : None\n",
      "  gamma_regularizer             : None\n",
      "  beta_constraint               : None\n",
      "  gamma_constraint              : None\n",
      "\n",
      "Parameters:\n",
      "-----------\n",
      "  Trainable: batch_normalization_1/gamma:0\n",
      "  Trainable: batch_normalization_1/beta:0\n",
      "             batch_normalization_1/moving_mean:0\n",
      "             batch_normalization_1/moving_variance:0\n",
      "\n",
      "model.get_weights():\n",
      "--------------------\n",
      "   [ 10.  10.  10.  10.  10.] (5,)\n",
      "   [ 11.  11.  11.  11.  11.] (5,)\n",
      "   [ 12.  12.  12.  12.  12.] (5,)\n",
      "   [ 13.  13.  13.  13.  13.] (5,)\n"
     ]
    }
   ],
   "source": [
    "for layer in model.layers:\n",
    "    print('\\nConfiguration:')\n",
    "    print('--------------')\n",
    "    for k, v in layer.get_config().items():\n",
    "        print('  {:30s}: {}'.format(k, v))\n",
    "    print('\\nParameters:')\n",
    "    print('-----------')\n",
    "    for p in layer.weights:\n",
    "        if p in layer.trainable_weights:\n",
    "            print('  Trainable:', p.name)\n",
    "        else:\n",
    "            print('            ', p.name)\n",
    "print('\\nmodel.get_weights():')\n",
    "print('--------------------')\n",
    "for w in model.get_weights():\n",
    "    print('  ', w, w.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Entrada com dimensão 4\n",
    "\n",
    "Usualmente, quando a entrada da camada tem quatro dimensões (amostras, filtros, altura e largura), a normalização é feita na segunda dimensão, *axis=1*, que corresponde aos filtros (canais). Ou seja, calcula-se a estatística (média e variância) para cada *mapa de atributos* do tensor. Assim, preserva-se a propriedade da invariância à translação, característica importante das convoluções."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "batch_normalization_2 (Batch (None, 3, 10, 10)         12        \n",
      "=================================================================\n",
      "Total params: 12\n",
      "Trainable params: 6\n",
      "Non-trainable params: 6\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "model = Sequential()\n",
    "model.add(BatchNormalization(axis=1, input_shape=(3, 10, 10), \n",
    "                             gamma_initializer=Constant(0), \n",
    "                             beta_initializer=Constant(1), \n",
    "                             moving_mean_initializer=Constant(2), \n",
    "                             moving_variance_initializer=Constant(3)))\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Configuration:\n",
      "--------------\n",
      "  name                          : batch_normalization_2\n",
      "  trainable                     : True\n",
      "  batch_input_shape             : (None, 3, 10, 10)\n",
      "  dtype                         : float32\n",
      "  axis                          : 1\n",
      "  momentum                      : 0.99\n",
      "  epsilon                       : 0.001\n",
      "  center                        : True\n",
      "  scale                         : True\n",
      "  beta_initializer              : {'class_name': 'Constant', 'config': {'value': 1}}\n",
      "  gamma_initializer             : {'class_name': 'Constant', 'config': {'value': 0}}\n",
      "  moving_mean_initializer       : {'class_name': 'Constant', 'config': {'value': 2}}\n",
      "  moving_variance_initializer   : {'class_name': 'Constant', 'config': {'value': 3}}\n",
      "  beta_regularizer              : None\n",
      "  gamma_regularizer             : None\n",
      "  beta_constraint               : None\n",
      "  gamma_constraint              : None\n",
      "\n",
      "Parameters:\n",
      "-----------\n",
      "  Trainable: batch_normalization_2/gamma:0\n",
      "  Trainable: batch_normalization_2/beta:0\n",
      "             batch_normalization_2/moving_mean:0\n",
      "             batch_normalization_2/moving_variance:0\n",
      "\n",
      "model.get_weights():\n",
      "--------------------\n",
      "   [ 0.  0.  0.] (3,)\n",
      "   [ 1.  1.  1.] (3,)\n",
      "   [ 2.  2.  2.] (3,)\n",
      "   [ 3.  3.  3.] (3,)\n"
     ]
    }
   ],
   "source": [
    "for layer in model.layers:\n",
    "    print('\\nConfiguration:')\n",
    "    print('--------------')\n",
    "    for k, v in layer.get_config().items():\n",
    "        print('  {:30s}: {}'.format(k, v))\n",
    "    print('\\nParameters:')\n",
    "    print('-----------')\n",
    "    for p in layer.weights:\n",
    "        if p in layer.trainable_weights:\n",
    "            print('  Trainable:', p.name)\n",
    "        else:\n",
    "            print('            ', p.name)\n",
    "print('\\nmodel.get_weights():')\n",
    "print('--------------------')\n",
    "for w in model.get_weights():\n",
    "    print('  ', w, w.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Keras: Execução na fase de treinamento"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": false,
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[  6.44   6.55  18.55   6.23   3.24]\n",
      " [  7.28  10.58  15.78  17.51  12.73]\n",
      " [ 19.79  16.32   0.83   4.06   3.05]\n",
      " [ 15.06   9.1   19.09  18.75   2.71]\n",
      " [  4.72   6.3   13.45  12.41  12.44]\n",
      " [ 16.76  12.62  11.22  19.74  13.66]\n",
      " [  2.03  18.8   13.03   4.55   8.64]\n",
      " [  7.8   15.12   2.85   0.2   16.76]\n",
      " [  2.18   4.98   9.52  17.68   3.55]\n",
      " [ 15.72   0.7   12.17   6.17  15.4 ]] [  9.78  10.11  11.65  10.73   9.22] [ 6.14  5.37  5.7   6.91  5.35]\n",
      "\n",
      "[[  7.28  -0.66   1.21  -0.65  -1.12]\n",
      " [  7.97   0.09   0.73   0.98   0.66]\n",
      " [ 18.16   1.16  -1.9   -0.97  -1.15]\n",
      " [ 14.3   -0.19   1.31   1.16  -1.22]\n",
      " [  5.88  -0.71   0.32   0.24   0.6 ]\n",
      " [ 15.68   0.47  -0.08   1.3    0.83]\n",
      " [  3.69   1.62   0.24  -0.89  -0.11]\n",
      " [  8.39   0.93  -1.54  -1.52   1.41]\n",
      " [  3.81  -0.95  -0.37   1.01  -1.06]\n",
      " [ 14.84  -1.75   0.09  -0.66   1.16]] [ 10.   0.   0.  -0.  -0.] [ 5.  1.  1.  1.  1.]\n"
     ]
    }
   ],
   "source": [
    "K.set_learning_phase(1)\n",
    "\n",
    "model = Sequential()\n",
    "model.add(BatchNormalization(axis=1, input_shape=(5,), momentum=0.5, epsilon=0.0001))\n",
    "\n",
    "model.set_weights([[ 5., 1., 1., 1., 1.],     # gamma\n",
    "                   [ 10., 0., 0., 0., 0.],     # beta\n",
    "                   [ 0., 0., 0., 0., 0.],\n",
    "                   [ 1., 1., 1., 1., 1.]])\n",
    "\n",
    "x = nr.random(size=(10, 5)) * 20\n",
    "print(x, x.mean(0), x.std(0))\n",
    "print()\n",
    "\n",
    "y = model.predict(x, batch_size=10)\n",
    "print(y, y.mean(0), y.std(0))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[  7.28  -0.66   1.21  -0.65  -1.12]\n",
      " [  7.97   0.09   0.73   0.98   0.66]\n",
      " [ 18.16   1.16  -1.9   -0.97  -1.15]\n",
      " [ 14.3   -0.19   1.31   1.16  -1.22]\n",
      " [  5.88  -0.71   0.32   0.24   0.6 ]\n",
      " [ 15.68   0.47  -0.08   1.3    0.83]\n",
      " [  3.69   1.62   0.24  -0.89  -0.11]\n",
      " [  8.39   0.93  -1.54  -1.52   1.41]\n",
      " [  3.81  -0.95  -0.37   1.01  -1.06]\n",
      " [ 14.84  -1.75   0.09  -0.66   1.16]] [ 10.  -0.   0.  -0.   0.] [ 5.  1.  1.  1.  1.]\n"
     ]
    }
   ],
   "source": [
    "gamma, beta, mv_mean, mv_var = model.get_weights()\n",
    "\n",
    "x2 = x - x.mean(0)\n",
    "x2 /= x2.std(0)\n",
    "\n",
    "x3 = x2 * gamma + beta\n",
    "\n",
    "print(x3, x3.mean(0), x3.std(0))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Keras: Execução na fase de testes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[  6.44   6.55  18.55   6.23   3.24]\n",
      " [  7.28  10.58  15.78  17.51  12.73]\n",
      " [ 19.79  16.32   0.83   4.06   3.05]\n",
      " [ 15.06   9.1   19.09  18.75   2.71]\n",
      " [  4.72   6.3   13.45  12.41  12.44]\n",
      " [ 16.76  12.62  11.22  19.74  13.66]\n",
      " [  2.03  18.8   13.03   4.55   8.64]\n",
      " [  7.8   15.12   2.85   0.2   16.76]\n",
      " [  2.18   4.98   9.52  17.68   3.55]\n",
      " [ 15.72   0.7   12.17   6.17  15.4 ]] [  9.78  10.11  11.65  10.73   9.22] [ 6.14  5.37  5.7   6.91  5.35]\n",
      "\n",
      "[[  6.44   6.55  18.55   6.23   3.24]\n",
      " [  7.28  10.58  15.78  17.51  12.73]\n",
      " [ 19.79  16.32   0.83   4.06   3.05]\n",
      " [ 15.06   9.1   19.09  18.75   2.71]\n",
      " [  4.72   6.3   13.45  12.41  12.44]\n",
      " [ 16.76  12.62  11.22  19.74  13.66]\n",
      " [  2.03  18.8   13.03   4.55   8.63]\n",
      " [  7.8   15.11   2.85   0.2   16.76]\n",
      " [  2.18   4.98   9.52  17.68   3.55]\n",
      " [ 15.72   0.7   12.17   6.17  15.4 ]] [  9.78  10.11  11.65  10.73   9.22] [ 6.14  5.37  5.7   6.91  5.35]\n"
     ]
    }
   ],
   "source": [
    "K.set_learning_phase(0)\n",
    "\n",
    "model = Sequential()\n",
    "model.add(BatchNormalization(axis=1, input_shape=(5,), momentum=0.999, epsilon=0.0001))\n",
    "\n",
    "model.set_weights([[ 1., 1., 1., 1., 1.],     # gamma\n",
    "                   [ 0., 0., 0., 0., 0.],     # beta\n",
    "                   [ 0., 0., 0., 0., 0.],     # moving_mean\n",
    "                   [ 1., 1., 1., 1., 1.]])    # moving_variance\n",
    "\n",
    "x = nr.random(size=(10, 5)) * 20\n",
    "print(x, x.mean(0), x.std(0))\n",
    "print()\n",
    "\n",
    "y = model.predict(x, batch_size=10)\n",
    "print(y, y.mean(0), y.std(0))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[  6.44   6.55  18.55   6.23   3.24]\n",
      " [  7.28  10.58  15.78  17.51  12.73]\n",
      " [ 19.79  16.32   0.83   4.06   3.05]\n",
      " [ 15.06   9.1   19.09  18.75   2.71]\n",
      " [  4.72   6.3   13.45  12.41  12.44]\n",
      " [ 16.76  12.62  11.22  19.74  13.66]\n",
      " [  2.03  18.8   13.03   4.55   8.64]\n",
      " [  7.8   15.12   2.85   0.2   16.76]\n",
      " [  2.18   4.98   9.52  17.68   3.55]\n",
      " [ 15.72   0.7   12.17   6.17  15.4 ]] [  9.78  10.11  11.65  10.73   9.22] [ 6.14  5.37  5.7   6.91  5.35]\n"
     ]
    }
   ],
   "source": [
    "gamma, beta, mv_mean, mv_var = model.get_weights()\n",
    "\n",
    "x2 = x - mv_mean\n",
    "x2 /= np.sqrt(mv_var)\n",
    "\n",
    "x3 = x2 * gamma + beta\n",
    "\n",
    "print(x3, x3.mean(0), x3.std(0))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Keras: Verificando o cálculo das médias móveis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[(5,), (5,), (5,), (5,), (5, 1), (1,)]\n",
      "\n",
      "[[  1.74   4.4    7.11  15.93   7.74]\n",
      " [ 15.79  16.52   3.59   8.45   0.57]\n",
      " [  6.19   1.2   19.06   9.33   6.74]\n",
      " [ 14.86   8.33  19.11  12.7   10.43]\n",
      " [  6.52  11.71   0.5   11.32  17.42]\n",
      " [  2.81   6.7   15.46  13.86  18.72]\n",
      " [ 19.9    5.29  15.4    6.41   5.52]\n",
      " [ 15.81   4.68   0.07   0.84  11.68]\n",
      " [ 13.75  17.97  17.19   6.23  12.38]\n",
      " [  1.05  18.93   1.34   6.03   2.17]] [ 9.84  9.57  9.88  9.11  9.34] [ 6.55  6.    7.67  4.25  5.67]\n",
      "\n",
      "lambda: [ 1.    0.98  0.98  1.    1.  ]\n",
      "beta:   [-0.03 -0.02  0.03  0.   -0.02]\n",
      "\n",
      "mv_mean: [ 7.87  7.66  7.91  7.29  7.47]\n",
      "         [ 7.87  7.66  7.91  7.29  7.47]\n",
      "mv_var:  [ 34.54  28.98  47.32  14.66  25.91]\n",
      "         [ 34.54  28.98  47.32  14.66  25.91]\n"
     ]
    }
   ],
   "source": [
    "nr.seed(234588)\n",
    "K.set_learning_phase(1)\n",
    "mom = 0.2\n",
    "\n",
    "model = Sequential()\n",
    "model.add(BatchNormalization(axis=1, input_shape=(5,), momentum=mom, epsilon=0.0001))\n",
    "model.add(Dense(1, activation='sigmoid'))\n",
    "\n",
    "print([x.shape for x in model.get_weights()], end='\\n\\n')\n",
    "model.set_weights([[ 1., 1., 1., 1., 1.],     # gamma\n",
    "                   [ 0., 0., 0., 0., 0.],     # beta\n",
    "                   [ 0., 0., 0., 0., 0.],     # moving_mean\n",
    "                   [ 1., 1., 1., 1., 1.]])    # moving_variance\n",
    "\n",
    "gamma, beta, mv_mean, mv_var, w, b = model.get_weights()\n",
    "\n",
    "x = nr.random(size=(10, 5)) * 20\n",
    "y = nr.random(size=(10, 1))\n",
    "print(x, x.mean(0), x.std(0))\n",
    "print()\n",
    "\n",
    "mv_mean_new = (1 - mom) * x.mean(0) + mom * mv_mean\n",
    "mv_var_new  = (1 - mom) * x.std(0) * x.std(0) + mom * mv_var\n",
    "\n",
    "sgd = SGD(0.5)\n",
    "model.compile(sgd, loss='mse')\n",
    "h = model.fit(x, y, batch_size=10, epochs=1, verbose=0)\n",
    "\n",
    "new_weights = model.get_weights()\n",
    "\n",
    "print('lambda:', new_weights[0])\n",
    "print('beta:  ', new_weights[1])\n",
    "print()\n",
    "print('mv_mean:', new_weights[2])\n",
    "print('        ', mv_mean_new)\n",
    "print('mv_var: ', new_weights[3])\n",
    "print('        ', mv_var_new)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.0"
  },
  "latex_envs": {
   "LaTeX_envs_menu_present": true,
   "autocomplete": true,
   "bibliofile": "biblio.bib",
   "cite_by": "apalike",
   "current_citInitial": 1,
   "eqLabelWithNumbers": true,
   "eqNumInitial": 1,
   "hotkeys": {
    "equation": "Ctrl-E",
    "itemize": "Ctrl-I"
   },
   "labels_anchors": false,
   "latex_user_defs": false,
   "report_style_numbering": false,
   "user_envs_cfg": false
  },
  "toc": {
   "colors": {
    "hover_highlight": "#DAA520",
    "navigate_num": "#000000",
    "navigate_text": "#333333",
    "running_highlight": "#FF0000",
    "selected_highlight": "#FFD700",
    "sidebar_border": "#EEEEEE",
    "wrapper_background": "#FFFFFF"
   },
   "moveMenuLeft": true,
   "nav_menu": {
    "height": "12px",
    "width": "252px"
   },
   "navigate_menu": true,
   "number_sections": true,
   "sideBar": true,
   "threshold": 4,
   "toc_cell": true,
   "toc_section_display": "block",
   "toc_window_display": false,
   "widenNotebook": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
