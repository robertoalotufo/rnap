{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Exercício sobre Transfer Learning\n",
    "\n",
    "Nesse exercício você irá utilizar uma rede pré-treinada bastante conhecida, a VGG-16 (http://www.robots.ox.ac.uk/~vgg/research/very_deep/). Como tarefa, você irá criar cum classificador utilizado-se de camadas densas no dataset do Cifar-10. As camadas anteriores ao seu classificador deverão ser congeladas, de modo que durante o treino apenas os pesos do seu classificador sejam sintonizados. A opção de congelar menos camadas fica por sua conta. Reporte suas dúvidas e resultados para serem discutidos no próximo dia do curso. Boa sorte!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import os\n",
    "os.environ['THEANO_FLAGS'] = \"device=gpu0,floatX=float32\"  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "%matplotlib inline\n",
    "import matplotlib.pylab as plt\n",
    "import h5py\n",
    "\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Convolution2D, MaxPooling2D, ZeroPadding2D\n",
    "from keras.layers import Activation, Dropout, Flatten, Dense\n",
    "from keras import backend as K\n",
    "from keras.datasets import cifar10\n",
    "from keras.utils import np_utils\n",
    "\n",
    "import sys\n",
    "sys.path.append('../src')\n",
    "from my_keras_utilities import TrainingPlotter, load_model_and_history\n",
    "\n",
    "K.set_image_dim_ordering('th')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Definição da CNN"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Carrega o modelo da VGG-16 com seus devidos pesos sem as camadas densas (totalmente conectadas)\n",
    "def get_tr_vgg_model(weights_path, img_width, img_height):\n",
    "    \n",
    "    model = Sequential()\n",
    "    model.add(ZeroPadding2D((1, 1), input_shape=(3, img_width, img_height)))\n",
    "\n",
    "    model.add(Convolution2D(64, 3, 3, activation='relu', name='conv1_1'))\n",
    "    model.add(ZeroPadding2D((1, 1)))\n",
    "    model.add(Convolution2D(64, 3, 3, activation='relu', name='conv1_2'))\n",
    "    model.add(MaxPooling2D((2, 2), strides=(2, 2)))\n",
    "\n",
    "    model.add(ZeroPadding2D((1, 1)))\n",
    "    model.add(Convolution2D(128, 3, 3, activation='relu', name='conv2_1'))\n",
    "    model.add(ZeroPadding2D((1, 1)))\n",
    "    model.add(Convolution2D(128, 3, 3, activation='relu', name='conv2_2'))\n",
    "    model.add(MaxPooling2D((2, 2), strides=(2, 2)))\n",
    "\n",
    "    model.add(ZeroPadding2D((1, 1)))\n",
    "    model.add(Convolution2D(256, 3, 3, activation='relu', name='conv3_1'))\n",
    "    model.add(ZeroPadding2D((1, 1)))\n",
    "    model.add(Convolution2D(256, 3, 3, activation='relu', name='conv3_2'))\n",
    "    model.add(ZeroPadding2D((1, 1)))\n",
    "    model.add(Convolution2D(256, 3, 3, activation='relu', name='conv3_3'))\n",
    "    model.add(MaxPooling2D((2, 2), strides=(2, 2)))\n",
    "\n",
    "    model.add(ZeroPadding2D((1, 1)))\n",
    "    model.add(Convolution2D(512, 3, 3, activation='relu', name='conv4_1'))\n",
    "    model.add(ZeroPadding2D((1, 1)))\n",
    "    model.add(Convolution2D(512, 3, 3, activation='relu', name='conv4_2'))\n",
    "    model.add(ZeroPadding2D((1, 1)))\n",
    "    model.add(Convolution2D(512, 3, 3, activation='relu', name='conv4_3'))\n",
    "    model.add(MaxPooling2D((2, 2), strides=(2, 2)))\n",
    "\n",
    "    model.add(ZeroPadding2D((1, 1)))\n",
    "    model.add(Convolution2D(512, 3, 3, activation='relu', name='conv5_1'))\n",
    "    model.add(ZeroPadding2D((1, 1)))\n",
    "    model.add(Convolution2D(512, 3, 3, activation='relu', name='conv5_2'))\n",
    "    model.add(ZeroPadding2D((1, 1)))\n",
    "    model.add(Convolution2D(512, 3, 3, activation='relu', name='conv5_3'))\n",
    "    model.add(MaxPooling2D((2, 2), strides=(2, 2)))\n",
    "\n",
    "    # Carrega os pesos necesários até o último bloco da VGG-15 anterior as camadas densas\n",
    "    assert os.path.exists(weights_path), 'Model weights not found (see \"weights_path\" variable in script).'\n",
    "    \n",
    "    f = h5py.File(weights_path)\n",
    "    for k in range(f.attrs['nb_layers']):\n",
    "        if k >= len(model.layers):\n",
    "            break\n",
    "        g = f['layer_{}'.format(k)]\n",
    "        weights = [g['param_{}'.format(p)] for p in range(g.attrs['nb_params'])]\n",
    "        model.layers[k].set_weights(weights)\n",
    "    f.close()\n",
    "    \n",
    "    print ('Model loaded.')\n",
    "    \n",
    "    return model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Carregando e Normalizando os dados"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Carregando os dados\n",
    "(X_train, y_train), (X_test, y_test) = cifar10.load_data()\n",
    "y_train = y_train.ravel()\n",
    "y_test = y_test.ravel()\n",
    "\n",
    "# Transforma o vetor de labels para o formato de one-hot encoding.\n",
    "Y_train = np_utils.to_categorical(y_train)\n",
    "Y_test = np_utils.to_categorical(y_test)\n",
    "\n",
    "#Normalização dos dados\n",
    "X_train = X_train.astype('float32')\n",
    "X_test = X_test.astype('float32')\n",
    "X_train /= 255\n",
    "X_test /= 255\n",
    "\n",
    "img_width, img_height = X_train.shape[2:]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Carregando e inicializando pesos da CNN"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# Caminho pesos da VGG-16\n",
    "weights_path = '/root/vgg16_weights.h5'\n",
    "\n",
    "# Carrega o modelo até a última camada convolucional\n",
    "vgg16_tr_model = get_tr_vgg_model(weights_path, img_width, img_height)\n",
    "\n",
    "# Execute esse comando para conhecer a arquitetura das camadas convolucionais da VGG-16\n",
    "#print vgg16_tr_model.summary()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Agora é sua vez!!"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Crie um classificador usando camadas densas baseando-se no exmeplo do \"cats and dogs 2\". \n",
    "Dicas: \n",
    "    - a dimensão de saída da VGG-16 truncada será a dimensão de entrada do seu novo modelo.\n",
    "    - a dimensão da saída do classificador é o número de classes do Cifar-10.\n",
    "    - metódos de combate ao overfitting podem ser utilizados (i.e. dropout)\n",
    "  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "####### Adicione novas camadas ######\n",
    "#vgg16_tr_model.add()\n",
    "\n",
    "#####################################\n",
    "\n",
    "\n",
    "# Execute esse comando para conhecer a nova arquitetura após a adição do seu classificador\n",
    "#print vgg16_tr_model.summary()\n",
    "\n",
    "n =  # número de camadas que não serão re-treinadas\n",
    "\n",
    "# Congela as camadas até última camada convolucional da VGG-16\n",
    "for layer in vgg16_tr_model.layers[:n]: \n",
    "    layer.trainable = False"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "model_name = './minha_rede' # toda vez que mudar o modelo, altere o nome dele\n",
    "ploss = 2.0\n",
    "nepochs = 10\n",
    "\n",
    "if not os.path.isfile(model_name + '.model'):\n",
    "    print(\"[INFO] creating model...\")\n",
    "    # History, checkpoint, earlystop, plot losses:\n",
    "    my_big_callback = TrainingPlotter(n=1, filepath=model_name, patience=10)\n",
    "    \n",
    "    # initialize the optimizer and model\n",
    "    print(\"[INFO] compiling model...\")\n",
    "    vgg16_tr_model.compile(loss=\"categorical_crossentropy\", optimizer='adam', metrics=[\"accuracy\"])    \n",
    "    \n",
    "else:\n",
    "    print(\"[INFO] loading model...\")\n",
    "    vgg16_tr_model, my_big_callback = load_model_and_history(model_name)\n",
    "\n",
    "past_epochs = my_big_callback.get_nepochs()\n",
    "\n",
    "fig = plt.figure(figsize=(15,6))\n",
    "plt.ylim(0.0, ploss)\n",
    "plt.xlim(0, nepochs)\n",
    "plt.grid(True)\n",
    "\n",
    "print(\"[INFO] training...\")\n",
    "try:\n",
    "    vgg16_tr_model.fit(X_train, Y_train, batch_size=128, nb_epoch=nepochs,\n",
    "                       verbose=0, validation_split=0.33, callbacks = [my_big_callback])\n",
    "except KeyboardInterrupt:\n",
    "    pass\n",
    "\n",
    "print(\"[INFO] evaluating...\")\n",
    "loss, accuracy = vgg16_tr_model.evaluate(X_test, Y_test, batch_size=128, verbose=2)\n",
    "print(\"[INFO] accuracy: {:.2f}%\".format(accuracy * 100))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Sugestões \n",
    "\n",
    "1. Realize uma seleção de modelo para encontrar os melhores parâmetros para o seu classificador.\n",
    "2. Visualize as imagens de teste em que a sua rede falha.\n",
    "3. Visualize os features nas saídas das camadas intermediárias da rede."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python [Root]",
   "language": "python",
   "name": "Python [Root]"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
