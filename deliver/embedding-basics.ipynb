{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Embedding - Atributos Latentes - Entradas categóricas"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Este notebook apresenta o conceito de embedding e como usá-lo no Keras, através dos seguintes exemplos numérico:\n",
    "- Rede com entrada categórica (one-hot) e camada densa\n",
    "- Embedding como forma eficiente de tratar entrada categórica\n",
    "- Aplicação de um camada convolução unidimensional numa sequência categórica (com embedding)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Importação"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n"
     ]
    }
   ],
   "source": [
    "%matplotlib inline\n",
    "import matplotlib.pyplot as plot\n",
    "from IPython import display\n",
    "from __future__ import print_function\n",
    "\n",
    "import os\n",
    "import sys\n",
    "import numpy as np\n",
    "import numpy.random as nr\n",
    "\n",
    "from keras.utils import to_categorical\n",
    "from keras.layers import Dense, Input, Flatten, Dropout\n",
    "from keras.layers import Conv1D, MaxPooling1D, Embedding, GlobalMaxPooling1D\n",
    "from keras.models import Model, Sequential\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Variável categórica"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Uma variável categórica pode ter um valor dentro de um conjunto limitado que represente uma categoria nominal.\n",
    "Alguns exemplos de variáveis categóricas:\n",
    "- Grupo sanguíneo: A, B, AB or O.\n",
    "- Cidade onde uma pessoa reside\n",
    "- Cor de um produto: vermelho, verde, azul\n",
    "- Uma palavra, dentro de um vocabulário limitado"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Rede neural com entrada categórica"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Quando a rede neural possui entradas categóricas, temos a necessidade de colocá-lo na forma \n",
    "categórica utilizando a codificação *one-hot*. \n",
    "Iremos fazer um exemplo de rede neural com apenas uma camada densa e entrada com \n",
    "dados categóricos com os seguintes parâmetros:\n",
    "- entrada categórica pertencente a um conjunto de 20 classes (n_classes)\n",
    "- amostra é constituída de 10 amostras categóricos (n_amostras)\n",
    "- cada amostra é um número (id) entre 0 e 19: [19, 10, 0, 1, 7, 5, 0, 1, 15, 2]\n",
    "- camada densa com 5 neurônios (n_neuronios)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "n_classes = 20\n",
    "n_neuronios = 5\n",
    "n_amostras = 10"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Diagrama da rede neural com entradas categóricas de uma camada e sem bias"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<img src='../figures/Embedding_neural.png', width = 400pt></img>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Criação da codificação categórica (one-hot) da sequência de entrada"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(array([19, 10,  0,  1,  7,  5,  0,  1, 15,  2]), (10,))"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data = np.array([19, 10, 0, 1, 7, 5, 0, 1, 15, 2])\n",
    "data, data.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(array([[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1],\n",
       "        [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0],\n",
       "        [1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0],\n",
       "        [0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0],\n",
       "        [0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0],\n",
       "        [0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0],\n",
       "        [1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0],\n",
       "        [0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0],\n",
       "        [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0],\n",
       "        [0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]]),\n",
       " (10, 20))"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "nb_seqs,SEQ_LEN = sequences.shape\n",
    "data_oh = to_categorical(data, n_classes).astype(np.int)\n",
    "data_oh, data_oh.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Criação do modelo da rede densa com 5 camadas"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "dense_2 (Dense)              (None, 5)                 100       \n",
      "=================================================================\n",
      "Total params: 100\n",
      "Trainable params: 100\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "model_eq = Sequential()\n",
    "model_eq.add(Dense(n_neuronios, \n",
    "                   input_shape=(n_classes,),\n",
    "                   use_bias=False))\n",
    "model_eq.summary()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Criação dos pesos da rede"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Como ilustração, iremos inicializar a rede com pesos de modo que possamos identificar quando cada conjunto de pesos\n",
    "for utilizado para cada símbolo categórico:\n",
    "- quando a categoria for $i$, os neurônios de saída devem receber os valores $[i,2i,3i,4i,5i]$.\n",
    "\n",
    "Os pesos da rede possuem 20 linhas (uma para cada classes de entrada) por 5 colunas (atributos de cada categoria):"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(array([[ 0,  0,  0,  0,  0],\n",
       "        [ 1,  2,  3,  4,  5],\n",
       "        [ 2,  4,  6,  8, 10],\n",
       "        [ 3,  6,  9, 12, 15],\n",
       "        [ 4,  8, 12, 16, 20],\n",
       "        [ 5, 10, 15, 20, 25],\n",
       "        [ 6, 12, 18, 24, 30],\n",
       "        [ 7, 14, 21, 28, 35],\n",
       "        [ 8, 16, 24, 32, 40],\n",
       "        [ 9, 18, 27, 36, 45],\n",
       "        [10, 20, 30, 40, 50],\n",
       "        [11, 22, 33, 44, 55],\n",
       "        [12, 24, 36, 48, 60],\n",
       "        [13, 26, 39, 52, 65],\n",
       "        [14, 28, 42, 56, 70],\n",
       "        [15, 30, 45, 60, 75],\n",
       "        [16, 32, 48, 64, 80],\n",
       "        [17, 34, 51, 68, 85],\n",
       "        [18, 36, 54, 72, 90],\n",
       "        [19, 38, 57, 76, 95]]), (20, 5), dtype('int64'))"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "W = np.arange(n_classes).reshape(-1,1).dot(np.arange(1,n_neuronios+1).reshape(1,-1))\n",
    "W, W.shape, W.dtype"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Predição com as 10 amostras: [19, 10, 0, 1, 7, 5, 0, 1, 15, 2]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Observe que a predição da rede com a sequência categórica acima é feita com a substituição\n",
    "da categoria com os 5 atributos de cada classe."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(array([[19, 38, 57, 76, 95],\n",
       "        [10, 20, 30, 40, 50],\n",
       "        [ 0,  0,  0,  0,  0],\n",
       "        [ 1,  2,  3,  4,  5],\n",
       "        [ 7, 14, 21, 28, 35],\n",
       "        [ 5, 10, 15, 20, 25],\n",
       "        [ 0,  0,  0,  0,  0],\n",
       "        [ 1,  2,  3,  4,  5],\n",
       "        [15, 30, 45, 60, 75],\n",
       "        [ 2,  4,  6,  8, 10]]), (10, 5))"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model_eq.set_weights([W])\n",
    "pp = model_eq.predict(data_oh).astype(np.int)\n",
    "pp, pp.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Embedding como implementação eficiente de entradas categóricas"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Nesta implementação de rede neural com entrada categórica, existem dois fatores que dificultam a sua\n",
    "implementação eficiente:\n",
    "- necessidade de se fazer a codificação para categórico antes de colocá-lo na rede\n",
    "- se o número de classes for muito alto, a implementação pode se tornar muito ineficiente. É comum\n",
    "  termos centenas de milhares de classes, como é o caso de palavras dentro de um vocabulário.\n",
    "  \n",
    "A camada `Embedding` implementado no Keras resolve estes dois problemas de forma eficiente:\n",
    "- faz a codificação categórica automaticamente e já retorna a aplicação dos pesos nos valores categóricos\n",
    "\n",
    "Assim, a camada `Embedding` é sempre uma camada de entrada e nela é preciso especificar o número de\n",
    "classes e o número de atributos de cada classe:\n",
    "\n",
    "O diagrama a seguir mostra a aplicação do Embedding."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<img src = '../figures/Embedding_1.png',width=700pt></img>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Criação da mesma rede, porém agora mais eficiente, com o uso do Embedding"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "embedding_5 (Embedding)      (None, 1, 5)              100       \n",
      "_________________________________________________________________\n",
      "flatten_2 (Flatten)          (None, 5)                 0         \n",
      "=================================================================\n",
      "Total params: 100\n",
      "Trainable params: 100\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "model = Sequential()\n",
    "model.add(Embedding(n_classes, n_neuronios, input_length=1))\n",
    "model.add(Flatten())\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Predição com mesma sequência: [19, 10, 0, 1, 7, 5, 0, 1, 15, 2]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Confirmamos aqui que a camada Embedding é equivalente à rede densa da entrada categórica feita anteriormente."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(array([[19, 38, 57, 76, 95],\n",
       "        [10, 20, 30, 40, 50],\n",
       "        [ 0,  0,  0,  0,  0],\n",
       "        [ 1,  2,  3,  4,  5],\n",
       "        [ 7, 14, 21, 28, 35],\n",
       "        [ 5, 10, 15, 20, 25],\n",
       "        [ 0,  0,  0,  0,  0],\n",
       "        [ 1,  2,  3,  4,  5],\n",
       "        [15, 30, 45, 60, 75],\n",
       "        [ 2,  4,  6,  8, 10]]), (10, 5))"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.set_weights([W])\n",
    "p = model.predict(data).astype(np.int)\n",
    "p, p.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Embedding como atributos latentes de um objeto categórico"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Podemos interpretar o embedding como uma codificação de atributos latentes de um objeto\n",
    "categórico. Por exemplo, se estamos codificando filmes, as 5 categorias visto no exemplo\n",
    "acima poderiam representar a quantidade de suspense, romantismo, aventura, infantil e terror\n",
    "que um filme possui. Se fosse processar palavras, os atributos poderiam representar o seu\n",
    "significado (*word embedding*).\n",
    "\n",
    "O embedding pode ser fixo (não deve ser treinado), quando sabemos exatamente os atributos\n",
    "das classes ou treináveis, quando queremos que a rede utilize estes atributos como parâmetros\n",
    "a serem minimizados."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Aprendizados com este notebook"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.0"
  },
  "latex_envs": {
   "LaTeX_envs_menu_present": true,
   "autocomplete": true,
   "bibliofile": "biblio.bib",
   "cite_by": "apalike",
   "current_citInitial": 1,
   "eqLabelWithNumbers": true,
   "eqNumInitial": 1,
   "hotkeys": {
    "equation": "Ctrl-E",
    "itemize": "Ctrl-I"
   },
   "labels_anchors": false,
   "latex_user_defs": false,
   "report_style_numbering": false,
   "user_envs_cfg": false
  },
  "toc": {
   "colors": {
    "hover_highlight": "#DAA520",
    "running_highlight": "#FF0000",
    "selected_highlight": "#FFD700"
   },
   "moveMenuLeft": true,
   "nav_menu": {
    "height": "12px",
    "width": "252px"
   },
   "navigate_menu": true,
   "number_sections": true,
   "sideBar": true,
   "threshold": 4,
   "toc_cell": false,
   "toc_section_display": "block",
   "toc_window_display": false,
   "widenNotebook": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
