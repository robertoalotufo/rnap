{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Explorando convolução no Keras usando o Theano\n",
    "\n",
    "O objetivo deste notebook é de explorar a convolução que é implementada pelo Theano através do Keras.\n",
    "\n",
    "A convolução é a operação essencial das redes convolucionais. É uma operação demorada e a sua implementação na GPU acelera bastante o seu processamento. A implementação é feita no Theano utilizando GPU. Se a GPU não for encontrada, a implementação roda na CPU.\n",
    "\n",
    "[A guide to convolution arithmetic for deep\n",
    "learning by Vincent Dumoulin and Francesco Visin, 2016](https://arxiv.org/pdf/1603.07285.pdf)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using Theano backend.\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "\n",
    "import os\n",
    "os.environ['KERAS_BACKEND'] = 'theano'\n",
    "#os.environ['THEANO_FLAGS'] = 'mode=FAST_RUN,device=gpu0,floatX=float32'\n",
    "os.environ['THEANO_FLAGS'] = 'mode=FAST_RUN,device=cpu,floatX=float32'\n",
    "\n",
    "import keras\n",
    "from keras.models import Sequential\n",
    "from keras.layers.convolutional import Convolution2D, Conv2D\n",
    "#from keras.utils.np_utils import convert_kernel"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\"\\nimport os\\nos.environ['KERAS_BACKEND'] = 'tensorflow'\\n\\n%matplotlib inline\\nimport matplotlib.pyplot as plot\\n\\nimport sys\\nimport numpy as np\\nimport numpy.random as nr\\n\\nimport tensorflow\\n\\nimport keras\\nfrom keras.callbacks import EarlyStopping,ModelCheckpoint,TensorBoard\\nfrom keras.models import Sequential\\nfrom keras.layers import Convolution2D, MaxPooling2D, Conv2D\\nfrom keras.layers import Activation, Dropout, Flatten, Dense\\n\\nprint('Tensorflow', tensorflow.__version__)\\nprint('Keras ', keras.__version__)\\n\""
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "'''\n",
    "import os\n",
    "os.environ['KERAS_BACKEND'] = 'tensorflow'\n",
    "\n",
    "%matplotlib inline\n",
    "import matplotlib.pyplot as plot\n",
    "\n",
    "import sys\n",
    "import numpy as np\n",
    "import numpy.random as nr\n",
    "\n",
    "import tensorflow\n",
    "\n",
    "import keras\n",
    "from keras.callbacks import EarlyStopping,ModelCheckpoint,TensorBoard\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Convolution2D, MaxPooling2D, Conv2D\n",
    "from keras.layers import Activation, Dropout, Flatten, Dense\n",
    "\n",
    "print('Tensorflow', tensorflow.__version__)\n",
    "print('Keras ', keras.__version__)\n",
    "'''"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Uma rede com uma única camada convolucional\n",
    "\n",
    "O objetivo deste experimento é explorar numericamente a convolução implementada na rede\n",
    "convolucional do Keras/Theano. Para isso iremos criar uma rede convolucional com apenas\n",
    "uma camada de convolução. A sua predição será o resultado da rede, que neste caso será apenas uma convolução.\n",
    "\n",
    "Uma convolução pode ser visto como uma média móvel ponderada sobre a imagem. A equação matemática da convolução é dada por:\n",
    "\n",
    "$$ \\boldsymbol{Y} = \\boldsymbol{X} \\ast \\boldsymbol{W} $$\n",
    "\n",
    "onde $\\boldsymbol{X}$ é a imagem de entrada, $\\boldsymbol{Y}$ é o resultado da convolução e $\\boldsymbol{W}$ é chamado de peso,\n",
    "núcleo, máscara, entre outros nomes. A convolução é a implementação de filtro linear\n",
    "invariante à translação. Este filtro é totalmente especificado pelo núcleo (array $\\boldsymbol{W}$) que\n",
    "contém os parâmetros do filtro linear (da rede convolucional) que precisam ser treinados.\n",
    "\n",
    "A figura a seguir ilustra uma convolução da imagem verde de entrada, utilizando o núcleo da convolução (kernel) em amarelo, deslizando sobre a imagem verde. O resultado da convolução é a imagem rosa, de tamanho ligeiramente menor, devido ao processamento na borda da imagem.\n",
    "\n",
    "![](http://mourafiq.com/images/posts/convolution_schematic.gif)\n",
    "\n",
    "Esta próxima figura ilustra a convolução quando a imagem de saída (em verde) é igual às\n",
    "dimensões da imagem de entrada (em azul). Neste caso, a imagem de entrada é artificialmente\n",
    "aumentada com valores zeros. Este processo de aumentar a imagem de entrada com zeros é \n",
    "denominado *zero padding*.\n",
    "\n",
    "![](https://raw.githubusercontent.com/vdumoulin/conv_arithmetic/master/gif/same_padding_no_strides.gif)\n",
    "\n",
    "## Organização da imagem de entrada\n",
    "\n",
    "As convoluções do Theano foram projetadas principalmente para tratar imagens ou sons. Assim, a organização dos arrays da imagem de entrada, de saída e dos pesos são feitos de forma específica para atender às necessidades das redes convolucionais. Iremos ilustrar as convoluções utilizando imagem de entrada em nível de cinza e coloridas com 3 bandas, usando\n",
    "a convenção do *shape* de imagens do Theano. Diferentemente da organização utilizada nos classificadores usuais (não convolucionais), onde a organização da matriz $\\boldsymbol{X}$ de entrada é bidimensional, com $n$ amostras nas linhas e $k$ *features* nas colunas. O shape de $\\boldsymbol{X}$ é então\n",
    "\n",
    "$$ (n,k)$$.\n",
    " \n",
    "No caso de imagens, como elas têm\n",
    "natureza bidimensional, a relação de vizinhança entre os pixels é fundamental, principalmente\n",
    "para que os pesos dos núcleo abranjam uma região bidimensional da imagem. Assim, as *features* passam agora a terem duas dimensões: são $k$ pixels organizados em `(img_height, img_width)`. Desta forma o array passa a ter uma nova dimensão: ($n$, image_height, image_width). Numa \n",
    "imagem em nível de cinza temos apenas um valor para representar o pixel, que é sua intensidade, variando de escuro a claro. Quando a imagem é colorida, são necessários 3 valores\n",
    "para cada pixel. No Theano, este 3 valores são organizados em uma dimensão adicional, denominada canal (*channel*) ou banda. A imagem colorida é organizada no *shape*:`(bandas, img_height, img_width)`. Desta forma o *shape* da imagem de entrada deve ter 4 dimensões:\n",
    "\n",
    "$\\boldsymbol{X}: $` (samples, channels, img_height, img_width)`\n",
    "\n",
    "## Organização dos pesos (kernel) da convolução\n",
    "\n",
    "Os pesos do kernel da convolução para tratar imagens devem ser 2D, quando a imagem\n",
    "de entrada for em nível de cinza e devem ter 3 bandas 2D para imagens coloridas. Assim, a organização\n",
    "do *shape* do kernel é $(bands, I_{height}, I_{width})$. Entretanto, nas arquiteturas das redes\n",
    "convolucionais, é usual definir vários filtros (vários kernels), para que a rede tenha um\n",
    "maior número de parâmetros a serem ajustados. Assim, o shape dos pesos devem ter 4 dimensões:\n",
    "\n",
    "$\\boldsymbol{W}:$ `(nb_filters, channels, img_height, img_width)`\n",
    "\n",
    "Observe que a primeira dimensão (`nb_filters`) diz respeito ao número de filtros na saída,\n",
    "enquanto que as três demais dimensões `(channels, img_height, img_width)` à janela deslizante\n",
    "(*kernel*) da convolução.\n",
    "\n",
    "## Organização da imagem de saída (filtrada)\n",
    "\n",
    "A organização da imagem de saída é a mesma da imagem de entrada, até porque a camada convolucional pode ser colocada não apenas na entrada, mas como qualquer camada interna da\n",
    "rede. A principal diferença está na nomenclatura da segunda dimensão: enquanto que na\n",
    "imagem da camada de entrada a segunda dimensão é o *channel*, isto é o número de bandas \n",
    "da imagem colorida, na saída e demais camadas, a segunda dimensão passa a ser o número de\n",
    "filtros aplicados naquela camada. Assim, o *shape* da imagem de saída fica como:\n",
    "\n",
    "$\\boldsymbol{Y}: $` (samples, filtros, img_height, img_width)`\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Analisando as convoluções em uma rede convolucional típica\n",
    "\n",
    "Veja a rede a seguir com 4 camadas convolucionais:\n",
    "\n",
    "![](../figures/architecture.png)\n",
    "Fonte: [Figura apresentação do Sander Dieleman](http://benanne.github.io/images/architecture.png)\n",
    "\n",
    "A imagem de entrada é uma imagem colorida\n",
    "quadrada de 45 pixels de lado. Utiliza-se um kernel de 6x6 gerando 32 filtros, então os *shapes* são:\n",
    "* Camada 1:\n",
    "    - entrada: (amostras, 3, 45, 45)\n",
    "    - kernel:  (32, 3, 6, 6)\n",
    "    - saída: (amostras, 32, 40, 40) Obs: a imagem de saída fica menor\n",
    "* Camada 2:\n",
    "    - entrada: (amostras, 32, 40, 40) Obs: é a imagem de saída da camada anterior\n",
    "    - kernel: (64, 32, 5, 5)\n",
    "    - saída: (amostras, 64, 16, 16)\n",
    "* Camada 3:\n",
    "    - entrada: (amostras, 64, 16, 16)\n",
    "    - kernel: (128, 64, 3, 3)\n",
    "    - saída: (amostras, 128, 6, 6)\n",
    "* Camada 4:\n",
    "    - entrada: (amostras 128, 6, 6)\n",
    "    - kernel: (128, 128, 3, 3)\n",
    "    - saída: (amostras, 128, 4, 4)\n",
    "    \n",
    "## Cálculo do número de parâmetros no núcleos das convoluções\n",
    "\n",
    "O número de parâmetros de cada convolução é igual ao número de elementos do kernel,\n",
    "contabilizando todas as suas dimensões. Assim, um kernel de *shape* (10, 3, 5, 5) terá 750 elementos.\n",
    "\n",
    "Como exercício, calcule o número de elementos dos kernels de cada uma das 4 camadas da rede\n",
    "ilustrativa e o total de elementos."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Resposta:\n",
    "- Camada 1:\n",
    "- Camada 2:\n",
    "- Camada 3:\n",
    "- Camada 4:\n",
    "- Total:"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Definição da convolução usando Keras\n",
    "\n",
    "A implementação da convolução utiliza um modelo sequencial do Keras com `Convolution2D`.\n",
    "Obtemos o resultado da rede pela função `predict`:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 4-D convolution\n",
    "def conv4d(x,w,border_mode='same'):\n",
    "    assert x.ndim == 4\n",
    "    assert w.ndim == 4\n",
    "    samples,channels,xh,xw = x.shape\n",
    "    nb_filters,wd,wh,ww = w.shape\n",
    "    \n",
    "    #x = np.rollaxis(x, 1, 4)\n",
    "    w = np.rollaxis(w, 1, 4)\n",
    "    w = np.rollaxis(w, 0, 4)\n",
    "    \n",
    "    #print(x.shape)\n",
    "    #print(w.shape)\n",
    "    \n",
    "    #print(w.shape)\n",
    "    \n",
    "    \n",
    "    #print(w)\n",
    "    #w.reshape(wh,ww,wd, nb_filters)\n",
    "    model = Sequential([\n",
    "                Conv2D(filters=nb_filters, kernel_size=(wh, ww), input_shape=(channels, xh, xw), \n",
    "                       weights=[w], padding=border_mode, use_bias=False, data_format=\"channels_first\")\n",
    "                #Convolution2D(nb_filters, (wh, ww), \n",
    "                #        input_shape=(channels, xh, xw),\n",
    "                #        weights=[w.reshape(wh,ww,wd, nb_filters)], \n",
    "                #        border_mode=border_mode, bias=False,\n",
    "                        #dim_ordering='th')\n",
    "                #        data_format=\"channels_first\")\n",
    "    ])\n",
    "\n",
    "    y = model.predict(x,batch_size=1)\n",
    "    return y #np.rollaxis(y, 3, 1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Primeiro caso, resposta ao impulso\n",
    "\n",
    "Quando a imagem de entrada é apenas um 1 rodeado de vários zeros, o resultado da convolução\n",
    "é o próprio kernel posicionado no local do 1. Esta é uma forma usual para se verificar se\n",
    "a convolução está funcionando. Assim, utilizaremos uma imagem cinza 3x5 com um \"1\" no centro.\n",
    "O kernel é de 2 linhas e 3 colunas. O resultado é uma imagem 3x5 com o kernel posicionado\n",
    "no local do 1 da imagem de entrada."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "x.shape: (1, 1, 5, 7)\n",
      "[[[[0 0 0 0 0 0 0]\n",
      "   [0 0 0 0 0 0 0]\n",
      "   [0 0 0 1 0 0 0]\n",
      "   [0 0 0 0 0 0 0]\n",
      "   [0 0 0 0 0 0 0]]]]\n",
      "W.shape: (1, 1, 2, 3)\n",
      "[[[[ 1.  2.  3.]\n",
      "   [ 4.  5.  6.]]]]\n",
      "y.shape: (1, 1, 4, 5)\n",
      "[[[[ 0.  0.  0.  0.  0.]\n",
      "   [ 0.  1.  2.  3.  0.]\n",
      "   [ 0.  4.  5.  6.  0.]\n",
      "   [ 0.  0.  0.  0.  0.]]]]\n"
     ]
    }
   ],
   "source": [
    "np.set_printoptions(suppress=True, precision=3)\n",
    "\n",
    "x = np.array([[0,0,0,0,0,0,0],\n",
    "              [0,0,0,0,0,0,0],\n",
    "              [0,0,0,1,0,0,0],\n",
    "              [0,0,0,0,0,0,0],\n",
    "              [0,0,0,0,0,0,0]]).reshape(1,1,5,7)\n",
    "W = np.array([[1.,2.,3.],\n",
    "              [4.,5.,6.]]).reshape(1,1,2,3)\n",
    "\n",
    "y = conv4d(x,W, 'valid')\n",
    "\n",
    "print('x.shape:', x.shape)\n",
    "print(x)\n",
    "print('W.shape:', W.shape)\n",
    "print(W)\n",
    "print('y.shape:', y.shape)\n",
    "print(y)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "## Reproduzindo o exemplo da figura animada acima"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "x.shape: (1, 1, 5, 5)\n",
      "[[[[1 1 1 0 0]\n",
      "   [0 1 1 1 0]\n",
      "   [0 0 1 1 1]\n",
      "   [0 0 1 1 0]\n",
      "   [0 1 1 0 0]]]]\n",
      "W.shape: (1, 1, 3, 3)\n",
      "[[[[1 0 1]\n",
      "   [0 1 0]\n",
      "   [1 0 1]]]]\n",
      "y.shape: (1, 1, 3, 3)\n",
      "[[[[ 4.  3.  4.]\n",
      "   [ 2.  4.  3.]\n",
      "   [ 2.  3.  4.]]]]\n"
     ]
    }
   ],
   "source": [
    "x = np.array([[1,1,1,0,0],\n",
    "              [0,1,1,1,0],\n",
    "              [0,0,1,1,1],\n",
    "              [0,0,1,1,0],\n",
    "              [0,1,1,0,0]]).reshape(1,1,5,5)\n",
    "W = np.array([[1,0,1],\n",
    "              [0,1,0],\n",
    "              [1,0,1]]).reshape(1,1,3,3)\n",
    "\n",
    "y = conv4d(x,W,'valid')\n",
    "\n",
    "print('x.shape:', x.shape)\n",
    "print(x)\n",
    "print('W.shape:', W.shape)\n",
    "print(W)\n",
    "print('y.shape:', y.shape)\n",
    "print(y)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 4 amostras de imagem cinza 3x5, 1 filtro com kernel de 3x3 \n",
    "\n",
    "Neste caso, \n",
    "- shape da entrada, x:(4,1,3,5)\n",
    "- shape dos pesos W:(1, 1, 3,3). \n",
    "- shape de saída será y:(4,1,3,5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "x.shape: (4, 1, 3, 5)\n",
      "[[[[0 0 0 0 0]\n",
      "   [0 0 0 0 0]\n",
      "   [0 0 0 0 0]]]\n",
      "\n",
      "\n",
      " [[[0 0 0 0 0]\n",
      "   [0 0 1 0 0]\n",
      "   [0 0 0 0 0]]]\n",
      "\n",
      "\n",
      " [[[0 0 0 0 0]\n",
      "   [0 0 2 0 0]\n",
      "   [0 0 0 0 0]]]\n",
      "\n",
      "\n",
      " [[[0 0 0 0 0]\n",
      "   [0 0 3 0 0]\n",
      "   [0 0 0 0 0]]]]\n",
      "W.shape: (1, 1, 3, 3)\n",
      "[[[[1 0 1]\n",
      "   [0 1 0]\n",
      "   [1 0 1]]]]\n",
      "y.shape: (4, 1, 3, 5)\n",
      "[[[[ 0.  0.  0.  0.  0.]\n",
      "   [ 0.  0.  0.  0.  0.]\n",
      "   [ 0.  0.  0.  0.  0.]]]\n",
      "\n",
      "\n",
      " [[[ 0.  1.  0.  1.  0.]\n",
      "   [ 0.  0.  1.  0.  0.]\n",
      "   [ 0.  1.  0.  1.  0.]]]\n",
      "\n",
      "\n",
      " [[[ 0.  2.  0.  2.  0.]\n",
      "   [ 0.  0.  2.  0.  0.]\n",
      "   [ 0.  2.  0.  2.  0.]]]\n",
      "\n",
      "\n",
      " [[[ 0.  3.  0.  3.  0.]\n",
      "   [ 0.  0.  3.  0.  0.]\n",
      "   [ 0.  3.  0.  3.  0.]]]]\n"
     ]
    }
   ],
   "source": [
    "W = np.array([[1,0,1],\n",
    "              [0,1,0],\n",
    "              [1,0,1]]).reshape(1,1,3,3)\n",
    "# criando 4 amostras de imagens\n",
    "x = np.array([[0,0,0,0,0],\n",
    "              [0,0,1,0,0],\n",
    "              [0,0,0,0,0]]).reshape(1,1,3,5) * np.arange(4).reshape(4,1,1,1)\n",
    "y = conv4d(x,W,'same')\n",
    "print('x.shape:', x.shape)\n",
    "print(x)\n",
    "print('W.shape:', W.shape)\n",
    "print(W)\n",
    "print('y.shape:', y.shape)\n",
    "print(y)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2 filtros com kernel de 3x3, 1 amostra de imagem cinza 3x5\n",
    "\n",
    "Neste caso, \n",
    "- shape da entrada, x:(1,1,3,5)\n",
    "- shape dos pesos W:(2, 1, 3,3). \n",
    "- shape de saída será y:(1,2,3,5)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "x.shape: (1, 1, 3, 5)\n",
      "[[[[0 0 0 0 0]\n",
      "   [0 0 1 0 0]\n",
      "   [0 0 0 0 0]]]]\n",
      "W.shape: (2, 1, 3, 3)\n",
      "[[[[1 0 1]\n",
      "   [0 1 0]\n",
      "   [1 0 1]]]\n",
      "\n",
      "\n",
      " [[[0 1 0]\n",
      "   [1 2 1]\n",
      "   [0 1 0]]]]\n",
      "y.shape: (1, 2, 3, 5)\n",
      "[[[[ 0.  1.  0.  1.  0.]\n",
      "   [ 0.  0.  1.  0.  0.]\n",
      "   [ 0.  1.  0.  1.  0.]]\n",
      "\n",
      "  [[ 0.  0.  1.  0.  0.]\n",
      "   [ 0.  1.  2.  1.  0.]\n",
      "   [ 0.  0.  1.  0.  0.]]]]\n"
     ]
    }
   ],
   "source": [
    "W = np.array([[[1,0,1],\n",
    "               [0,1,0],\n",
    "               [1,0,1]],\n",
    "              [[0,1,0],\n",
    "               [1,2,1],\n",
    "               [0,1,0]]]).reshape(2,1,3,3)\n",
    "x = np.array([[0,0,0,0,0],\n",
    "              [0,0,1,0,0],\n",
    "              [0,0,0,0,0]]).reshape(1,1,3,5)\n",
    "y = conv4d(x,W,'same')\n",
    "print('x.shape:', x.shape)\n",
    "print(x)\n",
    "print('W.shape:', W.shape)\n",
    "print(W)\n",
    "print('y.shape:', y.shape)\n",
    "print(y)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1 filtro com kernel de 3x3 e 3 canais, 1 amostra de imagem 3x5 RGB (3 canais)\n",
    "Neste caso, como a imagem de entrada possui 3 bandas, para guardar as bandas Red, Green e Blue, o kernel também precisa ter 3 bandas pois são necessários pesos para cada banda de cor.\n",
    "- shape da entrada, x:(1,3,3,5)\n",
    "- shape dos pesos W:(1, 3, 3,3). \n",
    "- shape de saída será y:(1,2,3,5)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "x.shape: (1, 3, 3, 5)\n",
      "[[[[0 0 0 0 0]\n",
      "   [0 1 0 0 0]\n",
      "   [0 0 0 0 0]]\n",
      "\n",
      "  [[0 0 0 0 1]\n",
      "   [0 0 1 0 0]\n",
      "   [0 0 0 0 0]]\n",
      "\n",
      "  [[0 0 0 0 0]\n",
      "   [0 0 0 1 0]\n",
      "   [0 0 0 0 0]]]]\n",
      "W.shape: (1, 3, 3, 3)\n",
      "[[[[1 0 1]\n",
      "   [0 1 0]\n",
      "   [1 0 1]]\n",
      "\n",
      "  [[0 1 0]\n",
      "   [1 1 1]\n",
      "   [0 1 0]]\n",
      "\n",
      "  [[0 1 0]\n",
      "   [0 1 0]\n",
      "   [0 1 0]]]]\n",
      "y.shape: (1, 1, 3, 5)\n",
      "[[[[ 1.  0.  2.  2.  1.]\n",
      "   [ 0.  2.  1.  2.  1.]\n",
      "   [ 1.  0.  2.  1.  0.]]]]\n"
     ]
    }
   ],
   "source": [
    "W = np.array([[[1,0,1],\n",
    "               [0,1,0],\n",
    "               [1,0,1]],\n",
    "              [[0,1,0],\n",
    "               [1,1,1],\n",
    "               [0,1,0]],\n",
    "              [[0,1,0],\n",
    "               [0,1,0],\n",
    "               [0,1,0]]]).reshape(1,3,3,3)\n",
    "x = np.array([[[0,0,0,0,0],\n",
    "               [0,1,0,0,0],\n",
    "               [0,0,0,0,0]],\n",
    "              [[0,0,0,0,1],\n",
    "               [0,0,1,0,0],\n",
    "               [0,0,0,0,0]],\n",
    "              [[0,0,0,0,0],\n",
    "               [0,0,0,1,0],\n",
    "               [0,0,0,0,0]]]).reshape(1,3,3,5)\n",
    "y = conv4d(x,W,'same')\n",
    "print('x.shape:', x.shape)\n",
    "print(x)\n",
    "print('W.shape:', W.shape)\n",
    "print(W)\n",
    "print('y.shape:', y.shape)\n",
    "print(y)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Exercícios\n",
    "\n",
    "### Teórico\n",
    "\n",
    "1. Supondo uma imagem de entrada 100 x 100 e um kernel 3 x 3. Utilizando-se o border_mode como válido, a imagem de saída será de 98 x 98. Se fosse utilizar uma rede densa, com entrada de 100 x 100 e saída 98 x 98, quantos parâmetros seriam necessários para ser treinados? E no caso da rede convolucional? Qual é o fator de redução?\n",
    "\n",
    "### Práticos\n",
    "\n",
    "1. Trocar o parâmetro ``border_mode`` para ``same`` e veja a diferença.\n",
    "2. Rodar a convolução para uma imagem de cinza\n",
    "3. Rodar a convolução para uma imagem colorida RGB\n",
    "4. Comparar o tempo de execução desta convolução com outras implementações: scipy, skimage ou openCV"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Aprendizados com este notebook\n",
    "\n",
    "1. A rede convolucional é uma forma eficiente de se ter uma rede densa restrita, onde os parâmetros são localizados (em imagens). Os parâmetros do filtro da convolução agem como pesos compartilhados na rede densa. As vantagens são que o número de parâmetros é extremamente reduzido se comparado com a rede densa, permitindo assim criar redes com muitas camadas (maior flexibilidade) facilitando o treinamento.\n",
    "2. Este notebook ilustra como usar a convolução no Keras.\n"
   ]
  }
 ],
 "metadata": {
  "anaconda-cloud": {},
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.1"
  },
  "toc": {
   "colors": {
    "hover_highlight": "#DAA520",
    "running_highlight": "#FF0000",
    "selected_highlight": "#FFD700"
   },
   "moveMenuLeft": true,
   "nav_menu": {
    "height": "334px",
    "width": "252px"
   },
   "navigate_menu": true,
   "number_sections": true,
   "sideBar": true,
   "threshold": 4,
   "toc_cell": false,
   "toc_section_display": "block",
   "toc_window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
