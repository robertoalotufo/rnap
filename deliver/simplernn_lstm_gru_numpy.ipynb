{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "toc": "true"
   },
   "source": [
    "# Table of Contents\n",
    " <p><div class=\"lev1 toc-item\"><a href=\"#Redes-Recorrentes\" data-toc-modified-id=\"Redes-Recorrentes-1\"><span class=\"toc-item-num\">1&nbsp;&nbsp;</span>Redes Recorrentes</a></div><div class=\"lev2 toc-item\"><a href=\"#Base-Class\" data-toc-modified-id=\"Base-Class-11\"><span class=\"toc-item-num\">1.1&nbsp;&nbsp;</span>Base Class</a></div><div class=\"lev2 toc-item\"><a href=\"#SimpleRNN\" data-toc-modified-id=\"SimpleRNN-12\"><span class=\"toc-item-num\">1.2&nbsp;&nbsp;</span>SimpleRNN</a></div><div class=\"lev3 toc-item\"><a href=\"#implementação\" data-toc-modified-id=\"implementação-121\"><span class=\"toc-item-num\">1.2.1&nbsp;&nbsp;</span>implementação</a></div><div class=\"lev3 toc-item\"><a href=\"#modelo-básico\" data-toc-modified-id=\"modelo-básico-122\"><span class=\"toc-item-num\">1.2.2&nbsp;&nbsp;</span>modelo básico</a></div><div class=\"lev3 toc-item\"><a href=\"#return_sequences\" data-toc-modified-id=\"return_sequences-123\"><span class=\"toc-item-num\">1.2.3&nbsp;&nbsp;</span><em>return_sequences</em></a></div><div class=\"lev3 toc-item\"><a href=\"#stateful\" data-toc-modified-id=\"stateful-124\"><span class=\"toc-item-num\">1.2.4&nbsp;&nbsp;</span><em>stateful</em></a></div><div class=\"lev2 toc-item\"><a href=\"#LSTM\" data-toc-modified-id=\"LSTM-13\"><span class=\"toc-item-num\">1.3&nbsp;&nbsp;</span>LSTM</a></div><div class=\"lev3 toc-item\"><a href=\"#implementação\" data-toc-modified-id=\"implementação-131\"><span class=\"toc-item-num\">1.3.1&nbsp;&nbsp;</span>implementação</a></div><div class=\"lev3 toc-item\"><a href=\"#teste\" data-toc-modified-id=\"teste-132\"><span class=\"toc-item-num\">1.3.2&nbsp;&nbsp;</span>teste</a></div><div class=\"lev2 toc-item\"><a href=\"#GRU\" data-toc-modified-id=\"GRU-14\"><span class=\"toc-item-num\">1.4&nbsp;&nbsp;</span>GRU</a></div><div class=\"lev3 toc-item\"><a href=\"#implementação\" data-toc-modified-id=\"implementação-141\"><span class=\"toc-item-num\">1.4.1&nbsp;&nbsp;</span>implementação</a></div><div class=\"lev3 toc-item\"><a href=\"#teste\" data-toc-modified-id=\"teste-142\"><span class=\"toc-item-num\">1.4.2&nbsp;&nbsp;</span>teste</a></div>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Redes Recorrentes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n"
     ]
    }
   ],
   "source": [
    "%matplotlib inline\n",
    "import matplotlib.pyplot as plot\n",
    "from IPython import display\n",
    "from __future__ import print_function\n",
    "\n",
    "import os\n",
    "import sys\n",
    "import glob\n",
    "import numpy as np\n",
    "import numpy.random as nr\n",
    "\n",
    "from keras.preprocessing.text import Tokenizer\n",
    "from keras.preprocessing.sequence import pad_sequences\n",
    "from keras.utils import to_categorical\n",
    "from keras.layers import Dense, Input, Flatten, Dropout\n",
    "from keras.layers import Conv1D, MaxPooling1D, Embedding\n",
    "from keras.layers.recurrent import SimpleRNN, LSTM, GRU\n",
    "from keras.models import Model\n",
    "from keras.optimizers import (SGD, \n",
    "                              RMSprop, \n",
    "                              Adam, \n",
    "                              Adadelta, \n",
    "                              Adagrad)\n",
    "\n",
    "sys.path.append('../src')\n",
    "from my_keras_utilities import (get_available_gpus, \n",
    "                                load_model_and_history, \n",
    "                                save_model_and_history, \n",
    "                                TrainingPlotter)\n",
    "\n",
    "os.makedirs('../../models',exist_ok=True)\n",
    "np.set_printoptions(precision=3, linewidth=120, suppress=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Backend:        tensorflow\n",
      "Data format:    channels_first\n",
      "Available GPUS: []\n"
     ]
    }
   ],
   "source": [
    "import keras.backend as K\n",
    "\n",
    "# K.set_image_data_format('channels_first')\n",
    "K.set_floatx('float32')\n",
    "\n",
    "print('Backend:        {}'.format(K.backend()))\n",
    "print('Data format:    {}'.format(K.image_data_format()))\n",
    "print('Available GPUS:', get_available_gpus())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Base Class "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "class MyRecurrentNet:\n",
    "    def __init__(self, n_units, input_shape=None, return_sequences=False, stateful=False):\n",
    "        self.return_sequences = return_sequences\n",
    "        self.stateful = stateful\n",
    "        self.n_steps, self.n_inputs = input_shape\n",
    "        self.n_units = n_units\n",
    "        self.h0 = None\n",
    "        self.Wx = None\n",
    "        self.Ws = None\n",
    "        self.b = 0\n",
    "        \n",
    "    def reset_states(self):\n",
    "        pass\n",
    "    \n",
    "    def set_weights(self, Wx, Ws, b):\n",
    "        self.Wx = Wx\n",
    "        self.Ws = Ws\n",
    "        self.b = b\n",
    "        \n",
    "    def predict(self, X, batch_size=None):\n",
    "        n_samples, n_steps, n_inputs = X.shape\n",
    "        assert n_inputs == self.n_inputs\n",
    "        assert n_steps == self.n_steps\n",
    "        batch_size = batch_size or n_samples\n",
    "        n_batches = int(np.ceil(n_samples / batch_size)) \n",
    "        yb = []\n",
    "        for i in range(n_batches):\n",
    "            Xb = X[i*batch_size:(i+1)*batch_size]\n",
    "            yb.append(self._predict_one_batch(Xb))\n",
    "        # reset if specified\n",
    "        return np.vstack(yb)\n",
    "        \n",
    "    def _predict_one_batch(self, X):\n",
    "        raise NotImplementedError(\"This method should be implemented in subclasses.\")\n",
    "\n",
    "    def _init_state(self, n_samples):\n",
    "        if self.stateful and self.h0 is not None:\n",
    "            h = self.h0\n",
    "            s = self.s0\n",
    "        else:\n",
    "            h = np.zeros((n_samples, self.n_units), np.float)\n",
    "            s = np.zeros((n_samples, self.n_units), np.float)\n",
    "        return h, s\n",
    "    \n",
    "    def _get_output(self, h, s=(None,)):\n",
    "        self.h0 = h[-1]\n",
    "        self.s0 = s[-1]\n",
    "        if self.return_sequences:\n",
    "            output = np.stack(h[1:], axis=-1).transpose(0, 2, 1)\n",
    "        else:\n",
    "            output = h[-1]\n",
    "        return output\n",
    "\n",
    "    @staticmethod\n",
    "    def _sigmoid(z):\n",
    "        z = np.asarray(z)\n",
    "        return np.ones(z.shape)/(1.0 + np.exp(-z))\n",
    "    \n",
    "    @staticmethod\n",
    "    def _hard_sigmoid(x):\n",
    "        # Faster than sigmoid.\n",
    "        z = 0.2*x + 0.5\n",
    "        z = np.where(x < -2.5, 0.0, z)\n",
    "        z = np.where(x > 2.5, 1.0, z)\n",
    "        return z\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": false,
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Input:\n",
      "[[[ 0.251  0.126  0.48   0.302 -0.184]\n",
      "  [-0.401  0.002  0.301  0.029 -0.486]\n",
      "  [-0.223  0.36  -0.42  -0.318 -0.123]]\n",
      "\n",
      " [[ 0.332  0.464 -0.123  0.359  0.403]\n",
      "  [-0.422 -0.    -0.397 -0.142  0.438]\n",
      "  [ 0.257  0.272 -0.32   0.034 -0.167]]]\n"
     ]
    }
   ],
   "source": [
    "# dados pata os testes\n",
    "a = nr.random((2, 3, 5)) - 0.5\n",
    "print('Input:')\n",
    "print(a)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## SimpleRNN\n",
    "\n",
    "<table align='left'>\n",
    "<tr><td> <img src=\"../figures/rnn_2.png\"> </td></tr>\n",
    "</table>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### implementação"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "class MySimpleRNN(MyRecurrentNet):\n",
    "    \n",
    "    def _predict_one_batch(self, X):\n",
    "        n_samples, n_steps, n_seq = X.shape        \n",
    "        h = [None for _ in range(n_steps + 1)]\n",
    "        h[0], _ = self._init_state(n_samples)\n",
    "        for i in range(n_steps):\n",
    "            h[i+1] = np.tanh(np.dot(X[:, i], Wx) + np.dot(h[i], Ws) + b)\n",
    "        return self._get_output(h)\n",
    "        "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### modelo básico"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "input_1 (InputLayer)         (None, 3, 5)              0         \n",
      "_________________________________________________________________\n",
      "simple_rnn_1 (SimpleRNN)     (None, 10)                160       \n",
      "=================================================================\n",
      "Total params: 160\n",
      "Trainable params: 160\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "Weight shapes: [(5, 10), (10, 10), (10,)]\n",
      "\n",
      "Output:\n",
      "[[ 0.24  -0.164  0.113 -0.261  0.008  0.365 -0.197  0.756  0.046  0.37 ]\n",
      " [-0.331 -0.621  0.191 -0.125 -0.089  0.422 -0.043 -0.346  0.267  0.873]]\n",
      "--------\n",
      "OK: True\n"
     ]
    }
   ],
   "source": [
    "inp = Input(shape=(3, 5))\n",
    "out = SimpleRNN(10)(inp)\n",
    "model = Model(inp, out)\n",
    "\n",
    "model.summary()\n",
    "print('Weight shapes:', [w.shape for w in model.get_weights()], end='\\n\\n')\n",
    "Wx, Ws, b = model.get_weights()\n",
    "\n",
    "rnn = MySimpleRNN(10, input_shape=(3, 5))\n",
    "rnn.set_weights(Wx, Ws, b)\n",
    "\n",
    "preds_1 = model.predict(a)\n",
    "preds_2 = rnn.predict(a)\n",
    "print('Output:')\n",
    "print(preds_1)\n",
    "\n",
    "ok = np.allclose(preds_1, preds_2)\n",
    "print('--------\\nOK:', ok)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### *return_sequences*"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "input_2 (InputLayer)         (None, 3, 5)              0         \n",
      "_________________________________________________________________\n",
      "simple_rnn_2 (SimpleRNN)     (None, 3, 10)             160       \n",
      "=================================================================\n",
      "Total params: 160\n",
      "Trainable params: 160\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "Weight shapes: [(5, 10), (10, 10), (10,)]\n",
      "\n",
      "Output:\n",
      "[[[ 0.105  0.265  0.168  0.536 -0.248  0.005 -0.064 -0.298  0.111  0.057]\n",
      "  [ 0.161  0.634 -0.297 -0.042 -0.086 -0.125  0.043  0.018  0.317 -0.497]\n",
      "  [ 0.24  -0.164  0.113 -0.261  0.008  0.365 -0.197  0.756  0.046  0.37 ]]\n",
      "\n",
      " [[-0.285 -0.372 -0.113  0.209 -0.437  0.313 -0.046  0.019 -0.31   0.369]\n",
      "  [-0.59  -0.449 -0.558 -0.588  0.006  0.344  0.402 -0.267 -0.285 -0.302]\n",
      "  [-0.331 -0.621  0.191 -0.125 -0.089  0.422 -0.043 -0.346  0.267  0.873]]]\n",
      "--------\n",
      "OK: True\n"
     ]
    }
   ],
   "source": [
    "inp = Input(shape=(3, 5))\n",
    "out = SimpleRNN(10, return_sequences=True)(inp)\n",
    "model = Model(inp, out)\n",
    "\n",
    "model.summary()\n",
    "print('Weight shapes:', [w.shape for w in model.get_weights()], end='\\n\\n')\n",
    "model.set_weights([Wx, Ws, b])\n",
    "\n",
    "rnn = MySimpleRNN(10, input_shape=(3, 5), return_sequences=True)\n",
    "rnn.set_weights(Wx, Ws, b)\n",
    "\n",
    "preds_1 = model.predict(a)\n",
    "preds_2 = rnn.predict(a)\n",
    "print('Output:')\n",
    "print(preds_1)\n",
    "\n",
    "ok = np.allclose(preds_1, preds_2)\n",
    "print('--------\\nOK:', ok)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### *stateful*"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "input_3 (InputLayer)         (1, 3, 5)                 0         \n",
      "_________________________________________________________________\n",
      "simple_rnn_3 (SimpleRNN)     (1, 10)                   160       \n",
      "=================================================================\n",
      "Total params: 160\n",
      "Trainable params: 160\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "Weight shapes: [(5, 10), (10, 10), (10,)]\n",
      "\n",
      "Output:\n",
      "[[ 0.24  -0.164  0.113 -0.261  0.008  0.365 -0.197  0.756  0.046  0.37 ]\n",
      " [-0.164 -0.653  0.084 -0.184 -0.257  0.168 -0.164 -0.12   0.45   0.936]]\n",
      "--------\n",
      "OK: True\n"
     ]
    }
   ],
   "source": [
    "inp = Input(batch_shape=(1, 3, 5))\n",
    "out = SimpleRNN(10, stateful=True)(inp)\n",
    "model = Model(inp, out)\n",
    "\n",
    "model.summary()\n",
    "print('Weight shapes:', [w.shape for w in model.get_weights()], end='\\n\\n')\n",
    "model.set_weights([Wx, Ws, b])\n",
    "\n",
    "rnn = MySimpleRNN(10, input_shape=(3, 5), stateful=True)\n",
    "rnn.set_weights(Wx, Ws, b)\n",
    "\n",
    "preds_1 = model.predict(a, batch_size=1)\n",
    "preds_2 = rnn.predict(a, batch_size=1)\n",
    "print('Output:')\n",
    "print(preds_1)\n",
    "\n",
    "ok = np.allclose(preds_1, preds_2)\n",
    "print('--------\\nOK:', ok)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## LSTM\n",
    "\n",
    "<table align='left'>\n",
    "<tr><td> <img src=\"../figures/rnn_3.png\"> </td></tr>\n",
    "</table>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### implementação"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "class MyLSTM(MyRecurrentNet):\n",
    "    \n",
    "    def _predict_one_batch(self, X):\n",
    "        n_samples, n_steps, n_seq = X.shape\n",
    "        \n",
    "        Wix, Wfx, Wcx, Wox = np.split(self.Wx, 4, axis=1)\n",
    "        Wis, Wfs, Wcs, Wos = np.split(self.Ws, 4, axis=1)\n",
    "        bi,  bf,  bc,  bo  = np.split(self.b,  4, axis=0)\n",
    "        \n",
    "        h = [None for _ in range(n_steps + 1)]     # hidden state\n",
    "        c = [None for _ in range(n_steps + 1)]     # cell state\n",
    "        h[0], c[0] = self._init_state(n_samples)\n",
    "        for i in range(n_steps):\n",
    "            ft = self._hard_sigmoid(np.dot(X[:,i], Wfx) + np.dot(h[i], Wfs) + bf)    # forget gate\n",
    "            it = self._hard_sigmoid(np.dot(X[:,i], Wix) + np.dot(h[i], Wis) + bi)    # input gate\n",
    "            ot = self._hard_sigmoid(np.dot(X[:,i], Wox) + np.dot(h[i], Wos) + bo)    # output gate\n",
    "            ct = np.tanh(np.dot(X[:,i], Wcx) + np.dot(h[i], Wcs) + bc)              \n",
    "            c[i+1] = ft * c[i] + it * ct      # update cell state\n",
    "            h[i+1] = ot * np.tanh(c[i+1])     # update hidden state\n",
    "        return self._get_output(h, c)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### teste"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "input_4 (InputLayer)         (None, 3, 5)              0         \n",
      "_________________________________________________________________\n",
      "lstm_1 (LSTM)                (None, 10)                640       \n",
      "=================================================================\n",
      "Total params: 640\n",
      "Trainable params: 640\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "Weight shapes: [(5, 40), (10, 40), (40,)]\n",
      "\n",
      "Output:\n",
      "[[-0.026 -0.     0.009  0.056  0.027  0.015  0.018  0.019  0.019  0.011]\n",
      " [-0.004 -0.026 -0.03   0.004  0.052  0.018 -0.049  0.029  0.089 -0.013]]\n",
      "--------\n",
      "OK: True\n"
     ]
    }
   ],
   "source": [
    "inp = Input(shape=(3, 5))\n",
    "out = LSTM(10)(inp)\n",
    "model = Model(inp, out)\n",
    "\n",
    "model.summary()\n",
    "print('Weight shapes:', [w.shape for w in model.get_weights()], end='\\n\\n')\n",
    "Wx, Ws, b = model.get_weights()\n",
    "\n",
    "rnn = MyLSTM(10, input_shape=(3, 5))\n",
    "rnn.set_weights(Wx, Ws, b)\n",
    "\n",
    "preds_1 = model.predict(a)\n",
    "preds_2 = rnn.predict(a)\n",
    "print('Output:')\n",
    "print(preds_1)\n",
    "# print()\n",
    "# print(preds_2)\n",
    "\n",
    "ok = np.allclose(preds_1, preds_2)\n",
    "print('--------\\nOK:', ok)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## GRU\n",
    "\n",
    "<table align='left'>\n",
    "<tr><td> <img src=\"../figures/rnn_5.png\"> </td></tr>\n",
    "</table>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### implementação"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "class MyGRU(MyRecurrentNet):\n",
    "    \n",
    "    def _predict_one_batch(self, X):\n",
    "        n_samples, n_steps, n_seq = X.shape\n",
    "        \n",
    "        Wzx, Wrx, Whx = np.split(self.Wx, 3, axis=1)\n",
    "        Wzs, Wrs, Whs = np.split(self.Ws, 3, axis=1)\n",
    "        bz,  br,  bh  = np.split(self.b,  3, axis=0)\n",
    "        \n",
    "        h = [None for _ in range(n_steps + 1)]\n",
    "        h[0], _ = self._init_state(n_samples)\n",
    "        for i in range(n_steps):\n",
    "            zt = self._hard_sigmoid(np.dot(X[:,i], Wzx) + np.dot(h[i], Wzs) + bz)\n",
    "            rt = self._hard_sigmoid(np.dot(X[:,i], Wrx) + np.dot(h[i], Wrs) + br)\n",
    "            \n",
    "            ht = np.tanh(np.dot(X[:,i], Whx) + np.dot(rt * h[i], Whs) + bh)\n",
    "            \n",
    "            h[i+1] = (1 - zt) * ht + zt * h[i]\n",
    "        return self._get_output(h)\n",
    "        "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### teste"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "input_5 (InputLayer)         (None, 3, 5)              0         \n",
      "_________________________________________________________________\n",
      "gru_1 (GRU)                  (None, 10)                480       \n",
      "=================================================================\n",
      "Total params: 480\n",
      "Trainable params: 480\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "Weight shapes: [(5, 30), (10, 30), (30,)]\n",
      "\n",
      "Output:\n",
      "[[-0.071  0.024 -0.081  0.1    0.096  0.046  0.05  -0.041  0.105  0.099]\n",
      " [-0.165 -0.036 -0.008  0.046  0.158  0.07   0.065 -0.088 -0.058  0.038]]\n",
      "--------\n",
      "OK: True\n"
     ]
    }
   ],
   "source": [
    "inp = Input(shape=(3, 5))\n",
    "out = GRU(10)(inp)\n",
    "model = Model(inp, out)\n",
    "\n",
    "model.summary()\n",
    "print('Weight shapes:', [w.shape for w in model.get_weights()], end='\\n\\n')\n",
    "Wx, Ws, b = model.get_weights()\n",
    "\n",
    "rnn = MyGRU(10, input_shape=(3, 5))\n",
    "rnn.set_weights(Wx, Ws, b)\n",
    "\n",
    "preds_1 = model.predict(a)\n",
    "preds_2 = rnn.predict(a)\n",
    "print('Output:')\n",
    "print(preds_1)\n",
    "# print()\n",
    "# print(preds_2)\n",
    "\n",
    "ok = np.allclose(preds_1, preds_2)\n",
    "print('--------\\nOK:', ok)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.0"
  },
  "latex_envs": {
   "LaTeX_envs_menu_present": true,
   "autocomplete": true,
   "bibliofile": "biblio.bib",
   "cite_by": "apalike",
   "current_citInitial": 1,
   "eqLabelWithNumbers": true,
   "eqNumInitial": 1,
   "hotkeys": {
    "equation": "Ctrl-E",
    "itemize": "Ctrl-I"
   },
   "labels_anchors": false,
   "latex_user_defs": false,
   "report_style_numbering": false,
   "user_envs_cfg": false
  },
  "toc": {
   "colors": {
    "hover_highlight": "#DAA520",
    "running_highlight": "#FF0000",
    "selected_highlight": "#FFD700"
   },
   "moveMenuLeft": true,
   "nav_menu": {
    "height": "246px",
    "width": "252px"
   },
   "navigate_menu": true,
   "number_sections": true,
   "sideBar": true,
   "threshold": 4,
   "toc_cell": true,
   "toc_section_display": "block",
   "toc_window_display": false,
   "widenNotebook": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
