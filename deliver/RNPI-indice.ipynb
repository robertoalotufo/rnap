{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# FEE 0156 - Prática de Redes Neurais Profundas para Análise de Imagens\n",
    "\n",
    "Professores: *Roberto Lotufo, Rubens Machado, Letícia Rittner*<br>\n",
    "Auxiliares: *Roberto M Souza, Oeslle Lucena, Irene H Fantini*<br>\n",
    "Data: 20 a 23 de fevereiro de 2017, das 9h às 12h e das 14h às 17h<br>\n",
    "Local: Universidade Estadual de Campinas\n",
    "\n",
    "![capa](../figures/curso-Deep-Learning-Processamento-Imagens-Unicamp.png)\n",
    "\n",
    "## Conteúdo\n",
    "\n",
    "### I - Introdução ao curso\n",
    "\n",
    "1. Conteúdo e formato do curso \n",
    "2. Introdução a Aprendizagem de Máquina, Redes Neurais Profundas e Redes Convolucionais\n",
    "3. Ferramentas e Ambiente de trabalho durante o curso\n",
    "    - Conceitos novos: acesso ao Jupyter AWS; Usando o Jupyter; Programando Python/Numpy\n",
    "    * NB:[*Acessando o Jupyter da AWS*]() Precisa ser feito\n",
    "    * NB:[*Python e Numpy*]() Precisa ser feito\n",
    "    \n",
    "\n",
    "### II - Introdução a redes neurais\n",
    "\n",
    "#### Regressão Linear\n",
    "- Conceitos novos:\n",
    "- Teoria: Otimização Mínimos Quadrados usando gradiente descendente\n",
    "- Prática: Programação matricial Y = XW + B; Laço de gradiente descendente; Plotando gráficos; visualizando animação da otimização na função custo e no ajuste reta\n",
    "    * NB: [*Regressão Linear*]() Precisa ser feito\n",
    "\n",
    "#### Regressão Logística\n",
    "- Conceitos novos:\n",
    "- Teoria: Classificação binária; mesmo modelo anterior de otimização, função Sigmóide\n",
    "- Prática: visualização animação otimização espaço de parâmetros e espaço de atributos\n",
    "    * NB: [*Regressão Logística*]() Precisa ser feito\n",
    "\n",
    "#### Regressão Logística multiclasse\n",
    "- Conceitos novos: \n",
    "- Teoria: Classificação multiclasse com Softmax; Custo entropia cruzada; one-hot-encoding; mesmo modelo anterior de otimização\n",
    "    * NB: [Regressão Logística Multiclasse Softmax - Iris 2D - Programação matricial](Regressao-Logistica-Softmax-Iris-2D-matricial.ipynb)\n",
    "\n",
    "#### Regressão Logística multiclasse, agora no Keras\n",
    "- Conceitos novos:\n",
    "- Prática: Introdução inicial do Keras, mostrando que executa o mesmo exemplo anterior; criando a rede, definindo otimizador\n",
    "    * NB: [Regressão Logística Multiclasse Softmax - Iris 2D - usando o Keras](Regressao-Logistica-Softmax-Iris-2D-Keras.ipynb)\n",
    "\n",
    "#### Regressão Logística multiclasse, dataset NMIST\n",
    "- Conceitos novos:\n",
    "- Prática: dataset NMIST, Visualização dos pesos na forma de template; não é possível mais visualizar espaço de atributos nem espaço de parâmetros. Visualiza-se a queda da função de perda\n",
    " * NB: [Regressão Logística Multiclasse Softmax - NMIST - Programação Matricial](Regressao-Logistica-Softmax-NMIST-matricial.ipynb)\n",
    "\n",
    "#### Regressão Logística multiclasse, dataset NMIST, agora no Keras\n",
    "- Conceitos novos:\n",
    "- Prática: extraindo os pesos aprendidos da rede no Keras\n",
    " * NB: [Regressão Logística Multiclasse Softmax - NMIST - usando o Keras](Regressao-Logistica-Softmax-NMIST-Keras.ipynb)\n",
    "\n",
    "#### Rede neural 2 camadas\n",
    "- Conceitos novos:\n",
    "- Teoria: concatenação de camadas com elemento não linear reLU; retropropagação;\n",
    "- Prática: Dificuldade de otimização, falta de atributos\n",
    " * NB: [Rede Neural 2 camadas com reLU - Iris - usando Keras](Duas-Camadas-Densas-reLU-Softmax-Iris-Keras.ipynb)\n",
    "\n",
    "#### Ilustrando overfitting e underfitting, regularização com exemplo de  ajuste de polinômio\n",
    "- Conceitos novos:\n",
    "- Teoria: Conceito de overfitting e underfitting, conceito de regularização, função de custo\n",
    "- Prática: Explorando parâmetros de ajustes e parâmetros de regularização\n",
    " * NB: [*Ajuste curvas: Overfitting - Underfitting*](../dev/2017-02-08-RMS-Polynomial-Curve-Fitting.ipynb)\n",
    " \n",
    "### III - Redes neurais profundas - redes convolucionais\n",
    "\n",
    "#### Convolução Keras/Theano\n",
    "- Conceitos novos:\n",
    "- Teoria: Convolução, processamento borda, zero-padding, dimensionalidade dos arrays\n",
    "- Prática: rede convolucional no Keras, variação de número de imagens, kernels e filtros de saída\n",
    " * NB: [Convolução](Explorando-Convolucao-no-Keras-usando-Theano.ipynb)\n",
    "\n",
    "#### Introdução ao Keras\n",
    "- Conceitos novos:\n",
    "- Prática: Keras, criando o modelo, colocando pesos, retirando pesos e retirando camadas\n",
    " * NB: [*Introdução ao Keras*](2017-02-10-OASL-CNN-Intro.ipynb)\n",
    "\n",
    "#### Otimizadores\n",
    "- Conceitos novos: \n",
    "- Teoria: Diversos otimizadores: SGD com momento, SGD com momento Nesterov, SGD com queda de fator de aprendizagem, RMSprop, Adadelta, Adam\n",
    "- Prática: Observação do desempenho de diversos otimizadores\n",
    " * NB: [*Otimizadores*](../dev/2017-01-30-RCM-Keras-optimizers.ipynb)\n",
    " \n",
    "#### Rede totalmente convolucional\n",
    "- Conceitos novos:\n",
    "- Teoria: Convertendo uma rede com camadas densas para totalmente convolucionais para otimizar varredura da imagem\n",
    "- Prática: Explorando o exemplo implementado\n",
    " * NB: [*Convertendo camadas densas para totalmente convolucionais*](../dev/2017-02-02-RCM-Keras-full-conv-01.ipynb)\n",
    " * NB: [*Aplicando rede totalmente convolucional*](../dev/2017-02-02-RCM-Keras-full-conv-02.ipynb)\n",
    " \n",
    "#### Aprendizado com pouco dados\n",
    "- Conceitos novos:\n",
    "- Teoria: Aprendizado com poucos dados\n",
    " * NB: [*Aprendizado com poucos dados*](../dev/2017-02-10-RCM-cats-and-dogs-1.ipynb)\n",
    " * NB: [*Aprendizado com poucos dados*](../dev/2017-02-10-RCM-cats-and-dogs-2.ipynb)\n",
    " * NB: [*Aprendizado com poucos dados*](../dev/2017-02-10-RCM-cats-and-dogs-3.ipynb)\n",
    " \n",
    "\n",
    "### IV - Aplicações\n",
    "\n",
    "#### Face spoofing\n",
    "\n",
    "#### Skull Stripping\n",
    " * NB: [*Skull Stripping 2D*](../dev/2017-02-10-OASL-CNN-Intro.ipynb)\n",
    "\n",
    "## Documentação\n",
    "\n",
    "- [Jupyter Notebook](http://jupyter-notebook.readthedocs.io/en/latest/notebook.html)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[NbConvertApp] Converting notebook RNPI-indice.ipynb to html\n",
      "[NbConvertApp] Writing 257899 bytes to RNPI-indice.html\n"
     ]
    }
   ],
   "source": [
    "!jupyter nbconvert RNPI-indice.ipynb"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python [Root]",
   "language": "python",
   "name": "Python [Root]"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
